No,Title,Abstract,Abstract_gpt4o,Abstract_llama3,Abstract_gemini,cola_gpt4o,cola_llama3,cola_gemini,stsb_gpt4o,stsb_llama3,stsb_gemini
1,Peer relationship increasing the risk of social media addiction among Chinese adolescents who have negative emotions,"Social media has expanded the scope and method of interpersonal communication, and presents the risk of social media addiction as well. This study reported the psychometrics of the Bergen Social Media Addiction Scale (BSMAS) and further analyzed the moderating role of peer relationship on the association between negative emotions and risk of social media addiction. A total of 1258 survey participants were asked to complete a set of scales online. Exploratory structural equation modeling enabled BSMAS to reveal a solid one-factor structure with satisfactory internal consistency coefficient. Criterion-related validity and variance explanation rate analysis implied a positive relationship between negative emotions and risk of social media addiction, and identified the significant contributions of negative emotions and peer relationship to the risk of social media addiction. Moderation analysis demonstrated that peer relationship positively moderated the effect of negative emotions on the risk of social media addiction. However, gender was not a moderator affecting negative emotions on the risk of social media addiction. BSMAS was a valid tool for measuring the risk of social media addiction among Chinese adolescents. Lastly, peer relationship is a positive moderator in influencing negative emotions and risk of social media addiction.","The reach and means of personal communication have been broadened by social media, which also brings the potential danger of social media addiction. This research detailed the psychometric properties of the Bergen Social Media Addiction Scale (BSMAS) and examined the moderating influence of peer relationships on the link between negative emotions and the likelihood of social media addiction. A total of 1258 individuals participated in an online survey, completing various scales. Through exploratory structural equation modeling, BSMAS was found to exhibit a robust one-factor structure with a reliable internal consistency coefficient. The analysis of criterion-related validity and explained variance suggested a positive correlation between negative emotions and the risk of social media addiction while noting the significant impact of negative emotions and peer relationships. Moderation analysis revealed that peer relationships enhanced the effect of negative emotions on the risk of social media addiction, whereas gender did not serve as a moderator. The BSMAS proved to be a valid measure for assessing the risk of social media addiction in Chinese adolescents. Ultimately, peer relationships were identified as a beneficial moderator in the context of negative emotions and social media addiction risk.","The proliferation of social media has revolutionized the dynamics of interpersonal interaction, but concurrently, it poses the threat of excessive usage. This investigation examined the psychometric properties of the Bergen Social Media Addiction Scale and probed the mediating influence of peer relationships on the link between adverse emotional states and the propensity for social media addiction. A total of 1258 online survey respondents completed a battery of scales, which were subsequently analyzed using exploratory structural equation modeling. The results revealed a robust one-factor structure for the BSMAS, accompanied by satisfactory internal consistency. Furthermore, the analysis demonstrated a positive correlation between negative emotions and the risk of social media addiction, with both negative emotions and peer relationships emerging as significant predictors of this risk. Notably, peer relationships were found to exert a positive moderating effect on the relationship between negative emotions and social media addiction, whereas gender did not exhibit a moderating influence. The BSMAS was thus validated as a reliable instrument for assessing social media addiction among Chinese adolescents, with peer relationships playing a crucial role in mitigating the impact of negative emotions on social media addiction.","The pervasiveness of social media, while revolutionizing interpersonal communication, brings with it the potential for addiction. This research examined the psychometric properties of the Bergen Social Media Addiction Scale (BSMAS) among 1258 Chinese adolescents, and investigated the influence of peer relationships on the link between negative emotions and the likelihood of social media addiction. Structural equation modeling confirmed the robust one-factor structure of the BSMAS, demonstrating its reliability. Further analysis revealed a strong correlation between negative emotions and social media addiction risk, highlighting the significant role of both factors. Importantly, peer relationships were found to positively moderate the impact of negative emotions on addiction risk, signifying their protective influence. Conversely, gender did not demonstrate a moderating effect. The study validates the BSMAS as an effective instrument for assessing social media addiction risk in this population and underscores the importance of positive peer relationships in mitigating the detrimental effects of negative emotions on this risk.",acceptable,acceptable,acceptable,3.2,3.2,3.2
2,A novel machine learning and face recognition technique for fake accounts detection system on cyber social networks,"Online Social Networks (OSN) such as Facebook, Instagram, Twitter, and others have seen rapid growth in recent years. Such applications provide attractive online social networks and communications with the opportunity to connect with relatives and acquaintances, meet new people, enter communities, talk, exchange photos, organize events, and network with others who are close to real-life; unfortunately, on the other hand, they also raise privacy and security issues. We identified OSN threats in this paper and recommended a digital face-processing authentication method as a double-factor authentication after entering the password using Matlab. After applying deep learning classification by attending to a real dataset from the live webcam to train the model, we achieved the best accuracy rate of 95%. However, such methods have yet to be deployed to all social networks, so we also mentioned the problem of fake accounts, which is one of the most significant problems in OSN. These are effective tools for executing spam campaigns and spreading malware and phishing attacks. Fake accounts could lead to the loss of money for businesses, loss of reputation, stealing information for malicious purposes, and much more. This study is related to detecting fake and legitimate profiles on OSN. For this purpose, we chose two datasets that contain fake and legitimate accounts on Facebook and Instagram. Each contains different features after applying machine learning using Naive Bayes, Logistic Regression, Support Vector Machines, K-Nearest Neighbour, Boosted Tree, Neural Networks, SVM Kernal, and Logistec Regression Kernal. SVM achieved the highest classification accuracy for the Fake Profiles detection datasets with 97.1%.","Online Social Networks (OSNs) like Facebook, Instagram, Twitter, and others have experienced swift expansion in recent times. These platforms offer engaging online social frameworks, allowing users to interact with family and friends, meet new individuals, join groups, chat, share images, plan events, and connect with peers similarly to real-life interactions. However, they also pose privacy and security concerns. In this paper, we identified threats within OSNs and suggested a digital face-processing authentication approach as a two-factor authentication method following password entry using Matlab. Utilizing deep learning classification with data gathered from a live webcam for model training, we achieved an optimal accuracy rate of 95%. Despite this, such techniques have yet to be widely adopted across all social networks. Hence, we also addressed the issue of fake accounts, a major challenge in OSNs. These accounts are potent tools for launching spam campaigns and disseminating malware and phishing schemes. Fake profiles can result in financial losses for companies, reputational damage, information theft for malicious activities, and more. This research focuses on distinguishing fake and authentic profiles within OSNs. We analyzed two datasets containing fake and real accounts on Facebook and Instagram, each with distinct attributes. After applying machine learning algorithms such as Naive Bayes, Logistic Regression, Support Vector Machines, K-Nearest Neighbor, Boosted Tree, Neural Networks, SVM Kernel, and Logistic Regression Kernel, the SVM classifier yielded the highest accuracy in detecting fake profiles, with a rate of 97.1%.","The proliferation of Online Social Networks (OSNs) like Facebook, Instagram, Twitter, and others has been remarkable in recent years, offering users a platform to reconnect with family and friends, expand their social circles, and engage in various online activities. While these platforms provide a multitude of benefits, they also pose significant concerns regarding privacy and security. This paper identifies the threats associated with OSNs and proposes a novel digital face-processing authentication method, which involves a two-factor verification process utilizing Matlab. By leveraging deep learning classification and training the model with a real dataset from a live webcam, we achieved an impressive accuracy rate of 95%. However, the widespread adoption of such methods across all social networks remains a challenge, particularly in light of the pervasive issue of fake accounts, which are often exploited to launch spam campaigns, spread malware, and execute phishing attacks. These fraudulent accounts can result in substantial financial losses, reputational damage, and unauthorized access to sensitive information. This study focuses on distinguishing between genuine and fake profiles on OSNs, utilizing two datasets from Facebook and Instagram that comprise diverse features. By applying machine learning algorithms, including Naive Bayes, Logistic Regression, and Support Vector Machines, among others, we found that SVM achieved the highest classification accuracy of 97.1% in detecting fake profiles.","The explosive rise of Online Social Networks (OSNs) like Facebook, Instagram, and Twitter has brought both benefits and risks. While these platforms offer unparalleled opportunities for connection and communication, they also raise concerns regarding privacy and security. This paper explores the threats inherent in OSNs and proposes a dual-factor authentication method using digital face processing alongside password entry. Implemented in Matlab, this approach achieved a 95% accuracy rate after training a deep learning model with real-time webcam data. However, the pervasive issue of fake accounts persists across social networks, posing significant challenges. These fabricated profiles serve as potent instruments for spreading spam, malware, and phishing attacks, leading to financial losses, reputational damage, information theft, and other serious consequences. This research focuses on distinguishing fake from legitimate profiles on Facebook and Instagram using two distinct datasets. By applying machine learning algorithms like Naive Bayes, Logistic Regression, Support Vector Machines, K-Nearest Neighbors, Boosted Trees, Neural Networks, and kernel-based SVM and Logistic Regression, we analyzed various features associated with these profiles. Notably, SVM achieved the highest accuracy (97.1%) in classifying fake profiles.",acceptable,acceptable,acceptable,3.2,3.2,3.2
3,Linking health impact and Post-environmental impact assessments: a case of municipal sewage treatment plant volatile organic compounds,"Deficiencies remain in current health impact assessment (HIA) and environmental impact assessment (EIA) projects. To address the shortcomings in EIA theory, a case of odors from a municipal sewage treatment plant (MSTP) was examined and geographic factors were employed to associate the spatial diffusion of the pollutants with the population’s activities based on land-use attributes. After screening the MSTP priority control pollutants, odors, hydrogen sulfide, and ammonia were selected for this study. Then, the spatial parameters for the pollutant simulation were surveyed, including parameters concerning the meteorological analysis, environmental emission monitoring, and emission source analysis, and a prediction of the pollutant diffusion as imaged and identified. The types of human social activity and exposure patterns were sorted as land-use attributes. An integration of the spatial diffusion of the pollutants with the exposure profiles of the scenario population according to the land-use attributes was achieved using counterpart spatial coordination factors. In our study, the commonly applied method of HIA risk calculation was followed and then extended by the spatial techniques introduced. The results of the scenario HIA contours are presented here, making it easy to determine the acceptable levels of the MSTP odor pollutants on a geographic scale. This study examines a significant approach to associate HIA with post-EIA via spatial factors and addresses the deficiencies of HIA in EIA empirical applications.","Current health impact assessments (HIA) and environmental impact assessments (EIA) have notable deficiencies. To address gaps in EIA theory, a case study on odors from a municipal sewage treatment plant (MSTP) was conducted, using geographic factors to link the spatial spread of pollutants with population activities classified by land-use characteristics. After identifying priority pollutants from the MSTP, odors, hydrogen sulfide, and ammonia were chosen for study. Spatial parameters for pollutant modeling, including meteorological analysis, environmental emission monitoring, and emission source analysis, were then collected, and pollutant diffusion was predicted. Human activity types and exposure patterns were organized by land-use attributes. The spatial diffusion of pollutants was integrated with the exposure profiles of the local population using corresponding spatial coordination factors. The typical HIA risk calculation method was applied and expanded with spatial techniques in our study. The resulting HIA contour maps for the scenario are presented, highlighting the acceptable levels of odor pollutants from the MSTP in relation to geography. This study explores a significant method for linking HIA with post-EIA through spatial factors and addresses the shortcomings of HIA in empirical EIA applications.","""Despite ongoing limitations in health impact assessments (HIAs) and environmental impact assessments (EIAs), a novel approach was developed to bridge the theoretical gaps in EIA by investigating the case of a municipal sewage treatment plant's (MSTP) odor emissions. By leveraging geographic factors, the study correlated the spatial dispersion of pollutants with human activities based on land-use characteristics. Following a thorough screening of priority pollutants, odors, hydrogen sulfide, and ammonia were identified as key targets. Subsequently, spatial parameters were surveyed, encompassing meteorological analysis, environmental emission monitoring, and emission source analysis, to predict pollutant diffusion patterns. Land-use attributes were categorized to reflect various human social activities and exposure patterns. By integrating pollutant dispersion with exposure profiles using spatial coordination factors, the study successfully linked the spatial distribution of pollutants with the scenario population's activities. Building upon conventional HIA risk calculation methods, this research introduced spatial techniques to enhance the approach. The resulting HIA contour maps provide a geographic framework for determining acceptable levels of MSTP odor pollutants, thereby addressing the shortcomings of HIA in EIA applications and offering a significant step towards integrating HIA with post-EIA via spatial factors.""","Existing health and environmental impact assessments still exhibit limitations. To tackle these shortcomings, a case study investigating odors emanating from a municipal sewage treatment plant was conducted. Geographic information was leveraged to link the spread of pollutants with population activities, classified by land use. Odors, hydrogen sulfide, and ammonia were chosen as the focus pollutants after a screening process. Subsequently, data collection for pollutant simulation encompassed meteorological analysis, environmental monitoring, and emission source analysis, leading to a visual representation of predicted pollutant dispersion. Human activities and exposure patterns were categorized by land-use attributes. By utilizing spatial coordination factors, the spatial distribution of pollutants was integrated with the predicted exposure profiles of the population based on their land use. A conventional health impact assessment (HIA) risk calculation method was employed and enhanced through the integration of spatial techniques. The resulting scenario HIA contours allow for the easy identification of acceptable odor pollutant levels on a geographic scale. This research presents a novel approach to connect HIA with post-environmental impact assessment using spatial factors, effectively addressing limitations of HIA in real-world applications.",acceptable,acceptable,acceptable,3.6,3.2,3.2
4,"Blockchain-enabled supply chain: analysis, challenges, and future directions","Managing the integrity of products and processes in a multi-stakeholder supply chain environment is a significant challenge. Many current solutions suffer from data fragmentation, lack of reliable provenance, and diverse protocol regulations across multiple distributions and processes. Amongst other solutions, Blockchain has emerged as a leading technology, since it provides secure traceability and control, immutability, and trust creation among stakeholders in a low cost IT solution. Although Blockchain is making a significant impact in many areas, there are many impediments to its widespread adoption in supply chains. This article is the first survey of its kind, with detailed analysis of the challenges and future directions in Blockchain-enabled supply chains. We review the existing digitalization of the supply chain including the role of GS1 standards and technologies. Current use cases and startups in the field of Blockchain-enabled supply chains are reviewed and presented in tabulated form. Technical and non-technical challenges in the adoption of Blockchain for supply chain applications are critically analyzed, along with the suitability of various consensus algorithms for applications in the supply chain. The tools and technologies in the Blockchain ecosystem are depicted and analyzed. Some key areas as future research directions are also identified which must be addressed to realize mass adoption of Blockchain-based in supply chain traceability. Finally, we propose MOHBSChain, a novel framework for Blockchain-enabled supply chains.","Ensuring the integrity of products and processes within a multi-participant supply chain environment presents considerable difficulties. A number of current approaches are hindered by fragmented data, unreliable provenance, and varying protocol regulations across different distributions and procedures. Notably, Blockchain has surfaced as a dominant technology, offering secure traceability, stringent immutability, and trust-building among stakeholders at a low IT cost. Despite Blockchain's broad impact across various sectors, numerous obstacles hinder its extensive adoption in supply chains. This article represents the first survey of its kind, providing a comprehensive analysis of the hurdles and future prospects for Blockchain-enabled supply chains. It examines the current state of supply chain digitalization, including the contribution of GS1 standards and technologies. Existing use cases and startups in the Blockchain-enabled supply chain arena are reviewed and cataloged. Both technical and non-technical challenges in deploying Blockchain in supply chains are scrutinized, along with the appropriateness of various consensus algorithms for these applications. The tools and technologies within the Blockchain ecosystem are showcased and assessed. Additionally, key areas for future research necessary for the widespread adoption of Blockchain-based supply chain traceability are pinpointed. Ultimately, we introduce MOHBSChain, an innovative framework for Blockchain-enabled supply chains.","""Ensuring the authenticity and consistency of products and processes across complex, multi-party supply chain networks poses a substantial hurdle. Existing solutions often struggle with dispersed data, unreliable origin tracking, and disparate regulatory requirements spanning multiple channels and processes. Amidst various alternatives, Blockchain technology has emerged as a frontrunner, offering secure, tamper-proof tracking, and fostering trust among stakeholders at a relatively low IT cost. Despite its significant influence in numerous domains, Blockchain's widespread adoption in supply chains faces several obstacles. This comprehensive survey provides an in-depth examination of the challenges and future trajectories in Blockchain-integrated supply chains, including a review of the current digital landscape, GS1 standards, and technologies. We present a detailed analysis of existing use cases, startups, and technical and non-technical barriers to Blockchain adoption, as well as the suitability of various consensus algorithms for supply chain applications. The Blockchain ecosystem's tools and technologies are also mapped and analyzed. Furthermore, we identify key areas for future research to facilitate the large-scale adoption of Blockchain-based supply chain traceability, culminating in the proposal of MOHBSChain, a novel framework for Blockchain-enabled supply chains.""","Maintaining the reliability and quality of goods and procedures within a complex supply chain involving numerous participants poses a considerable hurdle. Existing approaches often grapple with issues like data inconsistency, uncertain origins, and varying regulatory protocols across different distribution and operational stages. Blockchain technology has emerged as a frontrunner, offering secure tracking and oversight, tamper-proof records, and enhanced trust among stakeholders through a cost-effective IT framework. Despite its growing influence, widespread integration of Blockchain within supply chains faces various obstacles. This comprehensive survey delves into the challenges and future prospects of Blockchain-driven supply chains, analyzing existing digital supply chain practices, including the significance of GS1 standards. It examines real-world implementations and emerging companies in Blockchain-powered supply chains, presenting them in a structured format. The study critically assesses both technical and non-technical barriers to Blockchain adoption, evaluating the appropriateness of diverse consensus mechanisms for supply chain applications. It further explores the tools and technologies within the Blockchain ecosystem, highlighting key research areas that demand attention for achieving mainstream adoption of Blockchain in supply chain transparency. Lastly, the paper introduces MOHBSChain, a groundbreaking framework designed for Blockchain-enabled supply chains.",acceptable,acceptable,acceptable,3.6,3.2,3.2
5,Exploring Temporal Analytics in Fog-Cloud Architecture for Smart Office HealthCare,"Ever since the boost realized in Information and Communication Technology (ICT), market is flooded with high-end multi-tasking devices, presenting a real-time computational environment for technologies like Internet of Things (IoT). With computation at user-end, it provides a fog-based computing paradigm to generate time senstive results, which along with cloud storage presents a comprehensive Fog-Cloud computing paradigm. Because of these reasons, the work presented in this paper focuses on utilizing the potential of IoT Technology to provide a novel Fog-Cloud architecture for efficient healthcare services in smart office. Specifically, a Fog-Cloud architecture has been proposed to monitor and analyze various health attributes of a person during his working hours. Moreover, the framework indulges various activities in the ambient office environment with the purpose of analyzing it for health severity. In order to realize this, a probabilistic measure, named as Severity Index (SI) is defined to evaluate the adverse effects of different activities on personal health. Finally, an application scenario of temporal healthcare predictive monitoring and alert generation is discussed to depict the ideology of Smart Office Healthcare. In order to validate the system, an experimental implmentation is performed on heterogenous datasets. The results obtained in comparison to state-of-the-art techniques show that the proposed model is highly efficient and accurate for providing appropriate healthcare environment during working hours of a person in a smart office.","Since the advancements in Information and Communication Technology (ICT), the market has been inundated with high-end multi-tasking devices, creating a real-time computational environment for technologies such as the Internet of Things (IoT). By enabling user-end computation, this fosters a fog-based computing paradigm that generates time-sensitive results, which, coupled with cloud storage, forms a comprehensive Fog-Cloud computing framework. Therefore, this paper focuses on leveraging IoT technology to introduce an innovative Fog-Cloud architecture aimed at delivering efficient healthcare services within a smart office. Specifically, a Fog-Cloud framework has been developed to monitor and analyze various health metrics of individuals during their working hours. Additionally, the system incorporates various activities in the office environment to assess their impact on health severity. To achieve this, a probabilistic measure called the Severity Index (SI) is defined to evaluate the negative effects of different activities on personal health. Finally, a use case scenario of temporal healthcare predictive monitoring and alert generation is discussed to illustrate the concept of Smart Office Healthcare. To validate the system, an experimental implementation is conducted on heterogeneous datasets, and the results, when compared with state-of-the-art techniques, demonstrate that the proposed model is highly efficient and accurate in providing a suitable healthcare environment during office hours in a smart office.","""Following the significant advancements in Information and Communication Technology (ICT), the market has been inundated with sophisticated, multi-functional devices, thereby creating a dynamic, real-time computational ecosystem conducive to the proliferation of innovative technologies such as the Internet of Things (IoT). By harnessing the power of edge computing, these devices enable the generation of time-critical results, which, when combined with cloud storage, form a comprehensive Fog-Cloud computing framework. This paper capitalizes on the potential of IoT technology to design a novel, efficient Fog-Cloud architecture tailored to provide high-quality healthcare services in intelligent office environments. Specifically, a proposed Fog-Cloud framework is designed to monitor and analyze various physiological parameters of individuals during their working hours, while also integrating ambient office activities to assess their impact on health. A probabilistic metric, dubbed the Severity Index (SI), is introduced to quantify the adverse effects of different activities on personal health. The paper also explores a scenario involving temporal healthcare predictive monitoring and alert generation, exemplifying the concept of Smart Office Healthcare. To validate the system, an experimental implementation is conducted on diverse datasets, yielding results that surpass those of existing techniques, thereby demonstrating the proposed model's exceptional efficiency and accuracy in creating an optimal healthcare environment during working hours in intelligent offices.""","The rapid evolution of Information and Communication Technology (ICT) has led to an abundance of sophisticated, multi-functional devices, fostering a real-time computational landscape that enables technologies like the Internet of Things (IoT). This user-end computational power facilitates a fog-based computing model for generating time-sensitive data, which, when combined with cloud storage, forms a comprehensive Fog-Cloud computing paradigm. This paper leverages the capabilities of IoT technology to propose a novel Fog-Cloud architecture aimed at delivering efficient healthcare services within a smart office environment. The proposed architecture focuses on monitoring and examining various health indicators of individuals during their work hours. Additionally, the framework incorporates diverse activities occurring within the office environment to assess their potential impact on health. To achieve this, a probabilistic measure, termed the Severity Index (SI), is introduced to quantify the negative effects of different activities on individual well-being. A practical application scenario involving temporal healthcare prediction and alert generation is then presented to illustrate the concept of Smart Office Healthcare. The system's efficacy is validated through an experimental implementation using diverse datasets. The results, benchmarked against established techniques, demonstrate the proposed model's superior efficiency and accuracy in providing a suitable healthcare environment during working hours within a smart office.",acceptable,acceptable,acceptable,3.6,3.2,3.2
6,Virtual team training with Mixed Reality and Virtual Reality – benefits and limitations illustrated on the example of two paramedic classes,"In the field of medical case simulations, strong technologization has been observed for years, for example through Extended Reality. This study examined the impact of Virtual and Mixed Reality (VR, resp. MR) on the team training of paramedic trainees. In the quasi-experimental cross-sectional controlled comparison study, participants were assigned to an experimental group (= EG, mixed reality with manikin) and a comparison group (= CG, virtual reality without manikin). After a virtual case simulation, “VR sickness”, sense of presence, motivation, and sociodemographic variables were elicited. Parametric tests were used for mean comparison and correlation analysis. A total of 20 participants were evaluated in the EG and 16 in the CG. In both groups, high intrinsic motivation (mean 5.32/7), an acceptable sense of spatial presence (mean 4.24/6), and advanced usability (mean 68.54/100), were observed. VR sickness symptoms were present (SSQ total score: 11.43). In both groups, correlation was found between Identified Regulation and Usability (EG: r = .74, p < .001, CG: r = .76, p < .001). The same pattern could be observed for Intrinsic Motivation and Usability (EG: r = .83, p < .001, CG: r = .70, p = .003). Spatial Presence and Usability were also correlated in both groups (EG: r = .71, p < .001, CG: r = .61, p = .01). A significant mean score difference (p = .021) was found for Amotivation between the EG (Mean = 1.92/6) and the CG (Mean = 1.56/6). VR and MR are potential learning methods if they are implemented in a planned manner by competent faculty. Our recommendation is to use setup checklists, but also a competence-oriented approach, considering fiction contract and structured debriefing. The use of wireless head-mounted displays and ""data gloves"" is also recommended.","The domain of medical case simulations has witnessed significant technological advancements over the years, particularly with the integration of Extended Reality. This research investigated how Virtual Reality (VR) and Mixed Reality (MR) influence team training for paramedic learners. The study adopted a quasi-experimental, cross-sectional, controlled comparison methodology, categorizing participants into an experimental group (EG) using mixed reality with a manikin, and a control group (CG) utilizing virtual reality without a manikin. Post-simulation, participants were assessed on ""VR sickness,"" presence, motivation, and demographic variables. Analysis through parametric tests was used to compare mean scores and identify correlations. Twenty participants were evaluated in the EG and sixteen in the CG. Findings demonstrated high intrinsic motivation (mean 5.32/7), acceptable spatial presence (mean 4.24/6), and good usability (mean 68.54/100) in both groups, despite reports of VR sickness (SSQ total score: 11.43). Positive correlations were seen between identified regulation and usability (EG: r = .74, p < .001; CG: r = .76, p < .001), intrinsic motivation and usability (EG: r = .83, p < .001; CG: r = .70, p = .003), and spatial presence and usability (EG: r = .71, p < .001; CG: r = .61, p = .01) across both groups. There was a notable mean score difference in amotivation between the EG (mean 1.92/6) and CG (mean 1.56/6, p = .021). VR and MR can be effective learning tools when thoughtfully implemented by knowledgeable instructors. We recommend the use of preparation checklists, a competence-focused approach, recognition of implicit agreements, structured debriefing, wireless head-mounted displays, and ""data gloves.""","In the realm of medical simulation training, a pronounced trend towards technological advancement has been evident for some time, exemplified by the integration of Extended Reality. This investigation explored the effects of Virtual and Mixed Reality (VR and MR, respectively) on the collaborative training of paramedic students. A quasi-experimental, cross-sectional, controlled study was conducted, wherein participants were divided into an experimental cohort (EC), utilizing MR with a manikin, and a control group (CG), employing VR without a manikin. Following a virtual simulation exercise, the incidence of ""VR sickness,"" sense of immersion, motivational levels, and demographic characteristics were assessed. Parametric statistical analyses were employed to compare means and examine correlations. The study evaluated 20 participants in the EC and 16 in the CG. Notably, both groups exhibited high levels of intrinsic motivation (mean score: 5.32/7), a satisfactory sense of spatial immersion (mean score: 4.24/6), and advanced usability (mean score: 68.54/100). Symptoms of VR sickness were present, with a total SSQ score of 11.43. Correlations were observed between identified regulation and usability, intrinsic motivation and usability, as well as spatial presence and usability in both groups. A significant difference in mean scores was found for amotivation between the EC (mean score: 1.92/6) and the CG (mean score: 1.56/6). The strategic implementation of VR and MR by competent instructors holds promise as a learning methodology. Recommendations include the use of setup checklists, a competence-oriented approach incorporating fiction contracts and structured debriefing, as well as the integration of wireless head-mounted displays and ""data gloves.""","The increasing integration of technology, notably Extended Reality, in medical simulation training has spurred investigations into its effectiveness. This study explored the influence of Virtual and Mixed Reality (VR/MR) on paramedic team training using a quasi-experimental design. Participants, divided into an MR group using manikins and a VR group without, completed a virtual case simulation. Assessments included VR sickness, sense of presence, motivation, and sociodemographic factors. Both groups exhibited high intrinsic motivation, moderate spatial presence, and good usability, but experienced VR sickness symptoms. Significant correlations emerged between self-regulation, intrinsic motivation, spatial presence, and usability within each group. Notably, the MR group showed lower amotivation levels. This suggests that VR/MR can be valuable learning tools when thoughtfully implemented by skilled instructors, emphasizing setup protocols, competency-based approaches, acknowledging the simulation context, and incorporating structured debriefings. The study also recommends the use of wireless VR headsets and haptic gloves.",acceptable,acceptable,acceptable,3.2,3.2,3.2
7,Virtual reality and gamification in education: a systematic review,"This study aims to analyze the use of virtual reality and gamification in education by examining the existing literature. In addition to virtual reality, this study focuses on gamified virtual reality learning environments which refer to virtual reality learning environments that integrate gamification elements and mechanisms. Based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement, a systematic literature review was carried out. No limitations were set regarding educational level, type of study, subject, and publication year. The related articles were retrieved from 5 databases (ERIC, Google Scholar, IEEE, SCOPUS, and Web of Science). A total of 112 articles were included, 16 research questions were explored, and a thematic analysis was conducted. To evaluate the quality of the articles included, the Mixed Methods Appraisal Tool (MMAT) was used. According to the findings, gamification and virtual reality support several pedagogical theories and approaches. Their adoption to and integration into education can enrich and transform traditional teaching and learning and were assessed positively by students and teachers. Gamification elements significantly affected students’ achievements. In comparison to traditional learning environments, gamified virtual reality learning environments were more motivating, engaging, and interactive and offered more opportunities for personalized and collaborative learning. Through the realistic and interactive experiences offered, students’ immersion and social presence can be enhanced, knowledge acquisition can be improved, and material comprehension can be facilitated. Positive changes in student attitude, behavior, and mentality as well as improved cognitive, physical, and social–emotional development were observed. When using learning environments that integrate both virtual reality and gamification, students’ learning outcomes, motivation, engagement, and self-efficacy were increased. Additionally, students’ academic performance, active involvement, and satisfaction were improved. Students’ curiosity, imagination, focus, and interest were enhanced and their skills and competences were developed. Finally, gamified virtual reality emerged as an effective educational tool that can improve learning at all educational levels, subjects, and contexts.","This research seeks to evaluate the application of virtual reality and gamification in education through a comprehensive review of current literature. Beyond examining virtual reality, the focus extends to gamified virtual reality educational environments, which incorporate gamification features into VR settings. Utilizing the PRISMA guidelines, a systematic literature review was performed with no restrictions on educational level, study type, subject matter, or publication date. Relevant articles were sourced from five databases: ERIC, Google Scholar, IEEE, SCOPUS, and Web of Science. A total of 112 articles were selected, from which 16 research questions were investigated, and thematic analysis was executed. The Mixed Methods Appraisal Tool (MMAT) was employed to assess the quality of the included studies. The findings indicate that both gamification and virtual reality align with several educational theories and methodologies. Their integration into education can enhance and transform conventional teaching and learning approaches, receiving positive feedback from both students and educators. Gamification elements notably impacted students’ performance. Compared to traditional educational environments, gamified virtual reality settings were more motivating, engaging, and interactive, offering greater opportunities for personalized and collaborative learning. The realistic and engaging experiences provided served to enhance students’ immersion and social presence, improve knowledge acquisition, and aid in material comprehension. Observations showed positive shifts in student attitudes, behaviors, and mindsets, along with improvements in cognitive, physical, and social-emotional development. These integrated learning environments bolstered students’ learning outcomes, motivation, engagement, and self-efficacy. Additionally, increases in academic performance, active participation, and satisfaction were noted. The integration also fostered growth in students’ curiosity, imagination, focus, and interests, along with the development of their skills and competencies. Ultimately, gamified virtual reality proved to be an effective educational tool that can enhance learning across various educational levels, subjects, and contexts.","This research endeavors to investigate the application of immersive virtual reality and engaging gamification strategies in educational settings through a comprehensive examination of existing research literature. Specifically, it delves into the realm of gamified virtual reality learning platforms, which seamlessly integrate game design elements and mechanics into virtual reality environments. Guided by the rigorous methodology outlined in the PRISMA statement, a systematic review of the literature was conducted without imposing any constraints on educational level, study type, subject area, or publication date. A total of 112 relevant articles were retrieved from five prominent databases, yielding 16 research questions and a thematic analysis. The quality of the included studies was assessed using the MMAT tool. The findings suggest that the synergistic combination of gamification and virtual reality aligns with various pedagogical theories and approaches, holding the potential to revitalize and transform traditional teaching and learning practices. Both students and educators responded positively to the adoption of these innovative tools. Notably, gamification elements had a significant impact on student achievement. In contrast to conventional learning environments, gamified virtual reality platforms were found to be more stimulating, interactive, and engaging, offering enhanced opportunities for personalized and collaborative learning. By providing realistic and interactive experiences, these platforms can foster increased student immersion, social presence, and knowledge acquisition, while facilitating material comprehension. Furthermore, the integration of gamification and virtual reality was observed to positively influence student attitudes, behaviors, and mentalities, as well as cognitive, physical, and socio-emotional development. The use of these innovative learning environments was found to boost student learning outcomes, motivation, engagement, and self-efficacy, while improving academic performance, active participation, and satisfaction. Additionally, students' curiosity, imagination, focus, and interest were enhanced, and their skills and competencies were developed. Ultimately, gamified virtual reality emerged as a potent educational tool capable of enhancing learning across diverse educational levels, subjects, and contexts.","This research investigates the application of virtual reality and gamification in educational settings through a comprehensive review of existing research. Specifically, the study examines virtual reality learning environments enriched with gamification elements. Employing the PRISMA guidelines, a systematic literature review was conducted, encompassing publications from five prominent databases without constraints on educational level, study type, subject matter, or publication date. A total of 112 articles were analyzed to address 16 research questions through a thematic analysis approach. The quality of the included articles was rigorously evaluated using the MMAT tool. The results highlight that both gamification and virtual reality align with various pedagogical theories and practices. Integrating these technologies into education holds the potential to enhance and revolutionize traditional teaching and learning, garnering positive feedback from both students and educators. Notably, gamification elements were found to have a significant impact on student achievement. Compared to conventional learning environments, gamified virtual reality environments fostered higher levels of motivation, engagement, and interactivity, while also providing greater opportunities for personalized and collaborative learning. The immersive and interactive experiences facilitated by these environments led to enhanced student immersion, social presence, knowledge acquisition, and material comprehension. Positive shifts in student attitudes, behaviors, and mindsets were observed, accompanied by improvements in cognitive, physical, and socio-emotional development. Learning environments incorporating both virtual reality and gamification demonstrated a positive influence on student learning outcomes, motivation, engagement, and self-efficacy. Furthermore, they resulted in improvements in academic performance, active participation, and overall satisfaction. Students exhibited increased curiosity, imagination, focus, and interest, while also developing valuable skills and competencies. The study concludes that gamified virtual reality serves as a powerful educational tool capable of enhancing learning across all levels of education, subjects, and contexts.",acceptable,acceptable,acceptable,3.6,3.6,3.2
8,Wordsphere: virtual reality text input interface,"In recent years, virtual reality has moved from a fantasy or science fiction theme to a reality increasingly closer to our homes and computers. As is the case of various technological advances, from military and scientific use to casual and routine use, which are increasingly adapted to day-to-day use cases, as is observed with the announcement of a new fashionable term, the metaverse. In the same way, this possibility today in the sight of innovators, entrepreneurs, merchants, and businesspeople, among others, begins to generate applications that show benefits in different branches such as education, medicine, psychology, human resources, real estate, tourism. The detail is that within the innovation, very little is being done for an improvement in text input, which generates a stagnation for continuing with a method of capturing text, even already known with lack of intuition and not optimal, such as the provided by the QWERTY keyboard. This article presents a proposal for a new text input method, a three-dimensional (3D) text input prototype focused on immersion in virtual reality, Wordsphere, which takes advantage of the need for technological adoption for novice users in virtual reality and, in turn, leaves on the table future lines of work and research.","In recent times, virtual reality has transitioned from being a mere fantasy or science fiction concept to a tangible reality that is increasingly integrated into our homes and computers. Like many other technological advancements that shift from military and scientific origins to everyday casual uses, virtual reality is becoming a part of our daily lives, especially with the emergence of the trendy term, the metaverse. Innovators, entrepreneurs, merchants, and business professionals are now exploring applications that demonstrate benefits across various fields such as education, healthcare, psychology, human resources, real estate, and tourism. However, despite this wave of innovation, there is a significant lack of progress in improving text input methods, which remain stagnant due to the continued use of the outdated and unintuitive QWERTY keyboard. This article introduces a novel text input method, a three-dimensional (3D) text input prototype called Wordsphere, designed to enhance immersion in virtual reality. Wordsphere aims to address the need for technological adaptation among virtual reality novices and lays the groundwork for future research and development in this area.","Over the past few years, virtual reality has transitioned from a fictional concept to a tangible presence in our daily lives, mirroring the trajectory of other technological breakthroughs that have evolved from specialized military and scientific applications to mainstream, everyday uses. The metaverse, a trendy buzzword, has captured the attention of innovators, entrepreneurs, and business leaders, who are now developing a wide range of applications that demonstrate benefits across various sectors, including education, healthcare, psychology, human resources, real estate, and tourism. However, amidst this innovation, there has been a notable lack of progress in improving text input methods, resulting in the continued reliance on outdated and inefficient systems, such as the QWERTY keyboard. This article proposes a novel solution: Wordsphere, a 3D text input prototype designed for immersive virtual reality experiences, which leverages the need for user-friendly technology in VR and opens up avenues for future research and development.","Once a figment of imagination and science fiction, virtual reality (VR) has rapidly infiltrated our personal spaces, becoming increasingly integrated with our computers and daily lives. This trajectory mirrors numerous technological advancements that have transitioned from specialized fields like military and scientific research to commonplace applications seamlessly woven into our routines. The emergence of the ""metaverse"" exemplifies this trend. Similarly, innovators, entrepreneurs, and various professionals are exploring VR's potential, creating applications that benefit sectors like education, healthcare, psychology, human resources, real estate, and tourism. However, despite this burgeoning innovation, text input methods remain largely stagnant, relying on outdated and inefficient systems like the QWERTY keyboard. This lack of progress hinders the seamless integration of text in VR environments. This article proposes a novel solution: Wordsphere, a three-dimensional (3D) text input prototype designed for immersive VR experiences. Wordsphere capitalizes on the demand for user-friendly VR technologies and paves the way for future research and development in this field.",acceptable,acceptable,acceptable,3.2,3.2,3.2
9,Effectiveness of Virtual Reality in Improving Oral Health,"The traditional methods of educating the population to empower them and improve their daily lifestyle as well as their general health and their health literacy, has changed over the years. The current generation is technologically oriented; therefore use of technology to gain their interest is paramount in health education. The aim of this study is to assess the effectiveness of using a virtual reality tool compared to a traditional method of dental education among school children aged 10-18 years old in Riyadh, Saudi Arabia. A longitudinal phase of assessment for student’s daily dental hygiene was assessed using a mixed method. There was a statistically significant improvement in plaque index score (p=.000), plaque percentage (p=.000), and brushing score (p=.000), when comparing education using Virtual Reality vs traditional method. Conclusion: Use of virtual reality education is more effective in improving the oral health status of children compared to the traditional educational method.","Over the years, traditional approaches to educating the populace to enhance their daily lives, overall health, and health literacy have evolved. With the current generation being technologically inclined, it is crucial to leverage technology to captivate their interest in health education. This study aims to evaluate the effectiveness of a virtual reality tool versus traditional dental education methods among school children aged 10-18 in Riyadh, Saudi Arabia. Students' daily dental hygiene was monitored over a longitudinal phase using a mixed-method approach. Results showed a statistically significant enhancement in plaque index score (p=.000), plaque percentage (p=.000), and brushing score (p=.000) when comparing Virtual Reality education to traditional methods. In conclusion, virtual reality education proves to be more effective in improving children's oral health than traditional educational methods.","The conventional approaches to promoting empowerment, lifestyle enhancement, and health awareness among the populace have undergone a significant transformation over time. In today's digitally savvy era, harnessing technology is crucial for capturing the attention of the younger generation in health promotion initiatives. This research endeavors to evaluate the comparative efficacy of a virtual reality-based tool versus traditional instructional methods in dental health education among school-going children in Riyadh, Saudi Arabia, within the 10-18 age bracket. A mixed-methods longitudinal assessment was employed to monitor students' daily dental hygiene practices, revealing a statistically significant enhancement in plaque index scores (p=.000), plaque percentage (p=.000), and brushing scores (p=.000) when virtual reality-based education was compared to traditional methods. The findings conclusively indicate that virtual reality-based education yields superior outcomes in enhancing the oral health of children relative to traditional pedagogical approaches.","Evolving societal shifts have transformed the pedagogical approaches employed to enhance public health awareness and lifestyle choices. Given the current generation's affinity for technology, leveraging these tools is crucial in capturing their attention for health education. This research sought to evaluate the comparative efficacy of a virtual reality educational tool and conventional methods in dental hygiene instruction among Riyadh school children aged 10 to 18. A mixed-methods longitudinal assessment of daily dental hygiene practices revealed statistically significant enhancements in plaque indices, percentage, and brushing scores within the VR group. In conclusion, the study suggests VR-based education exhibits superior effectiveness in elevating children's oral health compared to traditional pedagogical approaches.",acceptable,acceptable,acceptable,,,
10,Utilizing Virtual Reality for Distraction in Emergency Care,"Purpose of ReviewThis paper will review the published literature involving virtual reality as a tool for distraction during emergency department waiting periods and minor procedures, with a special emphasis on virtual reality’s analgesic and anxiolytic potential.Recent FindingsWith virtual reality becoming increasingly accessible and affordable, clinicians have started utilizing virtual reality as an intervention in the emergency department for pediatric and adult patients. These interventions have been implemented during waiting periods and minor procedures, showing promise for anxiolysis, analgesia, and distress management.SummaryThis paper summarizes the evolution of virtual reality use in patient interventions, with a focus on emergency department applications, logistical considerations, and future directions. Virtual reality is not discussed as a replacement for pharmaceuticals; rather, it is compared against inconsistent standard-of-care distractions (e.g., televisions, tablets) as a more immersive option. Positive findings with this technology are tempered by the limitations of current research, but VR still holds great potential.","Objective of ReviewThis article aims to examine the existing literature on the utilization of virtual reality for distraction during emergency department wait times and minor medical procedures, with a particular focus on its pain-relieving and anxiety-reducing capabilities.Recent DiscoveriesAs virtual reality becomes more accessible and affordable, medical professionals have started employing it in the emergency department for both children and adults. These applications during waiting periods and minor procedures demonstrate its potential in reducing anxiety and pain, as well as managing distress.SummaryThis review outlines the progression of virtual reality in patient care, emphasizing its use in emergency department settings, logistical challenges, and future prospects. Rather than serving as a substitute for medications, virtual reality is compared to the less consistent traditional distractions like televisions and tablets as a more engaging alternative. While positive outcomes are noted, current research limitations necessitate caution, yet VR continues to show significant promise.","""This review examines the existing body of research on leveraging virtual reality as a diversionary tactic during emergency department wait times and minor medical procedures, with a particular focus on its capacity to alleviate pain and anxiety. As virtual reality technology becomes more widely available and cost-effective, healthcare professionals have begun to integrate it into emergency department care for both pediatric and adult patients, yielding promising results in reducing anxiety, pain, and distress during waiting periods and minor procedures. This paper provides an overview of the development of virtual reality in patient care, highlighting its applications in emergency department settings, practical considerations, and future avenues for exploration. Rather than positioning virtual reality as a substitute for pharmaceutical interventions, this review compares its efficacy to conventional distraction methods, such as televisions and tablets, and finds that, despite current research limitations, virtual reality holds significant promise as a more immersive and effective alternative.""","This review examines the existing research on employing virtual reality (VR) as a distraction technique in emergency departments, particularly during wait times and minor procedures. The focus is on VR's capacity to alleviate pain and anxiety. As VR technology becomes more readily available, clinicians are integrating it into their practice to support both children and adults in emergency settings. Studies suggest that VR holds promise for managing anxiety, pain, and overall distress during waiting periods and minor procedures. This review traces the development of VR in patient care, highlighting its use in emergency departments, logistical aspects, and potential future applications. VR is not presented as a substitute for medication but rather as an immersive alternative to traditional, often inconsistent, distractions like televisions and tablets. Although existing research has limitations, the positive results indicate that VR has significant potential for improving patient experiences.",acceptable,acceptable,acceptable,3.6,3.2,3.2
11,Brief Report: Virtual Reality to Raise Awareness About Autism,"PurposeThe purpose of the study was to develop and test a virtual reality application designed to put the participants “in the shoes” of an autistic person during a routine task.MethodThe study involved a randomized controlled trial that included 103 participants recruited from a technical college. Each participant responded to three questionnaires to measure attitudes, knowledge, and openness toward autism. Prior to responding to these questionnaires, the participants in the experimental group also completed an 8-min virtual reality simulation designed by the research team in collaboration with autistic individuals.ResultsThe participants who completed the virtual reality simulation reported better attitudes, more knowledge, and higher openness toward autism than the participants in the control group.ConclusionThe results of the study suggest that virtual reality simulations are promising tools to raise awareness about autism.","ObjectiveThe objective of this research was to create and evaluate a virtual reality application aimed at enabling participants to experience the perspective of an autistic individual during a common task.ApproachA randomized controlled trial was conducted with 103 students from a technical college. Participants filled out three surveys assessing their attitudes, knowledge, and openness regarding autism. Before completing these surveys, those in the experimental group underwent an 8-minute virtual reality simulation, developed in partnership with autistic individuals.FindingsParticipants who engaged in the virtual reality simulation exhibited more positive attitudes, greater knowledge, and increased openness toward autism compared to those in the control group.ImplicationsThese findings indicate that virtual reality simulations can be effective tools for enhancing awareness and understanding of autism.","Objective: This investigation aimed to create and evaluate a virtual reality platform that enables users to experience a routine task from the perspective of an individual with autism, thereby fostering empathy and understanding. Approach: A randomized controlled trial was conducted, involving 103 participants from a technical college, who completed three surveys assessing their attitudes, knowledge, and receptivity towards autism. The experimental group additionally underwent an 8-minute virtual reality experience, co-designed with autistic individuals, prior to completing the surveys. Findings: Participants who engaged with the virtual reality simulation demonstrated improved attitudes, enhanced knowledge, and increased receptivity towards autism compared to the control group. Inference: The study's outcomes indicate that virtual reality simulations hold significant potential as a means of promoting awareness and understanding of autism.","This investigation aimed to construct and evaluate a virtual reality tool intended to immerse participants in the experience of an autistic individual during a commonplace activity. Employing a randomized controlled design, the study enrolled 103 individuals from a technical institution who completed three surveys assessing their perspectives, comprehension, and receptivity towards autism. Participants in the experimental arm also engaged in an 8-minute virtual reality simulation, collaboratively crafted by the research team and autistic individuals, prior to survey completion. Findings revealed that individuals exposed to the virtual reality simulation demonstrated enhanced attitudes, knowledge, and openness towards autism compared to the control group. Consequently, the study posits that virtual reality simulations hold significant potential as instruments for fostering greater understanding and awareness of autism.",acceptable,acceptable,acceptable,3.6,3.8,3.2
12,Towards Education 4.0 in Geotechnical Engineering Using a Virtual Reality/Augmented Reality Visualization Platform,"Education 4.0 can play a significant role in the future of geotechnical engineering education. It can provide personalized and equitable learning experiences and be used to develop skills for the fourth industrial revolution in geotechnical engineering. In this paper, we explore the application of Augmented Reality (AR) and Virtual Reality (VR) models, as part of Education 4.0, to enhance the presentation and communication of soil mechanics concepts. A detailed step-by-step process for creating 3D representations of geotechnical concepts, including texturing, UV mapping, animation, and export and publishing techniques, is introduced. For this purpose, two powerful 3D modeling and animation software programs, Autodesk Maya and Blender, are employed to develop geotechnical avatars in a soil mechanics laboratory. In Autodesk Maya, a detailed representation of the soil phase diagram is presented, while Blender is utilized to create a Consolidated Undrained (CU) triaxial laboratory experiment. The geotechnical testing avatars are then uploaded to Sketchfab, a popular publishing website that supports AR/VR formats. We also explore the potential for establishing a virtual laboratory for geotechnical engineering, highlighting the transformative possibilities it offers in terms of practical learning experiences and educational accessibility.","Geotechnical engineering education stands to benefit greatly from Education 4.0, which can offer tailored and fair learning opportunities while fostering skills relevant to the fourth industrial revolution. This study examines the utilization of Augmented Reality (AR) and Virtual Reality (VR) within Education 4.0 to improve the understanding and communication of soil mechanics principles. It outlines a comprehensive, step-by-step method for generating 3D visualizations of geotechnical concepts, detailing processes such as texturing, UV mapping, animation, and the techniques for export and publication. Two advanced 3D modeling and animation tools, Autodesk Maya and Blender, are used to create geotechnical avatars for a soil mechanics lab. Autodesk Maya is employed to produce an intricate representation of the soil phase diagram, while Blender is used to simulate a Consolidated Undrained (CU) triaxial test. These geotechnical avatars are then published on Sketchfab, a widely-used platform that supports AR/VR formats. Additionally, the paper discusses the potential creation of a virtual laboratory for geotechnical engineering, emphasizing the significant improvements it could bring to practical learning and educational inclusivity.","The future of geotechnical engineering education can be revolutionized by the integration of Education 4.0, which has the potential to offer tailored and inclusive learning environments, thereby equipping students with the skills necessary to thrive in the fourth industrial revolution. This study delves into the application of immersive technologies, such as Augmented Reality (AR) and Virtual Reality (VR), as a key component of Education 4.0, to revitalize the teaching and communication of complex soil mechanics concepts. A comprehensive, step-by-step guide is presented for crafting interactive 3D models of geotechnical concepts, encompassing techniques such as texturing, UV mapping, animation, and exportation. To achieve this, two industry-leading 3D modeling and animation software programs, Autodesk Maya and Blender, are leveraged to design geotechnical avatars within a simulated soil mechanics laboratory setting. Autodesk Maya is utilized to create a detailed, interactive representation of the soil phase diagram, whereas Blender is employed to recreate a Consolidated Undrained (CU) triaxial laboratory experiment. The resulting geotechnical testing avatars are then uploaded to Sketchfab, a prominent online platform supporting AR/VR formats. Furthermore, this study explores the feasibility of establishing a virtual geotechnical engineering laboratory, highlighting its potential to transform practical learning experiences and expand educational accessibility.","The integration of Education 4.0 technologies holds immense potential for revolutionizing geotechnical engineering education. By tailoring learning experiences and equipping students with skills essential for the fourth industrial revolution, this approach promises to significantly enhance pedagogy. This study delves into the utilization of Augmented Reality (AR) and Virtual Reality (VR) models within the framework of Education 4.0 to enrich the conveyance of soil mechanics principles. A comprehensive, sequential methodology for generating 3D visualizations of geotechnical concepts is outlined, encompassing texturing, UV mapping, animation, and dissemination techniques. Leveraging the capabilities of two robust 3D modeling and animation software packages, Autodesk Maya and Blender, geotechnical avatars are meticulously crafted within a virtual soil mechanics laboratory setting. Autodesk Maya facilitates the intricate depiction of the soil phase diagram, while Blender is employed to simulate a Consolidated Undrained (CU) triaxial laboratory test. These geotechnical testing avatars are subsequently disseminated via Sketchfab, a widely recognized publishing platform compatible with AR/VR formats. Furthermore, the study examines the prospects of establishing a virtual laboratory environment for geotechnical engineering, emphasizing its transformative potential in delivering immersive practical learning experiences and fostering educational accessibility.",acceptable,acceptable,acceptable,3.6,3.6,3.6
13,"Lightness constancy in reality, in virtual reality, and on flat-panel displays","Virtual reality (VR) displays are being used in an increasingly wide range of applications. However, previous work shows that viewers often perceive scene properties very differently in real and virtual environments and so realistic perception of virtual stimuli should always be a carefully tested conclusion, not an assumption. One important property for realistic scene perception is surface color. To evaluate how well virtual platforms support realistic perception of achromatic surface color, we assessed lightness constancy in a physical apparatus with real lights and surfaces, in a commercial VR headset, and on a traditional flat-panel display. We found that lightness constancy was good in all three environments, though significantly better in the real environment than on the flat-panel display. We also found that variability across observers was significantly greater in VR and on the flat-panel display than in the physical environment. We conclude that these discrepancies should be taken into account in applications where realistic perception is critical but also that in many cases VR can be used as a flexible alternative to flat-panel displays and a reasonable proxy for real environments.","Virtual reality (VR) displays are being employed across a growing array of applications. Research indicates, however, that there are often significant differences in how viewers perceive scenes in real versus virtual settings. Therefore, concluding that virtual stimuli offer realistic perception requires careful testing rather than assumptions. One key aspect for realistic scene perception is surface color. To assess how well VR platforms provide realistic perception of achromatic surface color, we measured lightness constancy using a physical setup with real lights and surfaces, a commercial VR headset, and a traditional flat-panel display. The results showed that lightness constancy was effective in all three settings, although it was notably superior in the real environment compared to the flat-panel display. Additionally, we observed greater variability among observers in both VR and the flat-panel display than in the physical environment. These findings suggest that such discrepancies should be considered in applications where accurate perception is crucial, but also highlight that VR can often serve as a versatile alternative to flat-panel displays and a reasonable stand-in for real environments.","The scope of virtual reality (VR) technology is expanding rapidly, but research highlights that individuals tend to perceive environmental attributes distinctly in virtual and real-world settings, emphasizing the need to verify, rather than assume, the accuracy of virtual stimuli. A crucial aspect of realistic scene interpretation is surface color, particularly achromatic hues. To investigate the efficacy of virtual platforms in replicating realistic achromatic surface color perception, we conducted an experiment involving a physical setup with real lighting and surfaces, a commercial VR headset, and a traditional flat-screen display. Our results showed that lightness constancy was satisfactory across all three environments, although it was significantly superior in the real-world setting compared to the flat-screen display. Notably, we also observed greater inter-observer variability in VR and flat-screen display environments relative to the physical setup. These findings underscore the importance of considering these discrepancies in applications where accurate perception is paramount, while also suggesting that VR can serve as a versatile alternative to flat-screen displays and a reasonable surrogate for real-world environments in many cases.","The expanding use of VR displays necessitates careful consideration of their ability to accurately depict reality. Research indicates discrepancies in scene perception between real and virtual environments, particularly concerning surface color. To investigate this, a study comparing lightness constancy across a physical setup, a commercial VR headset, and a standard flat-panel display revealed robust performance in all conditions, albeit superior in the physical realm compared to the flat-panel. Notably, inter-observer variability was heightened in both VR and flat-panel environments. These findings highlight the need for rigorous testing of perceptual realism in VR applications, yet also suggest its potential as a versatile substitute for flat-panel displays and a feasible approximation of real-world settings.",acceptable,acceptable,acceptable,3.6,3.2,3.2
14,Exploratory analysis of the effectiveness of virtual reality in cardiovascular rehabilitation,"Virtual reality therapy has been shown to be effective in coping with psychological disorders accompanied by cardiovascular disease. Age appears to be a factor that can affect the effectiveness of psychological therapy in a virtual environment. Therefore, the aim of the study was to explore whether there are age-related differences in the effectiveness of reducing levels of depression and anxiety during a virtual reality psychological intervention implemented for rehabilitation. The study included 25 younger (< 65 years) and 25 older (65 +) patients with cardiovascular disease who participated in virtual reality therapy to cope with anxiety and depression. The Hospital Anxiety and Depression Scale was used to assess anxiety and depressive disorders before and after intervention. Significant reductions in anxiety and depression scores after intervention were observed in both age-matched groups, and no significant differences were found between the younger and older participants. Further evaluation of patient age as a predictor of the effectiveness of psychological intervention in virtual reality did not show a significant effect of age on effectiveness in reducing anxiety and depressive disorders. The results obtained suggest that older patients benefit similarly to younger patients from psychological intervention in a virtual environment. Furthermore, age does not appear to be considered a predictor of effectiveness in reducing the level of anxiety and depression in patients with cardiovascular disease using virtual reality therapy.","Research indicates that virtual reality therapy can effectively help manage psychological disorders in individuals with cardiovascular disease. The effectiveness of such therapy in a virtual setting may be influenced by age. Consequently, this study aimed to assess whether there are age-related disparities in reducing depression and anxiety through virtual reality psychological interventions utilized for rehabilitation. The study involved 25 patients under 65 and 25 patients aged 65 and over, all diagnosed with cardiovascular disease, who underwent virtual reality therapy for anxiety and depression. Anxiety and depression levels were evaluated before and after the intervention using the Hospital Anxiety and Depression Scale. Notable declines in anxiety and depression scores post-intervention were observed in both age groups, with no significant differences between younger and older participants. Further analysis did not indicate that age impacts the effectiveness of virtual reality therapy in reducing anxiety and depressive disorders. The findings suggest that older patients benefit equally to their younger counterparts from virtual reality psychological interventions, and age should not be considered a predictor of the therapy's effectiveness in alleviating anxiety and depression in cardiovascular disease patients.","Research has demonstrated the efficacy of virtual reality therapy in managing psychological disorders comorbid with cardiovascular disease. However, the impact of age on the therapeutic outcomes in virtual settings remains unclear. This study aimed to investigate whether age influences the effectiveness of virtual reality interventions in alleviating depression and anxiety in patients with cardiovascular disease. A total of 50 patients, divided into two age groups (<65 and 65+), participated in virtual reality therapy and were assessed using the Hospital Anxiety and Depression Scale before and after the intervention. The results revealed significant decreases in anxiety and depression scores across both age groups, with no notable differences between younger and older participants. Moreover, age was found not to be a significant predictor of the intervention's effectiveness in reducing anxiety and depressive symptoms. These findings suggest that older patients can derive similar benefits from virtual reality-based psychological interventions as their younger counterparts, and age does not appear to be a determining factor in the therapy's success.","Research suggests that virtual reality therapy can effectively address psychological distress in individuals with cardiovascular disease, but age may influence its impact. This study examined age-related differences in the effectiveness of VR therapy for anxiety and depression in 25 younger and 25 older cardiovascular patients. Pre- and post-intervention assessments using the Hospital Anxiety and Depression Scale revealed significant symptom reduction in both age groups, with no statistically significant difference between them. Further analysis confirmed that age did not significantly predict the efficacy of VR therapy in alleviating anxiety and depression. These findings indicate that older patients experience similar benefits to younger patients from virtual reality-based psychological interventions, suggesting that age should not be a primary factor in considering the suitability of this therapeutic approach for cardiovascular patients struggling with anxiety and depression.",acceptable,acceptable,acceptable,3.6,3.2,3.2
15,Designing for collaborative learning in immersive virtual reality: a systematic literature review,"Immersive learning technologies such as virtual reality have long been deemed as the next generation of digital learning environments. There is a limited number of studies addressing how immersive technologies can be designed, applied, and studied in collaborative learning settings. This paper presents a systematic review of empirical studies reporting on use of immersive virtual reality in collaborative learning within educational and professional learning settings. 11 studies have been grouped and coded in a textual narrative synthesis, outlining the pedagogical concepts behind the learning design, as well as the design of virtual reality environments and the collaborative learning activities in which the technology is employed. The results suggest that collaborative learning in virtual reality can currently be conceptualised as a shared experience in an immersive, virtually mediated space, where there is a shared goal/problem which learners must attend to collaboratively. This conceptualisation implies a need to design technologies, environments, and activities that support participation and social interaction, fostering collaborative learning processes. Based on the outlined conceptualisation, we present a series of recommendations for designing for collaborative learning in immersive virtual reality. The paper concludes that collaborative learning in virtual reality creates a practice- and reflection space, where learning is perceived as engaging, without the risk of interfering with actual practices. Current designs however struggle with usability, realism, and facilitating social interaction. The paper further identifies a need for future research into what happens within virtual reality, rather than only looking at post-virtual reality evaluations.","Advanced digital learning environments are increasingly seen as the future, with immersive learning technologies like virtual reality at the forefront. However, research on the design, application, and study of these technologies in collaborative learning settings remains limited. This paper systematically reviews empirical studies that investigate the use of immersive virtual reality for collaborative learning in both educational and professional contexts. It categorizes and synthesizes 11 studies, highlighting the pedagogical principles underlying learning design, the creation of virtual reality environments, and the collaborative activities facilitated by this technology. The findings indicate that collaborative learning in virtual reality is currently viewed as a shared immersive experience in a digitally mediated space, where learners collaborate on a common goal or problem. This view necessitates the development of technologies, environments, and activities that enhance participation and social interaction, thereby supporting collaborative learning. Based on this conceptualization, the paper offers several recommendations for designing immersive virtual reality for collaborative learning. It concludes that virtual reality promotes an engaging learning experience, allowing for practice and reflection without disrupting real-world activities. However, current designs face challenges in terms of usability, realism, and fostering social interaction. The paper also emphasizes the need for future research to focus on the in-VR experience, rather than solely on post-VR evaluations.","Advanced digital learning platforms, exemplified by virtual reality, have been hailed as the future of educational environments. Despite this, there is a scarcity of research exploring the design, implementation, and analysis of immersive technologies in collaborative educational settings. This study presents a comprehensive review of empirical research on the utilization of immersive virtual reality in collaborative learning within academic and professional contexts. A total of 11 studies were categorized and analyzed through a narrative synthesis, highlighting the pedagogical principles underlying learning design, virtual environment development, and collaborative activities facilitated by the technology. The findings indicate that collaborative learning in virtual reality can be characterized as a shared, immersive experience where learners collectively address a common objective or challenge. This understanding underscores the need to develop technologies, environments, and activities that promote participation, social interaction, and collaborative learning processes. Based on this conceptual framework, we offer a set of guidelines for designing collaborative learning experiences in immersive virtual reality. The study concludes that virtual reality-based collaborative learning creates a simulated environment for practice and reflection, enhancing engagement without compromising real-world practices. However, current designs face challenges related to usability, realism, and facilitating social interaction. Furthermore, the study identifies a need for future research to investigate the dynamics within virtual reality, moving beyond post-experience evaluations.","Cutting-edge technologies like virtual reality (VR) have been hailed as the future of digital education. However, research on designing, implementing, and evaluating VR for collaborative learning remains scarce. This review examines empirical studies on VR-supported collaborative learning in educational and professional contexts. Eleven studies were analyzed, revealing pedagogical approaches, VR environment design, and collaborative activities. Findings suggest that collaborative VR learning involves shared experiences within immersive virtual spaces, where learners work together on common goals or challenges. This necessitates designing technologies, environments, and activities that promote participation, social interaction, and collaborative processes. Based on this conceptualization, the paper offers recommendations for designing collaborative VR learning experiences. It concludes that VR provides a safe space for practice and reflection, engaging learners without real-world consequences. However, current designs face challenges related to usability, realism, and fostering social interaction. The paper emphasizes the need for research that delves into the intricacies of VR interactions, going beyond post-experience evaluations.",acceptable,acceptable,acceptable,3.2,3.2,3.2
16,Implementation of virtual reality in healthcare: a scoping review on the implementation process of virtual reality in various healthcare settings,"BackgroundVirtual reality (VR) is increasingly used in healthcare settings as recent technological advancements create possibilities for diagnosis and treatment. VR is a technology that uses a headset to simulate a reality in which the user is immersed in a virtual environment, creating the impression that the user is physically present in this virtual space. Despite the potential added value of virtual reality technology in healthcare, its uptake in clinical practice is still in its infancy and challenges arise in the implementation of VR. Effective implementation could improve the adoption, uptake, and impact of VR. However, these implementation procedures still seem to be understudied in practice. This scoping review aimed to examine the current state of affairs in the implementation of VR technology in healthcare settings and to provide an overview of factors related to the implementation of VR.MethodsTo give an overview of relevant literature, a scoping review was undertaken of articles published up until February 2022, guided by the methodological framework of Arksey and O’Malley (2005). The databases Scopus, PsycINFO, and Web of Science were systematically searched to identify records that highlighted the current state of affairs regarding the implementation of VR in healthcare settings. Information about each study was extracted using a structured data extraction form.ResultsOf the 5523 records identified, 29 were included in this study. Most studies focused on barriers and facilitators to implementation, highlighting similar factors related to the behavior of adopters of VR and the practical resources the organization should arrange for. However, few studies focus on systematic implementation and on using a theoretical framework to guide implementation. Despite the recommendation of using a structured, multi-level implementation intervention to support the needs of all involved stakeholders, there was no link between the identified barriers and facilitators, and specific implementation objectives or suitable strategies to overcome these barriers in the included articles.ConclusionTo take the implementation of VR in healthcare to the next level, it is important to ensure that implementation is not studied in separate studies focusing on one element, e.g., healthcare provider-related barriers, as is common in current literature. Based on the results of this study, we recommend that the implementation of VR entails the entire process, from identifying barriers to developing and employing a coherent, multi-level implementation intervention with suitable strategies. This implementation process could be supported by implementation frameworks and ideally focus on behavior change of stakeholders such as healthcare providers, patients, and managers. This in turn might result in increased uptake and use of VR technologies that are of added value for healthcare practice.","Background The use of virtual reality (VR) in healthcare is on the rise, thanks to recent technological advancements that open up new avenues for diagnosis and treatment. VR employs a headset to immerse users in a simulated environment, making them feel as if they are physically present in that virtual space. Despite its promising potential in healthcare, the integration of VR into clinical practice remains in its early stages and faces several implementation challenges. Successful integration could enhance the adoption, utilization, and effectiveness of VR, but the implementation process is still under-explored in practical terms. This scoping review aimed to assess the current landscape of VR implementation in healthcare settings and identify factors that influence this process. Methods A scoping review of literature up to February 2022 was conducted, following the methodological guidelines of Arksey and O’Malley (2005). Databases including Scopus, PsycINFO, and Web of Science were systematically searched to find studies focused on the implementation of VR in healthcare. Data from each study were extracted using a structured form. Results Out of 5523 records, 29 were included in the analysis. Most studies examined the barriers and facilitators to implementation, identifying common factors related to adopter behavior and the organizational resources required. However, few studies addressed systematic implementation guided by theoretical frameworks. While the use of a structured, multi-level approach to meet stakeholder needs is recommended, no clear link between identified barriers, specific implementation objectives, and strategies to overcome these barriers was found in the reviewed articles. Conclusion Advancing VR implementation in healthcare requires a comprehensive approach, not fragmented studies focusing on single elements like healthcare provider-related barriers, which is prevalent in current literature. This study suggests that a holistic implementation framework should encompass the entire process—from identifying barriers to developing and deploying a coherent, multi-level intervention with effective strategies. This approach should leverage implementation frameworks and focus on behavior change among stakeholders such as healthcare providers, patients, and managers, potentially leading to an increased adoption and beneficial use of VR technologies in healthcare.","Here is a paraphrased version of the original text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""The incorporation of virtual reality (VR) technology in healthcare settings is gaining momentum, driven by recent breakthroughs that unlock new possibilities for diagnosis and treatment. This immersive technology, which utilizes a headset to simulate a virtual environment, creates a convincing illusion of physical presence. Despite VR's potential to revolutionize healthcare, its integration into clinical practice remains in its early stages, hindered by challenges in implementation. Effective integration could significantly enhance the adoption, utilization, and impact of VR. However, the procedures for implementing VR technology in healthcare settings remain understudied. This scoping review aimed to investigate the current state of VR implementation in healthcare and identify key factors influencing its integration. A comprehensive literature review was conducted, encompassing articles published up to February 2022, guided by the methodological framework of Arksey and O'Malley (2005). A systematic search of Scopus, PsycINFO, and Web of Science databases yielded 5523 records, of which 29 were selected for this study. The extracted data revealed that most studies focused on the obstacles and facilitators to implementation, highlighting similar factors related to the behavior of VR adopters and the organizational resources required. However, few studies examined systematic implementation or employed theoretical frameworks to guide integration. Despite the recommendation for a structured, multi-level implementation intervention to support the needs of all stakeholders, the identified barriers and facilitators were not linked to specific implementation objectives or strategies to overcome these barriers. To propel VR implementation in healthcare forward, it is essential to adopt a comprehensive approach that encompasses the entire process, from identifying barriers to developing and employing a coherent, multi-level implementation intervention with suitable strategies. This process could be supported by implementation frameworks, focusing on behavior change among stakeholders such as healthcare providers, patients, and managers, ultimately leading to increased adoption and utilization of VR technologies that add value to healthcare practice.""","The integration of virtual reality (VR) into healthcare is gaining momentum due to ongoing technological progress that opens new avenues for diagnosis and treatment. VR headsets immerse users in simulated environments, creating a sense of physical presence in the virtual world. However, despite its potential, VR implementation in clinical practice remains limited. This review examined existing research on VR implementation in healthcare, published before February 2022, across various databases. Out of a large pool of articles, 29 were deemed relevant. The majority concentrated on hurdles and enablers in implementation, emphasizing factors tied to user behavior and organizational resources. However, research on systematic implementation and the use of theoretical frameworks is scarce. Although a structured, multi-level implementation approach is recommended to cater to all stakeholders, the studies lacked a connection between identified obstacles, implementation goals, and strategies to address these challenges. To advance VR integration in healthcare, research should move beyond examining isolated implementation aspects. This review suggests a comprehensive approach encompassing the entire implementation journey, from identifying barriers to designing and employing a cohesive, multi-level intervention with appropriate strategies. Implementation frameworks can support this process, focusing on behavioral changes among stakeholders like healthcare providers, patients, and administrators. This could ultimately lead to increased adoption and utilization of VR technologies that bring value to healthcare.",acceptable,acceptable,acceptable,3.2,3.6,3.2
17,Virtual and augmented reality in biomedical engineering,"In the future, extended reality technology will be widely used. People will be led to utilize virtual reality (VR) and augmented reality (AR) technologies in their daily lives, hobbies, numerous types of entertainment, and employment. Medical augmented reality has evolved with applications ranging from medical education to picture-guided surgery. Moreover, a bulk of research is focused on clinical applications, with the majority of research devoted to surgery or intervention, followed by rehabilitation and treatment applications. Numerous studies have also looked into the use of augmented reality in medical education and training.MethodsUsing the databases Semantic Scholar, Web of Science, Scopus, IEEE Xplore, and ScienceDirect, a scoping review was conducted in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) criteria. To find other articles, a manual search was also carried out in Google Scholar. This study presents studies carried out over the previous 14 years (from 2009 to 2023) in detail. We classify this area of study into the following categories: (1) AR and VR in surgery, which is presented in the following subsections: subsection A: MR in neurosurgery; subsection B: spine surgery; subsection C: oral and maxillofacial surgery; and subsection D: AR-enhanced human-robot interaction; (2) AR and VR in medical education presented in the following subsections; subsection A: medical training; subsection B: schools and curriculum; subsection C: XR in Biomedicine; (3) AR and VR for rehabilitation presented in the following subsections; subsection A: stroke rehabilitation during COVID-19; subsection B: cancer and VR, and (4) Millimeter-wave and MIMO systems for AR and VR.ResultsIn total, 77 publications were selected based on the inclusion criteria. Four distinct AR and/or VR applications groups could be differentiated: AR and VR in surgery (N = 21), VR and AR in Medical Education (N = 30), AR and VR for Rehabilitation (N = 15), and Millimeter-Wave and MIMO Systems for AR and VR (N = 7), where N is number of cited studies. We found that the majority of research is devoted to medical training and education, with surgical or interventional applications coming in second. The research is mostly focused on rehabilitation, therapy, and clinical applications. Moreover, the application of XR in MIMO has been the subject of numerous research.ConclusionExamples of these diverse fields of applications are displayed in this review as follows: (1) augmented reality and virtual reality in surgery; (2) augmented reality and virtual reality in medical education; (3) augmented reality and virtual reality for rehabilitation; and (4) millimeter-wave and MIMO systems for augmented reality and virtual reality.","Looking ahead, it is anticipated that extended reality technology will see widespread adoption. Individuals will be encouraged to integrate virtual reality (VR) and augmented reality (AR) into their everyday activities, leisure pursuits, various forms of entertainment, and professional endeavors. The field of medical augmented reality has advanced, with applications ranging from educational purposes to image-guided surgeries. A significant portion of research is concentrated on clinical uses, predominantly focusing on surgical and interventional procedures, followed by rehabilitation and treatment applications. Additionally, numerous studies have investigated the role of augmented reality in medical education and training. In order to conduct this scoping review, databases such as Semantic Scholar, Web of Science, Scopus, IEEE Xplore, and ScienceDirect were utilized, adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A manual search on Google Scholar was also performed to identify additional articles. This review comprehensively examines studies from the past 14 years (2009 to 2023). The research is categorized as follows: (1) AR and VR in surgery, detailed in subsections: A: MR in neurosurgery; B: spine surgery; C: oral and maxillofacial surgery; and D: AR-enhanced human-robot interaction; (2) AR and VR in medical education, detailed in subsections: A: medical training; B: schools and curriculum; C: XR in Biomedicine; (3) AR and VR for rehabilitation, detailed in subsections: A: stroke rehabilitation during COVID-19; B: cancer and VR; and (4) Millimeter-wave and MIMO systems for AR and VR. Overall, 77 publications met the inclusion criteria, categorized into four groups: AR and VR in surgery (N = 21), AR and VR in medical education (N = 30), AR and VR for rehabilitation (N = 15), and Millimeter-wave and MIMO systems for AR and VR (N = 7), where N represents the number of studies cited. The findings reveal that most research is dedicated to medical training and education, with surgical or interventional applications being the second most prominent. The focus is primarily on rehabilitation, therapy, and clinical applications, with the application of XR in MIMO also being extensively researched. In summary, this review showcases the diverse applications of AR and VR in the following domains: (1) surgery, (2) medical education, (3) rehabilitation, and (4) millimeter-wave and MIMO systems.","In the years to come, the widespread adoption of extended reality technology is anticipated. As a result, individuals will increasingly incorporate virtual reality (VR) and augmented reality (AR) into their daily routines, leisure activities, diverse forms of entertainment, and professional pursuits. The medical sector has witnessed significant advancements in AR, with applications spanning from educational initiatives to image-guided surgical interventions. Furthermore, a substantial body of research is concentrated on clinical applications, with the majority focused on surgical or interventional procedures, followed by rehabilitation and treatment strategies. Additionally, numerous investigations have probed the utilization of AR in medical education and training.","The pervasive integration of extended reality (XR) technology, encompassing virtual reality (VR) and augmented reality (AR), into various facets of life, including work, leisure, and entertainment, is anticipated. The medical realm has witnessed a significant evolution in AR applications, spanning medical education to image-guided surgery. A comprehensive scoping review, adhering to PRISMA guidelines, was undertaken using databases like Semantic Scholar, Web of Science, and others, supplemented by a manual Google Scholar search. This review, encompassing studies from 2009 to 2023, categorized AR and VR applications into four primary domains: surgical interventions, medical education, rehabilitation, and millimeter-wave and MIMO systems. Analysis of the 77 selected publications revealed a predominance of research in medical training and education, followed by surgical applications. The emphasis on rehabilitation, therapy, and clinical applications was prominent, with considerable research exploring XR's role in MIMO systems. This review showcases diverse applications of AR and VR, encompassing surgery, medical education, rehabilitation, and millimeter-wave and MIMO systems.",acceptable,acceptable,acceptable,3.6,3.2,3.2
18,An immersive virtual reality learning environment with CFD simulations: Unveiling the Virtual Garage concept,"Virtual reality has become a significant asset to diversify the existing toolkit supporting engineering education and training. The cognitive and behavioral advantages of virtual reality (VR) can help lecturers reduce entry barriers to concepts that students struggle with. Computational fluid dynamics (CFD) simulations are imperative tools intensively utilized in the design and analysis of chemical engineering problems. Although CFD simulation tools can be directly applied in engineering education, they bring several challenges in the implementation and operation for both students and lecturers. In this study, we develop the “Virtual Garage” as a task-centered educational VR application with CFD simulations to tackle these challenges. The Virtual Garage is composed of a holistic immersive virtual reality experience to educate students with a real-life engineering problem solved by CFD simulation data. The prototype is tested by graduate students (n = 24) assessing usability, user experience, task load and simulator sickness via standardized questionnaires together with self-reported metrics and a semi-structured interview. Results show that the Virtual Garage is well-received by participants. We identify features that can further leverage the quality of the VR experience with CFD simulations. Implications are incorporated throughout the study to provide practical guidance for developers and practitioners.","Virtual reality has emerged as a pivotal tool to broaden the repertoire supporting engineering education and training. The cognitive and behavioral benefits of VR assist educators in lowering the barriers to understanding challenging concepts for students. Computational fluid dynamics (CFD) simulations are critical instruments extensively used in the design and analysis of chemical engineering issues. Despite their direct applicability in engineering education, CFD simulation tools present numerous challenges in their implementation and operation for both students and instructors. This research introduces the ""Virtual Garage,"" a task-focused educational VR application incorporating CFD simulations to address these challenges. The Virtual Garage offers an all-encompassing immersive VR experience, educating students through a real-world engineering problem solved with CFD simulation data. The prototype was tested with graduate students (n=24), who evaluated usability, user experience, task load, and simulator sickness using standardized questionnaires along with self-reported metrics and a semi-structured interview. Findings indicate that the Virtual Garage is positively received by participants. We pinpoint features that can further enhance the quality of the VR experience incorporating CFD simulations. Practical recommendations for developers and practitioners are provided throughout the study.","The incorporation of virtual reality into the engineering education and training paradigm has yielded a substantial enhancement, broadening the scope of available resources. By harnessing the cognitive and behavioral benefits of virtual reality, educators can facilitate a more seamless understanding of complex concepts that often pose difficulties for students. In the realm of chemical engineering, computational fluid dynamics simulations play a vital role in the design and analysis of problems, although their direct application in educational settings can be hindered by implementation and operational challenges. To address these obstacles, this study introduces the ""Virtual Garage,"" a task-oriented virtual reality platform that integrates CFD simulations to provide a comprehensive, immersive learning experience centered on real-world engineering problems. The efficacy of the Virtual Garage was evaluated through a pilot study involving 24 graduate students, who assessed its usability, user experience, task load, and simulator sickness via standardized questionnaires, self-reported metrics, and semi-structured interviews. The results indicate a positive reception among participants, highlighting areas for further improvement to optimize the virtual reality experience with CFD simulations. The study's findings offer practical insights for developers and practitioners seeking to integrate virtual reality into their educational approaches.","Immersive virtual reality (VR) technologies are increasingly recognized as valuable tools for enhancing engineering education. VR's ability to influence cognition and behavior can be leveraged by educators to simplify complex concepts that students often find challenging. Computational fluid dynamics (CFD) simulations, while crucial for analyzing and designing chemical engineering solutions, pose considerable operational and implementation difficulties for both educators and learners. To address these obstacles, we have created ""Virtual Garage,"" an educational VR application centered around a real-world engineering challenge that utilizes CFD simulation data. This immersive experience provides students with a comprehensive understanding of the problem and its resolution. Graduate students (n=24) evaluated a prototype of the Virtual Garage, assessing its usability, user experience, task load, and simulator sickness through standardized questionnaires, self-reported measures, and semi-structured interviews. The Virtual Garage was favorably received by participants, and the study identifies areas for improvement to enhance the quality of the VR experience with CFD simulations. Practical guidance for developers and practitioners is provided throughout the study, highlighting the implications of integrating VR and CFD simulations in engineering education.",acceptable,acceptable,acceptable,3.6,3.2,3.2
19,Virtual reality headsets for perimetry testing: a systematic review,"Standard automated perimetery is considered the gold standard for evaluating a patient’s visual field. However, it is costly and requires a fixed testing environment. In response, perimetric devices using virtual reality (VR) headsets have emerged as an alternative way to measure visual fields in patients. This systematic review aims to characterize both novel and established VR headsets in the literature and explore their potential applications within visual field testing. A search was conducted using MEDLINE, Embase, CINAHL, and the Core Collection (Web of Science) for articles published until January 2023. Subject headings and keywords related to virtual reality and visual field were used to identify studies specific to this topic. Records were first screened by title/abstract and then by full text using predefined criteria. Data was extracted accordingly. A total of 2404 records were identified from the databases. After deduplication and the two levels of screening, 64 studies describing 36 VR headset perimetry devices were selected for extraction. These devices encompassed various visual field measurement techniques, including static and kinetic perimetry, with some offering vision rehabilitation capabilities. This review reveals a growing consensus that VR headset perimetry devices perform comparably to, or even better than, standard automated perimetry. They are better tolerated by patients in terms of gaze fixation, more cost-effective, and generally more accessible for patients with limited mobility.","Standard automated perimetry is widely regarded as the benchmark for assessing a patient's visual field. Nonetheless, it is expensive and necessitates a stationary testing setting. Consequently, virtual reality (VR) headset-based perimetric devices have been developed as an alternative method for evaluating visual fields in patients. This systematic review seeks to describe both innovative and established VR headsets discussed in the literature and examine their potential uses in visual field assessment. A thorough search was performed using MEDLINE, Embase, CINAHL, and the Core Collection (Web of Science) for articles available up to January 2023. Subject headings and keywords related to virtual reality and visual fields were employed to locate relevant studies. Titles and abstracts were initially screened, followed by full texts, based on pre-established criteria. Data were subsequently extracted. Out of 2404 records retrieved from the databases, 64 studies detailing 36 VR headset perimetry devices were chosen after deduplication and two screening rounds. These devices used various visual field measurement methods, including static and kinetic perimetry, and some also featured vision rehabilitation functions. This review identifies a growing agreement that VR headset perimetry devices perform on par with or superior to standard automated perimetry. They are better accepted by patients in terms of gaze fixation, more cost-effective, and typically more accessible for patients with limited mobility.","The assessment of a patient's visual field is typically conducted using conventional automated perimetry, regarded as the benchmark for this purpose. However, this method is hindered by its high cost and requirement for a fixed testing setting. As a result, innovative perimetric tools utilizing virtual reality (VR) technology have emerged as a viable alternative for measuring visual fields. This systematic review seeks to provide a comprehensive overview of both cutting-edge and established VR headsets in the existing literature, exploring their potential uses in visual field assessment. A thorough search of prominent databases, including MEDLINE, Embase, CINAHL, and the Core Collection (Web of Science), was conducted to identify relevant articles published up to January 2023. Studies specific to this topic were identified using relevant subject headings and keywords related to virtual reality and visual field. Following a rigorous screening process, 64 studies describing 36 VR headset perimetry devices were selected for analysis. These devices employ diverse visual field measurement techniques, including static and kinetic perimetry, with some offering additional vision rehabilitation capabilities. The findings of this review suggest a growing agreement that VR headset perimetry devices perform equally well as, or even surpass, standard automated perimetry in terms of accuracy, while offering advantages such as improved patient tolerance, cost-effectiveness, and increased accessibility for patients with mobility limitations.","While standard automated perimetry remains the benchmark for assessing patients' visual fields, its high cost and reliance on a stationary setting have spurred the development of virtual reality (VR) headset-based perimetric devices as a viable alternative. This systematic review sought to analyze both established and novel VR headsets described in scientific literature, investigating their potential for visual field assessment. A comprehensive search encompassing MEDLINE, Embase, CINAHL, and Web of Science's Core Collection yielded 2404 records published up to January 2023, using keywords and subject headings pertaining to both virtual reality and visual field testing. After removing duplicates and conducting a two-stage screening process (title/abstract and full text) based on predetermined criteria, 64 studies detailing 36 distinct VR headset perimetry devices were ultimately selected for data extraction. These devices utilized a range of visual field measurement techniques, including static and kinetic perimetry, with some even incorporating vision rehabilitation functionalities. This review highlights a growing body of evidence suggesting that VR headset perimetry devices demonstrate performance comparable to, if not exceeding, standard automated perimetry. Furthermore, they offer improved patient tolerance regarding gaze fixation, greater cost-effectiveness, and enhanced accessibility for individuals with mobility limitations.",acceptable,acceptable,acceptable,3.6,3.2,3.2
20,Immersive virtual reality in orthopaedics—a narrative review,"This narrative review explores the applications and benefits of immersive virtual reality (VR) in orthopaedics, with a focus on surgical training, patient functional recovery, and pain management.MethodsThe review examines existing literature and research studies on immersive VR in orthopaedics, analyzing both experimental and clinical studies.ResultsImmersive VR provides a realistic simulation environment for orthopaedic surgery training, enhancing surgical skills, reducing errors, and improving overall performance. In post-surgical recovery and rehabilitation, immersive VR environments can facilitate motor learning and functional recovery through virtual embodiment, motor imagery during action observation, and virtual training. Additionally VR-based functional recovery programs can improve patient adherence and outcomes. Moreover, VR has the potential to revolutionize pain management, offering a non-invasive, drug-free alternative. Virtual reality analgesia acts by a variety of means including engagement and diverting patients’ attention, anxiety reduction, and specific virtual-body transformations.ConclusionImmersive virtual reality holds significant promise in orthopaedics, demonstrating potential for improved surgical training, patient functional recovery, and pain management but further research is needed to fully exploit the benefits of VR technology in these areas.","This narrative review investigates the uses and advantages of immersive virtual reality (VR) within the field of orthopaedics, concentrating on training for surgeries, functional recovery for patients, and the management of pain. The review analyzes existing literature and research concerning immersive VR in orthopaedics, including both experimental and clinical studies. Immersive VR delivers a realistic simulation environment that enhances orthopaedic surgical training by improving surgical skills, minimizing errors, and boosting overall performance. For post-surgical rehabilitation, immersive VR environments aid motor learning and functional recovery through virtual embodiment, motor imagery during action observation, and virtual training, leading to better patient adherence and outcomes. Additionally, VR offers a revolutionary approach to pain management, providing a non-invasive, drug-free alternative. VR-based pain relief operates through mechanisms such as patient engagement, distraction, anxiety reduction, and specific virtual-body transformations. In conclusion, immersive VR shows great promise in orthopaedics, demonstrating potential advancements in surgical training, patient recovery, and pain management, though additional research is needed to fully realize VR’s capabilities in these areas.","This comprehensive analysis delves into the multifaceted advantages and uses of immersive virtual reality technology in the field of orthopaedics, with a particular emphasis on its role in refining surgical proficiency, expediting patient rehabilitation, and alleviating pain. The study synthesizes findings from existing research and clinical trials to assess the efficacy of immersive VR in orthopaedics. The results indicate that immersive VR simulations can significantly enhance surgical competence by providing a realistic and interactive environment, thereby minimizing errors and optimizing overall performance. Furthermore, VR-based rehabilitation programs can facilitate motor skill acquisition, functional recovery, and patient compliance through virtual embodiment, motor imagery, and simulated training exercises. Additionally, VR technology has the potential to transform pain management by offering a non-pharmacological, non-invasive alternative that leverages distraction, anxiety reduction, and virtual-body transformations to mitigate pain perception. In conclusion, immersive virtual reality technology exhibits considerable potential in orthopaedics, with promising applications in surgical training, patient rehabilitation, and pain management, although further investigation is necessary to fully harness its benefits.","This comprehensive analysis delves into the diverse applications and advantages of immersive virtual reality (VR) within the field of orthopaedics, emphasizing its utility in surgical education, patient rehabilitation, and pain alleviation. By meticulously examining existing literature and research, encompassing both experimental and clinical investigations, the review illuminates the profound impact of immersive VR. The technology offers a remarkably realistic simulated setting for orthopaedic surgical training, demonstrably enhancing surgical proficiency, diminishing errors, and elevating overall performance. In the realm of post-surgical recovery and rehabilitation, immersive VR environments serve as catalysts for motor learning and functional restoration through virtual embodiment, motor imagery evoked during action observation, and virtual training regimens. Notably, VR-based functional recovery programs exhibit the potential to bolster patient adherence and optimize outcomes. Furthermore, VR emerges as a revolutionary force in pain management, presenting a non-invasive, drug-free alternative to traditional methods. Virtual reality analgesia operates through a multifaceted approach, encompassing patient engagement and attention diversion, anxiety mitigation, and specific virtual-body transformations. While immersive virtual reality undeniably holds immense promise in orthopaedics, underscoring its potential to revolutionize surgical training, patient functional recovery, and pain management, further research is imperative to fully harness the benefits of this transformative technology.",acceptable,acceptable,acceptable,4.8,3.6,4.0
21,"Design, development, and evaluation of educational virtual reality environment: EVRECA","Numerous studies have been carried out in recent years on the use of virtual reality (VR) technologies and environments in education. On the other hand, many researchers have drawn attention to the inadequacy of studies that deal with the education process in virtual reality environments from a broad perspective. In this research, the process of designing, developing, and testing an educational virtual reality environment in the light of a design model that includes pedagogical, design, and technical steps have been experienced and reported with a holistic perspective. The study was carried out in a two meso cycle structure based on the educational design research methodology. In the scope of research, the educational virtual reality campus platform has been developed to provide a skill-based educational environment for learners. The Internet of Things training process in the platform was held in a single session with each participant. At the end of the practices, it has been seen that the training carried out on the platform can provide learning at both cognitive and skill levels; the knowledge learned in the virtual reality environment can be transferred to real life and has a lasting effect. Furthermore, it was determined that there was a reverse relationship between the participants’ sense of presence and their cognitive load, and there was a positive relationship between the participants’ sense of presence and their pleasure and arousal levels. It has been concluded that technical data such as frames per second, latency, draw call, and polygon count provided by the platform can have a remarkable effect on the VR experience.","A multitude of investigations has been conducted in the recent past concerning the application of virtual reality (VR) technologies and settings in education. Nevertheless, several researchers have highlighted the insufficiency of studies addressing the educational process within virtual reality environments from a comprehensive standpoint. This study explores the design, development, and evaluation of an educational VR environment, guided by a model encompassing pedagogical, design, and technical phases, and reports the findings from a holistic viewpoint. The research followed an educational design research methodology structured in two meso cycles. Within the study's framework, an educational VR campus platform was created to offer a skill-based learning setting for students. The Internet of Things training on the platform was conducted in a single session per participant. Post-practice results indicated that training via the platform could facilitate learning at both cognitive and skill levels, enabling the transfer of knowledge acquired in the VR environment to real-world applications with lasting effects. Additionally, it was found that there is an inverse relationship between participants' sense of presence and cognitive load, and a positive correlation between their sense of presence and their levels of enjoyment and arousal. The research concluded that technical aspects such as frames per second, latency, draw call, and polygon count provided by the platform can significantly influence the VR experience.","""A plethora of investigations have explored the integration of virtual reality (VR) technologies and environments in educational settings over the past few years. However, a significant number of scholars have highlighted the limitations of research that examines the educational process within VR environments from a comprehensive viewpoint. This study aimed to address this gap by designing, developing, and testing an educational VR environment grounded in a multifaceted design model encompassing pedagogical, design, and technical considerations. Employing an educational design research methodology, the study was structured around a two-meso cycle framework. The research involved the development of an educational VR campus platform, which provided a competency-based learning environment for students. The Internet of Things training program was conducted in a single session with each participant. The findings indicated that the training facilitated learning at both cognitive and skill levels, with knowledge acquired in the VR environment transferable to real-life situations and yielding a lasting impact. Additionally, the study revealed an inverse correlation between participants' sense of presence and cognitive load, as well as a positive correlation between sense of presence and pleasure and arousal levels. Furthermore, the technical specifications of the platform, including frames per second, latency, draw call, and polygon count, were found to have a profound influence on the overall VR experience.""","Recent research has extensively explored the integration of virtual reality (VR) in education, yet a gap exists in comprehensive studies examining the educational process within VR environments. This study aimed to address this gap by meticulously documenting the design, development, and evaluation of an educational VR environment based on a multifaceted model encompassing pedagogical, design, and technical aspects. Using an educational design research methodology with a two-cycle structure, the research culminated in the creation of a virtual reality campus platform designed to foster skill-based learning. Participants engaged in a single-session Internet of Things training within the platform, demonstrating that the VR-based training facilitated both cognitive and practical learning, with acquired knowledge transferable to real-world scenarios and exhibiting enduring effects. The study also revealed an inverse correlation between the sense of presence and cognitive load experienced by participants, while a positive relationship was observed between presence, pleasure, and arousal. Significantly, the research underscores the impact of technical parameters such as frames per second, latency, draw call, and polygon count on the overall VR experience.",acceptable,acceptable,acceptable,3.2,3.2,3.2
22,Virtual reality evaluation of the spatial learning strategies in gamers,"Psychological memory tests have traditionally relied on paper-based methods. However, the emergence of virtual reality tools, including adaptations of animal lab tests, has opened up new possibilities for evaluating and enhancing attention and memory processes. The impact of virtual environments on spatial memory remains a topic of ongoing debate. To contribute to this discussion, we conducted a comprehensive study with two primary objectives. Firstly, we aimed to develop a virtual reality tool that could effectively assess search strategies in gamers within virtual environments. To achieve this, we designed a virtual water maze inspired by those used in animal research. Secondly, we conducted a cross-sectional study involving participants to analyze how spatial memory strategies evolve in a virtual environment with increasing gaming experience. The results revealed that participants with more gaming experience exhibited faster and more precise learning in the virtual water maze, along with improved search strategies. Additionally, our study allowed for the evaluation of our software and enabled us to track changes in the efficacy of learning strategies. Overall, this study emphasizes the potential of virtual environments for both evaluation and cognitive stimulation purposes.","Psychological assessments of memory have historically been conducted using paper-based techniques. Nevertheless, the advent of virtual reality applications, including adaptations of experiments originally designed for animal laboratories, has introduced new methods for assessing and improving attention and memory skills. The influence of virtual settings on spatial memory is still a subject of considerable debate. To add to this discourse, we performed an extensive study with two main goals. Firstly, our aim was to create a virtual reality application capable of effectively evaluating search strategies in gamers operating within virtual settings. For this purpose, we developed a virtual water maze modeled after those used in animal studies. Secondly, we implemented a cross-sectional analysis involving participants to examine the changes in spatial memory strategies as gaming experience increases in a virtual environment. The findings indicated that participants with greater gaming experience demonstrated faster and more accurate learning in the virtual water maze, along with enhanced search strategies. Moreover, our study facilitated the assessment of our software and enabled the monitoring of the evolution of learning strategy efficiency. In sum, this research highlights the potential of virtual environments for both evaluation and cognitive stimulation.","Conventional assessments of psychological memory have long been rooted in traditional paper-based approaches, but the advent of virtual reality technologies, including adaptations of laboratory tests used with animals, has unlocked innovative avenues for examining and enhancing attentional and mnemonic processes. The influence of immersive virtual settings on spatial memory remains a contentious issue, sparking ongoing deliberation. To inform this discourse, we undertook an exhaustive investigation with two overarching goals. Firstly, we sought to create a virtual reality instrument capable of accurately evaluating navigational tactics employed by gamers within virtual realms. To accomplish this, we crafted a virtual aquatic labyrinth inspired by its animal research counterparts. Secondly, we conducted a cross-sectional analysis involving participants to examine the evolution of spatial memory strategies in response to increasing gaming proficiency within virtual environments. Our findings indicated that participants with greater gaming experience demonstrated accelerated and more precise learning within the virtual aquatic labyrinth, accompanied by enhanced search strategies. Furthermore, our study enabled the evaluation of our software and facilitated the tracking of changes in the effectiveness of learning strategies over time. Ultimately, this study underscores the vast potential of virtual environments for both evaluative and cognitive enhancement purposes.","Cognitive memory assessments have historically depended on traditional paper-and-pencil approaches. However, the advent of virtual reality technology, encompassing adaptations of tests originally designed for animal research, has ushered in novel avenues for evaluating and augmenting attention and memory functions. The influence of immersive virtual environments on spatial memory remains a subject of active discussion. Contributing to this discourse, our research pursued two key goals. First, we sought to create a virtual reality instrument capable of effectively gauging search tactics employed by video game players within virtual settings. This objective led to the development of a virtual water maze, modeled after those used in animal studies. Second, we undertook a cross-sectional investigation, involving a diverse group of individuals, to examine how spatial memory strategies develop within a virtual environment as gaming experience accumulates. Our findings indicated that participants with greater gaming proficiency demonstrated swifter and more accurate learning within the virtual water maze, accompanied by enhanced search strategies. Moreover, our study facilitated the assessment of our software's capabilities and allowed us to monitor shifts in the effectiveness of learning strategies. In conclusion, this research underscores the significant potential of virtual environments for both assessment and cognitive enhancement purposes.",acceptable,acceptable,acceptable,3.6,3.6,3.6
23,Adaptation of virtual reality interfaces to psychological diagnosis and medical rehabilitation applications,"The challenge of increasing the efficiency of virtual reality interfaces in psychological diagnostic and medical rehabilitation applications is addressed. Implementation of a system for external monitoring of the psychoemotional state of users and monitoring the depth of their immersion based on computer vision technologies is proposed. As an illustrative example, adaptation of a rehabilitation procedure based on monitoring head movements and facial activity is described. Implementation of means for adapting virtual reality user interfaces produces some increase in the complexity of developing software and hardware for psychological diagnostic and medical rehabilitation systems, but at the same time expands the scope of their application due to more correct and evidence-based targeted use.","The problem of enhancing the effectiveness of virtual reality interfaces in psychological assessments and medical rehabilitation is tackled. A system for externally monitoring users’ psychoemotional states and the extent of their immersion using computer vision technologies is suggested. An example includes adapting a rehabilitation process by tracking head movements and facial expressions. Integrating methods to adapt virtual reality user interfaces does complicate the development of software and hardware for psychological diagnostics and medical rehabilitation, but it simultaneously broadens the application range by enabling more accurate and evidence-based targeted use.","""The optimization of virtual reality interfaces for psychological assessment and medical rehabilitation purposes is tackled by introducing a novel system that leverages computer vision to track users' emotional states and levels of immersion. A case in point is the adaptation of a rehabilitation protocol that utilizes head movement and facial expression analysis. While integrating these adaptive virtual reality interfaces may add a layer of intricacy to the development of software and hardware for psychological and medical applications, it ultimately broadens their applicability by enabling more precise and data-driven targeted interventions.""","This research tackles the issue of enhancing the effectiveness of virtual reality interfaces within the domains of psychological diagnostics and medical rehabilitation. A system leveraging computer vision is presented, designed to externally track users' psychoemotional states and their level of immersion. The adaptation of a rehabilitative process, reliant on monitoring head movements and facial expressions, is delineated as a practical demonstration. While the integration of adaptable VR interfaces elevates the intricacy of software and hardware development for these systems, it concurrently broadens their applicability by enabling more precise and evidence-supported targeted interventions.",acceptable,acceptable,acceptable,3.2,3.2,3.2
24,Investigating Educators’ and Students’ Perspectives on Virtual Reality Enhanced Teaching in Preschool,"Recent developments in technology have introduced new tools, such as virtual reality, into the learning process. Although virtual reality appears to be a promising technology for education and has been adopted by a few schools worldwide, we still do not know students’ and educators’ opinions, preferences, and challenges with it, particularly in relation to preschool education. Therefore, this study: (a) analyzes the preferences of 175 children aged 3 to 6 years regarding traditional teaching compared to enhanced teaching with virtual reality and (b) captures educators’ perspectives on virtual reality technology. This evaluation of virtual reality took place in 12 Greek preschool classrooms. A combination of quantitative and qualitative methods were used for data collection. Specifically, regarding the qualitative data collection, the study included semi-structured interviews with the participating educators, oriented by 2 axes: (a) preschoolers’ motivation and engagement in virtual reality activities, and (b) virtual reality technology prospects and difficulties as an educational tool in a real class. Regarding the quantitative data collection, specially designed questionnaires were used. Bootstrapping was utilized with 1000 samples to strengthen the statistical analysis. The analysis of the students’ responses indicated a statistically significant difference in preference in favor of virtual reality enhanced teaching compared to a traditional method. Statistically significant differences were also observed regarding gender. Furthermore, based on the educators’ answers and comments, difficulties were encountered initially but eventually, virtual reality was regarded as an effective approach for educational purposes. However, concerns arose among educators as to whether this technology could adequately promote preschoolers’ cooperative skills.","Advancements in technology have brought forth innovative tools like virtual reality into educational environments. While virtual reality shows potential benefits for learning and has been adopted by some schools globally, the opinions, preferences, and challenges faced by students and educators, particularly in preschool settings, remain unclear. This investigation: (a) evaluates the preferences of 175 children aged 3 to 6 for conventional teaching versus instruction enhanced with virtual reality, and (b) collects educators’ viewpoints on virtual reality's role in education. The assessment took place in 12 preschool classrooms in Greece, employing both quantitative and qualitative data collection methods. For qualitative data, semi-structured interviews with the educators focused on two main areas: (a) the children’s engagement and motivation during virtual reality activities, and (b) the potential and challenges of virtual reality as an instructional tool. Quantitative data were gathered through specially designed questionnaires, and the statistical analysis was reinforced using bootstrapping with 1000 samples. The analysis showed a statistically significant preference for virtual reality-enhanced teaching over traditional methods among the students, with notable differences across genders. Educators noted initial challenges but ultimately considered virtual reality an effective educational tool. However, they voiced concerns about its effectiveness in fostering cooperative skills among preschoolers.","Advances in technology have brought innovative resources, including immersive virtual reality, into the educational arena. Despite its promising potential and adoption by some schools globally, the views, preferences, and challenges of students and educators regarding this technology, particularly in the context of early childhood education, remain largely unknown. This investigation aims to: (a) examine the inclinations of 175 children aged 3-6 towards traditional instruction versus virtual reality-enriched learning, and (b) gather insights from educators on the application of virtual reality technology. This assessment was conducted in 12 Greek preschool settings, employing a mixed-methods approach that combined quantitative and qualitative data collection techniques. Semi-structured interviews with participating educators focused on two key dimensions: (a) the motivational and engaging aspects of virtual reality activities for young learners, and (b) the opportunities and hurdles of integrating virtual reality into real-world classrooms. Custom-designed questionnaires were used to gather quantitative data, which was subsequently strengthened through bootstrapping with 1000 samples. The analysis revealed a statistically significant preference among students for virtual reality-enhanced instruction over traditional methods, with notable differences observed according to gender. Furthermore, educators' responses and comments highlighted initial difficulties, but ultimately, virtual reality was deemed an effective educational tool. However, concerns were raised regarding its ability to foster cooperative skills in young children.","The integration of cutting-edge technologies like virtual reality (VR) into education holds immense potential, yet its practical implications in early childhood education remain largely unexplored. This study delves into the perceptions and experiences of both preschoolers and educators regarding VR-enhanced learning within 12 Greek preschools. A mixed-methods approach, encompassing questionnaires, semi-structured interviews, and robust statistical analysis, was employed. Findings reveal a notable predilection among children aged 3 to 6 for VR-integrated instruction over conventional methods, with gender-based preferences also emerging. While educators initially faced hurdles, they ultimately recognized VR's educational efficacy. Nevertheless, concerns persist regarding its capacity to foster collaborative skills among young learners.",acceptable,acceptable,acceptable,3.6,3.2,3.2
25,NestedChain: “Blockchain-inside-a-Blockchain” new generation prototype,"New developments of blockchain designs, for both research and commercial environments, focus on improving security and energy consumption. Indeed, these implementations are based on managing a single type of information linked to a single blockchain. In this paper, we propose a new design called NestedChain. This proposal creates a system that allows two completely different types of information to be held in the same physical structure, enabling the creation of a blockchain within a blockchain. The new blockchain design can be implemented in various environments where it is necessary to have two different and parallel sets of information in the same network infrastructure. This new conception of blockchain offers a new way to understand the limitations of existing implementations and suggests how the evolution of the blockchain environment could be enhanced.","Emerging innovations in blockchain designs, targeting both research and commercial sectors, aim to enhance security and reduce energy consumption. These advancements typically manage a single type of data associated with one blockchain. In this study, we introduce NestedChain, a novel design that facilitates the storage of two distinct types of information within the same physical structure, effectively creating a blockchain within a blockchain. This new configuration can be utilized in environments where maintaining two separate yet concurrent sets of information within the same network infrastructure is required. This reimagined blockchain approach not only clarifies the constraints of current implementations but also indicates potential improvements for the future development of the blockchain landscape.","""Innovative blockchain architectures, tailored for both academic and industrial settings, prioritize advancements in security and energy efficiency. Notably, current solutions rely on a single data type tied to a solitary blockchain. This paper introduces NestedChain, a novel paradigm that enables the coexistence of two disparate data categories within a unified physical framework, effectively nesting one blockchain within another. This groundbreaking design can be seamlessly integrated into diverse environments requiring the simultaneous management of two distinct, parallel information sets within a shared infrastructure. By rethinking the constraints of existing blockchain implementations, this concept paves the way for a more sophisticated and enhanced blockchain ecosystem.""","Recent advancements in blockchain architecture, spanning both academic and industrial spheres, prioritize enhanced security and reduced energy usage. Existing implementations, however, typically handle a single data type within a singular blockchain framework. In contrast, this article introduces NestedChain, an innovative design enabling the coexistence of two distinct data types within a unified physical structure, effectively establishing a ""blockchain within a blockchain."" This novel approach finds applicability across diverse environments requiring parallel yet distinct data sets within the same network, thereby offering a fresh perspective on the constraints of current blockchain implementations and potential avenues for future development.",acceptable,acceptable,acceptable,3.2,3.2,3.2
26,Advancements in scalability of blockchain infrastructure through IPFS and dual blockchain methodology,"Blockchain technology has gained widespread popularity due to its robust security features, making it an attractive solution for various applications such as cryptocurrency, healthcare, supply chain management, and asset administration. However, limited research has been conducted on the limitations and security issues associated with blockchain technology. In this research article, we focus on the key limitations of blockchain technology, namely, throughput and storage optimization. In this work, we address these issues by designing a faster and less storage-dependent blockchain system while maintaining the security and essential features of blockchain technology. By combining the dual blockchain concept with the Interplanetary File System (IPFS), a higher number of transactions can be accommodated within a single block. This leads to amplified throughput and diminished storage requirements. IPFS is harnessed to circumvent storage limitations and enhance overall transaction throughput. Our proposed system is implemented in real-time, resulting in significantly increased throughput and reduced storage requirements. Our findings demonstrate that this system is suitable for use in both cryptocurrencies and real-life applications.","Blockchain technology has become highly popular due to its strong security capabilities, making it a compelling choice for a variety of uses, such as digital currencies, healthcare, supply chain management, and asset management. Despite its popularity, there has been limited investigation into the constraints and security vulnerabilities of blockchain. This research paper aims to highlight the main drawbacks of blockchain technology, specifically throughput and storage efficiency. Our work tackles these challenges by developing a blockchain system that is both faster and less dependent on storage, while preserving the core security features. By integrating the dual blockchain model with the Interplanetary File System (IPFS), a greater volume of transactions can be processed within a single block. This results in enhanced throughput and reduced storage needs. Utilizing IPFS helps mitigate storage constraints and boosts the overall transaction rate. The proposed system is deployed in real-time, achieving significantly higher throughput and lower storage requirements, proving its effectiveness for both cryptocurrencies and practical applications.","The burgeoning appeal of blockchain technology stems from its impregnable security architecture, rendering it an ideal fit for diverse domains, including digital currencies, medical records management, logistics oversight, and asset governance. Despite its widespread adoption, however, the limitations and vulnerabilities inherent to blockchain technology have received scant attention from researchers. This study delves into the primary constraints of blockchain technology, specifically its throughput and storage capacity bottlenecks. To overcome these hurdles, we propose a novel blockchain framework that prioritizes speed and storage efficiency while preserving the core security features and integrity of the technology. By integrating the dual blockchain paradigm with the Interplanetary File System (IPFS), we can significantly boost the transaction capacity of individual blocks, thereby enhancing overall throughput and mitigating storage demands. The strategic deployment of IPFS enables us to bypass storage constraints and amplify transaction processing capabilities. Our real-time implementation yields substantial gains in throughput and reductions in storage requirements, rendering our system suitable for both cryptocurrency and real-world applications.","The extensive adoption of blockchain technology stems from its robust security infrastructure, rendering it suitable for diverse applications including digital currencies, healthcare, logistics, and asset management. Despite its prevalence, research on the shortcomings and vulnerabilities of blockchain remains limited. This study delves into two primary constraints of blockchain: transaction processing capacity and storage efficiency. We propose a novel blockchain system that mitigates these issues by enhancing speed and reducing storage dependency while upholding security and core functionalities. Leveraging a dual blockchain architecture in conjunction with the Interplanetary File System (IPFS), our system allows for a greater volume of transactions within each block. This results in improved throughput and decreased storage demands. IPFS is employed to overcome storage limitations and bolster overall transaction processing speed. The real-time implementation of our system showcases a significant increase in throughput and a reduction in storage requirements, suggesting its applicability for both cryptocurrencies and practical applications.",acceptable,acceptable,acceptable,3.2,3.2,3.2
27,Evolution of blockchain consensus algorithms: a review on the latest milestones of blockchain consensus algorithms,"Blockchain technology has gained widespread adoption in recent years due to its ability to enable secure and transparent record-keeping and data transfer. A critical aspect of blockchain technology is the use of consensus algorithms, which allow distributed nodes in the network to agree on the state of the blockchain. In this review paper, we examine various consensus algorithms that are used in blockchain systems, including proof-of-work, proof-of-stake, and hybrid approaches. We go over the trade-offs and factors to think about when choosing a consensus algorithm, such as energy efficiency, decentralization, and security. We also look at the strengths and weaknesses of each algorithm as well as their potential impact on the scalability and adoption of blockchain technology.","In recent times, blockchain technology has seen extensive adoption because of its capability to ensure secure and transparent data recording and transfer. A vital component of blockchain systems is the use of consensus mechanisms, which enable distributed nodes within the network to concur on the blockchain's status. This review paper explores several consensus mechanisms employed in blockchain technologies, such as proof-of-work, proof-of-stake, and hybrid models. We discuss the trade-offs and considerations in selecting a consensus mechanism, including energy consumption, decentralization, and security. Additionally, we assess the advantages and disadvantages of each mechanism and their potential effects on blockchain technology's scalability and widespread adoption.","The proliferation of blockchain technology in recent times can be attributed to its capacity to facilitate trustworthy and open data management and exchange. A pivotal component of this technology is the employment of consensus mechanisms, which enable dispersed network nodes to converge on a unified view of the blockchain's status. This review delves into an examination of diverse consensus mechanisms utilized in blockchain frameworks, encompassing proof-of-work, proof-of-stake, and hybrid methodologies. We scrutinize the compromises and considerations involved in selecting a consensus mechanism, including ecological sustainability, decentralization, and security assurances. Furthermore, we assess the advantages and disadvantages of each mechanism, as well as their potential influence on the scalability and widespread acceptance of blockchain technology.","Due to its capacity for secure and transparent data management and exchange, blockchain technology has experienced a surge in popularity in recent times. A core component of this technology is the implementation of consensus algorithms, which enable distributed network nodes to reach an agreement on the blockchain's state. This review paper delves into the diverse range of consensus algorithms employed in blockchain systems, encompassing proof-of-work, proof-of-stake, and hybrid models. We explore the inherent compromises and considerations involved in selecting a consensus algorithm, such as energy consumption, decentralization, and security. Furthermore, we analyze the advantages and disadvantages of each algorithm, alongside their potential influence on the scalability and widespread acceptance of blockchain technology.",acceptable,acceptable,acceptable,3.6,3.2,3.2
28,Kickstarting blockchain: designing blockchain-based tokens for equity crowdfunding,"Blockchain-based tokens seek to overcome the friction and opaqueness of the legacy financial infrastructure in the company funding process, particularly in the early-stage and equity crowdfunding domain. While Initial Coin Offerings and Security Token Offerings proposed a solution for crowdfunding, early-stage companies still face challenges in using blockchain as an alternative equity funding infrastructure. In this context, the idea of blockchain-based equity tokens remains hypothetical. In addition, the literature lacks design theory for the development and implementation of blockchain-based equity tokens. This research bridges this gap by designing, developing, and evaluating an equity token prototype for crowdfunding, following the design science research approach. We propose a refined crowdfunding model and derive seven design principles that contribute to the design theory of equity tokens. The research results show that blockchain-based equity tokens improve efficiency, transparency, and interoperability while meeting regulatory requirements and facilitating secondary market trading.","Blockchain tokens aim to mitigate the inefficiencies and lack of transparency inherent in traditional financial structures during the company funding process, especially in the realms of early-stage investments and equity crowdfunding. Although Initial Coin Offerings (ICOs) and Security Token Offerings (STOs) have offered crowdfunding solutions, startups still encounter difficulties when employing blockchain for equity funding. Consequently, the concept of blockchain equity tokens remains speculative. Moreover, existing literature does not provide design theories for creating and implementing these tokens. This study addresses this gap by crafting, developing, and assessing a prototype for equity tokens in crowdfunding, utilizing the design science research methodology. We introduce an improved crowdfunding framework and establish seven design principles that enhance the theoretical foundation of equity tokens. The findings demonstrate that blockchain-based equity tokens boost efficiency, ensure transparency, and promote interoperability, all while complying with regulatory standards and supporting secondary market trading.","""Novel digital assets built on blockchain technology aim to alleviate the inefficiencies and lack of transparency inherent in traditional corporate financing mechanisms, particularly in the realms of early-stage funding and equity-based crowdfunding. Although Initial Coin Offerings and Security Token Offerings have attempted to address these issues, nascent companies continue to encounter obstacles in leveraging blockchain as a viable alternative for equity financing. Consequently, the concept of blockchain-based equity tokens remains largely theoretical. Furthermore, existing literature fails to provide a comprehensive framework for the creation and implementation of such tokens. This study addresses this knowledge gap by designing, developing, and testing a prototype for equity tokens in crowdfunding, adhering to the principles of design science research. Our findings yield a refined crowdfunding paradigm and seven fundamental design principles that contribute to the theoretical foundation of equity tokens, demonstrating that blockchain-based equity tokens can enhance efficiency, transparency, and interoperability while satisfying regulatory requirements and facilitating secondary market liquidity.""","Leveraging the decentralized and transparent nature of blockchain technology, tokenized securities aim to revolutionize company financing, particularly for early-stage ventures and equity crowdfunding. Despite the emergence of ICOs and STOs as potential solutions, utilizing blockchain for alternative equity funding remains challenging for burgeoning companies, leaving the concept of blockchain-based equity tokens largely theoretical. Furthermore, the existing literature lacks a comprehensive framework for designing and implementing such tokens. Addressing this gap, this study employs a design science research methodology to conceptualize, build, and assess a prototype equity token specifically tailored for crowdfunding. We introduce an enhanced crowdfunding model and establish seven design principles that contribute to the theoretical foundation of equity tokens. The findings demonstrate that these tokens offer improved efficiency, transparency, and interoperability, while adhering to regulatory standards and facilitating secondary market transactions.",acceptable,acceptable,acceptable,3.6,3.6,3.6
29,A scalable blockchain storage scheme for VANET,"Intelligent transportation systems (ITSs) make it possible for applications such as autonomous driving, active safety systems and smart cities. As the infrastructure of ITSs, vehicular ad-hoc network (VANET) plays a key role in ensuring traffic safety while improving driving experience and comfort. However, VANET faces many challenges as the network is exposed to the public and involves sensitive information such as vehicle control commands and driving records. Although blockchain technology can provide such features as decentralization, immutability, non-reliance on trust and traceability, most of the existing blockchain systems impose high storage and computing capacity requirements for participating nodes while terminals nodes in VANET, such as road-side units (RSUs), on-board units (OBUs) and sensors, usually have very limited storage and computing capacity. To solve this problem, this paper proposes a blockchain system that provides scalable storage capacity for VANETs. The proposed scheme uses network sharding and multi-consensus strategy to improve the topology and consensus process of the blockchain. Aimed at lowering the storage requirement on the RSU nodes that participate in the blockchain, a collaborative storage mechanism and a dynamic copy number strategy for the blockchain ledger is designed. Experimental results show that compared to existing schemes, the proposed scalable blockchain storage scheme can significantly lower the storage requirement for the blockchain nodes, thus making it possible for the nodes with limited storage capacity in VANET to participate in the maintenance of the blockchain to prevent the blockchain from drifting towards centralization, and support maximal sharing of road traffic information while ensuring the security, privacy and trustworthiness of information.","Intelligent transportation systems (ITSs) enable technologies like autonomous driving, active safety systems, and smart cities. Vehicular ad-hoc network (VANET), as the backbone of ITSs, is crucial for traffic safety and enhancing driving comfort and experience. However, VANET encounters several challenges due to its public exposure and the sensitive nature of the information it handles, such as vehicle control commands and driving logs. While blockchain technology offers benefits like decentralization, immutability, trustlessness, and traceability, most current blockchain implementations demand substantial storage and computational power from participating nodes. This poses a problem for VANET's terminal nodes, such as road-side units (RSUs), on-board units (OBUs), and sensors, which typically have limited storage and computational capabilities. To address this issue, this paper presents a blockchain system designed to provide scalable storage capacity for VANETs. The proposed approach utilizes network sharding and a multi-consensus strategy to enhance the blockchain's topology and consensus process. A collaborative storage mechanism combined with a dynamic copy number strategy for the blockchain ledger is implemented to reduce the storage requirements on RSU nodes. Experimental results indicate that, compared to existing solutions, the proposed scalable blockchain storage scheme drastically reduces the storage demands on blockchain nodes, enabling those with limited storage capacity in VANET to participate in blockchain maintenance. This prevents the blockchain from becoming centralized and supports the extensive sharing of road traffic information while ensuring the security, privacy, and trustworthiness of the data.","The advent of intelligent transportation systems (ITSs) has paved the way for innovative applications like autonomous vehicles, advanced safety features, and smart urban infrastructure. At the heart of ITSs lies vehicular ad-hoc networks (VANETs), which play a crucial role in enhancing traffic safety, driving comfort, and overall experience. However, the open nature of VANETs and the sensitivity of transmitted data, including vehicle control commands and driving records, pose significant security risks. While blockchain technology offers a promising solution with its decentralized, immutable, and transparent characteristics, most existing blockchain systems are resource-intensive, making them incompatible with the limited storage and computing capacities of VANET terminals, such as road-side units, on-board units, and sensors. To address this challenge, this paper presents a novel blockchain system designed specifically for VANETs, featuring a scalable storage architecture that leverages network sharding and multi-consensus strategies to optimize topology and consensus processes. By introducing a collaborative storage mechanism and dynamic ledger replication strategy, the proposed system significantly reduces storage requirements for participating nodes, enabling even resource-constrained VANET terminals to contribute to blockchain maintenance and ensuring the secure, private, and trustworthy sharing of road traffic information.","Vehicular ad-hoc networks (VANETs), which serve as the foundation for smart transportation systems enabling advancements like self-driving cars, safety features, and interconnected cities, face significant security and privacy challenges due to their public nature and the sensitive data they handle. Blockchain technology, with its inherent decentralization, immutability, and traceability, offers a potential solution. However, conventional blockchain systems demand substantial storage and processing power, which is often beyond the capabilities of resource-constrained VANET devices like roadside units (RSUs), onboard units (OBUs), and sensors. To address this, this study introduces a novel blockchain framework designed for scalable storage within VANETs. This framework leverages network partitioning and a multi-consensus approach to optimize the blockchain's structure and consensus mechanism. To minimize storage demands on participating RSU nodes, a collaborative storage system and a dynamic replication strategy for the blockchain ledger are employed. Evaluations demonstrate that this scalable storage solution significantly reduces storage requirements for blockchain nodes compared to existing methods, enabling resource-limited VANET devices to participate in blockchain maintenance, preventing centralization, and promoting secure and trustworthy sharing of traffic data.",acceptable,acceptable,acceptable,3.6,3.2,3.2
30,Blockchain-Technologie im Supply Chain Management – Anwendungspotenziale und Kompetenzlücken,"Unternehmen und anwendungsorientierte Forschung weisen der Blockchain-Technologie enorme Potenziale in diversen Sektoren zu. Besonders erfolgversprechend erscheint dabei der Einsatz von Blockchain-Technologien im Kontext des Supply Chain-Managements, da hiermit die Effizienz, die Transparenz und das Vertrauen zwischen den unterschiedlichen Akteuren über die gesamte Lieferkette gesteigert werden können. Ein Erfolgsfaktor für die Einführung und den Betrieb produktiver Blockchain-Lösungen bildet dabei ein adäquates Kompetenzmanagement, mit dem sichergestellt wird, dass die Mitarbeiter die notwendigen Fähigkeiten und Kenntnisse besitzen. Bestehende Kompetenzrahmen umfassen zwar eine Vielzahl digitaler Kompetenzen, jedoch adressieren diese bislang keine dedizierten Kompetenzen zum Einsatz von Blockchain-Technologien. Dieses Defizit wird mit dem vorliegenden Beitrag aufgegriffen, indem aufbauend auf einer kurzen Einführung und Darstellung der Blockchain-Technologie deren Anwendungspotenziale im Supply Chain-Management identifiziert werden. Anschließend wird ein Kompetenzrahmen zum Blockchain-basierten Supply Chain-Management entwickelt. Schließlich werden Kompetenzlücken in der Praxis aufgezeigt, Handlungsempfehlungen für Unternehmen formuliert sowie eine Schlussbetrachtung durchgeführt.","Unternehmen und praxisorientierte Forschung sehen in der Blockchain-Technologie großes Potenzial in verschiedenen Branchen. Besonders vielversprechend erscheint die Anwendung von Blockchain im Bereich des Supply Chain Managements, da sie die Effizienz, Transparenz und das Vertrauen zwischen den verschiedenen Beteiligten entlang der gesamten Lieferkette verbessern kann. Ein entscheidender Erfolgsfaktor für die Einführung und den Betrieb effektiver Blockchain-Lösungen ist ein geeignetes Kompetenzmanagement, das sicherstellt, dass die Mitarbeiter über die erforderlichen Fähigkeiten und Kenntnisse verfügen. Obwohl bestehende Kompetenzrahmen eine Vielzahl digitaler Kompetenzen abdecken, berücksichtigen sie bisher keine speziellen Fähigkeiten für den Einsatz von Blockchain-Technologien. Dieses Manko wird in dem vorliegenden Beitrag behandelt, indem nach einer kurzen Einführung und Darstellung der Blockchain-Technologie deren Anwendungsmöglichkeiten im Supply Chain Management aufgezeigt werden. Daraufhin wird ein Kompetenzrahmen für blockchainbasiertes Supply Chain Management entwickelt. Abschließend werden bestehende Kompetenzlücken in der Praxis analysiert, Handlungsempfehlungen für Unternehmen vorgestellt und eine abschließende Betrachtung durchgeführt.","""Companies and application-oriented research attribute immense potential to blockchain technology across various sectors. The deployment of blockchain technology in supply chain management appears particularly promising, as it can enhance efficiency, transparency, and trust among diverse stakeholders throughout the entire supply chain. A crucial success factor for introducing and operating productive blockchain solutions lies in adequate competence management, ensuring that employees possess the necessary skills and knowledge. While existing competence frameworks encompass a range of digital skills, they currently fail to address dedicated competencies for blockchain technology deployment. This gap is addressed in this contribution, which identifies blockchain technology's application potential in supply chain management following a brief introduction and overview. A competence framework for blockchain-based supply chain management is then developed, and competence gaps in practice are highlighted, along with recommendations for companies and a concluding reflection.""","In vielen Branchen erkennen Unternehmen und praxisorientierte Forschung das enorme Potenzial der Blockchain-Technologie. Insbesondere im Bereich des Supply Chain Managements verspricht der Einsatz dieser Technologie signifikante Verbesserungen in puncto Effizienz, Transparenz und Vertrauen zwischen den verschiedenen Akteuren entlang der gesamten Lieferkette. Für die erfolgreiche Implementierung und den Betrieb leistungsfähiger Blockchain-Lösungen ist ein angemessenes Kompetenzmanagement von entscheidender Bedeutung, um sicherzustellen, dass die Mitarbeiter über die erforderlichen Fähigkeiten und Kenntnisse verfügen. Obwohl bestehende Kompetenzrahmen eine Bandbreite digitaler Kompetenzen abdecken, fehlt es bisher an spezifischen Kompetenzen für den Einsatz von Blockchain-Technologien. Dieser Beitrag adressiert diesen Mangel, indem er nach einer kurzen Einführung in die Blockchain-Technologie und deren Funktionsweise die Anwendungsmöglichkeiten im Supply Chain Management aufzeigt. Darauf aufbauend wird ein Kompetenzrahmen für Blockchain-basiertes Supply Chain Management entwickelt. Abschließend werden Kompetenzdefizite in der Praxis beleuchtet, Handlungsempfehlungen für Unternehmen formuliert und eine Schlussfolgerung gezogen.",acceptable,acceptable,acceptable,3.2,3.2,3.2
31,Blockchain-Enabled land management systems,"Land registration system is a very critical component of a revenue department as it holds the record of lands and their owners. In many countries, land records are stored in paper form at centralized locations, making them vulnerable to forgery. Moreover, the centralized system has performance bottleneck, non-transparency, double-spending problems, and a single point of failure. Such issues lead to corruption and conflicts. Recently, Blockchain has been conceived as a technology having the potential to implement and enforce critical security requirements in land revenue systems. With Blockchain, the common issues in revenue systems, such as forgery, falsification, misrepresentation, and human-induced anomalies in records at various levels/stages, can be prevented. The focus of this research is to identify the relationship between Blockchain technology and the land administration system. We discuss issues with current paper-based centralized systems. The potential benefits of Blockchain technology in land management systems are also examined. We present the comparisons of state-of-the-art solutions along with their problems in detail. Finally, research challenges and future directions in Blockchain-enabled land management systems are explored.","A land registration system is an essential element of a revenue department since it maintains the record of land ownership. In numerous nations, these records are documented on paper and kept at central repositories, making them susceptible to tampering. Furthermore, centralization results in performance inefficiencies, lack of transparency, double-spending issues, and a single point of failure, which can foster corruption and disputes. Recently, Blockchain technology has been recognized as having the potential to fulfill crucial security needs in land revenue systems. Blockchain could address common revenue system problems, such as tampering, misrepresentation, and human errors at various levels. This study aims to explore the link between Blockchain technology and land administration. It details the flaws of current paper-based centralized systems and examines the potential advantages of Blockchain in land management. Comparisons are provided for the latest solutions and their associated issues. Finally, the research discusses challenges and future directions for Blockchain-based land management systems.","""A robust land registration framework is essential for a revenue department, as it serves as a repository of land ownership information. However, traditional paper-based systems, often housed in central locations, are susceptible to tampering and plagued by inefficiencies, opacity, and single-point failures, which can lead to corruption and disputes. The emergence of Blockchain technology offers a promising solution to address these vulnerabilities by ensuring the integrity and security of land records, thereby preventing fraudulent activities, data manipulation, and human errors. This study investigates the nexus between Blockchain technology and land administration systems, highlighting the limitations of current centralized systems and exploring the advantages of Blockchain-based land management systems. A comprehensive analysis of existing solutions and their drawbacks is presented, along with an examination of the challenges and future directions in harnessing Blockchain technology for efficient land management.""","A key element of any revenue department is its land registration system, acting as a repository of land ownership information. However, many nations rely on centralized, paper-based land records, leaving them susceptible to fraudulent activities. This centralized approach also suffers from inefficiencies, a lack of transparency, potential for double-spending, and vulnerability to system-wide failures, all of which can breed corruption and disputes. Blockchain technology has emerged as a potential solution for strengthening security in land revenue systems. By leveraging Blockchain, common issues like forgery, falsification, misrepresentation, and human error at various levels can be mitigated. This study delves into the interplay between Blockchain technology and land administration. It analyzes the shortcomings of existing paper-based, centralized systems and explores the potential advantages of incorporating Blockchain into land management. A comparative analysis of current technological solutions, including their limitations, is presented. Finally, the research identifies challenges and future directions for Blockchain-powered land management systems.",acceptable,acceptable,acceptable,3.2,3.2,3.2
32,Olympus: a GDPR compliant blockchain system,"Blockchain has been gaining significant interest in several domains. However, this technology also raises relevant challenges, namely in terms of data protection. After the General Data Protection Regulation (GDPR) has been published by the European Union, companies worldwide changed the way they process personal data. This project provides a model and implementation of a blockchain system to store personal data complying with GDPR. We examine the advantages and challenges and evaluate the system. We use Hyperledger Fabric as blockchain, Interplanetary File System to store personal data off-chain, and a Django REST API to interact with both the blockchain and the distributed file system. Olympus has three possible types of users: Data Subjects, Data Processors and Data Controllers and a fourth participant, Supervisor Authority, that, despite not being an explicit role, can perform all verifications that GDPR mandates. We conclude that it is possible to create a system that overcomes the major challenges of storing personal data in a blockchain (Right to be Forgotten and Right to Rectification), while maintaining its desirable characteristics (auditability, verifiability, tamper resistance, distributed—remove single points of failure) and complying with GDPR.","Several sectors have shown a growing interest in blockchain technology, though it also introduces considerable challenges, particularly regarding data privacy. Following the European Union's establishment of the General Data Protection Regulation (GDPR), global companies altered their personal data processing methods. This project offers a model and implementation for a blockchain system designed to store personal data in compliance with GDPR. We explore the benefits and difficulties, and assess the system's performance. The project utilizes Hyperledger Fabric for blockchain, the Interplanetary File System for off-chain personal data storage, and a Django REST API to facilitate communication between the blockchain and the distributed file system. Olympus identifies three user roles: Data Subjects, Data Processors, and Data Controllers, and includes a fourth entity, Supervisory Authority, which, though not an explicit role, can conduct all GDPR-required verifications. Our findings indicate that it is feasible to develop a system addressing the principal issues of storing personal data on a blockchain, such as the Right to be Forgotten and Right to Rectification, while preserving essential features like auditability, verifiability, tamper resistance, decentralized architecture, and GDPR compliance.","Across various industries, blockchain technology has garnered substantial attention, yet it also presents notable hurdles, particularly with regard to safeguarding sensitive information. Following the European Union's introduction of the General Data Protection Regulation (GDPR), companies globally have revamped their approach to handling personal data. This project develops and implements a blockchain-based system for storing personal data in compliance with GDPR regulations. We assess the benefits and drawbacks of this system, which leverages Hyperledger Fabric as the blockchain framework, Interplanetary File System for off-chain data storage, and a Django REST API to facilitate interactions between the blockchain and distributed file system. The Olympus system accommodates four distinct roles: Data Subjects, Data Processors, Data Controllers, and the Supervisor Authority, which, although not an explicit role, is responsible for conducting all GDPR-mandated verifications. Ultimately, our findings suggest that it is feasible to design a system that surmounts the primary challenges associated with storing personal data on a blockchain (namely, the Right to be Forgotten and Right to Rectification), while preserving its desirable attributes (auditability, verifiability, tamper resistance, and decentralization).","The increasing popularity of blockchain technology across various fields has been accompanied by significant data protection concerns. The European Union's General Data Protection Regulation (GDPR) prompted global companies to revamp their personal data processing practices. This initiative presents a GDPR-compliant model and implementation of a blockchain system for personal data storage. Through an evaluation of the system's strengths and limitations, we demonstrate its feasibility. The system leverages Hyperledger Fabric as the blockchain framework, the Interplanetary File System for off-chain personal data storage, and a Django REST API to facilitate interactions with both the blockchain and the distributed file system. Olympus accommodates three user types: Data Subjects, Data Processors, and Data Controllers. A fourth participant, the Supervisor Authority, while not an explicit role, is empowered to conduct all GDPR-mandated verifications. Our findings suggest that it is feasible to develop a system that addresses the key challenges of storing personal data on a blockchain (Right to be Forgotten and Right to Rectification) while preserving its advantageous attributes (auditability, verifiability, tamper resistance, and distributed nature for single point of failure elimination) and adhering to GDPR requirements.",acceptable,acceptable,acceptable,3.2,3.2,3.2
33,Blockchain meets machine learning: a survey,"Blockchain and machine learning are two rapidly growing technologies that are increasingly being used in various industries. Blockchain technology provides a secure and transparent method for recording transactions, while machine learning enables data-driven decision-making by analyzing large amounts of data. In recent years, researchers and practitioners have been exploring the potential benefits of combining these two technologies. In this study, we cover the fundamentals of blockchain and machine learning and then discuss their integrated use in finance, medicine, supply chain, and security, including a literature review and their contribution to the field such as increased security, privacy, and decentralization. Blockchain technology enables secure and transparent decentralized record-keeping, while machine learning algorithms can analyze vast amounts of data to derive valuable insights. Together, they have the potential to revolutionize industries by enhancing efficiency through automated and trustworthy processes, enabling data-driven decision-making, and strengthening security measures by reducing vulnerabilities and ensuring the integrity of information. However, there are still some important challenges to be handled prior to the common use of blockchain and machine learning such as security issues, strategic planning, information processing, and scalable workflows. Nevertheless, until the difficulties that have been identified are resolved, their full potential will not be achieved.","Blockchain and machine learning are two swiftly advancing technologies being increasingly adopted across various sectors. Blockchain ensures secure and transparent transaction recording, while machine learning facilitates data-driven decisions through extensive data analysis. Recently, there has been a surge in exploring the combined advantages of these technologies. This study outlines the basics of blockchain and machine learning and examines their integration in finance, healthcare, supply chains, and security, including a literature review emphasizing their contributions like enhanced security, privacy, and decentralization. Blockchain supports secure, transparent, decentralized records, while machine learning processes significant data volumes for insightful analysis. Their synergy holds the promise of revolutionizing industries by boosting efficiency via automated and reliable systems, fostering data-informed decisions, and reinforcing security by minimizing vulnerabilities and maintaining data integrity. Nonetheless, to fully leverage blockchain and machine learning, challenges such as security concerns, strategic planning, information processing, and scalability must be addressed. Until these challenges are overcome, their complete potential remains unrealized.","The convergence of blockchain and machine learning, two burgeoning technologies, is transforming diverse sectors by harnessing their synergistic potential. Blockchain's decentralized ledger technology ensures the integrity and transparency of transaction records, whereas machine learning's analytical capabilities facilitate informed decision-making by processing vast datasets. Recent explorations have delved into the advantages of integrating these technologies, and this study provides a comprehensive overview of their fundamental principles and interdisciplinary applications in finance, healthcare, logistics, and security. A thorough literature review highlights their collective contributions, including enhanced security, privacy, and decentralization. The fusion of blockchain's secure, decentralized record-keeping and machine learning's data-driven insights has the potential to revolutionize industries by streamlining processes, fostering trust, and fortifying security measures. However, several hurdles, including security vulnerabilities, strategic planning, data processing, and scalable implementation, must be addressed before their widespread adoption can be realized.","Two burgeoning technologies, blockchain and machine learning, are rapidly transforming diverse sectors. While blockchain offers a secure and transparent system for transaction recording, machine learning facilitates data-driven insights through large-scale data analysis. The synergistic potential of these technologies has become a focal point for researchers and practitioners alike. This work delves into the core principles of both blockchain and machine learning, followed by an exploration of their combined applications in finance, healthcare, supply chain management, and security. Through a comprehensive literature review, the study highlights the benefits of integration, including enhanced security, privacy, and decentralization. Blockchain's decentralized and immutable record-keeping capabilities, coupled with machine learning's ability to extract valuable insights from massive datasets, hold the promise of revolutionizing industries. This integration can lead to increased efficiency through automated and trustworthy processes, data-driven decision-making, and fortified security measures that mitigate vulnerabilities and ensure data integrity. However, several challenges, such as security concerns, strategic planning, information processing, and scalable workflow development, need to be addressed before widespread adoption can occur. Overcoming these hurdles is crucial for unlocking the full potential of blockchain and machine learning.",acceptable,acceptable,acceptable,3.2,3.2,3.2
34,IoT-based eHealth using blockchain technology: a survey,"The eHealth sector has witnessed significant growth due to technological advancements, facilitating care delivery in patients' homes and moving away from traditional hospital settings. Blockchain and the Internet of Things (IoT) play pivotal roles in enhancing healthcare services, offering features such as remote patient monitoring, streamlined electronic medical record (EMR) management, drug traceability, and effective disease control, particularly during events like the COVID-19 pandemic. The growing utilization of IoT devices brings about security challenges, including concerns related to data integrity and device authentication. This paper proposes the integration of blockchain technology as a robust solution. Leveraging its decentralized and tamper-resistant features, blockchain establishes trust among diverse IoT devices, ensuring the integrity of IoT data. Additionally, smart contracts enhance device authentication, fortifying overall security by addressing vulnerabilities associated with centralization. Regarding the management of eHealth, this survey begins with an overview of the industry, highlighting IoT-related challenges in healthcare. It explores various IoT applications in eHealth and discusses how blockchain can effectively address obstacles in healthcare management through IoT. Notably, the paper provides insights into examining consensus algorithm parameters within blockchain systems, clarifying the methodology used to assess and optimize these critical components. The survey extends to a thorough review of existing research on integrating blockchain-based IoT in eHealth. Finally, it presents an overview of challenges and potential solutions for implementing blockchain-based IoT in the eHealth sector. This comprehensive survey aims to empower stakeholders by providing insights to enhance patient care in this dynamic and evolving field.","The eHealth industry has experienced considerable expansion driven by technological progress, enabling care provision within patients' homes rather than conventional hospital environments. Blockchain and the Internet of Things (IoT) are crucial in improving healthcare services, offering capabilities such as remote patient monitoring, efficient management of electronic medical records (EMRs), drug traceability, and effective disease control, especially during events like the COVID-19 pandemic. However, the increasing adoption of IoT devices brings about security issues, including concerns regarding data integrity and device authentication. This paper suggests incorporating blockchain technology as a robust solution. Utilizing its decentralized and tamper-proof characteristics, blockchain fosters trust among various IoT devices, ensuring the integrity of IoT data. Moreover, smart contracts improve device authentication, enhancing overall security by mitigating centralization vulnerabilities. This survey begins with an overview of the eHealth industry, highlighting IoT-related healthcare challenges. It examines several IoT applications in eHealth and discusses how blockchain can effectively address hurdles in healthcare management through IoT. The paper also offers insights into analyzing consensus algorithm parameters in blockchain systems, explaining the methodology for evaluating and optimizing these essential components. The survey includes a comprehensive review of current research on the integration of blockchain-based IoT in eHealth. Finally, it outlines the challenges and potential solutions for implementing blockchain-based IoT in the eHealth sector, aiming to provide stakeholders with insights to improve patient care in this evolving field.","The digital health industry has experienced remarkable expansion, driven by innovative technologies that enable remote patient care and shift the focus away from conventional hospital-based treatment. The convergence of blockchain and the Internet of Things (IoT) has revolutionized healthcare services, offering a range of benefits, including real-time patient monitoring, efficient electronic health record management, pharmaceutical supply chain tracking, and effective disease surveillance, particularly during crises like the COVID-19 pandemic. However, the increasing adoption of IoT devices has raised concerns about data security and authentication. This study proposes the integration of blockchain technology as a robust solution, leveraging its decentralized and tamper-evident architecture to establish trust among diverse IoT devices and ensure the integrity of IoT-generated data. Furthermore, smart contracts enhance device authentication, mitigating vulnerabilities associated with centralized systems. This comprehensive review provides an in-depth examination of the eHealth industry, highlighting IoT-related challenges and exploring the potential of blockchain technology to address these obstacles. The study delves into the assessment and optimization of consensus algorithm parameters, providing valuable insights into the methodology used. A thorough analysis of existing research on blockchain-based IoT integration in eHealth is also presented, along with an overview of the challenges and potential solutions for implementing this technology in the sector, ultimately aiming to inform stakeholders and improve patient outcomes in this rapidly evolving field.","Driven by technological progress, the eHealth domain has experienced substantial expansion, enabling healthcare delivery within patients' residences and shifting away from conventional hospital environments. Technologies like blockchain and the Internet of Things (IoT) are instrumental in improving healthcare services, offering capabilities such as remote patient observation, efficient electronic health record (EHR) handling, medication tracking, and effective disease management, especially during crises like the COVID-19 pandemic. However, the increasing use of IoT devices introduces security concerns, particularly regarding data reliability and device validation. This study proposes incorporating blockchain technology as a potent solution. Utilizing its decentralized and immutable characteristics, blockchain fosters trust among various IoT devices, guaranteeing the integrity of IoT data. Moreover, smart contracts enhance device verification, strengthening overall security by addressing vulnerabilities linked to centralized systems. This review commences with an eHealth industry overview, emphasizing IoT-related healthcare challenges. It examines various IoT applications within eHealth and analyzes how blockchain can effectively overcome obstacles in healthcare management via IoT. Significantly, the study provides insights into evaluating consensus algorithm parameters within blockchain systems, elucidating the methodology employed to assess and optimize these crucial elements. The review encompasses a comprehensive examination of existing research on integrating blockchain-based IoT in eHealth. Finally, it presents an overview of challenges and potential solutions for implementing blockchain-based IoT in the eHealth sector. This comprehensive review aims to equip stakeholders with insights to improve patient care in this rapidly evolving and dynamic field.",acceptable,acceptable,acceptable,3.6,3.2,3.6
35,Mapping the landscape of blockchain technology: a bibliometric analysis,"Blockchain technology has experienced a meteoric rise in popularity, revolutionising industries and igniting intense research efforts around the world. The intellectual environment surrounding research on blockchain technology has been meticulously analysed in this bibliometric paper. We seek to shed light on the major trends, research themes, and key contributors influencing the blockchain research domain by utilising comprehensive bibliometric data from Dimension.ai (An Open Access Database). Our analysis spans between the year 2019 to July 2023 and includes a wide range of scholarly articles. Initially, a screening process was employed to assess 16,479 published articles against our inclusion criteria based on keyword search. Finally, 11,593 articles met the criteria and were included in our analysis. We offer a thorough overview of the development and dynamics of blockchain research using bibliometric indicators like publication counts, citation counts, co-authorship networks, and patterns of international collaboration, with visualizations generated using VOSviewer. Furthermore, our analysis highlights the distribution of research efforts distributed globally, demonstrating the participation of various nations and institutions. We investigate the degree of international cooperation, illuminating the global interconnectedness of researchers in the advancement of blockchain knowledge. In conclusion, this paper provides a thorough overview of the state of the research on blockchain technology, offering insightful information to both academics and business stakeholders. This paper elucidates the evolution of research on blockchain technology by outlining the intellectual landscape, and it also provides a road map for future efforts to realise the transformative potential of blockchain technology.","The rapid ascent of blockchain technology has significantly transformed various sectors and sparked vigorous global research initiatives. This bibliometric study meticulously examines the intellectual milieu of blockchain research. By leveraging extensive bibliometric data from Dimension.ai, an open access database, we aim to uncover major trends, predominant research themes, and key contributors within the blockchain research landscape. Our analysis, covering the period from 2019 to July 2023, encompasses a broad spectrum of scholarly articles. Initially, a screening of 16,479 published works was conducted based on specified keywords, subsequently narrowing down to 11,593 articles that met our inclusion criteria. We provide a comprehensive overview of blockchain research development and dynamics through bibliometric indicators such as publication and citation counts, co-authorship networks, and international collaboration patterns, with visualizations created using VOSviewer. Additionally, the analysis highlights the global distribution of research efforts, showcasing the involvement of various countries and institutions. We explore the extent of international collaboration, revealing the global connectivity among researchers in blockchain advancement. Ultimately, this paper presents an exhaustive overview of the current state of blockchain research, offering valuable insights to both scholars and industry stakeholders. It elucidates the progression of blockchain research, mapping out the intellectual domain and suggesting pathways for future endeavors to harness the transformative capabilities of blockchain technology.","The blockchain phenomenon has witnessed an exponential surge in global attention, catalyzing a paradigm shift across industries and fuelling fervent academic inquiry worldwide. This bibliometric study undertakes a meticulous examination of the intellectual ecosystem surrounding blockchain research, aiming to illuminate the dominant patterns, thematic priorities, and influential thought leaders shaping the blockchain knowledge domain. Leveraging an exhaustive dataset from Dimension.ai, an open-access repository, our investigation spans from 2019 to July 2023, encompassing a diverse array of scholarly publications. Following a rigorous screening process, 11,593 articles out of 16,479 were deemed eligible based on keyword search criteria. Our analysis employs a range of bibliometric metrics, including publication frequencies, citation rates, co-authorship networks, and international collaboration patterns, visualized using VOSviewer. The study also maps the global distribution of research endeavours, highlighting the contributions of various nations and institutions. Furthermore, we probe the extent of international cooperation, revealing the intricate web of global connections among researchers driving blockchain innovation. Ultimately, this paper presents a comprehensive snapshot of the blockchain research landscape, offering actionable insights for both academic and industry stakeholders, while charting a course for future initiatives to unlock the transformative power of blockchain technology.","The rapid growth of blockchain technology has sparked widespread interest and fueled extensive research globally. This bibliometric study meticulously examines the scholarly landscape surrounding blockchain, employing comprehensive data from Dimension.ai to identify key trends, research areas, and influential contributors from 2019 to July 2023. From an initial pool of 16,479 articles, 11,593 met the inclusion criteria for analysis. Utilizing bibliometric indicators such as publication and citation counts, co-authorship networks, and international collaborations, visualized through VOSviewer, this paper offers a comprehensive understanding of the development and dynamism within blockchain research. It sheds light on the global distribution of research efforts, showcasing the participation of diverse countries and institutions. By investigating the extent of international collaboration, the study illuminates the interconnectedness of researchers worldwide in advancing blockchain knowledge. In summary, this paper provides a detailed snapshot of the current state of blockchain research, offering valuable insights for both academic and industry stakeholders. It not only maps the intellectual terrain of blockchain research but also charts a course for future endeavors aiming to unlock the revolutionary potential of this technology.",acceptable,acceptable,acceptable,4.0,3.2,4.0
36,Salsal: blockchain for vetting cultural object collections,"Many modern cultural object collections suffer from the problem of being obtained in unethical and illegal circumstances. Additionally, information about collections, including their status, object descriptions, and other data need up-to-date information presented to users. We propose a novel blockchain tool called Salsal that enables the vetting of objects, individually or as part of more extensive collections, to meet required ethical and legal guidelines while informing users about relevant information regarding collections. Blockchain provides a better and more rapid way for users to know about collections using a decentralized and immutable ledger technology. Blockchain can be used to incentivize or even pressure collections to vet their objects for ethical and legal guidelines that can benefit the public who use object collections. The prototype software we have made is presented and compared to other blockchains, with code and demonstration provided. We present how our blockchain can enable benefit, providing a useful vetting process for cultural objects, and allowing a user community to contribute to collections in a transparent and secure manner.","Numerous contemporary cultural collections face issues due to acquisition under unethical and unlawful conditions. Furthermore, up-to-date information on collections, including their status, object descriptions, and other associated data, is essential for users. Our innovative blockchain tool, Salsal, proposes a solution by facilitating the verification of objects, either individually or as part of larger collections, ensuring compliance with ethical and legal standards while delivering pertinent collection information to users. Utilizing decentralized and immutable ledger technology, blockchain offers a superior and faster method for users to access information about collections. It can incentivize or exert pressure on collections to authenticate their objects according to ethical and legal criteria that benefit the public. We introduce our prototype software, complete with code and a demonstration, and compare it to other blockchain technologies. Our blockchain aims to provide a beneficial vetting process for cultural objects, promoting transparency and security, and allowing the user community to actively contribute to collections.","Numerous contemporary cultural repositories are plagued by the issue of acquiring artifacts through illicit and unethical means. Furthermore, users require access to up-to-date information about these collections, including their provenance, item descriptions, and supplementary data. To address this, we introduce Salsal, a pioneering blockchain-based solution that facilitates the verification of individual objects or entire collections against established ethical and legal standards, while providing users with pertinent information about these collections. By leveraging decentralized and immutable ledger technology, blockchain enables rapid and secure dissemination of information about collections to users. This technology can also be utilized to encourage or compel collections to adhere to ethical and legal guidelines, ultimately benefiting the public that engages with these repositories. Our prototype software is showcased, benchmarked against other blockchain solutions, and accompanied by code and a demonstration. We demonstrate how our blockchain can foster a transparent and secure environment, empowering a community of users to contribute to cultural collections while ensuring a rigorous vetting process for artifacts.","Numerous contemporary collections of cultural artifacts are marred by provenance issues, often acquired through illicit or ethically questionable means. Moreover, these collections frequently lack comprehensive and current documentation, encompassing their status, object details, and other pertinent information. To address these challenges, we introduce Salsal, a pioneering blockchain-based solution. Salsal facilitates the scrutiny of individual objects or entire collections, ensuring compliance with ethical and legal standards while disseminating relevant information to users. Leveraging the decentralized and immutable nature of blockchain technology, Salsal provides a more efficient and transparent means for users to access collection data. Furthermore, it can incentivize or even compel collections to undergo ethical and legal vetting, ultimately benefiting the public who engage with these artifacts. Our prototype software is presented alongside a comparative analysis of existing blockchain solutions, with accompanying code and demonstration. We elaborate on how our blockchain can facilitate a valuable vetting process for cultural objects, empowering a user community to contribute to collections in a secure and transparent manner.",acceptable,acceptable,acceptable,3.6,3.6,3.2
37,Decentralization System Using Smart Blockchain with Secure Hash,"Blockchain decentralization is a reference to decision making and transferring of data control. It is derived as a distributed network from a centralized network, either in an individual, organization, or group. The decentralized system reduces the user’s trust level, which has to be shown by one another. Instead, they confine the functionality of the system network to be degraded. This determines the ability to control the decentralized system using smart contracts. In this paper, we propose a blockchain decentralization system on the smart contracts produced by the blocks. This is called smart blockchain. Smart blockchain or Smart chain is the new generation of blockchain network that allows one or more than a smart contract. The decentralized system of smart contracts here collects the data accurately and flawlessly. The decentralized nature of smart blockchain ensures that there is no single point of control or failure, making it resistant to tampering, hacking, and other malicious activities. Simultaneously this decentralization method helps store and register the data in new blocks. The complete process of a transaction is automatic, without any human interaction. The blockchain used in networks like Ethereum, etc., can be entirely replaced by the smart blockchain or smart chain. The deployment and registration done in smart contracts are overcome with the smart blockchain. We have worked on the four processes in this paper. They are new_block, new_transaction, last_block, and hash. Using the flask framework, the requests are communicated and satisfied on the HTTP Protocol. The further assessment of this decentralized system enabling the smart blockchain can bring a difference in application research, such as Smart Homes using IoT Technology. Smart blockchain technology evaluates security, complexity, privacy, integrity, and implementation protocols. Additionally, we experimentally show the protocols’ outperformance towards multiple blocks of a blockchain.","Blockchain decentralization refers to the distribution of decision-making and control over data. It evolves from a centralized structure, whether it involves an individual, organization, or group, into a distributed network. In a decentralized system, user trust does not have to be placed in one another; rather, the functionality of the network is limited. This allows for the control of the decentralized system via smart contracts. This paper introduces a blockchain decentralization approach based on smart contracts linked to blocks, known as a smart blockchain. Smart blockchain, or Smart chain, represents the next evolution of blockchain technology, enabling the use of multiple smart contracts. This decentralized system of smart contracts ensures precise and flawless data collection. The decentralized characteristic of smart blockchain eliminates single points of control or failure, enhancing resilience against tampering, hacking, and other malicious activities. Simultaneously, this decentralization strategy supports the storage and registration of data in new blocks. Transactions are processed automatically without human intervention. The smart blockchain, or Smart chain, can fully substitute blockchain networks like Ethereum. We address four processes in this study: new_block, new_transaction, last_block, and hash. Using the Flask framework, requests are communicated and fulfilled over HTTP Protocol. Further exploration of this decentralized system facilitating the smart blockchain can impact application research areas, including Smart Homes using IoT Technology. Smart blockchain technology assesses security, complexity, privacy, integrity, and implementation protocols. Additionally, our experiments demonstrate the superior performance of the protocols across multiple blockchain blocks.","Here is a paraphrased version of the original text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""The concept of blockchain decentralization revolves around the redistribution of authority and data governance. This paradigm shift transforms a centralized network into a distributed one, where decision-making power is relinquished from a single entity, be it an individual, organization, or group. By doing so, the decentralized system minimizes the need for mutual trust among users, instead relying on the inherent functionality of the network to prevent degradation. This, in turn, enables the utilization of smart contracts to regulate and control the decentralized system. This paper proposes a novel blockchain decentralization framework, dubbed 'smart blockchain' or 'smart chain,' which leverages smart contracts generated by blocks to facilitate accurate and seamless data collection. The decentralized nature of smart blockchain ensures that there is no single point of vulnerability, rendering it impervious to tampering, hacking, and other malicious activities. Concurrently, this decentralization approach enables the secure storage and registration of data in new blocks, with transactions being executed automatically, sans human intervention. The smart blockchain technology has the potential to supplant traditional blockchain networks, such as Ethereum, and overcome the limitations of smart contract deployment and registration. Our research focuses on four key processes: new_block, new_transaction, last_block, and hash, which are facilitated through the Flask framework and communicated via HTTP Protocol. The assessment of this decentralized system, enabled by smart blockchain, is poised to revolutionize application research, including IoT-powered Smart Homes. Furthermore, our evaluation of smart blockchain technology examines its security, complexity, privacy, integrity, and implementation protocols, demonstrating its superior performance across multiple blockchain blocks.""","Distributed decision-making and data control are central to blockchain decentralization. This concept arises from the shift of a centralized network, controlled by a single entity, organization, or collective, to a distributed one. This distribution diminishes the need for user trust, as reliance on a central authority is minimized. However, this decentralization can potentially limit system functionality. Control over this decentralized system is achieved through smart contracts. This work introduces a novel blockchain decentralization system built on smart contracts generated by blocks, termed ""smart blockchain"" or ""smart chain."" This next-generation blockchain network accommodates one or more smart contracts, facilitating precise and reliable data collection through its decentralized structure. The absence of a single point of control or vulnerability makes smart blockchain resilient to tampering, hacking, and other malicious acts. This decentralized system also enables data storage and registration in new blocks, with the entire transaction process automated, eliminating human intervention. Networks currently utilizing blockchain, such as Ethereum, could potentially be replaced with smart blockchain or smart chain. The deployment and registration challenges associated with smart contracts are addressed within the smart blockchain framework. This study focuses on four key processes: new_block, new_transaction, last_block, and hash, using the Flask framework for communication and fulfillment of requests via HTTP protocol. Further exploration of this smart blockchain-enabled decentralized system holds significant potential for advancements in various application domains, including IoT-based Smart Homes. Smart blockchain technology offers advantages in security, complexity management, privacy, data integrity, and implementation protocols, with experimental results demonstrating its superior performance across multiple blockchain blocks.",acceptable,acceptable,acceptable,3.2,3.2,3.2
38,Data Mesh Meets Blockchain,"Effective dataset management is crucial for enterprises to make informed decisions and remain competitive. However, centralized dataset management approaches often result in poor scalability, unclear governance, inaccessible data silos, and duplication of efforts. This paper proposes a distributed blockchain-based framework inspired by the data mesh architecture to address these challenges. Our proposed framework leverages blockchain’s decentralized nature to enable efficient and transparent dataset sharing across enterprise business domains. By turning datasets into digital assets and business domains into peers, our framework utilizes blockchain smart contracts to allow business domains to view, request, and share datasets. In this paper, we describe the details of our framework, and we analyze it from scalability, accessibility, security, and data governance perspectives. To validate our framework, we provide a proof-of-concept implementation with a publicly available source code.","Efficient dataset management is essential for companies to make well-informed choices and stay competitive. Nonetheless, traditional centralized methods often lead to scalability issues, ambiguous governance, data silos that are hard to access, and duplicated efforts. This study introduces a decentralized, blockchain-based framework modeled after the data mesh architecture to overcome these issues. The proposed framework exploits blockchain's decentralized features to facilitate effective and transparent data sharing among different enterprise departments. By converting datasets into digital assets and transforming business domains into network peers, our framework uses blockchain smart contracts to allow these departments to view, request, and exchange data. This paper details our framework and examines it in terms of scalability, accessibility, security, and data governance. To demonstrate its effectiveness, we provide a proof-of-concept implementation with source code available to the public.","""Optimal data management is vital for businesses to make data-driven decisions and stay ahead in the market. Nevertheless, traditional centralized approaches to data management often lead to scalability limitations, ambiguous data ownership, isolated data repositories, and redundant efforts. This study introduces a novel decentralized framework, drawing inspiration from data mesh architecture, to overcome these hurdles. By harnessing blockchain technology's distributed nature, our proposed framework facilitates seamless and transparent data exchange across diverse business units. Through the tokenization of datasets and the peerification of business domains, our framework employs blockchain-based smart contracts to enable business units to discover, request, and share datasets. This paper delves into the intricacies of our framework, examining its performance from the perspectives of scalability, accessibility, security, and data governance. To substantiate our framework, we provide a functional prototype with open-source code, available for public scrutiny.""","For businesses to make insightful choices and stay ahead of the curve, skillful dataset management is essential. However, traditional centralized approaches to managing datasets often lead to limitations in scalability, ambiguous governance structures, isolated data pockets, and redundant work. To overcome these hurdles, this study introduces a decentralized framework rooted in blockchain technology and drawing inspiration from the data mesh architecture. Our proposed framework harnesses the decentralized nature of blockchain to facilitate efficient and transparent sharing of datasets across various business domains within an enterprise. By conceptualizing datasets as digital assets and business domains as peers, the framework employs blockchain smart contracts, empowering business domains to browse, request, and share datasets. This paper delves into the specifics of our framework, examining its scalability, accessibility, security, and data governance aspects. We substantiate our framework's efficacy through a proof-of-concept implementation, accompanied by publicly accessible source code.",acceptable,acceptable,acceptable,4.2,3.2,3.6
39,Quantum blockchain architecture using cyclic QSCD and QKD,"Quantum blockchain (QBC) is a novel decentralised concept anticipated to offer an alternative to the classical blockchain to provide transaction security and transparency. The QBC frameworks can offer the most tangible advantage against the security threat posed by quantum computers on the classical blockchain. The proposed scheme offers a new QBC framework in which voting is performed by the Quantum-Secured Yet Another Consensus (QSYAC) algorithm to create a fast decentralised QBC. QSYAC algorithm is also used to ensure the reliability and fault tolerance of the blockchain framework. The classical information and the chaining are provided using a single qubit state and quantum entanglement. The transactions are signed via a cyclic permutation of the computational distinguishability of the quantum states problem, and quantum key distribution protocol is used for secure key sharing. Assuring the security of the key and the blockchain, the suggested model is more effective and safe from potential quantum assaults than earlier systems.","Quantum blockchain (QBC) introduces a decentralized approach expected to serve as an alternative to traditional blockchain, enhancing transaction security and transparency. QBC frameworks are particularly advantageous in addressing the security challenges posed by quantum computers to classical blockchains. The new scheme introduces a QBC framework where the Quantum-Secured Yet Another Consensus (QSYAC) algorithm is employed for voting, creating a quick decentralized QBC. The QSYAC algorithm also guarantees the blockchain framework’s reliability and fault tolerance. Classical data and chaining are achieved through a single qubit state and quantum entanglement. Transactions are signed using a cyclic permutation of the computational distinguishability problem of quantum states, and a quantum key distribution protocol ensures secure key sharing. By securing the key and the blockchain, the proposed model surpasses previous systems in effectiveness and protection against potential quantum threats.","""A pioneering decentralized paradigm, Quantum Blockchain (QBC), is poised to revolutionize transactional security and transparency by providing a viable alternative to traditional blockchain systems. By leveraging the QBC architecture, the threat of quantum computer-based attacks on classical blockchain can be effectively mitigated. This innovative framework employs the Quantum-Secured Yet Another Consensus (QSYAC) algorithm to facilitate rapid, decentralized decision-making, while ensuring the reliability and fault tolerance of the blockchain ecosystem. The integration of classical information and chaining is achieved through the strategic deployment of single qubit states and quantum entanglement. Transaction authentication is secured via a cyclic permutation of the computational distinguishability of quantum states problem, complemented by the utilization of quantum key distribution protocols for secure key exchange. This proposed model offers enhanced security and resilience against potential quantum threats, surpassing the capabilities of its predecessors.""","Leveraging the principles of quantum mechanics, a groundbreaking decentralized architecture known as quantum blockchain (QBC) presents a robust alternative to traditional blockchain systems, aiming to enhance transaction security and transparency. QBC frameworks are poised to effectively mitigate the security risks posed by quantum computers to conventional blockchains. A novel QBC framework is proposed, featuring a Quantum-Secured Yet Another Consensus (QSYAC) algorithm for efficient and decentralized voting. This algorithm also bolsters the reliability and resilience of the blockchain framework. Information and chaining are encoded using a single qubit state and quantum entanglement. Transaction signing employs cyclic permutation based on the computational distinguishability of quantum states, while quantum key distribution ensures secure key exchange. This model surpasses existing systems in its security, effectively shielding the key and blockchain from potential quantum attacks.",acceptable,acceptable,acceptable,3.6,3.2,3.2
40,The Mediating Effect of Self-Efficacy in the Relationship Between Parental Communication and Digital Addiction,"In recent years, the excessive use of digital technologies has led to the emergence of digital addiction at earlier ages. However, studies explaining the causes of digital addiction are limited. The purpose of the current study was to investigate the links between maternal communication, paternal communication, and digital addiction, and whether these relationships were mediated by self-efficacy. It was also tested whether these links were moderated by gender. The data were collected from 601 middle school students aged 11–14 (61.7% girls, Mage = 12.23 SD = 1.03). The participants completed the Digital Addiction Scale for Children, Adolescent Family Process Measure, General Self-Efficacy Scale, and Demographic Questionnaire. Study hypotheses were tested by structural equation modeling. Findings showed that paternal communication was directly associated with self-efficacy, and also indirectly with digital addiction, mediated by self-efficacy. However, maternal communication was only directly associated with digital addiction. Moderation tests by gender were significant. The indirect effect of maternal communication on digital addiction was significant only for girls. The results suggest that the development of programs that will support parents' communication with their children and increase children's self-efficacy may be beneficial in preventing digital addiction. The findings may also help mental health professionals to understand the effects of parent–child communication on children's digital addiction.","In recent years, the overuse of digital technologies has resulted in digital addiction emerging at younger ages. However, there are limited studies explaining the causes of digital addiction. This study aimed to explore the connections between communication with mothers and fathers and digital addiction, and whether self-efficacy mediated these relationships. Additionally, the study examined if gender moderated these links. Data were gathered from 601 middle school students aged 11–14 (61.7% girls, average age 12.23, SD 1.03). Participants completed the Digital Addiction Scale for Children, Adolescent Family Process Measure, General Self-Efficacy Scale, and a Demographic Questionnaire. Hypotheses were tested using structural equation modeling. Results indicated that paternal communication was directly linked to self-efficacy and indirectly to digital addiction via self-efficacy. Conversely, maternal communication was only directly linked to digital addiction. Gender moderation tests were significant; the indirect effect of maternal communication on digital addiction was significant only for girls. These results imply that developing programs to enhance parent-child communication and boost children's self-efficacy could help prevent digital addiction. The findings could also assist mental health professionals in understanding the impact of parent-child communication on children’s digital addiction.","Over the past few years, the rampant utilization of digital technologies has precipitated the onset of digital dependency at increasingly younger ages. Despite this, research elucidating the underlying causes of digital dependency remains scarce. The present investigation aimed to explore the correlations between maternal and paternal communication patterns, digital dependency, and the potential mediating role of self-efficacy, as well as the moderating influence of gender. A sample of 601 middle school students (61.7% female, mean age 12.23, SD 1.03) completed a battery of assessments, including the Digital Addiction Scale for Children, Adolescent Family Process Measure, General Self-Efficacy Scale, and Demographic Questionnaire. Structural equation modeling was employed to test the study's hypotheses. The results revealed that paternal communication exhibited a direct association with self-efficacy, which, in turn, was indirectly linked to digital dependency. In contrast, maternal communication was found to have a direct, yet distinct, relationship with digital dependency. Notably, gender moderation tests yielded significant results, with the indirect effect of maternal communication on digital dependency emerging as significant only among female participants. These findings suggest that initiatives aimed at enhancing parental communication and fostering self-efficacy in children may be instrumental in mitigating digital dependency, while also providing valuable insights for mental health professionals seeking to understand the complex interplay between parent-child communication and digital dependency in young people.","The increasing prevalence of digital addiction in younger populations due to widespread digital technology use has prompted research into its underlying causes, yet such studies remain scarce. This study aimed to examine the connections between maternal and paternal communication styles and digital addiction, exploring the mediating role of self-efficacy and potential gender-based moderation effects. Data from 601 middle school students (aged 11-14, with a majority being girls) were collected using various scales measuring digital addiction, family dynamics, self-efficacy, and demographics. Structural equation modeling revealed that paternal communication directly influenced self-efficacy, which, in turn, indirectly affected digital addiction. Conversely, maternal communication only showed a direct link to digital addiction. Notably, gender played a moderating role, with the indirect influence of maternal communication on digital addiction being significant only among girls. These findings underscore the potential value of interventions aimed at enhancing parental communication skills and bolstering children's self-efficacy as preventive measures against digital addiction. Additionally, these insights can contribute to a deeper understanding of the impact parent-child communication has on digital addiction within the mental health field.",acceptable,acceptable,acceptable,3.2,3.2,3.2
41,Face-to-face more important than digital communication for mental health during the pandemic,"During the lockdowns associated with the COVID-19 pandemic, many people tried to compensate for limited face-to-face interaction by increasing digital communication. Results of a four-week experience sampling study in the German-speaking countries (N = 411 participants; k = 9791 daily questionnaires) suggest, however, that digital communication was far less relevant for lockdown mental health than face-to-face communication. Digital text-based communication (e.g., e-mail, WhatsApp, SMS) nevertheless was meaningfully associated with mental health, and both face-to-face and digital text communication were more predictive of mental health than either physical or outdoor activity. Our results underscore the importance of face-to-face communication for mental health. Our results also suggest that videoconferencing was only negligibly associated with mental health, despite providing more visual and audible cues than digital text communication.","During the COVID-19 lockdowns, numerous individuals sought to offset the lack of in-person interactions by boosting their digital communications. Findings from a four-week experience sampling study in German-speaking countries (N = 411 participants; k = 9791 daily questionnaires) indicate that digital communication played a much smaller role in mental health during lockdowns compared to face-to-face interactions. However, digital text-based communication (e.g., email, WhatsApp, SMS) had a significant association with mental health, with both face-to-face and digital text communication being stronger predictors of mental health than physical or outdoor activities. The results highlight the critical role of face-to-face interactions for mental wellbeing. Additionally, the study found that videoconferencing had a minimal impact on mental health, despite offering more visual and audio cues than digital text communication.","Throughout the COVID-19 pandemic's restrictive periods, individuals sought to offset the dearth of in-person connections by ramping up their online interactions. However, a four-week daily diary study involving 411 participants from German-speaking regions, who completed 9791 questionnaires, revealed that digital communication played a relatively minor role in maintaining lockdown-era mental wellbeing compared to face-to-face exchanges. Notably, digital text-based interactions, such as emailing, WhatsApp messaging, and texting, exhibited a significant correlation with mental health outcomes, while both face-to-face and digital text-based communication proved more influential in predicting mental health than physical activity or outdoor pursuits. The findings emphasize the paramount importance of in-person connections for mental health, and also indicate that videoconferencing, despite offering enhanced visual and auditory cues, had a negligible impact on mental wellbeing.","When COVID-19 lockdowns restricted in-person interactions, individuals turned to digital communication as a substitute. However, a four-week study (N = 411 participants, k = 9791 daily questionnaires) conducted in German-speaking countries revealed that face-to-face interaction was significantly more crucial for mental well-being during this period than digital communication. While text-based digital communication (e.g., email, WhatsApp, SMS) showed a notable link to mental health, both in-person and text-based digital communication were stronger predictors of mental well-being than physical activity or time spent outdoors. These findings highlight the paramount importance of face-to-face interaction for mental health. Interestingly, despite offering more visual and auditory cues, videoconferencing exhibited only a negligible association with mental health.",acceptable,acceptable,acceptable,3.6,3.2,3.2
42,Emoji as gesture in digital communication: Emoji improve comprehension of indirect speech,"As reliance on digital communication grows, so does the importance of communicating effectively with text. Yet when communicating with text, benefits from other channels, such as hand gesture, are diminished. Hand gestures support comprehension and disambiguate characteristics of the spoken message by providing information in a visual channel supporting speech. Can emoji (pictures used to supplement text communication) perform similar functions? Here, we ask whether emoji improve comprehension of indirect speech. Indirect speech is ambiguous, and appropriate comprehension depends on the receiver decoding context cues, such as hand gesture. We adapted gesture conditions from prior research (Kelly et al., 1999, Experiment 2) to a digital, text-based format, using emoji rather than gestures. Participants interpreted 12 hypothetical text-message exchanges that ended with indirect speech, communicated via text only, text+emoji, or emoji only, in a between-subjects design. Like that previously seen for hand gesture, emoji improved comprehension. Participants were more likely to correctly interpret indirect speech in the emoji-only condition compared with the text+emoji and the text-only conditions, and more likely in the text+emoji condition compared to the text-only condition. Thus, emoji are not mere decoration, but rather are integrated with text to communicate and disambiguate complex messages. Similar to gesture in face-to-face communication, emoji improve comprehension during text-based communication.","As the dependence on digital communication increases, the significance of effectively conveying messages through text also rises. However, text communication lacks the advantages of other mediums like hand gestures. Hand gestures help in understanding and clarifying the spoken message by adding visual cues to support verbal communication. Can emojis (images used to enhance text communication) serve a similar role? This study explores whether emojis enhance the understanding of indirect speech. Indirect speech is ambiguous, and its proper comprehension relies on the receiver interpreting contextual clues, such as hand gestures. We adapted gesture conditions from previous research (Kelly et al., 1999, Experiment 2) into a digital, text-based context using emojis instead of gestures. Participants interpreted 12 hypothetical text-message exchanges featuring indirect speech in three conditions: text only, text+emoji, or emoji only, in a between-subjects design. Similar to the effect of hand gestures, emojis enhanced comprehension. Participants were better at accurately interpreting indirect speech in the emoji-only condition compared to the text+emoji and text-only conditions, and better in the text+emoji condition compared to the text-only condition. Therefore, emojis are not just decorative; they integrate with text to convey and clarify complex messages. Like hand gestures in face-to-face interactions, emojis enhance comprehension in text-based communication.","As digital communication becomes increasingly prevalent, the ability to convey meaning effectively through written language takes on greater significance. However, the shift to text-based communication also means that the benefits of nonverbal cues, such as hand gestures, are lost. These gestures play a crucial role in facilitating understanding and clarifying the nuances of spoken language by providing visual context. The question arises as to whether emojis, which are used to augment text-based communication, can serve a similar purpose. This study investigates whether emojis can enhance the comprehension of indirect speech, which relies heavily on contextual cues, such as hand gestures, to convey meaning. Building on previous research, we adapted gesture-based experiments to a digital, text-based format, substituting emojis for gestures. Participants were presented with 12 hypothetical text-message exchanges featuring indirect speech, conveyed through text alone, text with emojis, or emojis alone. The results showed that emojis improved comprehension, with participants more accurately interpreting indirect speech in the emoji-only condition, followed by the text-with-emoji condition, and then the text-only condition. These findings suggest that emojis are not merely decorative, but rather an integral component of text-based communication, serving to disambiguate complex messages and facilitate understanding, much like gestures do in face-to-face interactions.","The increasing prevalence of digital communication necessitates effective textual communication. However, textual communication lacks the nuances of other modalities, like hand gestures, which aid in understanding and resolving ambiguities in spoken language by offering visual cues. This study investigates whether emoji, pictorial symbols used to enrich text-based communication, can serve a similar purpose. Focusing on indirect speech, inherently ambiguous and requiring contextual interpretation, this research examines if emoji facilitate comprehension. Adapting gesture-based research (Kelly et al., 1999, Experiment 2) to a digital format, the study involved participants interpreting twelve hypothetical text message conversations concluding with indirect speech presented in three formats: text-only, text with emoji, and emoji-only. Results mirrored the positive impact of hand gestures on comprehension. Emoji demonstrably enhanced understanding, with participants interpreting indirect speech more accurately in the emoji-only condition compared to both text+emoji and text-only conditions, and improved comprehension in the text+emoji condition over the text-only condition. Therefore, emoji are not simply decorative elements but actively contribute to communication by clarifying and disambiguating intricate messages. Akin to gestures in face-to-face interactions, emoji enhance comprehension in text-based communication.",acceptable,acceptable,acceptable,3.2,3.2,3.2
43,Effect of digital literacy on social entrepreneurial intentions and nascent behaviours among students and practitioners in mass communication,"Because journalism and mass communication have changed dramatically in the digital era, exploring alternative career paths for students and practitioners in mass communication may offer valuable insights for the future of the field. Considering the emphasis on decent work opportunities and responsible production practices outlined in the Sustainable Development Goals, this study evaluates the determinants of social entrepreneurial intentions and behaviours of students and practitioners of mass communication in Taiwan. A quantitative survey method is adopted. In total, 814 participants, consisting of 373 students and 441 practitioners, provided valid responses, which were analysed utilising structural equation modelling. The results in both samples indicate positive direct effects of perceived social support, perceived social awareness of peers, and digital literacy on social entrepreneurial intentions, and positive direct effects of digital literacy and social entrepreneurial intentions on social entrepreneurial behaviours. The study identifies digital literacy as a critical element for fostering social entrepreneurial intentions and behaviours. Moreover, educational implications and suggestions are also provided.","Due to significant transformations in journalism and mass communication in the digital age, investigating alternative career trajectories for students and professionals in this field may yield important insights for its future. With a focus on decent work opportunities and responsible production practices as highlighted by the Sustainable Development Goals, this study examines the factors influencing social entrepreneurial intentions and behaviours among Taiwanese mass communication students and practitioners. Using a quantitative survey approach, 814 respondents—comprising 373 students and 441 professionals—provided valid data, which were analysed via structural equation modelling. Both groups' results show that perceived social support, peer social awareness, and digital literacy positively impact social entrepreneurial intentions, and that digital literacy and social entrepreneurial intentions positively influence social entrepreneurial behaviours. The study underscores digital literacy as a vital factor in promoting social entrepreneurial intentions and actions. Additionally, educational implications and recommendations are discussed.","In light of the profound transformations that have reshaped the landscape of journalism and mass communication in the digital age, it is essential to investigate novel career trajectories for students and professionals in this field, which may yield valuable lessons for its future development. Given the importance assigned to decent work opportunities and responsible production practices in the Sustainable Development Goals, this research examines the factors influencing the social entrepreneurial aspirations and actions of mass communication students and practitioners in Taiwan. A quantitative survey approach is employed, yielding 814 valid responses from 373 students and 441 professionals, which are subsequently analysed using structural equation modelling. The findings from both samples reveal that perceived social support, peer awareness, and digital proficiency have a direct, positive impact on social entrepreneurial aspirations, while digital proficiency and social entrepreneurial aspirations, in turn, directly influence social entrepreneurial actions. The study highlights digital literacy as a pivotal factor in cultivating social entrepreneurial aspirations and actions, and also provides educational recommendations and implications.","The rapid evolution of journalism and mass communication in the digital age necessitates investigating alternative career options for students and professionals in this field. This study, grounded in the Sustainable Development Goals' emphasis on ethical employment and production practices, examines the factors influencing social entrepreneurial intentions and actions among Taiwanese mass communication students and practitioners. Employing a quantitative survey approach, data from 814 valid respondents (373 students and 441 practitioners) were analyzed using structural equation modelling. Findings reveal that perceived social support, peer social awareness, and digital literacy positively and directly impact social entrepreneurial intentions in both groups. Additionally, digital literacy and entrepreneurial intentions directly contribute to actual entrepreneurial behaviors. This research highlights the crucial role of digital literacy in fostering social entrepreneurship. The study concludes by offering educational implications and recommendations for future practice.",acceptable,acceptable,acceptable,3.6,3.2,3.2
44,The digital power of the tower: digital communication technologies and dwelling experience in residential large urban developments,"Residential large urban developments are the dominant mode of housing development in many cities around the world. They introduce new technologies to the residential setting that reshape the dwelling experience. Using digital ethnography and in-depth interviews with residents of three residential large urban developments at the center of Israel, this paper portrays how the digital dimension is embedded in and reshapes the performance and experience of the housing environment. We argue the centrality of the digital dimension to the emergence of a distinctly different dwelling experience and the transformation of residential power relations in the city.","In numerous global cities, large-scale urban residential projects dominate housing trends, bringing innovative technologies that transform the living experience. This study utilizes digital ethnography and in-depth interviews with inhabitants of three such developments in central Israel to illustrate how digital elements are integrated into and alter the functionality and experience of these housing environments. We assert that the digital dimension is crucial to the emergence of a uniquely different dwelling experience and the reconfiguration of residential power dynamics in urban areas.","In numerous global metropolises, sprawling urban residential projects have become the prevailing paradigm for housing development, revolutionizing the domestic sphere by integrating innovative technologies that redefine the way people inhabit their living spaces. Through a mixed-methods approach combining digital ethnographic observations and in-depth resident interviews in three prominent Israeli urban complexes, this study illuminates the profound impact of digitalization on the dynamics and perception of residential environments. Our research underscores the pivotal role of digital technology in fostering a novel, distinctly urban dwelling experience and recalibrating the balance of power within urban residential ecosystems.","Across the globe, the predominant form of housing construction in numerous urban centers is large-scale residential development projects. These developments integrate novel technologies into living spaces, fundamentally altering the experience of dwelling. Through digital ethnography and comprehensive interviews with inhabitants of three such projects in central Israel, this study illustrates how the digital realm is woven into the fabric of the housing environment, thereby reshaping its functionality and lived experience. We contend that the digital dimension plays a pivotal role in the emergence of a unique dwelling experience, ultimately transforming the dynamics of power within the urban residential landscape.",acceptable,acceptable,acceptable,4.0,3.2,3.6
45,Intelligent patrol inspection of low code enabled electric power communication equipment based on digital transformation,"In order to meet the needs of digital development of power system and ensure the safety of power communication equipment, an intelligent patrol inspection method for power communication equipment with low code enabling based on digital transformation is proposed. Build an intelligent patrol platform for low code enabled power communication equipment based on digital transformation. The data acquisition module of the infrastructure layer scans the RFID tags on the communication equipment through the patrol personnel’s handheld devices to obtain the specific information of the current equipment. The UDT data transmission protocol of the data transmission module transmits the equipment information collected by the patrol personnel to the patrol application layer; The fault diagnosis module of patrol application layer uses convolutional neural network to analyze patrol data and complete fault detection of power communication equipment; The integrated component layer uses the application components developed by visual tools to enable the platform with low code through the low threshold platform development technology; The front-end service layer, supported by the technology of the integrated component layer, implements the simplification and configurable processing of front-end display results such as patrol results display, and views and manages the patrol results of the platform through the user terminal layer. The experiment shows that the method is accurate in data acquisition, fast in data transmission and high in fault diagnosis accuracy. It is a highly practical intelligent patrol method for power communication equipment.","To address the digital development needs of power systems and ensure the safety of power communication equipment, a low code-enabled intelligent patrol inspection method, rooted in digital transformation, is suggested. An intelligent patrol platform for low code-enabled power communication equipment, leveraging digital transformation, is constructed. The infrastructure layer’s data acquisition module uses handheld devices carried by patrol personnel to scan RFID tags on communication equipment, gathering detailed information about the current equipment. The data transmission module's UDT data protocol conveys the collected equipment information to the patrol application layer. The patrol application layer’s fault diagnosis module deploys a convolutional neural network to analyze patrol data and conduct fault detection on power communication equipment. The integrated component layer employs visual tool-developed application components to empower the platform with low code via low-threshold platform development technology. Supported by the integrated component layer's technology, the front-end service layer facilitates the simplification and customization of display outputs such as patrol results. The user terminal layer allows viewing and management of the platform’s patrol results. Experiments demonstrate the method’s precision in data capture, speed in data transmission, and high fault diagnosis accuracy, establishing it as a highly effective intelligent patrol method for power communication equipment.","To address the demands of power system digitalization and ensure the reliability of power communication infrastructure, a novel, low-code-enabled intelligent inspection approach is introduced, leveraging digital transformation to create a smart patrol platform. This platform's infrastructure layer is equipped with a data acquisition module that utilizes handheld devices to scan RFID tags on communication equipment, gathering specific information on current assets. The collected data is then transmitted to the patrol application layer via the UDT protocol, where a convolutional neural network-based fault diagnosis module analyzes the data to detect potential issues. The integrated component layer employs visual tools to develop application components, enabling low-code platform development with a low threshold. The front-end service layer, supported by the integrated component layer, simplifies and configures the display of patrol results, such as inspection outcomes, which can be viewed and managed through the user terminal layer. Experimental results demonstrate the method's accuracy in data collection, speed in data transmission, and high fault diagnosis precision, making it a highly practical intelligent patrol solution for power communication equipment.","To address the digital evolution of power systems and bolster the security of communication infrastructure, this study introduces a novel, intelligent patrol inspection method for power communication equipment. This method leverages low-code development techniques, facilitating digital transformation. The proposed system comprises a custom-built, intelligent patrol platform empowered by low-code tools. At its foundation, a data acquisition module utilizes handheld devices to scan RFID tags affixed to communication equipment, gathering comprehensive equipment details. The collected information is then relayed to the patrol application layer through the robust UDT data transmission protocol. Within this application layer, a fault diagnosis module, powered by convolutional neural networks, meticulously analyzes the patrol data to identify potential faults in the communication equipment. An integrated component layer, utilizing visually-developed application components and low-threshold platform development technology, enables low-code functionality within the platform. This empowers the front-end service layer to streamline and customize the presentation of patrol outcomes, including display and management of results through the user terminal layer. Experimental validation confirms the efficacy of this method, demonstrating precision in data acquisition, rapid data transmission, and high accuracy in fault diagnosis. The result is a highly practical and intelligent patrol system optimized for power communication equipment.",acceptable,acceptable,acceptable,3.6,3.6,3.2
46,A Model for Digital Education Management Information System Using Wireless Communication and BP Neural Networks,"With the popularity of wireless communication and different mobile intelligent terminals, digital education management information systems are becoming increasingly popular among students. The problem of modernized teaching has significantly influenced and altered teaching quality evaluation methodologies and models. However, the findings revealed that the existing intelligent teaching quality diagnostic still needs to improve design and execution. As a result, creating an education management information system is critical, and establishing a digital education management information system has become a critical undertaking. To address these problems, this research paper presents a model for a digital education management information system (DEMIS) that utilizes wireless communication and BP neural networks (BPNNs) to manage digital education in schools. The paper highlights the significance of wireless communication and DEMIS in modern education. The study employs a grey prediction model and a BP neural network model to predict the trend of education development. The DEMIS is set up using MATLAB simulation with management constraint parameters, and the sample data originate from 85 instructors’ digital education assessment ratings. The experiment is carried out in two parts: using the grey prediction model and the BPNNs, which verify the suggested method’s efficacy in managing digital education in schools. The experimental findings suggest that, by combining wireless communication and BPNNs, the system can handle the campus network’s information in a unified manner and give decision assistance to managers, which is very practicable. Therefore, the suggested DEMIS may effectively enhance students’ learning experiences and education quality.","As wireless communication and various mobile smart devices gain traction, digital education management information systems are becoming more prevalent among students. Modern teaching's evolution has notably impacted teaching quality assessment techniques and frameworks. Nonetheless, research indicates that current intelligent teaching quality diagnostics require further refinement in design and implementation. Consequently, developing an education management information system is pivotal, making the establishment of a digital education management information system a crucial endeavor. This study introduces a digital education management information system (DEMIS) model leveraging wireless communication and BP neural networks (BPNNs) to oversee digital education in schools. It underscores the importance of wireless communication and DEMIS in contemporary education. The investigation employs both a grey prediction model and a BP neural network model to forecast education development trends. DEMIS is implemented through MATLAB simulation with specific management constraint parameters, using sample data from the digital education assessments of 85 instructors. The experiment is divided into two phases: utilizing the grey prediction model and the BPNNs, which confirm the proposed method's effectiveness in administrating digital education in schools. Results indicate that integrating wireless communication with BPNNs allows the system to manage campus network information cohesively and provides decision support to administrators, proving to be highly feasible. Consequently, the proposed DEMIS can significantly improve students' learning experiences and the quality of education.","The proliferation of wireless communication and diverse mobile intelligent devices has led to a surge in the adoption of digital education management information systems among students, significantly impacting the assessment methodologies and frameworks of modernized teaching. However, the current intelligent teaching quality diagnostic tools require enhancements in design and implementation. Consequently, the development of an education management information system has become imperative, and establishing a digital education management information system is a pressing necessity. This study proposes a novel digital education management information system (DEMIS) model that leverages wireless communication and back-propagation neural networks to optimize digital education in educational institutions. The significance of wireless communication and DEMIS in contemporary education is underscored. The research employs a grey prediction model and a back-propagation neural network model to forecast educational development trends. The DEMIS is established using MATLAB simulation with management constraint parameters, utilizing sample data from 85 instructors' digital education assessment ratings. The experiment is conducted in two phases, utilizing the grey prediction model and back-propagation neural networks, which validate the proposed method's effectiveness in managing digital education in educational institutions. The experimental results indicate that the system can integrate campus network information and provide decision support to administrators in a unified manner, making it highly practical. Thus, the proposed DEMIS has the potential to significantly enhance students' learning experiences and education quality.","The rise of mobile technology has led to increased adoption of digital education management systems in education. This shift towards modern teaching practices has significantly impacted how teaching quality is evaluated. However, current methods for intelligent teaching quality diagnosis require improvement. Thus, building robust digital education management information systems is crucial. This study proposes a digital education management information system (DEMIS) model that leverages wireless communication and BP neural networks for effective school management. The paper emphasizes the importance of wireless communication and DEMIS in contemporary education. Using grey prediction and BP neural network models, the study forecasts educational development trends. MATLAB simulations, incorporating management constraints and assessment data from 85 instructors, were used to implement DEMIS. The efficacy of the proposed method was validated through experiments using grey prediction and BPNNs, demonstrating its capability in managing digital education. The results highlight that integrating wireless communication and BPNNs allows the system to manage campus network information effectively and offer valuable decision support for administrators. This suggests that the proposed DEMIS can significantly improve student learning experiences and overall education quality.",acceptable,acceptable,acceptable,3.2,3.6,3.2
47,"Corporate social responsibility communication in the ICT sector: digital issues, greenwashing, and materiality","Digitalization brings with it new social and governance issues and heightened responsibility, particularly for corporations. In recent years, society has demanded more transparency from companies about digital technology practices, oversight, and impacts. One sector that sharpens the view on these dynamics is information and communication technology (ICT). This study introduces for the first time an examination of corporate social responsibility (CSR) discourse on digital issues among large ICT firms by using signaling theory to analyze a broad set of media (sustainability, ESG, CSR, integrated, impact, purpose, consolidated management, and annual reports as well as issue briefs and webpages). It clarifies how ICT firms present materiality—a reporting concept associated with fair representation and relevance of information—in their CSR reporting on digital topics. It then discusses implications for greenwashing and makes recommendations for improving disclosure credibility.Graphical Abstract","The rise of digitalization introduces new social and governance challenges, with corporations bearing increased responsibility. Society has recently demanded that companies be more transparent about their digital technology practices, oversight, and impacts. The information and communication technology (ICT) sector particularly highlights these dynamics. This research offers a pioneering exploration of how major ICT firms address corporate social responsibility (CSR) concerning digital issues, using signaling theory to assess a diverse range of media, including sustainability, ESG, CSR, integrated, impact, purpose, consolidated management, and annual reports, as well as issue briefs and websites. It elucidates the way ICT companies report on materiality—a concept related to the fair representation and relevance of information—in their digital-related CSR disclosures. The study then explores the implications of potential greenwashing and proposes recommendations for enhancing the credibility of disclosures.","The advent of digitalization has ushered in a plethora of novel societal and governance concerns, accompanied by an increased sense of accountability, particularly within the corporate realm. In response to growing public pressure, companies are now expected to demonstrate greater openness regarding their digital technology practices, oversight mechanisms, and environmental impacts. The information and communication technology (ICT) sector serves as a prime lens through which to examine these complex dynamics. This pioneering study undertakes a comprehensive analysis of corporate social responsibility (CSR) narratives surrounding digital issues within large ICT firms, employing signaling theory to scrutinize a diverse range of media, including sustainability reports, ESG disclosures, and web-based communications. The research sheds light on how ICT companies convey materiality – a concept tied to the fair representation and relevance of information – in their CSR reporting on digital matters, and subsequently explores the implications for greenwashing, ultimately providing actionable recommendations for enhancing disclosure credibility.","The increasing prevalence of digital technologies presents novel challenges in societal and corporate governance, demanding greater accountability, especially from businesses. Growing public pressure in recent years has urged companies to be more open about their digital practices, oversight mechanisms, and societal consequences. The Information and Communication Technology (ICT) sector provides a particularly illuminating lens through which to examine these issues. Utilizing signaling theory as a framework, this research offers a pioneering analysis of how large ICT corporations engage in discussions around corporate social responsibility (CSR) related to digital technology. It examines a diverse range of communication channels, including sustainability reports, ESG disclosures, CSR reports, integrated reports, impact statements, purpose-driven narratives, consolidated management documents, annual reports, issue briefs, and online platforms. This study sheds light on how ICT companies define and convey ""materiality"" – a reporting principle emphasizing the equitable presentation and significance of information – within their CSR reporting on digital subjects. Furthermore, the research explores the implications for potential ""greenwashing"" and offers suggestions for enhancing the trustworthiness of corporate disclosures.",acceptable,acceptable,acceptable,3.6,3.2,3.2
48,Tactile Codec with Visual Assistance in Multi-modal Communication for Digital Health,"In the digital health, with the development of communication, medical information in all modalities is growing exponentially. Therefore, an effective communication for multi-modal data including tactile and visual information is paramount. In this paper, we propose a novel method to compress the tactile video data from GelSight sensors for the applications of digital health. Firstly, our method combines the visual and tactile modalities to extract the saliency information for the tactile videos. A target recognition network is designed as the visual assistance, which helps tactile videos to extract the effective information frames by recognizing whether objects are touching or not. Secondly, we design a special coding for inter- and intra-frame prediction to further extract the saliency information and compress the tactile signal. Intra-frame prediction utilizes a dynamic group of pictures (GOP) strategy to reduce time redundancy. And intra-frame prediction based on low-rank sparse decomposition (LRSD) is then used to further achieve efficient compression. Finally, Through extensive evaluation of metrics, such as peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and learned perceptual image patch similarity (LPIPS), our method obtains the better results than advanced video coding (AVC) and high efficiency video coding (HEVC). Our method achieves an average bitrate savings of 23.6% compared to HEVC and 61.4% compared to AVC. The results show that the proposed method can greatly compress the amount of haptic data with high reconstruction quality.","In digital healthcare, advancements in communication are leading to a rapid increase in medical data across various forms. Consequently, effective communication for multi-modal data, which includes tactile and visual information, is crucial. This paper introduces a new approach to compress tactile video data captured by GelSight sensors for digital health applications. Our method initially combines visual and tactile modalities to extract salient information from the tactile videos. A target recognition network, serving as visual assistance, aids tactile videos in identifying effective information frames by detecting whether objects are making contact. Additionally, we design a specialized coding scheme for predicting and compressing tactile signals both within and between frames. The intra-frame prediction employs a dynamic group of pictures (GOP) strategy to minimize temporal redundancy, while the intra-frame prediction relies on low-rank sparse decomposition (LRSD) for further compression efficiency. Comprehensive evaluations using metrics such as peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and learned perceptual image patch similarity (LPIPS) demonstrate that our method outperforms advanced video coding (AVC) and high-efficiency video coding (HEVC). Specifically, our approach achieves average bitrate reductions of 23.6% compared to HEVC and 61.4% compared to AVC, proving its capability to significantly compress haptic data while maintaining high reconstruction quality.","In the realm of digital healthcare, the proliferation of communication technologies has led to an exponential surge in medical information across various modalities. Consequently, the need for effective communication of multi-modal data, encompassing both tactile and visual information, has become crucial. This paper introduces a novel approach to compressing tactile video data from GelSight sensors, specifically designed for digital health applications. Our methodology involves a two-pronged approach: firstly, we integrate visual and tactile modalities to extract salient information from tactile videos, leveraging a target recognition network as visual assistance to identify frames with object contact. Secondly, we employ a specialized coding scheme that incorporates inter- and intra-frame prediction to further extract salient information and compress tactile signals. This involves utilizing a dynamic group of pictures strategy to reduce temporal redundancy and low-rank sparse decomposition to achieve efficient compression. Our approach is validated through a comprehensive evaluation of metrics, including peak signal-to-noise ratio, structural similarity index, and learned perceptual image patch similarity, demonstrating superior results compared to advanced video coding and high efficiency video coding. Notably, our method achieves an average bitrate reduction of 23.6% and 61.4% compared to HEVC and AVC, respectively, while maintaining high reconstruction quality, thereby significantly compressing haptic data.","The rapid expansion of multi-modal medical data in the digital health realm necessitates efficient communication strategies. This paper introduces a novel approach for compressing tactile video data acquired from GelSight sensors, specifically for digital health applications. The method leverages visual cues through a target recognition network to identify frames containing touch interactions, thereby highlighting salient information within the tactile video stream. Subsequently, a specialized coding scheme incorporating inter- and intra-frame prediction is employed. Inter-frame redundancy is reduced using a dynamic group of pictures (GOP) strategy, while intra-frame compression is achieved through low-rank sparse decomposition (LRSD). Rigorous evaluation using metrics like peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and learned perceptual image patch similarity (LPIPS) demonstrates the superior performance of the proposed method compared to established video coding standards like AVC and HEVC. Notably, the method achieves average bitrate savings of 23.6% and 61.4% relative to HEVC and AVC, respectively. This underscores its ability to significantly compress haptic data while maintaining high reconstruction quality.",acceptable,acceptable,acceptable,3.6,3.6,3.2
49,Linear digital precoding technology in massive multiple input multiple output wireless communication system,"The rapid development of wireless communication in today's society is facing the development bottleneck of increasingly tense spectrum resources. As the key technology of 5G technology, Massive Multiple Input Multiple Output (MMIMO) technology has been widely studied and applied in recent years. It is expected to bring progress to wireless communication systems. The key characteristic of MMIMO is its large antenna array that results in a high dimension of the wireless system channel. This article examines the use of precoding technology in large-scale multi-antenna MIMO systems to address the issue of Common Channel Interference (CCI). The study starts by introducing the concept of linear digital precoding and provides mathematical demonstrations of three linear digital precoding schemes. The performance of these schemes is then simulated and analyzed using MATLAB, with the results showing a significant improvement in the bit error performance and combining rate of the MIMO system.","The swift advancement of wireless communication in contemporary society is encountering the challenge of increasingly scarce spectrum resources. MMIMO technology, a crucial component of 5G, has garnered significant attention and application in recent times. It promises to enhance wireless communication networks. MMIMO is characterized by its extensive antenna array, which leads to a high-dimensional wireless system channel. This paper explores the utilization of precoding technology within large-scale multi-antenna MIMO systems to solve the problem of Common Channel Interference (CCI). Beginning with an introduction to linear digital precoding, the study offers mathematical explanations of three linear digital precoding approaches. The performance of these approaches is subsequently simulated and evaluated using MATLAB, with findings indicating notable improvements in bit error rate and combining rate for the MIMO system.","The exponential growth of wireless communication in modern times is hindered by the escalating scarcity of spectral resources, prompting a pressing need for innovative solutions. As a pivotal component of 5G technology, the Massive Multiple Input Multiple Output (MMIMO) system has garnered significant attention and widespread adoption in recent years, promising to revolutionize wireless communication networks. A distinctive feature of MMIMO is its massive antenna array, which yields a high-dimensional wireless system channel. This paper delves into the application of precoding techniques in large-scale multi-antenna MIMO systems to mitigate the detrimental effects of Co-Channel Interference (CCI). The investigation commences with an exposition of linear digital precoding, followed by mathematical derivations of three linear digital precoding algorithms. The efficacy of these schemes is subsequently evaluated and analyzed using MATLAB simulations, revealing a substantial enhancement in the bit error rate and combining capacity of the MIMO system.","Contemporary society's swift advancement in wireless communication is encountering a significant obstacle due to the escalating scarcity of spectrum resources. Massive Multiple Input Multiple Output (MMIMO), a pivotal technology in 5G development, has garnered substantial research and implementation in recent times, holding the potential to revolutionize wireless communication systems. The defining feature of MMIMO lies in its expansive antenna array, resulting in a highly dimensional wireless system channel. This study delves into the application of precoding techniques within large-scale multi-antenna MIMO systems to mitigate Common Channel Interference (CCI). Commencing with an elucidation of linear digital precoding, the study presents mathematical proofs of three distinct linear digital precoding methodologies. Subsequently, the efficacy of these schemes is evaluated through MATLAB simulations, revealing a notable enhancement in both the bit error rate and combining rate of the MIMO system.",acceptable,acceptable,acceptable,3.6,3.2,3.6
50,Digital information and communication technologies in political education in universities: conflict of pragmatic and civilizational goals,"The article aims to determine the correspondence of the value orientations of students and teachers to the pragmatic and civilizational goals of political education in the process of introducing digital information and communication technologies for sustainable development. The study involved 92 students of the School of Marxism, TongJi University, who are receiving political education at the master’s level in the speciality “Political Science” using digital mobile and cloud information and communication educational technologies, and 83 teachers of political disciplines of this university. The authors used the Portrait Values Questionnaire (PVQ) and the Eysenck Personality Questionnaire (EPQ). The accumulation, sorting and visualization of information in the course of the study were carried out in the Microsoft Excel program. The statistical significance and significance of the results of the study were assessed based on the Student’s t-test, which was calculated using the online calculator Social Science Statistics. Statistically significant (p < 0.05) differences between the motivational educational values of students and teachers have revealed: the teachers expressed conformity largely than the students (4.6 ± 0.2 and 3.4 ± 0.1 points, respectively) and the importance of traditions (4.9 ± 0.1 and 3.5 ± 0.3 points), and the students - independence (4.5 ± 0.2 vs. 3.3 ± 0.1 points). According to the neuroticism scale, the indicators of the teachers (15.6 ± 2.4) are at the upper limit of the norm and statistically significantly (p < 0.05) exceed the hands of the students (10.2 ± 1.0). The difference in the hierarchy of values of students receiving political education using digital information and communication technologies and teachers of political disciplines was revealed, reflecting the presence of a conflict between the pragmatic and civilizational goals of political education in the process of introducing digital information and communication technologies, primarily about the opposition of traditions and universalism, conformism and the desire for power and achievement.","The article seeks to identify how the value orientations of students and teachers align with the pragmatic and civilizational objectives of political education amid the integration of digital information and communication technologies for sustainable development. The research included 92 master’s level Political Science students from the School of Marxism at TongJi University and 83 teachers of political studies, all utilizing mobile and cloud-based digital educational technologies. The study employed the Portrait Values Questionnaire (PVQ) and the Eysenck Personality Questionnaire (EPQ). Data gathering, organization, and visualization were performed using Microsoft Excel. The statistical significance of the findings was evaluated through the Student’s t-test via the Social Science Statistics online calculator. Results showed significant differences (p < 0.05) between the motivational educational values of students and teachers: teachers valued conformity (4.6 ± 0.2 vs. 3.4 ± 0.1 points) and tradition (4.9 ± 0.1 vs. 3.5 ± 0.3 points) more than students, who prioritized independence (4.5 ± 0.2 vs. 3.3 ± 0.1 points). Regarding neuroticism, teachers' scores (15.6 ± 2.4) were at the upper limit of normal and significantly (p < 0.05) higher than students' scores (10.2 ± 1.0). The study uncovered a disparity in the hierarchical values between students undergoing political education with digital technologies and political science teachers, signaling a conflict between the pragmatic and civilizational objectives in the integration of digital information and communication technologies, particularly regarding the opposition between tradition and universalism, conformity, and the aspiration for power and achievement.","This research endeavors to investigate the alignment of value priorities between students and educators with the pragmatic and civilizational objectives of political education, amidst the integration of digital information and communication technologies for sustainable development. The study sample comprised 92 master's-level students from TongJi University's School of Marxism, specializing in ""Political Science"" and utilizing digital mobile and cloud-based educational technologies, as well as 83 instructors of political disciplines from the same institution. The authors employed the Portrait Values Questionnaire and the Eysenck Personality Questionnaire to gather data. Microsoft Excel was utilized for data accumulation, sorting, and visualization. The statistical significance of the findings was evaluated using the Student's t-test, calculated via the online Social Science Statistics calculator. The results revealed statistically significant (p < 0.05) disparities in motivational educational values between students and educators: teachers exhibited a stronger inclination towards conformity and tradition, whereas students prioritized independence. Furthermore, teachers' neuroticism scores (15.6 ± 2.4) fell within the upper normative range, significantly exceeding those of students (10.2 ± 1.0). The study uncovered a disparity in the value hierarchies of students receiving political education through digital technologies and educators of political disciplines, reflecting a conflict between the pragmatic and civilizational goals of political education, particularly regarding the tension between tradition and universalism, conformism, and the pursuit of power and achievement.","This research investigates the alignment between student and teacher values and the practical and societal objectives of political education within the context of integrating digital technologies for sustainable development. The study included 92 Master’s level Political Science students from TongJi University’s School of Marxism, who are being educated using digital mobile and cloud-based learning tools, along with 83 political science instructors from the same institution. Data collection employed the Portrait Values Questionnaire (PVQ) and the Eysenck Personality Questionnaire (EPQ). Data management and analysis were conducted using Microsoft Excel, while statistical significance was determined using Student’s t-test through the online calculator Social Science Statistics. Significant differences (p < 0.05) were found between students and teachers in terms of their motivation-related educational values: teachers placed greater emphasis on conformity (4.6 ± 0.2 vs. 3.4 ± 0.1 points) and tradition (4.9 ± 0.1 vs. 3.5 ± 0.3 points), whereas students prioritized independence (4.5 ± 0.2 vs. 3.3 ± 0.1 points). Furthermore, teachers exhibited higher neuroticism scores (15.6 ± 2.4), approaching the upper limit of the normal range and significantly surpassing student scores (10.2 ± 1.0). The observed discrepancies in value hierarchies between students exposed to digitally-driven political education and their instructors suggest a potential clash between the pragmatic and civilizational aims of political education in the digital age, particularly regarding the tension between tradition and universalism, conformity, and the pursuit of power and achievement.",acceptable,acceptable,acceptable,3.2,3.2,3.2
51,Synchronous restoration of video key frame loss based on digital media communication protocol,"This paper presents a synchronous recovery method for video key frame loss, aiming to analyze the experimental video through digital media feature extraction algorithm. By analyzing and designing effective communication protocols in real-time embedded systems, video data can be better processed. On this basis, key frames are restore synchronously through digital media communication protocol, and verified by comparing with other algorithms. Experimental results shows that the recall and precision of this algorithm for key frame extraction are 90.1% and 100% respectively, Among the three algorithms compared, the recall and precision of video key frame extraction based on single feature algorithm are the highest, 80.2% and 85.9% respectively. At the same time, the synchronization restoration time of this algorithm for lost key frames is 12.2 s, which took less time than other algorithms. It can be seen that the algorithm based on digital media feature extraction is of great significance for synchronous restoration of video key frame loss. It can be seen that the algorithm based on digital media feature extraction is of great significance for the synchronous recovery of video key frame loss, and can effectively promote the development of video data diversity and the improvement of information interaction. Under the digital media communication protocol, it can effectively synchronize the audio and video receiving end of multimedia information, and then recover and predict the lost frames in the video sequence. First, it can enhance the internal characteristics of video frames and the similarity and consistency of images between frames. Secondly, it can significantly improve the accuracy and efficiency of video data processing. Finally, from the perspective of practical development, the synchronous recovery of video key frame loss based on digital media communication protocol can effectively promote the sustainable development of media data, which has certain social value and practical significance in the current era of big data.","This study introduces a method for synchronously recovering lost video key frames by employing a digital media feature extraction algorithm to assess experimental video content. By meticulously designing and analyzing real-time embedded systems communication protocols, the processing of video data is enhanced. Consequently, key frames are restored concurrently using the digital media communication protocol and are validated through comparisons with other algorithms. Experimental outcomes demonstrate that the recall and precision rates of this algorithm for key frame extraction are 90.1% and 100%, respectively. Compared with three different algorithms, a single-feature algorithm yielded the highest recall and precision rates at 80.2% and 85.9%, respectively. Additionally, the time taken for synchronous restoration of lost key frames using this algorithm is 12.2 seconds, outperforming other algorithms in terms of speed. It is evident that the digital media feature extraction-based algorithm holds significant importance for the synchronous recovery of lost video key frames, facilitating improved video data diversity and enhanced information interaction. Under the digital media communication protocol, it effectively synchronizes audio and video at the receiving end of multimedia information, allowing for recovery and prediction of missing frames in video sequences. This approach bolsters the internal characteristics of video frames, enhancing image similarity and consistency between frames, while substantially improving the accuracy and efficiency of video data processing. From a practical standpoint, the synchronous recovery of video key frame loss based on digital media communication protocols significantly advances the sustainable development of media data, bearing notable social value and practical relevance in the current era of big data.","This study introduces a novel approach to recover lost video key frames in real-time, leveraging a digital media feature extraction algorithm to analyze experimental video data. By designing and optimizing communication protocols for embedded systems, video data processing can be significantly enhanced. Building on this foundation, key frames are restored synchronously via a digital media communication protocol and validated through comparisons with alternative algorithms. The experimental results demonstrate that this algorithm achieves a recall rate of 90.1% and a precision rate of 100% for key frame extraction, outperforming other algorithms. Notably, the synchronization restoration time for lost key frames is reduced to 12.2 seconds, surpassing other methods. The significance of this digital media feature extraction-based algorithm lies in its ability to facilitate synchronous recovery of video key frame loss, thereby promoting video data diversity and enhancing information interaction. Under the digital media communication protocol, this approach can effectively synchronize audio and video reception, recover lost frames, and predict future losses. By amplifying internal video frame characteristics and inter-frame image similarity, this method improves video data processing accuracy and efficiency. Furthermore, it contributes to the sustainable development of media data, holding significant social value and practical relevance in the era of big data.","This study introduces a novel approach for recovering lost video key frames synchronously. The method leverages digital media feature extraction algorithms to analyze experimental video data. By optimizing communication protocols within real-time embedded systems, the processing of video information is enhanced. Key frame restoration is achieved synchronously through a dedicated digital media communication protocol, and its efficacy is validated through comparisons with existing algorithms. The proposed method demonstrates superior performance, achieving a recall rate of 90.1% and perfect precision (100%) in key frame extraction. Notably, it outperforms other evaluated algorithms, including a single feature-based approach, in both recall and precision. Furthermore, the algorithm exhibits a significantly faster synchronous restoration time of 12.2 seconds for lost key frames. This underscores the substantial value of digital media feature extraction for efficient and accurate recovery of missing key frames. This approach not only facilitates the synchronous recovery of lost key frames but also fosters the diversification of video data and enhances information exchange. The digital media communication protocol enables effective synchronization between audio and video streams at the receiving end of multimedia information, facilitating the recovery and prediction of lost frames within the video sequence. Consequently, this approach enhances the inherent characteristics of video frames, promotes inter-frame image similarity and consistency, and significantly improves the accuracy and efficiency of video data processing. From a broader perspective, the synchronous recovery of video key frame loss based on a digital media communication protocol holds significant implications for the sustainable development of media data, offering social value and practical significance in the current era of big data.",acceptable,acceptable,acceptable,3.6,3.6,3.2
52,"Digital communication strategies used by private companies, entrepreneurs, and public entities to attract long-stay tourists: a review","Globalization and the changes in the technological and social industries have facilitated international mobility in such a way that the distinctions between tourism and other forms of mobility closer to migration have practically become blurred. Improvements in digital communication have promoted people’s search for a better quality of life in terms of health, work, leisure, and other aspects. New forms of communication have started to gradually displace the more conventional media. In this context, private companies, entrepreneurs, and public entities have grown aware of the importance of digital communication to achieve a greater scope in their population attraction policies. In this context, the present study aims to identify which digital communication strategies are used to generate interest and attraction to the destination. In our Systematic Literature Review (SLR), we examine the relationship between the terms “lifestyle migration” and “digital communication”, obtaining 294 articles found in Web of Science (WOS) and Scopus. After the analysis, we found 16 potential articles that were linked to the research objectives. The results of the methodology are classified according to the different digital communication actions identified, namely (i) Social Network Relationship; (ii) Digital Marketing, and (iii) Virtual Reality and Augmented Reality. Therefore, this this study contributes to link lifestyle migration and digital communication to destination management offices, companies and entrepreneurs. The paper finishes with a discussion of theoretical and practical implications of research on digital communication strategies in the field of long-stay tourism.","Globalization and transformations in technological and social sectors have made international mobility easier, to the point where the distinctions between tourism and migration-like mobility have nearly vanished. Advances in digital communication have encouraged people to seek improved quality of life concerning health, employment, leisure, and other facets. These new communication methods are slowly replacing traditional media. In this scenario, private companies, entrepreneurs, and public organizations have recognized the critical role of digital communication in enhancing their strategies to attract populations. This study aims to explore the digital communication tactics employed to generate interest in destinations. Through a Systematic Literature Review (SLR), we explored the terms ""lifestyle migration"" and ""digital communication,"" identifying 294 articles from the Web of Science (WOS) and Scopus. Our analysis highlighted 16 key papers relevant to our research goals. The outcomes of our study are categorized based on the digital communication actions identified: (i) Social Network Relationships; (ii) Digital Marketing; and (iii) Virtual Reality and Augmented Reality. Consequently, this research links lifestyle migration with digital communication for destination management offices, businesses, and entrepreneurs. The paper concludes by discussing the theoretical and practical implications of researching digital communication strategies within long-term tourism.","The convergence of globalization and advancements in technological and social sectors has led to a significant increase in international mobility, rendering the boundaries between tourism and migration-like movements increasingly ambiguous. The proliferation of digital communication has sparked a quest for enhanced well-being, encompassing aspects such as health, employment, leisure, and beyond. Novel communication platforms are gradually supplanting traditional media, prompting private enterprises, entrepreneurs, and public institutions to recognize the pivotal role of digital communication in expanding their reach and appeal to target populations. Against this backdrop, this study seeks to determine the digital communication strategies employed to foster interest and attraction to a given destination. A systematic review of existing literature, yielding 294 articles from Web of Science and Scopus, reveals 16 pertinent studies aligned with our research objectives. Our findings are categorized according to three primary digital communication approaches: (i) cultivating social network relationships, (ii) leveraging digital marketing, and (iii) harnessing virtual and augmented reality. Ultimately, this research bridges the gap between lifestyle migration and digital communication, providing valuable insights for destination management offices, companies, and entrepreneurs.","The interconnected world, shaped by rapid technological and societal shifts, has blurred the lines between tourism and migration, fostering unprecedented international movement. Driven by enhanced digital communication, individuals seek an improved quality of life encompassing health, work, and leisure. Traditional media are being overshadowed by these new forms of communication, prompting private and public sectors alike to recognize their power in attracting people. This research delves into the digital communication strategies employed to spark interest and entice individuals to specific destinations. A systematic review of 294 articles from Web of Science and Scopus, focusing on the intersection of ""lifestyle migration"" and ""digital communication,"" yielded 16 relevant studies. The findings are categorized into three digital communication approaches: social network engagement, digital marketing, and virtual/augmented reality. This study bridges the gap between lifestyle migration and digital communication, offering valuable insights for destination management organizations, businesses, and entrepreneurs. The concluding discussion explores the theoretical and practical implications of digital communication strategies within the realm of long-term tourism.",acceptable,acceptable,acceptable,3.2,3.2,3.2
53,Effects of robot-assisted digital storytelling on hospitalized children’s communication during the COVID-19 pandemic,"This study proposed a robot-assisted digital storytelling approach to reduce hospitalized children’s anxiety about intravenous injections and to improve their therapeutic communication and therapeutic engagement. In order to verify the effectiveness of the robot-assisted digital storytelling approach, a randomized controlled study was implemented. A total of 47 children from a regional hospital were randomly assigned to an experimental group (n = 21) and a control group (n = 26). The experimental group adopted the robot-assisted digital storytelling approach in health education for intravenous injections, while the control group received video-based health education. The study results indicated that the proposed robot-assisted digital storytelling approach not only reduced the children’s anxiety, but also had positive effects on children’s communication about intravenous injections, emotions during hospitalization, and therapeutic engagement. As a consequence, it is suggested that educators and researchers consider adopting robot-assisted digital storytelling to facilitate nursing clinical health education for children.","This research introduced a robot-assisted digital storytelling method designed to alleviate anxiety in hospitalized children regarding intravenous injections and to enhance their therapeutic communication and engagement. To test the method's efficacy, a randomized controlled trial was conducted. A total of 47 children from a regional hospital were randomly divided into an experimental group (n = 21) and a control group (n = 26). The experimental group utilized the robot-assisted digital storytelling method for health education on intravenous injections, whereas the control group received video-based health education. Findings revealed that the robot-assisted digital storytelling method significantly reduced the children's anxiety and positively impacted their communication about intravenous procedures, emotional states during hospitalization, and therapeutic engagement. Therefore, it is recommended that educators and researchers consider implementing robot-assisted digital storytelling in clinical health education for children.","This investigation introduced a novel, technology-driven narrative strategy, leveraging robots to alleviate hospitalized children's apprehension regarding intravenous injections, while fostering enhanced therapeutic dialogue and participation. To assess the efficacy of this innovative approach, a randomized controlled trial was conducted, involving 47 pediatric patients from a regional hospital, divided into an experimental cohort (n = 21) and a control group (n = 26). The experimental group received health education on intravenous injections via robot-assisted digital storytelling, whereas the control group received video-based instruction. The findings revealed that this pioneering approach not only mitigated anxiety in children but also had a profound impact on their ability to discuss injections, emotional well-being during hospitalization, and therapeutic engagement. Consequently, it is recommended that educators and researchers explore the integration of robot-assisted digital storytelling into pediatric clinical health education to optimize nursing outcomes.","To alleviate anxiety in hospitalized children facing intravenous injections and enhance their therapeutic communication and engagement, this research implemented a randomized controlled trial evaluating a novel robot-assisted digital storytelling intervention. 47 children from a regional hospital were randomly allocated to either an experimental group (n=21), exposed to the robot-assisted storytelling approach during intravenous injection education, or a control group (n=26) receiving standard video-based education. The findings demonstrated that the robot-assisted approach effectively mitigated anxiety in children and fostered positive outcomes in their communication about intravenous injections, emotional well-being during hospitalization, and overall therapeutic engagement. Based on these results, the integration of robot-assisted digital storytelling into pediatric nursing clinical education is recommended for educators and researchers.",acceptable,acceptable,acceptable,3.6,3.6,3.2
54,Internet of things connecting digital world through visible light communication,"This study focuses on the use of Light Emitting Diodes (LEDs) for lighting, incorporating Visible Light Communication (VLC) technology for data transmission. The Internet of Things (IoT), an inventive technology can connect physical objects to the digital world through VLC. In smart environments, IoT interacts with Wireless Sensor Networks (WSN) and Mobile Ad-Hoc Networks (MANET), enhancing user experience and economic viability. This interaction forms new MANET-IoT systems in VLC-based networks, offering increased user mobility, energy saving and reduced network deployment costs. This work compares the performance of Light Fidelity technology of VLC and Radio Frequency (RF) technology, considering factors such as data rate, Bit Error Rate, and power consumption. The focus extends beyond energy efficiency to emphasize the creation of a hazard-free environment in the near future by using LEDs in indoors and outdoors. The obtainable outcomes of this investigation is energy consumption using global MANET and WSN in IoT VLC based system, marking a significant step towards providing reliable services over internet. Packet Delivery Rate is estimated for 100 node counts of Cluster Nodes Reinforcement Scheme in comparison with Reliable Data Transmission Model and EA-based Imperialist Competitive Algorithm (MANET) schemes in the work.","This research investigates the application of Light Emitting Diodes (LEDs) for illumination, integrating Visible Light Communication (VLC) technology for data exchange. The Internet of Things (IoT), a novel technology, enables the connection of physical devices to the digital realm via VLC. In intelligent environments, IoT engages with Wireless Sensor Networks (WSNs) and Mobile Ad-Hoc Networks (MANETs), improving user experience and economic feasibility. This synergy creates new MANET-IoT frameworks within VLC-based networks, which offer enhanced user mobility, energy efficiency, and reduced network setup costs. This study evaluates the performance of Light Fidelity (Li-Fi) technology of VLC against Radio Frequency (RF) technology, examining parameters such as data speed, Bit Error Rate, and energy consumption. The emphasis goes beyond energy efficiency to promoting a safe environment for both indoor and outdoor LED use. The study's results highlight energy consumption using global MANET and WSN in an IoT VLC-based system, representing a significant advancement towards delivering reliable internet services. Packet Delivery Rate is estimated for 100 node counts of Cluster Nodes Reinforcement Scheme compared with Reliable Data Transmission Model and EA-based Imperialist Competitive Algorithm (MANET) schemes.","This research explores the application of Light Emitting Diodes (LEDs) in illumination systems, leveraging Visible Light Communication (VLC) technology to facilitate data exchange. The innovative Internet of Things (IoT) paradigm enables the interconnection of physical entities with the digital realm via VLC, fostering seamless interactions with Wireless Sensor Networks (WSN) and Mobile Ad-Hoc Networks (MANET) in intelligent environments. This synergy gives rise to novel MANET-IoT systems in VLC-based infrastructures, yielding benefits such as enhanced user mobility, reduced energy expenditure, and lower network deployment expenditures. A comparative analysis of the performance of VLC-based Light Fidelity technology and Radio Frequency (RF) technology is conducted, considering key metrics including data transmission rates, error rates, and power consumption. The investigation's scope extends beyond energy efficiency to prioritize the creation of a safe and hazard-free environment in the near future, both indoors and outdoors, through the strategic deployment of LEDs. The anticipated outcomes of this study include the optimization of energy consumption in global MANET and WSN systems integrated with IoT VLC, thereby paving the way for the provision of reliable internet services. The Packet Delivery Rate is evaluated for 100 node counts of the Cluster Nodes Reinforcement Scheme, benchmarked against the Reliable Data Transmission Model and EA-based Imperialist Competitive Algorithm (MANET) schemes.","This research explores the utilization of LEDs for illumination, integrating VLC technology to facilitate data transfer. VLC, coupled with the innovative IoT, bridges the physical and digital realms by connecting objects. Within intelligent environments, IoT interfaces with WSN and MANET, optimizing user satisfaction and cost-effectiveness. This synergy gives rise to novel MANET-IoT systems within VLC networks, characterized by enhanced user mobility, energy conservation, and minimized deployment expenses. The study benchmarks Light Fidelity technology (VLC) against RF technology, evaluating metrics such as data transfer speed, error rate, and power usage. The scope transcends energy efficiency, aiming to establish a secure environment using LEDs for both indoor and outdoor illumination. This investigation determines energy consumption within a global MANET and WSN integrated IoT VLC system, paving the way for dependable internet services. Packet delivery rates are projected for 100 nodes utilizing the Cluster Nodes Reinforcement Scheme, contrasted with the Reliable Data Transmission Model and the EA-based Imperialist Competitive Algorithm (MANET) schemes.",acceptable,acceptable,acceptable,3.6,3.2,3.2
55,"Invasiveness, Intrusiveness and Influence: three new metrics to measure communication between political digital echo chambers","The contemporary debate about the place and role of political digital echo chambers (DPECs) in political communication relies more on assumptions, guess work, and speculations rather than empirical conclusions. Such shortcomings reflect the lack of empirical tools to measure the communication between echo chambers and the outside world. We try to overcome this deficiency by construing three graph-level metrics: Invasiveness, Intrusiveness and Influence, which try to capture the information dominance of a DPEC over another one, its strength of information source, and the penetration capability of one DPEC’s message into another DPEC’s space. We tested our metrics with simulated and real network data, and they seem to respond according to their design and our expectations. Test results on real network data showed that our metrics would be very useful in measuring the comparative strength of political mobilization in face of opposing forces that use the same social networks for political countermobilization.","The current discussion on the significance and function of political digital echo chambers (DPECs) in political communication is primarily grounded in assumptions, guesswork, and speculations rather than empirical evidence. This deficit highlights the absence of empirical methods to assess the interaction between these echo chambers and external environments. To address this gap, we have developed three graph-level metrics: Invasiveness, Intrusiveness, and Influence. These metrics aim to measure the information dominance of one DPEC over another, its role as an information source, and its ability to infiltrate another DPEC’s space. We validated our metrics using both simulated and real network data, and they performed in line with their intended purpose and our predictions. Results from real network data indicated that our metrics are highly valuable for assessing the relative strength of political mobilization in the face of adversarial forces utilizing the same social networks for political counter-mobilization.","The ongoing discussion surrounding the significance and function of political digital echo chambers (DPECs) in the realm of political discourse is largely founded upon unsubstantiated claims, conjecture, and speculation, rather than being grounded in empirical evidence. This limitation stems from the absence of reliable methodologies for assessing the exchange of information between echo chambers and the external environment. To address this knowledge gap, we propose the development of three novel graph-level metrics – namely, Infiltration, Informational Authority, and Message Permeability – designed to quantify the informational supremacy of one DPEC over another, the potency of its information sources, and the capacity of its messages to permeate the boundaries of rival DPECs. Our metrics were validated through simulations and real-world network data, yielding results that align with their intended purpose and our expectations. Furthermore, the application of these metrics to real-world network data revealed their potential to effectively gauge the relative efficacy of political mobilization efforts in the face of countermobilization strategies employed by opposing forces within the same social media platforms.","Current discussions surrounding the influence and function of political digital echo chambers (DPECs) in political discourse often rely on conjecture and speculation rather than concrete evidence. This deficiency stems from a lack of effective empirical tools for analyzing interactions between echo chambers and the external world. To address this gap, we propose three novel graph-based metrics – Invasiveness, Intrusiveness, and Influence – designed to assess the informational dominance of one DPEC over another, its strength as an information source, and the extent to which its messaging penetrates other echo chamber environments. Our evaluation of these metrics using both simulated and real-world network data indicates that they perform as intended and align with our expectations. Real-world network data analysis suggests that these metrics could be highly valuable for gauging the relative effectiveness of political mobilization efforts against opposing forces leveraging the same social networks for counter-mobilization.",acceptable,acceptable,acceptable,3.2,3.2,3.2
56,Digital Development of Cultural and Creative Industries Under the Security of 5G Mobile and Communication,"With the rapid growth of global 5G technology, it inevitably has a certain impact on the growth of China’s cultural industry, and also encourages employees in the cultural industry to innovate and transform China’s cultural industry. Various technologies of 5G digital technology have important influence and strong impetus on cultural & creative industries. With the rapid progress of social development, people are gradually attracted by some new things, new media and other forms of content, and their attention to cultural legacy is gradually reduced, which in turn brings a large number of cultural relics, historical buildings, cultural relics, handicrafts, etc. that slowly disappear from people’s vision. Under the background of 5G mobile and communication security, this article proposes a digital protection model of cultural legacy based on deep learning (DL). The digital protection model of cultural legacy based on DL can effectively solve the problem of unclear and stereo images, while maintaining the clarity of cultural legacy images, which provides theoretical support for the digital growth of cultural & creative industries.","The swift expansion of global 5G technology unavoidably affects China’s cultural industry growth and motivates industry workers to innovate and reshape the sector. The diverse applications of 5G digital technology exert significant influence and provide robust momentum for cultural and creative industries. As society rapidly advances, people are increasingly drawn to new phenomena, new media, and various types of content, leading to a diminished focus on cultural heritage. Consequently, numerous cultural relics, historical structures, and handicrafts gradually vanish from public view. In the context of 5G mobile and communication security, this study suggests a deep learning (DL)-based digital preservation model for cultural heritage. This DL-based model effectively addresses issues of image clarity and stereoscopy in cultural legacy visuals, ensuring their sharpness and supporting the digital expansion of cultural and creative industries.","As the global 5G network expands at an unprecedented rate, it is bound to exert a profound influence on the development of China's cultural sector, driving professionals within the industry to adopt innovative strategies and revolutionize the cultural landscape. The multifaceted applications of 5G digital technology are poised to have a transformative impact on the creative economy. However, as societal progress accelerates, people's fascination with novel forms of media and content is diverting attention away from cultural heritage, leading to a decline in the visibility of historical artifacts, landmarks, and traditional crafts. Against the backdrop of 5G-enabled mobile and communication security, this article presents a novel digital preservation framework for cultural heritage, leveraging deep learning algorithms. This framework can effectively address the issue of low-quality and distorted images, while preserving the clarity of cultural heritage visuals, thereby providing a theoretical foundation for the digital advancement of creative industries.","The swift global expansion of 5G technology has unavoidable repercussions for the development of China's cultural sector, prompting innovation and transformation within the industry. The diverse capabilities of 5G digital technology exert considerable influence and provide powerful momentum to cultural and creative industries. However, rapid societal progress has shifted public attention towards novel experiences and digital media, leading to a decline in interest in cultural heritage. Consequently, numerous cultural relics, historical structures, artifacts, and crafts are fading from public consciousness. In light of the secure mobile communication infrastructure offered by 5G, this study presents a deep learning (DL)-based model for the digital preservation of cultural heritage. This DL-driven model effectively addresses issues of image clarity and dimensionality, ensuring high-fidelity digital representations of cultural artifacts, thereby offering theoretical support for the digital expansion of cultural and creative industries.",acceptable,acceptable,acceptable,3.2,3.2,3.2
57,"The underuse of AI in the health sector: Opportunity costs, success stories, risks and recommendations","PurposeThis contribution explores the underuse of artificial intelligence (AI) in the health sector, what this means for practice, and how much the underuse can cost. Attention is drawn to the relevance of an issue that the European Parliament has outlined as a ""major threat"" in 2020. At its heart is the risk that research and development on trusted AI systems for medicine and digital health will pile up in lab centers without generating further practical relevance. Our analysis highlights why researchers, practitioners and especially policymakers, should pay attention to this phenomenon.MethodsThe paper examines the ways in which governments and public agencies are addressing the underuse of AI. As governments and international organizations often acknowledge the limitations of their own initiatives, the contribution explores the causes of the current issues and suggests ways to improve initiatives for digital health.ResultsRecommendations address the development of standards, models of regulatory governance, assessment of the opportunity costs of underuse of technology, and the urgency of the problem.ConclusionsThe exponential pace of AI advances and innovations makes the risks of underuse of AI increasingly threatening.Graphical Abstract","Objective: This article investigates the insufficient application of artificial intelligence (AI) in the healthcare sector, its implications for practice, and the associated costs of this underutilization. The discussion underscores the importance of an issue identified by the European Parliament in 2020 as a ""major threat."" Central to this concern is the risk that research and development of reliable AI systems for medical and digital health may remain confined to laboratories, thereby failing to achieve significant practical impact. Our analysis illuminates the reasons for researchers, practitioners, and especially policymakers, to focus on this issue. Approach: The study explores how governments and public entities are managing the insufficient use of AI. Recognizing that governments and international bodies often concede the limitations of their efforts, the paper delves into the root causes of the prevailing challenges and proposes improvements for digital health initiatives. Findings: The recommendations include the creation of standards, models for regulatory oversight, evaluation of the opportunity costs of technology underuse, and the pressing nature of the problem. Conclusions: The rapid advancement of AI innovations accentuates the increasingly perilous nature of underutilization in this field.","""This study delves into the phenomenon of artificial intelligence (AI) being underutilized in the healthcare industry, its implications for real-world applications, and the substantial economic burden it entails. The significance of this issue is underscored by the European Parliament's designation of it as a ""major threat"" in 2020, with the core concern being that research on trustworthy AI systems for medicine and digital health may stagnate in laboratory settings without yielding tangible benefits. Our investigation emphasizes the need for researchers, practitioners, and policymakers to acknowledge this phenomenon. An examination of government and public agency initiatives reveals the limitations of current approaches, prompting an exploration of the underlying causes and potential solutions. The proposed recommendations encompass the establishment of standards, regulatory governance frameworks, and the assessment of opportunity costs associated with underutilizing technology, as well as the urgency of addressing this issue. The rapid acceleration of AI advancements heightens the risks of underutilization, making it an increasingly pressing concern.""","This paper investigates the insufficient implementation of artificial intelligence (AI) within healthcare, examining its practical implications and potential economic repercussions. Highlighting a concern deemed a ""major threat"" by the European Parliament in 2020, the study focuses on the risk of promising AI research for medicine and digital health remaining confined to laboratories without tangible real-world application. The analysis underscores the importance of this issue for researchers, practitioners, and particularly policymakers. By exploring governmental and public agency approaches to tackling this underutilization, and acknowledging the limitations of existing initiatives, the paper delves into the root causes of the problem. It proposes solutions for enhancing digital health initiatives, including the establishment of standards, frameworks for regulatory governance, evaluation of missed opportunities stemming from technology underuse, and emphasizes the pressing nature of the matter. The authors conclude that the rapid evolution of AI necessitates urgent action, as the risks associated with insufficient implementation become increasingly significant.",acceptable,acceptable,acceptable,,3.2,3.2
58,Healthcare professionals satisfaction and AI-based clinical decision support system in public sector hospitals during health crises: a cross-sectional study,"The entire world’s focus has shifted to a digital health management system after the COVID-19 pandemic and crisis management through information systems that provide potential health support and minimize the effects of similar healthcare emergencies. Artificial intelligence (AI) can create alternative techniques such as Clinical Decision Support System (CDSS), which can aid complex scenarios such as large volumes of data, information accuracy, patient turnover, and health management regimes. CDSS uses an AI-based health information system that is helpful, fast, effective, and offers advanced techniques in emergencies and pandemics such as COVID-19. Therefore, it is essential to analyze mechanisms that can influence the degree of health care professionals (HCP) satisfaction and intention to adopt CDSS. Based on DeLone and McLean’s information system success model (D&M and ISSM), the researchers recruited 237 on-duty HCP from three major hospitals in Wuhan, China, in 2021. Data is collected through an online survey questionnaire with the consent of the hospital administration. The empirical findings show the strong influence of IS qualities (system, information, and service quality) and user satisfaction. These findings support the foundation for CDSS adoption in developing countries.","In the wake of the COVID-19 pandemic, global attention has turned towards digital health management systems and the role of information systems in crisis management to provide health support and mitigate similar healthcare emergencies. Artificial intelligence (AI) can introduce innovative methods like the Clinical Decision Support System (CDSS), which excels in handling complex situations such as data overloads, ensuring information precision, managing patient turnover, and overseeing health management protocols. CDSS leverages an AI-based health information system that is efficient, rapid, effective, and deploys advanced techniques during emergencies and pandemics like COVID-19. Consequently, it is crucial to evaluate the factors that impact health care professionals' (HCP) satisfaction and their willingness to adopt CDSS. Utilizing DeLone and McLean's information system success model (D&M and ISSM), researchers surveyed 237 active HCP from three prominent hospitals in Wuhan, China, in 2021. The data, collected via an online survey with administrative approval from the hospitals, reveal that the quality of the information system (system, information, and service quality) significantly influences user satisfaction. These outcomes provide a robust basis for the adoption of CDSS in developing nations.","In the wake of the COVID-19 pandemic, the global spotlight has turned to digital health management systems, which leverage information systems to provide vital health support and mitigate the impact of similar crises. The integration of artificial intelligence (AI) can spawn innovative solutions, such as Clinical Decision Support Systems (CDSS), capable of navigating complex scenarios marked by vast data volumes, accuracy concerns, patient turnover, and diverse health management protocols. By harnessing AI-driven health information systems, CDSS offers rapid, effective, and cutting-edge responses to emergencies and pandemics like COVID-19. Consequently, it is crucial to examine the factors influencing healthcare professionals' (HCPs) satisfaction and adoption intentions regarding CDSS. Building on DeLone and McLean's information system success model, researchers surveyed 237 on-duty HCPs from three major Wuhan hospitals in 2021, yielding empirical evidence that underscores the significant impact of information system qualities (system, information, and service quality) and user satisfaction on CDSS adoption, particularly in developing countries.","The global pandemic spurred a dramatic shift towards digital health management, emphasizing the role of information systems in mitigating healthcare crises. Artificial intelligence, particularly through Clinical Decision Support Systems (CDSS), offers innovative solutions for navigating the complexities of data volume, accuracy, patient flow, and overall healthcare management. Characterized by speed, efficacy, and sophisticated analytical capabilities, AI-powered CDSS has proven invaluable in responding to emergencies like COVID-19. Consequently, understanding the factors driving healthcare professional (HCP) acceptance of CDSS is crucial. Utilizing DeLone and McLean's information system success model, a study involving 237 HCPs from three prominent Wuhan hospitals in 2021 investigated this phenomenon. Data gathered via an online survey, conducted with hospital approval, highlighted the significant impact of system, information, and service quality on user satisfaction, ultimately bolstering CDSS adoption in developing nations.",acceptable,acceptable,acceptable,3.2,3.2,3.2
59,Role of Regulatory Sandboxes and MLOps for AI-Enabled Public Sector Services,"This paper discusses how innovations in public sector AI-based services must comply with the Artificial Intelligence Act (AI Act) regulatory frameworks while enabling experimentation and participation of diverse stakeholders throughout the Artificial Intelligence (AI) lifecycle. The paper examines the implications of the emerging regulation, AI regulatory sandboxes and Machine Learning Operations (MLOps) as tools that facilitate compliance while enabling co-learning and active participation of multiple stakeholders. We propose a framework that fosters experimentation with automation pipelines and continuous monitoring for the deployment of future public sector AI-based services in a regulatory-compliant and technically innovative manner. AI regulatory sandboxes can be beneficial as a space for contained experimentation that goes beyond regulatory considerations to specific experimentation with the implementation of ML frameworks. While the paper presents a framework based on emerging regulations, tools and practices pertaining to the responsible use of AI, this must be validated through pilot experimentation with public and private stakeholders and regulators in different areas of high-risk AI-based services.","This paper explores the necessity for innovations in AI-driven public sector services to align with the regulatory structures of the Artificial Intelligence Act (AI Act) while fostering experimentation and engagement from a variety of stakeholders throughout the AI lifecycle. The paper investigates the outcomes of the new regulation, AI regulatory sandboxes, and Machine Learning Operations (MLOps) as mechanisms that aid in compliance and promote co-learning and active involvement from diverse stakeholders. We introduce a framework designed to encourage experimentation with automation pipelines and continuous oversight for the implementation of future public sector AI services in a manner that is both regulatory-compliant and technically innovative. AI regulatory sandboxes serve as conducive environments for controlled experiments, extending beyond regulatory concerns to specific testing with ML frameworks. Although the paper proposes a framework based on current regulations, tools, and practices for the responsible application of AI, it necessitates validation through pilot experiments involving public and private stakeholders, as well as regulators, in various domains of high-risk AI services.","This study delves into the imperative of aligning cutting-edge public sector AI-driven services with the Artificial Intelligence Act's regulatory guidelines, while simultaneously encouraging collaborative exploration and stakeholder engagement throughout the AI development cycle. The analysis explores the far-reaching consequences of burgeoning regulations, AI regulatory sandpits, and MLOps as catalysts for compliance, co-creation, and active stakeholder involvement. We advocate for a paradigm that cultivates experimentation with automated workflows and continuous oversight, ensuring the deployment of future public sector AI-driven services in a manner that is both regulatory-compliant and technologically pioneering. AI regulatory sandpits offer a controlled environment for experimentation, transcending regulatory constraints to explore the practical application of ML frameworks. While this study presents a framework grounded in emerging regulations, tools, and best practices for responsible AI adoption, its validity hinges on pilot testing with diverse stakeholders, regulators, and high-risk AI-based service providers.","This study explores the challenge of balancing regulatory compliance with innovation in public sector AI services. It analyzes the role of the Artificial Intelligence Act, regulatory sandboxes, and Machine Learning Operations (MLOps) in fostering a collaborative approach to AI development that includes diverse stakeholders. The authors propose a framework that integrates automation pipelines and continuous monitoring to ensure both regulatory adherence and technical advancement in the deployment of public sector AI services. Recognizing the potential of regulatory sandboxes as controlled environments for experimentation, the paper emphasizes their value in exploring practical implementation of ML frameworks beyond mere regulatory considerations. While the framework draws on existing regulations, tools, and best practices for responsible AI, its efficacy must be evaluated through pilot programs involving public and private stakeholders, as well as regulatory bodies, across various high-risk AI service domains.",acceptable,acceptable,acceptable,3.8,3.6,3.2
60,aiWATERS: an artificial intelligence framework for the water sector,"The presence of Artificial Intelligence (AI) and Machine Learning (ML) applications has led to its widespread adoption across diverse domains. AI is making its way into industry, beyond research and academia. Concurrently, the water sector is undergoing a digital transformation. Water utilities in the United States are at different stages in their journey of digital transformation, and the decision makers in water sector, who are non-expert stakeholders in AI applications, need to better understand this technology to make informed decisions. While AI has numerous benefits to offer, there are also many challenges related to data, model development, knowledge integration and ethical concerns that should be considered before implementing it for real world applications. Civil engineering is a licensed profession where critical decision making is involved. Therefore, trust in any decision support technology is critical for its acceptance in real-world applications. Therefore, this research proposes a framework called aiWATERS (Artificial Intelligence for the Water Sector) which can serve as a guide for the water utilities to successfully implement AI in their system. Based on this framework, we conduct pilot interviews and surveys with various small, medium, and large water utilities in the United States (US) to capture their current state of AI implementation and identify the challenges faced by them. The research findings reveal that most of the water utilities in the United States are at an early stage of implementing AI as they face concerns regarding the black box nature, trustworthiness, and sustainability of AI technology in their system. The aiWATERS framework is intended to help the utilities navigate through these issues in their journey of digital transformation.","The integration of Artificial Intelligence (AI) and Machine Learning (ML) applications has fostered their extensive use in various sectors. AI is branching out from research and academia to make significant inroads into industry. Simultaneously, the water sector is experiencing a digital revolution. Water utilities in the United States are progressing at different rates in their digital transformation journey. Decision-makers in the water sector, who typically lack expertise in AI, must gain a deeper understanding of this technology to make informed choices. While AI offers numerous advantages, it also presents challenges related to data, model development, knowledge integration, and ethical issues that must be considered prior to real-world deployment. Civil engineering, a regulated profession involving critical decision-making, necessitates a high level of trust in decision support technologies for their acceptance in practical applications. This study proposes the aiWATERS (Artificial Intelligence for the Water Sector) framework as a guide for water utilities to effectively implement AI in their systems. We conducted pilot interviews and surveys with various small, medium, and large water utilities across the US to assess their current AI implementation status and identify challenges. Findings indicate that most US water utilities are in the early stages of AI adoption, with concerns about the opaque nature, reliability, and sustainability of AI technology. The aiWATERS framework aims to help these utilities address these issues during their digital transformation journey.","The proliferation of Artificial Intelligence (AI) and Machine Learning (ML) solutions has triggered a far-reaching uptake across disparate industries, with AI transcending its traditional bastion in research and academia to permeate the industrial landscape. Concurrently, the water industry is undergoing a profound digital metamorphosis, with water utilities in the United States at varying stages of this transformation. However, non-technical stakeholders in the water sector, who are key decision-makers, require a deeper understanding of AI to make informed choices. While AI offers numerous advantages, its implementation is fraught with challenges related to data quality, model development, knowledge integration, and ethical considerations. In the realm of civil engineering, where critical decision-making is paramount, trust in decision-support technologies is crucial for their real-world adoption. This research proposes the aiWATERS framework, a guiding paradigm for water utilities to successfully integrate AI into their operations. Through pilot interviews and surveys with diverse water utilities in the United States, this study captures their current AI implementation status and identifies the hurdles they face. The findings reveal that most US water utilities are in the nascent stages of AI adoption, grappling with concerns about AI's opacity, reliability, and long-term viability. The aiWATERS framework aims to facilitate the utilities' navigation of these challenges as they embark on their digital transformation journey.","The burgeoning influence of Artificial Intelligence (AI) and Machine Learning (ML) has spurred their integration across a myriad of fields, extending beyond the confines of research and academia into practical industry applications. Simultaneously, the water sector is experiencing a significant digital shift, with US water utilities at varying points in this evolution. Decision-makers within the water sector, often lacking specialized AI knowledge, require a deeper understanding of this technology to make well-informed choices. Although AI offers substantial advantages, challenges pertaining to data, model creation, knowledge assimilation, and ethical considerations necessitate careful evaluation before real-world implementation. Given the critical decision-making inherent in the licensed profession of civil engineering, trust in any decision support tool is paramount for its real-world acceptance. To address this, the aiWATERS (Artificial Intelligence for the Water Sector) framework is proposed as guidance for water utilities seeking successful AI integration. Pilot interviews and surveys involving diverse US water utilities, ranging in size, were conducted within this framework to assess the current state of AI implementation and pinpoint existing challenges. The findings highlight that most US water utilities are in the nascent stages of AI adoption, grappling with concerns about AI's opacity, trustworthiness, and long-term viability within their systems. The aiWATERS framework aims to assist utilities in navigating these complexities as they progress through their digital transformation.",acceptable,acceptable,acceptable,3.6,3.6,3.6
61,Awareness among teaching on AI and ML applications based on fuzzy in education sector at USA,"This paper summarises the level of knowledge held by educators in the United States on the use of artificial intelligence and machine learning in the classroom. The education industry seems to have reaped little benefits from the AI & ML industry's growth thus far. In any event, the creation of new ML & AI-based systems is mostly aimed towards areas with higher societal needs, such as medical diagnostics and individual transportation, rather than institutions of higher education. With this analysis, we want to shed some light on the mysterious state of application development in the US education industry. The report was written using a triangulation of research approaches to achieve this objective. First, we surveyed the current state-of-the-art reports from other countries and reviewed the relevant literature on AI & ML applications in the field of education. In the second phase, we analysed, to the extent possible, official documents from the United States education sector that dealt with AI and ML based on fuzzy digitalization initiatives. Third, in order to corroborate and expand upon the impressions received from the relevant literature and the document analysis, 15 guideline-based expert interviews were undertaken. Based on this data, we provide a selection of the AI & ML systems in use in universities and colleges now, analyse the benefits and drawbacks of implementing them, and speculate on their potential future evolution. While it would be a stretch to say that this paper presents a comprehensive overview of the subject, it does provide light on key areas of application and potential future research directions for AI and ML.","This document encapsulates the knowledge level of U.S. educators regarding the application of artificial intelligence and machine learning in educational settings. The education sector appears to have gained limited advantages from the advancements in AI and ML industries so far. Predominantly, the development of new AI and ML systems has been directed towards fields with significant societal impact, such as healthcare diagnostics and personal transportation, rather than higher education institutions. Through this analysis, we aim to elucidate the enigmatic state of application development within the U.S. education sector. The report was compiled using a triangulated research methodology. Initially, we examined contemporary reports from other nations and reviewed relevant academic literature on AI and ML applications in education. Secondly, we analysed, as comprehensively as possible, official documents from the U.S. education sector that addressed AI and ML within fuzzy digitalization initiatives. Finally, to validate and enhance the insights drawn from the literature and document analysis, we conducted 15 guideline-based interviews with experts. Drawing from this data, we present an overview of the current AI and ML systems used in colleges and universities, assess their advantages and disadvantages, and predict their potential future development. While this document may not offer an exhaustive overview of the topic, it highlights crucial application areas and outlines possible future research avenues for AI and ML.","This study synthesizes the current understanding among American educators regarding the integration of artificial intelligence and machine learning technologies in educational settings. Despite the rapid expansion of the AI and ML industries, the education sector has yet to reap substantial benefits. Notably, the development of novel AI- and ML-driven systems tends to focus on areas of higher social impact, such as healthcare and transportation, rather than higher education institutions. This analysis aims to illuminate the enigmatic landscape of application development in the US education industry. To achieve this goal, a multi-faceted research approach was employed, involving a review of international reports and relevant literature on AI and ML applications in education, an examination of official US education sector documents related to AI and ML initiatives, and 15 expert interviews guided by a set of predetermined criteria. The resulting data provides an overview of AI and ML systems currently in use in universities and colleges, assesses their advantages and limitations, and speculates on their potential future trajectories. While this study does not provide an exhaustive treatment of the subject, it sheds light on crucial areas of application and identifies potential avenues for future research into AI and ML in education.","This study explores the current understanding of artificial intelligence (AI) and machine learning (ML) applications in US classrooms, revealing a surprising lack of integration despite significant advancements in these fields. The focus of AI & ML development appears to be directed towards sectors with more pressing societal demands, such as healthcare and personalized transportation, rather than education. Employing a multifaceted research approach, this investigation illuminates the current landscape of AI & ML utilization within the US education system. This involved examining international reports and relevant literature, analyzing US educational documents addressing AI & ML in the context of digitalization efforts, and conducting 15 expert interviews. The resulting analysis highlights existing AI & ML systems employed in higher education, assesses their advantages and disadvantages, and forecasts potential future developments. While not claiming to be exhaustive, this paper provides valuable insights into key areas of application and future research pathways for AI & ML in education.",acceptable,acceptable,acceptable,3.6,3.2,3.2
62,A global perspective on data powering responsible AI solutions in health applications,"Healthcare AI solutions have the potential to transform access, quality of care, and improve outcomes for patients globally. This review suggests consideration of a more global perspective, with a particular focus on marginalized communities, during the development of healthcare AI solutions. The review focuses on one aspect (medical applications) to allow technologists to build solutions in today’s environment with an understanding of the challenges they face. The following sections explore and discuss the current challenges in the underlying data and AI technology design on healthcare solutions for global deployment. We highlight some of the factors that lead to gaps in data, gaps around regulations for the healthcare sector, and infrastructural challenges in power and network connectivity, as well as lack of social systems for healthcare and education, which pose challenges to the potential universal impacts of such technologies. We recommend using these considerations in developing prototype healthcare AI solutions to better capture the needs of a global population.","AI solutions in healthcare hold the promise of revolutionizing patient care access, quality, and outcomes across the world. This analysis advocates for a globally inclusive viewpoint, emphasizing underserved communities in AI healthcare advancements. Concentrating primarily on medical applications, the review aims to equip technologists with insights into present-day challenges. Subsequent sections delve into the obstacles inherent in data acquisition and AI system design for global healthcare implementation. Highlighted are the contributors to data deficiencies, regulatory gaps, infrastructural issues like power and network connectivity, and the absence of robust social systems for healthcare and education. These hurdles challenge the universal applicability of AI technologies. We advise integrating these considerations when developing prototype healthcare AI solutions to better address the diverse needs of the global populace.","The integration of artificial intelligence in healthcare has the capacity to revolutionize patient outcomes, care quality, and accessibility worldwide. To ensure equitable benefits, it is essential to adopt a globally inclusive approach, prioritizing underserved populations, during the development of AI-driven healthcare solutions. By concentrating on a specific area, namely medical applications, innovators can create effective solutions that acknowledge the complexities of the current landscape. The subsequent sections delve into the existing obstacles in data infrastructure, AI system design, and regulatory frameworks, which hinder the widespread adoption of healthcare technologies. We identify key factors contributing to data disparities, inadequate regulations, and infrastructure limitations, including power outages, network connectivity issues, and insufficient social support systems for healthcare and education, all of which undermine the universal potential of these technologies. By incorporating these insights, developers can design prototype AI solutions that more accurately address the diverse needs of a global patient population.","Artificial intelligence holds transformative potential for healthcare, promising to revolutionize accessibility, elevate care quality, and enhance patient outcomes worldwide. This analysis advocates for a broader, more inclusive lens during the development of AI-driven healthcare solutions, emphasizing the needs of underserved populations. To facilitate the creation of practical solutions in the current technological landscape, the review centers on medical applications, providing developers with insights into the obstacles they may encounter. Subsequent sections delve into the existing hurdles related to data integrity, AI design, and their implications for the global implementation of healthcare solutions. We illuminate critical factors contributing to data deficiencies, regulatory ambiguities within the healthcare domain, and infrastructural limitations encompassing power supply and network access. Furthermore, we emphasize the detrimental impact of inadequate healthcare and educational infrastructures on the widespread adoption of these technologies. By integrating these considerations into the development of prototype AI solutions for healthcare, we can better address the diverse needs of a global populace.",acceptable,acceptable,acceptable,3.2,3.2,3.2
63,An example of governance for AI in health services from Aotearoa New Zealand,"Artificial Intelligence (AI) is undergoing rapid development, meaning that potential risks in application are not able to be fully understood. Multiple international principles and guidance documents have been published to guide the implementation of AI tools in various industries, including healthcare practice. In Aotearoa New Zealand (NZ) we recognised that the challenge went beyond simply adapting existing risk frameworks and governance guidance to our specific health service context and population. We also deemed prioritising the voice of Māori (the indigenous people of Aotearoa NZ) a necessary aspect of honouring Te Tiriti (the Treaty of Waitangi), as well as prioritising the needs of healthcare service users and their families. Here we report on the development and establishment of comprehensive and effective governance over the development and implementation of AI tools within a health service in Aotearoa NZ. The implementation of the framework in practice includes testing with real-world proposals and ongoing iteration and refinement of our processes.","Artificial Intelligence (AI) is advancing swiftly, which means that its potential risks are not yet fully comprehended. Several global principles and guidelines have been created to steer the use of AI tools across various sectors, notably in healthcare. In Aotearoa New Zealand (NZ), we identified that the issue extended beyond merely tailoring existing risk frameworks and governance guidelines to our unique health service environment and population. Additionally, we considered it crucial to prioritize the perspectives of Māori (the indigenous people of Aotearoa NZ) to respect Te Tiriti (the Treaty of Waitangi), as well as to address the needs of healthcare users and their families. This document details the creation and establishment of thorough and effective governance over the development and deployment of AI tools within a health service in Aotearoa NZ. The practical implementation of this framework involves testing with real-world proposals and continuous iteration and enhancement of our processes.","The rapid evolution of Artificial Intelligence (AI) has created uncertainty regarding its safe application, prompting the publication of numerous international guidelines and principles to inform the integration of AI systems across various sectors, including healthcare. In Aotearoa New Zealand, we acknowledged that merely tailoring existing risk management frameworks and governance protocols to our unique healthcare setting and population would be insufficient. Instead, we recognized the imperative of amplifying the voices of Māori, the indigenous people of Aotearoa NZ, in accordance with the principles of Te Tiriti, while also prioritizing the needs of healthcare recipients and their families. This report details the creation and establishment of a robust governance structure for the development and deployment of AI tools within a health service in Aotearoa NZ, featuring real-world pilot testing and continuous refinement of our methodologies.","The swift evolution of AI presents a challenge in fully comprehending its potential hazards in practical applications. Global initiatives have provided ethical frameworks and guidelines for utilizing AI in various sectors, including healthcare. However, in the context of Aotearoa New Zealand, we acknowledged that simply modifying existing risk management strategies would be insufficient. We prioritized the inclusion of Māori perspectives, honoring Te Tiriti, and centering the needs of patients and their families. This paper outlines the creation of a comprehensive governance structure for the development and implementation of AI within the New Zealand healthcare system, emphasizing real-world testing and ongoing refinement of our processes.",acceptable,acceptable,acceptable,3.6,3.2,3.2
64,Operationalising AI ethics through the agile software development lifecycle: a case study of AI-enabled mobile health applications,"Although numerous ethical principles and guidelines have been proposed to guide the development of artificial intelligence (AI) systems, it has proven difficult to translate these principles into actionable practices beyond mere adherence to ethical ideas. This is particularly challenging in the context of AI systems for healthcare, which requires balancing the potential benefits of the solution against the risks to patients and the wider community, including minorities and underserved populations. To address this challenge, we propose a shift from one-size-fits-all ethical principles to contextualized case-based ethical frameworks. This study uses an AI-enabled mHealth application as a case study. Our framework is built on existing ethical guidelines and principles, including the AI4People framework, the EU High-Level Expert Group on trustworthy AI, and wider human rights considerations. Additionally, we incorporate relational perspectives to address human value concerns and moral tensions between individual rights and public health. Our approach is based on ”ethics by design,” where ethical principles are integrated throughout the entire AI development pipeline, ensuring that ethical considerations are not an afterthought but implemented from the beginning. For our case study, we identified 7 ethical principles: fairness, agility, precision, safeguarding humanity, respect for others, trust and accountability, and robustness and reproducibility. We believe that the best way to mitigate and address ethical consequences is by implementing ethical principles in the software development processes that developers commonly use. Finally, we provide examples of how our case-based framework can be applied in practice, using examples of AI-driven mobile applications in healthcare.","Despite the introduction of numerous ethical guidelines and principles to steer the development of artificial intelligence (AI) systems, effectively implementing these principles into practical applications remains a challenge, especially in the healthcare sector. This sector demands careful consideration and balance between the benefits of AI solutions and their potential risks to patients and broader communities, including marginalized and underserved groups. To tackle this issue, we advocate for a shift from generic ethical principles to specific, case-based frameworks. We illustrate our approach with a case study involving an AI-powered mobile health (mHealth) application. Our framework draws from established ethical guidelines and principles such as the AI4People framework, the EU’s High-Level Expert Group on Trustworthy AI, and broader human rights considerations, supplemented by relational viewpoints that address value concerns and moral conflicts between individual rights and public health. We adopt an ""ethics by design"" methodology, embedding ethical principles throughout the AI development lifecycle to ensure they are integral, not supplementary. In our case study, we identified seven key ethical principles: fairness, agility, precision, humanity, respect for others, trust and accountability, and robustness and reproducibility. We argue that the most effective way to manage and mitigate ethical impacts is by integrating these principles into standard software development practices. Furthermore, we provide practical examples of how our contextualized framework can be applied using AI-driven healthcare mobile applications.","Despite the proliferation of ethical codes and guidelines for artificial intelligence (AI) development, their practical application remains elusive, particularly in healthcare where the benefits of AI solutions must be weighed against potential risks to patients, vulnerable populations, and the broader community. To overcome this hurdle, we advocate for a paradigm shift from universal ethical principles to context-specific, case-based frameworks that account for the nuances of real-world scenarios. This research leverages an AI-powered mobile health application as a test case, drawing on established ethical frameworks, including AI4People and the EU's trustworthy AI guidelines, as well as human rights considerations and relational perspectives to address value conflicts and moral trade-offs. By integrating ethical principles throughout the AI development lifecycle, our ""ethics by design"" approach ensures that ethical considerations are proactive, rather than reactive. We distill seven core ethical principles – fairness, adaptability, precision, human-centeredness, respect, trust, and reliability – and demonstrate how their incorporation into software development processes can mitigate ethical consequences. Through concrete examples of AI-driven healthcare applications, we illustrate the practical applicability of our contextualized framework.","Despite the abundance of ethical guidelines and principles aimed at steering the development of artificial intelligence (AI), bridging the gap between theory and actionable practice has proven to be a significant hurdle. This issue is particularly pronounced in the realm of AI-powered healthcare, where a delicate equilibrium must be struck between the potential advantages of AI solutions and the associated risks for patients, including marginalized and vulnerable groups. To navigate this complex terrain, we propose a departure from universal ethical principles, advocating instead for context-specific, case-based ethical frameworks. Utilizing an AI-driven mobile health application as a case study, our framework draws upon existing ethical guidelines, including the AI4People framework, the EU High-Level Expert Group on trustworthy AI, and broader human rights considerations. We further integrate relational perspectives to address concerns regarding human values and the potential conflicts between individual rights and public well-being. Grounded in the ""ethics by design"" philosophy, our approach ensures the seamless integration of ethical principles throughout the entire AI development lifecycle, preempting ethical concerns rather than treating them as an afterthought. Seven key ethical principles are identified for our case study: fairness, agility, precision, safeguarding humanity, respect for others, trust and accountability, and robustness and reproducibility. We posit that the most effective way to mitigate and address ethical implications is by embedding ethical principles within the software development processes routinely used by developers. We conclude by demonstrating the practical application of our case-based framework through illustrative examples of AI-powered mobile health applications.",acceptable,acceptable,acceptable,3.2,3.2,3.2
65,"Does AI-technology-based indoor environmental quality impact occupants’ psychological, physiological health, and productivity?","Over the past century, because of increased global travel, there high growth in the travel and tourism sector. But the outbreak of an ongoing pandemic has changed this scenario, which has put tremendous focus on the Indoor Environmental Quality (IEQ) embedded with the application of technologies, especially artificial intelligence (AI). This study aims to investigate the effect of AI-technology-based IEQ in the hospitality industry on occupants’ productivity through their psychological and physiological health. Drawing from Job demand - resource theory and Nudging philosophy, we formulated the hypothesis and conceptual model, which was empirically tested by structural equation modeling (SEM). The results show that AI-technology-based IEQ is statistically significant in people’s behavioral change, which reflects on occupants’ health and productivity. Notably, AI-technology-based IEQ of the hospitality industry had a greater influence on occupants’ productivity, followed by their psychological and physiological health.","Over the past hundred years, the travel and tourism industry has seen substantial growth due to increased global travel. However, the current pandemic has drastically altered this landscape, shining a spotlight on Indoor Environmental Quality (IEQ) enhanced with technology, particularly artificial intelligence (AI). This research examines the impact of AI-driven IEQ on occupants’ productivity in the hospitality sector, focusing on their psychological and physiological well-being. By utilizing Job Demand-Resource theory and Nudging philosophy, we developed hypotheses and a conceptual framework, which were tested using structural equation modeling (SEM). Findings indicate that AI-based IEQ significantly influences behavioral changes, affecting occupants' health and productivity. Specifically, AI-enhanced IEQ in the hospitality industry notably boosts productivity, with subsequent effects on psychological and physiological health.","During the past hundred years, the travel and tourism sector has experienced exponential expansion, driven largely by the surge in global mobility. However, the emergence of a persistent pandemic has dramatically altered this landscape, placing unprecedented emphasis on Indoor Environmental Quality (IEQ) integrated with technological innovations, particularly artificial intelligence (AI). This research endeavors to examine the impact of AI-driven IEQ on the productivity of hospitality industry occupants, as mediated by their psychological and physiological well-being. Grounded in the theoretical frameworks of Job Demand-Resource Theory and Nudging Philosophy, we developed a conceptual model and hypothesis, which were subsequently validated using structural equation modeling (SEM). The findings reveal that AI-driven IEQ has a statistically significant influence on behavioral modification, which, in turn, affects occupants' health and productivity outcomes. Notably, the hospitality industry's AI-driven IEQ exerts a more profound impact on occupants' productivity, followed closely by its effects on their psychological and physiological health.","Increased globalization in the last century fueled a booming travel and tourism industry. However, the recent pandemic dramatically altered this landscape, placing significant emphasis on Indoor Environmental Quality (IEQ) enhanced by technology, particularly artificial intelligence (AI). This research explores how AI-powered IEQ in hospitality impacts occupant productivity through psychological and physiological well-being. Leveraging the Job Demand-Resource theory and Nudging philosophy, a hypothesis and conceptual model were constructed and empirically validated using Structural Equation Modeling (SEM). The findings demonstrate a statistically significant link between AI-driven IEQ and behavioral shifts, subsequently impacting occupant health and productivity. Notably, the effect of AI-powered IEQ in the hospitality sector was most pronounced on productivity, followed by psychological and physiological health.",acceptable,acceptable,acceptable,3.6,3.6,3.6
66,Applying the ethics of AI: a systematic review of tools for developing and assessing AI-based systems,"Artificial Intelligence (AI)-based systems and their increasingly common use have made it a ubiquitous technology; Machine Learning algorithms are present in streaming services, social networks, and in the health sector. However, implementing this emerging technology carries significant social and ethical risks and implications. Without ethical development of such systems, there is the potential for this technology to undermine people’s autonomy, privacy, and equity, even affecting human rights. Considering the approaches necessary for ethical development and effective governance of AI, such as ethical principles, guidelines, and technical tools, the question arises regarding the limitations of implementing these measures by the highly technical personnel involved in the process. In this context, we propose the creation of a typology that distinguishes the different stages of the AI life-cycle, the high-level ethical principles that should govern their implementation, and the tools with the potential to foster compliance with these principles, encompassing both technical and conceptual resources. In addition, this typology will include relevant information such as developmental level, related tasks, sectors, and language. Our research is based on a systematic review in which we identified 352 resources and tools. We expect this contribution to be valuable in promoting ethical AI development for developers and leaders who manage these initiatives. The complete typology and the comprehensive list of resources are available for consultation at https://ricardo-ob.github.io/tools4responsibleai.","AI systems and their widespread integration have made this technology omnipresent, with machine learning algorithms embedded in streaming services, social media, and healthcare. Yet, bringing this innovative technology into use poses significant social and ethical challenges. Absent ethical development standards, such systems have the potential to compromise individual autonomy, privacy, equity, and even impact human rights. Given the necessity for ethical practices and effective AI governance—such as adhering to ethical principles, guidelines, and employing technical tools—a question arises regarding the ability of technical personnel to implement these measures effectively. Thus, we propose a categorization that delineates the various stages of the AI life cycle, the overarching ethical principles that should guide their implementation, and the resources that can ensure adherence to these principles, including both technical and conceptual tools. Additionally, this categorization will provide details such as developmental stage, relevant tasks, applications, and language. Our research, grounded in a systematic review that unearthed 352 resources and tools, aims to support ethical AI development for developers and project leaders. The full categorization and resource list are accessible at https://ricardo-ob.github.io/tools4responsibleai.","The pervasive integration of Artificial Intelligence (AI) systems, driven by Machine Learning algorithms, has led to their widespread adoption across various domains, including entertainment platforms, online communities, and healthcare. Nevertheless, the deployment of this nascent technology poses substantial societal and ethical concerns, threatening to erode individual autonomy, privacy, and fairness, with far-reaching implications for human rights. To mitigate these risks, it is essential to establish a framework for responsible AI development, incorporating guiding principles, regulatory guidelines, and technical instruments. However, the efficacy of these measures relies on the ability of technical experts to implement them effectively. In response, we propose the development of a comprehensive typology that categorizes the distinct phases of the AI lifecycle, outlines the overarching ethical principles governing their implementation, and identifies tools capable of ensuring compliance, encompassing both technical and conceptual frameworks. This typology will also provide supplementary information, including developmental stages, associated tasks, sectors, and language. Our research, grounded in a systematic review of 352 resources and tools, aims to facilitate the development of ethical AI solutions for developers and initiative leaders. The complete typology and exhaustive resource list are accessible at https://ricardo-ob.github.io/tools4responsibleai.","The pervasiveness of Artificial Intelligence (AI) is undeniable, with Machine Learning algorithms integrated into various aspects of our lives, from entertainment to healthcare. However, this technological advancement brings forth significant ethical and societal concerns. If AI systems are not developed responsibly, they pose a threat to fundamental human values like autonomy, privacy, equity, and even human rights. To address these concerns, ethical frameworks, guidelines, and technical tools have been proposed. However, the complexities of implementing these measures by highly technical personnel raise questions about their effectiveness. Our research proposes a novel typology to bridge this gap. This typology categorizes the different stages of the AI life cycle, outlines the overarching ethical principles for each stage, and identifies both technical and conceptual tools that can facilitate adherence to these principles. Furthermore, it incorporates relevant information such as developmental stage, associated tasks, relevant sectors, and language. This typology, derived from a systematic review of 352 resources and tools, aims to be a valuable resource for promoting ethical AI development. It serves as a guide for developers and leaders overseeing these initiatives. The complete typology and a comprehensive list of resources can be accessed at https://ricardo-ob.github.io/tools4responsibleai.",acceptable,acceptable,acceptable,3.2,3.2,3.2
67,"Opportunities, challenges, and benefits of AI innovation in government services: a review","Artificial intelligence (AI) has emerged as an excellent tool across multiple industries and holds great promise for the government, society, and economy. However, the absence of a distinct consensus regarding the definition and scope of artificial intelligence hinders its practical implementation in government settings. This article examines the various methodologies, emphases, and goals within artificial intelligence, emphasizing its ability to enhance human capabilities in critical situations. Considering the present advantages and enhanced productivity brought about by AI adoption in trailblazing government departments, this study explores the possible benefits and limitations of AI usage in the public sector. By looking at the cross-disciplinary difficulties of public AI applications, such as language hurdles and service delays, this study highlights the necessity for a thorough knowledge of the risks, impediments, and incentives of employing AI for government services. The study hopes to provide insight into AI research's ultimate aims, including object manipulation, natural language processing, and reasoning. This study emphasizes the potential for greater productivity, simplified procedures, and reduced obligations by analyzing the pros and cons of using AI in the public sector. Further, organizational theory is considered a tool for figuring out how to deal with challenges and maximize possibilities associated with AI deployment. The theory is used as the conceptual framework to understand the benefits, opportunities, and challenges involved in using AI when providing government services. The results of this research help us better understand how AI may revolutionize public service delivery by stimulating new ideas and improving efficiency. This study covers critical questions about organizational theory's role in improving government AI adoption, the challenges governments have in adopting AI, and the potential benefits AI might offer public service delivery. The research recommends a strategic approach to AI adoption in the public sector, considering organizational, ethical, and societal implications while recognizing the possibility of AI's transformative impacts on governments' service provision.","Artificial intelligence (AI) has gained recognition as a valuable asset across various industries and shows significant potential for government, society, and the economy. Nonetheless, the lack of a clear consensus on the definition and boundaries of AI obstructs its effective application in government contexts. This article delves into the diverse methodologies, focal points, and objectives within AI, underscoring its capacity to augment human capabilities in vital scenarios. Given the current benefits and increased efficiency achieved through AI adoption in pioneering government agencies, this study investigates the potential advantages and limitations of AI use in the public sector. By addressing the interdisciplinary challenges of public AI applications, such as language barriers and service delays, the study underscores the necessity for a comprehensive understanding of the risks, obstacles, and incentives associated with utilizing AI for government services. The study aims to shed light on the ultimate goals of AI research, including object manipulation, natural language processing, and reasoning. By evaluating the pros and cons of AI in the public sector, this study highlights the potential for enhanced productivity, streamlined processes, and reduced responsibilities. Additionally, organizational theory is employed as a framework to address challenges and capitalize on opportunities related to AI implementation. This theoretical approach helps to understand the benefits, prospects, and difficulties of integrating AI into government services. The findings of the research provide insights into how AI can revolutionize public service delivery by fostering innovation and boosting efficiency. The study addresses crucial questions about the role of organizational theory in facilitating government AI adoption, the challenges faced by governments in incorporating AI, and the potential benefits AI could bring to public service delivery. The research advocates for a strategic approach to AI in the public sector, taking into account organizational, ethical, and societal factors while acknowledging AI's transformative potential in enhancing government service delivery.","The advent of artificial intelligence (AI) has spawned a versatile instrument with far-reaching implications for governance, societal welfare, and economic growth. Nevertheless, the lack of a unified understanding of AI's definition and scope hampers its effective integration into government agencies. This examination delves into the diverse approaches, focal points, and objectives within AI, underscoring its capacity to augment human capabilities in high-stakes situations. Building upon the current advantages and enhanced efficiency achieved through AI adoption in pioneering government departments, this inquiry explores the potential benefits and limitations of AI utilization in the public sphere. By scrutinizing the interdisciplinary hurdles of public AI applications, such as linguistic barriers and service delays, this study underscores the imperative for a comprehensive grasp of the risks, obstacles, and incentives associated with AI deployment in government services. The study aims to provide insight into AI research's ultimate objectives, including object manipulation, natural language processing, and reasoning. This analysis highlights the potential for increased productivity, streamlined processes, and reduced liabilities by weighing the pros and cons of AI adoption in the public sector. Furthermore, organizational theory is leveraged as a tool to navigate challenges and maximize opportunities associated with AI implementation. The theory serves as the conceptual framework to understand the benefits, opportunities, and challenges inherent in AI-driven government service provision. The research findings facilitate a deeper understanding of how AI may revolutionize public service delivery by catalyzing innovation and enhancing efficiency. This study addresses critical questions regarding organizational theory's role in optimizing government AI adoption, the challenges governments face in adopting AI, and the potential benefits AI may offer public service delivery. The research advocates for a strategic approach to AI adoption in the public sector, considering organizational, ethical, and societal implications while acknowledging the possibility of AI's transformative impacts on governments' service provision.","Across various sectors, AI's potential is undeniable, promising significant advancements for government, societal, and economic landscapes. However, the lack of a unified understanding of AI's definition and reach creates obstacles for its practical integration within government. This research delves into the diverse methods, focuses, and objectives within the field of AI, highlighting its capacity to augment human capabilities in crucial situations. Examining the early successes and efficiency gains achieved by pioneering government agencies utilizing AI, this study investigates the potential advantages and drawbacks of AI implementation in public services. By analyzing the interdisciplinary challenges of public AI applications, such as linguistic barriers and service delays, this research stresses the need for a comprehensive understanding of the risks, obstacles, and motivators associated with employing AI in government. The study aims to shed light on the ultimate goals of AI research, encompassing areas like object manipulation, natural language processing, and logical reasoning. Through an assessment of the benefits and challenges of AI in the public sector, this research underscores the potential for increased productivity, streamlined processes, and minimized burdens. Furthermore, organizational theory is utilized as a framework to address challenges and capitalize on opportunities presented by AI integration. This theoretical lens provides insights into the benefits, opportunities, and challenges inherent in leveraging AI for government service delivery. This study's findings contribute to a deeper understanding of AI's potential to revolutionize public services by fostering innovation and enhancing efficiency. It addresses key questions regarding organizational theory's role in promoting AI adoption in government, the obstacles faced by governments in adopting AI, and the potential benefits AI offers to public service provision. The research advocates for a strategic approach to AI implementation in the public sector, taking into account organizational, ethical, and societal factors, while recognizing AI's transformative potential for government service delivery.",acceptable,acceptable,acceptable,3.6,3.6,3.6
68,Recent progress in organic waste recycling materials for solar cell applications,"Organic waste-derived solar cells (OWSC) are a classification of third-generation photovoltaic cells in which one or more constituents are fabricated from organic waste material. They are an inspirational complement to the conventional third-generation solar cell with the potential of revolutionizing our future approach to solar cell manufacture. This article provides a study and summary of solar cells that fall under the category of OWSC. OWSC own their merit to low cost of manufacturing and environmental friendliness. This review article reveals different organic waste raw materials, preparation-to-assembly methodologies, and novel approaches to solar cell manufacturing. Ideas for the optimization of the performance of OWSC are presented. The assembly configurations and photovoltaic parameters of reported OWSC are compared in detail. An overview of the trends in the research regarding OWSC in the past decade is given. Also, the advantages and disadvantages of the different solar cell technologies are discussed, and possible trends are proposed. Industrial organic waste raw materials such as paper, coal, and plastics are among the least explored and yet most attractive for solar cell fabrication. The power conversion efficiencies for the cited works are mentioned while emphasizing the products and functions of the organic waste raw materials used.Graphical Abstract","Organic waste-derived solar cells (OWSC) represent a segment of third-generation photovoltaic cells where one or more components are produced from organic waste. They serve as an inspiring adjunct to traditional third-generation solar cells, holding promise for a transformative impact on future solar cell production methods. This article examines and synthesizes information on OWSCs. The advantages of OWSCs include their affordability in production and their eco-friendliness. The review addresses various organic waste materials, the processes from preparation to assembly, and innovative solar cell manufacturing techniques. Strategies for enhancing the performance of OWSCs are discussed. Detailed comparisons of assembly designs and photovoltaic parameters of existing OWSCs are presented. The research trends over the past ten years regarding OWSCs are summarized. Furthermore, the pros and cons of different solar cell technologies are evaluated, and future trends are suggested. Industrial organic waste materials like paper, coal, and plastics, while less studied, present significant potential for solar cell creation. The power conversion efficiencies of the cited studies are highlighted, focusing on the products and roles of the organic waste materials used. Graphical Abstract.","Here is a paraphrased version of the original text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""A novel breed of photovoltaic devices, dubbed Organic Waste-Derived Solar Cells (OWSC), leverages organic waste materials to fabricate one or more components, thereby offering a groundbreaking alternative to traditional third-generation solar cells. This innovative approach has the potential to transform the solar cell manufacturing landscape. This comprehensive review delves into the realm of OWSC, highlighting their dual benefits of cost-effectiveness and eco-friendliness. The article explores diverse organic waste sources, fabrication methodologies, and pioneering techniques for solar cell production. Strategies for optimizing OWSC performance are also presented. A detailed comparison of the assembly configurations and photovoltaic parameters of reported OWSC is provided, along with an overview of the past decade's research trends. The advantages and limitations of various solar cell technologies are discussed, and potential future directions are proposed. Industrial organic waste materials, such as paper, coal, and plastics, remain underutilized yet promising resources for solar cell fabrication. The power conversion efficiencies of the cited studies are reported, with a focus on the products and functions of the organic waste materials employed.""","Third-generation photovoltaic cells that utilize organic waste materials in their construction are known as organic waste-derived solar cells (OWSCs). These innovative cells offer a sustainable alternative to traditional third-generation solar cells, potentially transforming the future of solar cell production. This review examines various OWSCs, highlighting their cost-effectiveness and environmentally friendly nature. It explores the diverse organic waste materials used, the fabrication and assembly processes involved, and innovative solar cell manufacturing techniques. The study delves into strategies for enhancing OWSC performance, provides a detailed comparison of assembly configurations and photovoltaic parameters, and traces the evolution of OWSC research over the past ten years. Furthermore, it analyzes the strengths and weaknesses of different solar cell technologies, suggesting potential future directions. The review emphasizes the untapped potential of industrial organic waste materials like paper, coal, and plastics for solar cell fabrication, reporting power conversion efficiencies and highlighting the specific roles played by the utilized organic waste materials.",acceptable,acceptable,acceptable,3.2,3.2,3.2
69,A Comprehensive Survey of Silicon Thin-film Solar Cell: Challenges and Novel Trends,"Solar cells are commonly recognized as one of the most promising devices that can be utilized to produce energy from renewable sources. As a result of their low production costs, little material consumption, and projected increasing trajectory in terms of efficiency, thin-film solar cells have emerged as the technology of choice in the solar industry at present. This study aims to provide a comprehensive review of silicon thin-film solar cells, beginning with their inception and progressing up to the most cutting-edge module made in a laboratory setting. There is a review of the fantastic development of each technology, as well as its cell configuration, restrictions, equivalent circuit model, cell performance, and global market share. The dependability and availability of cell materials, in addition to the comparison of numerous characteristics, are both areas of research that are conducted concurrently for each of the distinct technologies. New advances in solar cells are also highlighted; these hold the potential to be significant variables and solutions in the process of the future's development. This abbreviated and brief version of the comprehensive analysis is provided to readers in the hope that it will aid them in evaluating potential research avenues about the proper applications and production of solar cells.","Solar cells are widely acknowledged as highly promising devices for harnessing energy from renewable sources. Owing to their low manufacturing expenses, minimal material usage, and anticipated efficiency improvements, thin-film solar cells have become the preferred technology in today's solar sector. This paper intends to offer an exhaustive review of silicon thin-film solar cells, tracing their evolution from inception to the most advanced laboratory-produced modules. The review includes the remarkable advancements of each technology, their cell configurations, limitations, equivalent circuit models, cell performance, and global market distribution. Reliability and availability of cell materials, along with comparative analyses of various characteristics, are also examined for all the different technologies. Additionally, the study emphasizes recent innovations in solar cells, which could play crucial roles and provide solutions for future development. This succinct summary of the extensive analysis is intended to help readers explore potential research directions regarding the appropriate applications and production of solar cells.","Renewable energy harnessing has solar cells as a frontrunner, and among these, thin-film variants have gained prominence in the industry due to their economical production, minimal material usage, and anticipated efficiency surge. This review delves into the evolution of silicon thin-film solar cells, from their genesis to the latest laboratory-crafted modules, examining each technology's milestones, architectural design, limitations, circuitry, performance, and market penetration. Concurrently, the study investigates the reliability and accessibility of constituent materials, as well as comparative analyses of diverse characteristics for each technology. Emerging breakthroughs in solar cells are also spotlighted, holding promise as pivotal factors and solutions in shaping the future. This condensed review aims to facilitate readers in identifying potential research pathways for optimal solar cell applications and manufacturing.","Widely lauded as a leading contender for harnessing renewable energy, solar cells, particularly thin-film variants, have taken center stage in the contemporary solar industry due to their economical fabrication, minimal material requirements, and anticipated improvements in energy conversion efficiency. This investigation embarks on an extensive exploration of silicon thin-film solar cells, tracing their evolution from initial concepts to the most sophisticated laboratory-fabricated modules. The remarkable progress of each technology is meticulously documented, encompassing its structural arrangement, inherent limitations, corresponding electrical model, operational performance, and global market penetration. A parallel analysis delves into the reliability and accessibility of cell materials, while meticulously comparing diverse attributes across distinct technologies. Furthermore, this study illuminates recent breakthroughs in solar cell technology, highlighting their potential to serve as crucial catalysts and solutions in shaping the future of this field. This concise and focused distillation of the comprehensive analysis aims to equip readers with insights that facilitate the identification of promising research avenues and inform the appropriate implementation and fabrication of solar cells.",acceptable,acceptable,acceptable,3.2,3.2,3.2
70,A thorough review of the existing concentrated solar power technologies and various performance enhancing techniques,"Solar thermal power plants today are the most viable alternative to replace conventional thermal power plants to successfully combat climate change and global warming. In this paper, the reasons behind this imminent and inevitable transition and the advantages of solar thermal energy over other renewable sources including solar PV have been discussed. The current literature on different types of solar thermal power plants and their performance optimisation techniques is quite scattered. Efforts have been made in this paper to bring the scattered information together in one thorough review so that it helps researchers across the spectrum undertaking studies on concentrated solar power technologies. This paper has established a brief background of these technologies. Furthermore, it has put forth a comprehensive review of different concentrated solar power technologies implemented throughout the world. The review in its latter part has highlighted the current trends of various hybrid, performance enhancing techniques being employed with these technologies. A brief review of the importance of economic analysis of these technologies has also been done. The future scope and course of action adopted to keep this technology growing are also discussed.","Modern solar thermal power plants represent a highly feasible alternative to conventional thermal power stations, playing a critical role in combating climate change and global warming. This paper delves into the underlying reasons for this imminent and unavoidable shift, highlighting the benefits of solar thermal energy compared to other renewable energy sources, including solar photovoltaics (PV). The current body of literature on various solar thermal power plant types and their optimization strategies is fragmented. This paper consolidates this dispersed information into a comprehensive review, aiming to assist researchers focused on concentrated solar power (CSP) technologies. It provides an overview of these technologies, alongside a detailed examination of different CSP technologies deployed worldwide. The latter section of the review showcases current trends in hybrid techniques and performance enhancement methods utilized with these technologies. Additionally, a succinct review of the economic evaluation importance for these technologies is presented. The discussion also touches on future perspectives and strategies to ensure the continued advancement of this technology.","Here is a paraphrased version of the original text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""Conventional thermal power plants are on the cusp of being supplanted by solar thermal power plants, a development crucial for mitigating the pressing issues of climate change and global warming. This study delves into the rationale behind this impending paradigm shift and the benefits of solar thermal energy relative to other renewable sources, including solar photovoltaic systems. Despite the abundance of literature on various solar thermal power plant designs and optimization strategies, a comprehensive synthesis of this knowledge has been lacking. This paper seeks to bridge this gap by providing an exhaustive review of concentrated solar power technologies, encompassing their fundamental principles, global implementations, and cutting-edge hybrid approaches aimed at enhancing performance. Additionally, the importance of economic viability assessments for these technologies is underscored, and the future trajectory and necessary steps for their continued growth are outlined.""","The urgent need to mitigate climate change necessitates a shift from traditional thermal power plants to sustainable alternatives, with solar thermal power emerging as a frontrunner. This article delves into the rationale driving this transition and illuminates the superiorities of solar thermal energy compared to other renewable energy sources, including photovoltaic solar. Existing research on diverse solar thermal power plant types and their optimization strategies is currently fragmented. This paper endeavors to consolidate this dispersed knowledge, providing a comprehensive review aimed at assisting researchers exploring concentrated solar power technologies. After establishing a foundational understanding of these technologies, the paper presents an extensive overview of diverse concentrated solar power technologies deployed globally. It further examines contemporary trends in hybrid and performance-enhancing techniques integrated with these technologies. The economic implications of these technologies are also briefly analyzed. Finally, the paper explores future directions and outlines steps required to foster the continued growth of this vital technology.",acceptable,acceptable,acceptable,3.2,3.2,3.2
71,Socio-economic impacts of solar energy technologies for sustainable green energy: a review,"Although fossil fuels leave environmentally hazardous gases like carbon dioxide, to date, global energy production is mostly dependent on these sources. Depletion of fossil resource and changes in the price make it a major concert for the sustainable use in future and utilization of energy resources which is environmentally safe and sustainable. Therefore, an increase in the use natural sustainable energy like solar power observed to be increased recently. Effective use of solar energy depends on the proper knowledge on its use and techniques. This article reviews different solar storage technologies to obtain green sustainable energy generation. We discussed the variation, mechanism, effectiveness, and worth of greenhouse for solar heat storage and concentrated solar power technologies (CSP). The multi-level evaluation method establishes an evaluation index system, adopts the expert scoring method to determine the weight and score of the index, and combines qualitative and quantitative to obtain a comprehensive evaluation value. There is the evaluation of the socio-economic impact of the green power station construction. The detail of for socio-economic environmental factor for on large-scale operation applications dependence on the use and conditions both solar storage and technologies have advantage and disadvantages. Finally, directions for significant of waste to energy for safe environment are presented.","While fossil fuels emit environmentally harmful gases like carbon dioxide, global energy production still largely relies on these resources. The depletion of fossil fuel reserves and fluctuations in their prices pose significant challenges for sustainable future use and the adoption of eco-friendly energy sources. Consequently, there has been a recent rise in the utilization of natural, sustainable energy, such as solar power. The effective deployment of solar energy hinges on a thorough understanding of its applications and technologies. This article examines various solar storage technologies aimed at achieving green, sustainable energy generation. We explore the differences, mechanisms, effectiveness, and value of greenhouses for solar heat storage, as well as concentrated solar power (CSP) technologies. A multi-level evaluation method creates an index system, uses expert scoring to determine index weight and scores, and integrates qualitative and quantitative data to produce a comprehensive evaluation value. The socio-economic impacts of constructing green power stations are assessed. The socio-economic and environmental factors influencing large-scale operations depend on the use and conditions of both solar storage and various technologies, each with its own pros and cons. Lastly, directions for the importance of converting waste to energy for environmental safety are discussed.","Despite the environmental risks associated with fossil fuels, including the release of harmful gases such as carbon dioxide, they remain the primary source of global energy production. However, the finite nature of fossil resources and price volatility have raised concerns about their long-term sustainability, prompting a shift towards environmentally friendly and sustainable energy alternatives. In recent years, there has been a notable increase in the adoption of natural, sustainable energy sources like solar power. The effective harnessing of solar energy relies on a thorough understanding of its applications and techniques. This review examines various solar storage technologies aimed at promoting eco-friendly energy generation. We analyze the differences, mechanisms, efficacy, and value of greenhouse-based solar heat storage and concentrated solar power (CSP) technologies. A multi-faceted evaluation approach is employed, incorporating expert assessments and a scoring system to determine the weight and score of each index, thereby providing a comprehensive evaluation. The socio-economic implications of constructing green power stations are also assessed. The suitability of solar storage and technologies for large-scale applications depends on various factors, including their advantages and disadvantages. Ultimately, the article highlights the importance of waste-to-energy conversion for a safe environment.","While the combustion of fossil fuels releases detrimental greenhouse gases like carbon dioxide, these resources remain the cornerstone of global energy production. However, dwindling reserves and price fluctuations necessitate the exploration of sustainable and environmentally benign energy alternatives for future use. Consequently, the adoption of renewable energy sources like solar power has witnessed a recent surge. Optimizing solar energy utilization hinges on a thorough understanding of its applications and associated technologies. This study delves into various solar storage technologies aimed at achieving sustainable green energy generation. We analyze the variability, mechanisms, efficacy, and economic viability of both greenhouse-based solar heat storage and concentrated solar power (CSP) technologies. A multi-faceted evaluation method, incorporating expert scoring and a hybrid qualitative-quantitative approach, is employed to comprehensively assess these technologies. Furthermore, the socio-economic ramifications of green power plant construction are examined. The analysis reveals that the socio-economic and environmental impacts of large-scale deployment of both solar storage and CSP technologies are contingent on specific usage patterns and prevailing conditions, each presenting its own set of merits and drawbacks. The article concludes by outlining key strategies for harnessing waste-to-energy solutions to foster a secure and sustainable environment.",acceptable,acceptable,acceptable,3.2,3.2,3.2
72,A Review on Solar Photovoltaic System Efficiency Improving Technologies,"AbstractThe use of solar energy-based technologies has sparked increased interest in recent years to meet our society’s various energy demands. Photovoltaic (PV) cell efficiency is improved, and low-grade heat is generated by combining a PV and thermal system into a single unit. Researchers are working on improving the PVT system for the past two–three decades, but only a few effective PVT systems are currently available on the consumer scale. This paper reviews various tracking and cooling techniques that are being used to track maximum sun radiations and decrease the probability of increased temperature when attempting for improving PV solar panel performance. So, many research papers have been analyzed and classified based on their emphasis, contribution, and the technologies used to perform PV panel tracking and cooling. This research would be beneficial to new researchers who are interested in working in this area and technology.","AbstractSolar energy technology has gained substantial traction in recent years as a means to satisfy diverse energy needs. By integrating photovoltaic (PV) cells with thermal systems, improvements in PV efficiency and low-grade heat production are achieved within a unified structure. Despite researchers dedicating the past two to three decades to enhancing the photovoltaic-thermal (PVT) system, only a few efficient solutions are commercially accessible. This paper examines a range of tracking and cooling strategies designed to maximize solar radiation capture and mitigate temperature increases to boost PV panel performance. Numerous studies have been reviewed and categorized based on their focus, contributions, and the methods employed for PV panel tracking and cooling. This compilation serves as a valuable resource for new researchers aspiring to contribute to this field and its associated technologies.","Here is a paraphrased version of the original text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""In recent years, the quest to satisfy our society's diverse energy needs has driven a surge in interest in solar energy-based solutions. By integrating photovoltaic and thermal systems, the efficiency of PV cells can be enhanced, and low-grade heat can be harnessed. Despite two to three decades of research focused on optimizing PVT systems, only a limited number of effective solutions are currently accessible to consumers. This review examines various strategies for tracking and cooling, designed to maximize solar radiation capture and mitigate temperature increases that can compromise PV solar panel performance. A comprehensive analysis of existing research papers has been conducted, categorizing them according to their focus, contributions, and technological approaches to PV panel tracking and cooling. This study aims to provide valuable insights for newcomers to the field, seeking to contribute to this area of technology.""","In recent times, the growing need to satisfy societal energy requirements has led to a surge in exploring solar energy technologies. Integrating photovoltaic (PV) and thermal systems into hybrid units enhances PV cell efficiency while also capturing low-grade heat. While research on optimizing PVT systems has been ongoing for several decades, only a limited number of commercially viable options are available to consumers. This study examines a variety of tracking and cooling methodologies employed to maximize solar radiation capture and mitigate temperature increases in PV panels, ultimately enhancing performance. Through analysis and categorization of numerous research articles based on their focus, contributions, and employed technologies, this review provides valuable insights for researchers entering the field of PV panel tracking and cooling.",acceptable,acceptable,acceptable,3.2,3.2,3.2
73,A Detailed Review on Wind and Solar Hybrid Green Energy Technologies for Sustainable Smart Cities,"Smart City development is a program for urban redevelopment and refurbishment. The main goal of a smart city is to stimulate economic growth and improve the quality of life of people by facilitating local area development and utilizing technology, particularly technology that leads to Smart results. Power generation is also a very crucial factor in the power management of smart cities. Most developing countries still use non-renewable energy sources as their conventional ones for power generation. The important problems arising from Non-Renewable energy sources are the depletion of natural resources, incremental greenhouse gases, pollution of the environment, and the rising cost of power consumption. Nowadays, the people and government are becoming more conscious of the significance of switching from conventional energy sources to renewable energy sources as we become more mindful of our impact on the environment. Green Energy or Renewable Energy is a way to make our Smart cities and Power Grid more sustainable. Hydroelectric, Solar, Tidal, Wind, and Bio-gas are a few of the important green energy sources used for power generation. Solar and wind power harvesting can be adopted and more suited for the Smart city-like urban environment. Since solar radiation and wind speed change throughout the year, neither a solar nor a wind-powered system can offer consistent electricity individually. By considering this condition, hybrid solar and wind power harvesting is suggested for sustainable Smart future cities. The present work explains solar power, wind power, and hybrid solar-wind power harvesting in detail with a Smart City power generation perspective.","Urban redevelopment and revitalization are now being spearheaded through Smart City programs. A Smart City aims to boost economic growth and elevate residents' quality of life by promoting local development and leveraging technology, particularly those that yield Smart outcomes. An essential component of Smart City power management is power generation. Currently, many developing nations still rely on non-renewable energy sources for electricity production. Problems associated with non-renewable energy include the exhaustion of natural resources, increased greenhouse gas emissions, environmental pollution, and rising energy costs. Today, both citizens and governments are increasingly aware of the need to transition from traditional energy sources to renewable ones, given our growing environmental consciousness. Renewable or Green Energy is a crucial avenue for making our Smart Cities and Power Grids more sustainable. Hydroelectricity, solar, tidal, wind, and biogas are among the key renewable energy sources for electricity generation. Solar and wind energy are particularly well-suited for urban environments like Smart Cities. However, due to the variable nature of sunlight and wind throughout the year, neither solar nor wind power alone can guarantee a stable electricity supply. Hence, a hybrid approach combining solar and wind energy is recommended for a sustainable future in Smart Cities. This work delves into the specifics of solar power, wind power, and the hybrid solar-wind system from a Smart City power generation perspective.","Urban revitalization and modernization initiatives, collectively known as Smart City development, aim to catalyze economic prosperity and enhance citizens' well-being by leveraging technology and fostering local development. A pivotal aspect of smart urban planning is the strategic management of power generation, which is often reliant on non-renewable energy sources in developing nations, leading to resource depletion, environmental degradation, and escalating energy costs. However, there is a growing awareness among governments and citizens about the imperative to transition from conventional to renewable energy sources, thereby promoting eco-friendly and sustainable urban ecosystems. Green Energy, encompassing hydroelectric, solar, tidal, wind, and bio-gas power, offers a viable solution for creating resilient and environmentally conscious Smart Cities. While solar and wind power are well-suited for urban environments, their intermittent nature necessitates the adoption of hybrid solar-wind power harvesting systems to ensure a consistent and reliable energy supply. This study provides an in-depth examination of solar, wind, and hybrid solar-wind power generation in the context of Smart City energy infrastructure.","Urban renewal and modernization efforts are at the heart of Smart City initiatives. These initiatives aim to enhance residents' quality of life and propel economic growth by leveraging technology, specifically ""smart"" technologies, for localized development. Efficient power management is crucial for Smart Cities, yet many developing nations rely heavily on unsustainable, non-renewable energy sources for power generation. This reliance leads to several critical issues: dwindling natural resources, increased greenhouse gas emissions, environmental contamination, and escalating energy costs. Increasingly, individuals and governments are recognizing the necessity of transitioning to renewable energy sources for a more environmentally responsible approach. Green or renewable energy sources offer a path towards sustainable Smart Cities and power grids. Various sources, such as hydroelectric, solar, tidal, wind, and biogas, fall under the green energy umbrella. Solar and wind energy harvesting are particularly well-suited for urban Smart City environments. However, the fluctuating nature of solar radiation and wind speed necessitates a combined approach. Hybrid solar-wind energy harvesting emerges as a solution for consistent electricity generation, crucial for creating sustainable Smart Cities of the future. This work provides an in-depth exploration of solar, wind, and hybrid solar-wind energy harvesting, specifically focusing on their application in Smart City power generation.",acceptable,acceptable,acceptable,3.2,3.2,3.2
74,A review of advanced architectural glazing technologies for solar energy conversion and intelligent daylighting control,"Efficient management of solar radiation through architectural glazing is a key strategy for achieving a comfortable indoor environment with minimum energy consumption. Conventional glazing consisting of a single or multiple glass pane(s) exhibits high visible light transmittance and solar heat gain coefficient, which can be a double-edged sword, i.e., it allows sufficient sunlight to enter the building interior space for passive heating and lighting; on the other hand, it can cause glare discomfort and large cooling energy consumption. Among the various advanced glazing technologies being developed, Building Integrated Photovoltaic (BIPV) glazing has a prominent position due to its ability to reduce cooling load and visual discomfort while simultaneously generating electricity from sunlight. Recent years have witnessed remarkable advances in low-concentration optics such as Dielectric based Compound Parabolic Concentrators (DiCPCs), with a growing interest in the development of Building Integrated Concentrating Photovoltaic (BICPV) glazing to improve light harvesting and electric power output. One of the challenges faced by traditional BIPV glazing systems is the lack of dynamic control over daylight and solar heat transmission to cope with variations in weather conditions and seasonal heating/cooling demands of buildings. A promising solution is to integrate an optically switchable smart material into a BIPV glazing system, which enables dynamic daylighting control in addition to solar power conversion. Thermotropic (TT) hydrogel materials such as poly(N-isopropylacrylamide) (PNIPAm) and Hydroxypropyl Cellulose (HPC) are potential candidates for hybrid BIPV smart glazing applications, due to their unique features such as high visible transparency (in the clear state), strong light-scattering capability (in the translucent state) and large solar energy modulation. This paper reviews various types of electricity-generating glazing technologies including BIPV glazing and BICPV glazing, as well as smart glazing technologies with a particular focus on TT hydrogel integrated glazing. The characteristics, benefits and limitations of hybrid BIPV smart glazing are also evaluated. Finally, the challenges and research opportunities in this emerging field are discussed.","Efficient regulation of solar radiation via architectural glazing is essential for creating a comfortable indoor environment while minimizing energy use. Traditional glazing, whether single or multi-pane, offers high visible light transmittance and solar heat gain coefficient, functioning as a double-edged sword. It permits ample sunlight into the building for passive heating and illumination, yet it can lead to glare discomfort and increased cooling energy demands. Building Integrated Photovoltaic (BIPV) glazing stands out among innovative glazing technologies due to its capacity to lower cooling loads and visual discomfort, while concurrently generating electricity from sunlight. Recently, significant progress has been made in low-concentration optics, such as Dielectric based Compound Parabolic Concentrators (DiCPCs), fostering interest in Building Integrated Concentrating Photovoltaic (BICPV) glazing to enhance light capture and electricity production. A notable challenge with conventional BIPV glazing systems lies in their inability to dynamically control daylight and solar heat transmission, essential for adapting to weather variations and seasonal heating/cooling needs. Integrating optically switchable smart materials into BIPV glazing offers a promising solution, providing dynamic daylighting control and solar power conversion. Thermotropic (TT) hydrogel materials like poly(N-isopropylacrylamide) (PNIPAm) and Hydroxypropyl Cellulose (HPC) are viable options for hybrid BIPV smart glazing due to their high visible transparency in a clear state, strong light-scattering in a translucent state, and substantial solar energy modulation. This paper reviews various electricity-generating glazing technologies, including BIPV and BICPV glazing, and examines smart glazing technologies with a focus on TT hydrogel integrated glazing. The attributes, advantages, and limitations of hybrid BIPV smart glazing are assessed, and the challenges and research opportunities in this emerging field are discussed.","Optimizing solar radiation management through innovative glazing designs is crucial for creating a comfortable indoor atmosphere while minimizing energy expenditure. Traditional glazing systems, comprising single or multiple glass panes, exhibit high visible light transmission and solar heat gain coefficients, which can be both beneficial and detrimental, as they allow for natural lighting and passive heating but also lead to glare discomfort and increased cooling energy consumption. Among the cutting-edge glazing technologies being developed, Building Integrated Photovoltaic (BIPV) glazing stands out for its ability to reduce cooling loads and visual discomfort while generating electricity from sunlight. Recent breakthroughs in low-concentration optics, such as Dielectric-based Compound Parabolic Concentrators (DiCPCs), have sparked growing interest in the development of Building Integrated Concentrating Photovoltaic (BICPV) glazing to enhance light harvesting and electric power output. However, traditional BIPV glazing systems face the challenge of lacking dynamic control over daylight and solar heat transmission to adapt to changing weather conditions and seasonal heating/cooling demands. A promising solution lies in integrating optically switchable smart materials into BIPV glazing systems, enabling dynamic daylighting control and solar power conversion. Thermotropic (TT) hydrogel materials, such as poly(N-isopropylacrylamide) (PNIPAm) and Hydroxypropyl Cellulose (HPC), are potential candidates for hybrid BIPV smart glazing applications due to their unique features, including high visible transparency, strong light-scattering capability, and large solar energy modulation. This review examines various electricity-generating glazing technologies, including BIPV and BICPV glazing, as well as smart glazing technologies with a focus on TT hydrogel-integrated glazing, evaluating their characteristics, benefits, and limitations. Finally, the challenges and research opportunities in this emerging field are discussed.","Optimizing the way buildings utilize sunlight through their windows is crucial for creating comfortable indoor spaces without excessive energy use. Traditional windows, whether single or multi-paned, let in a lot of light and heat from the sun. This has both advantages and disadvantages: while providing natural light and warmth, it can also lead to uncomfortable glare and high cooling costs. Among emerging window technologies, Building Integrated Photovoltaic (BIPV) glazing stands out for its ability to generate electricity from sunlight while mitigating cooling needs and visual discomfort. Recent breakthroughs in light-concentrating optics, particularly Dielectric based Compound Parabolic Concentrators (DiCPCs), have spurred interest in Building Integrated Concentrating Photovoltaic (BICPV) glazing, which further enhances light capture and electricity generation. A key limitation of traditional BIPV systems is their inability to dynamically adjust daylight and solar heat transmission to match changing weather and building needs. Integrating optically switchable smart materials into BIPV glazing offers a promising solution, enabling both dynamic daylight control and solar energy conversion. Thermotropic (TT) hydrogels, like poly(N-isopropylacrylamide) (PNIPAm) and Hydroxypropyl Cellulose (HPC), are attractive candidates for hybrid BIPV smart glazing. They possess unique properties, including high transparency when clear, strong light-scattering when translucent, and significant solar energy modulation capabilities. This review examines various electricity-generating window technologies, including BIPV and BICPV glazing, as well as smart glazing technologies, with a focus on TT hydrogel integration. It also assesses the characteristics, advantages, and drawbacks of hybrid BIPV smart glazing. Finally, the paper discusses challenges and research opportunities within this burgeoning field.",acceptable,acceptable,acceptable,3.6,3.2,3.2
75,Integration of multi-criteria decision-making for performance evaluation of different solar batteries technologies,"The aim of this paper is to propose a new approach allowing the improvement of the operation, the performances and the lifetime of a photovoltaic system. This improvement concerns the energy storage system, and it is essentially ensured by a multi-criteria analysis integrating the dependability analysis tools. In this context, this approach is based on an evaluation focused on several selection criteria and several technical factors to properly determine the most relevant technology for solar batteries such as lead–acid battery, nickel–cadmium battery (Ni–Cd), nickel–metal hydride (Ni–MH) battery and lithium-ion battery. The factors that are taken into account by the authors in this multi-criteria analysis are reliability, security, size and cost. The assessment of the reliability of the available battery capacity is established using failure modes, effects and criticality analysis and a classification of failure modes by an appropriate calculation of the number risk priority (RPN). The analysis of the security criteria is based on the development of a preliminary risk analysis which shows the impact of different solar technologies batteries on the environment, human health and physical. This approach is also interested in the evaluation of the cost and the impact of the volume, the number and the mass of the batteries used in the photovoltaic system. Finally, this approach is completed by the utilization of the Preference Ranking Organization Method for Enrichment Evaluations (PROMETHEE) to develop a decision-making model and solve the problem of choosing solar battery technology.","The goal of this study is to introduce a novel methodology aimed at enhancing the functionality, efficiency, and lifespan of photovoltaic systems. This enhancement specifically targets the energy storage system and is primarily achieved through a multi-criteria analysis incorporating reliability assessment tools. Within this framework, the approach relies on an evaluation that considers multiple selection criteria and technical factors to identify the most suitable solar battery technology, including lead-acid, nickel-cadmium (Ni–Cd), nickel–metal hydride (Ni–MH), and lithium-ion batteries. Key factors considered in this multi-criteria analysis include reliability, safety, size, and cost. The reliability of the available battery capacity is assessed using failure modes, effects, and criticality analysis, coupled with a classification of failure modes via a calculated risk priority number (RPN). Safety criteria are evaluated through a preliminary risk analysis that assesses the environmental, human health, and physical impacts of various solar battery technologies. Additionally, the methodology assesses the cost and implications of the volume, number, and mass of batteries used in the photovoltaic system. This approach is further refined by employing the Preference Ranking Organization Method for Enrichment Evaluations (PROMETHEE) to develop a decision-making model and address the challenge of selecting solar battery technology.","This study's objective is to introduce an innovative methodology for enhancing the operational efficiency, performance, and lifespan of photovoltaic systems, with a specific focus on optimizing energy storage systems through a comprehensive multi-criteria evaluation. This approach incorporates dependability analysis tools to identify the most suitable solar battery technology, considering factors such as lead-acid, nickel-cadmium, nickel-metal hydride, and lithium-ion batteries. The selection process is guided by a set of technical criteria, including reliability, security, size, and cost, which are assessed through a combination of failure modes analysis, risk priority calculation, and environmental impact evaluation. Furthermore, the methodology takes into account the economic and spatial implications of battery selection, ultimately utilizing the PROMETHEE decision-making model to facilitate the choice of the most appropriate solar battery technology.","This study introduces a novel methodology to enhance the functionality, efficiency, and lifespan of photovoltaic systems by optimizing energy storage. This optimization is achieved through a multi-criteria analysis incorporating dependability assessment tools. The proposed approach evaluates various selection criteria and technical factors to identify the most suitable solar battery technology, including lead-acid, nickel-cadmium (Ni-Cd), nickel-metal hydride (Ni-MH), and lithium-ion batteries. Key factors considered in this multi-criteria analysis are reliability, safety, size, and cost. Reliability assessment of battery capacity is conducted using failure modes, effects, and criticality analysis (FMECA), along with a failure mode classification based on risk priority number (RPN) calculations. Safety analysis involves a preliminary risk evaluation that examines the environmental, human health, and physical impacts of different solar battery technologies. Additionally, the approach considers cost and the influence of volume, quantity, and weight of batteries within the photovoltaic system. Lastly, the Preference Ranking Organization Method for Enrichment Evaluations (PROMETHEE) is employed to construct a decision-making model and guide the selection of the optimal solar battery technology.",acceptable,acceptable,acceptable,3.2,3.2,3.2
76,An Extensive Analysis of Dye-Sensitized Solar Cell (DSSC),"In the 1800s, as the primary energy resource, the industrial revolution started with fossil fuels. Various research efforts have been carried out in finding an alternative for photovoltaic devices to traditional silicon (Si)-based solar cells. During the last three decades, dye-sensitized solar cells (DSSCs) have been investigated largely. DSSCs due to their simple preparation methodology, low cost, ease of production, and low toxicity have been used widely. This review helps the readers to fabricate the DSSC and to familiarize themselves with the operation and overview of DSSC principles and to improve the efficient possible routes for these devices to thrive and emerge. In addition to that, manufacturing, stability, and efficiency improvements need to be addressed in the future for these technologies to be discussed and to represent their suitability as a breakthrough of consumer electronics in the market. An overview of developing current prototypes of DSSC and products of the main companies is included.","In the 1800s, the industrial revolution was fueled primarily by fossil fuels. Researchers have continuously sought alternatives to traditional silicon (Si) solar cells for photovoltaic devices. Over the past thirty years, dye-sensitized solar cells (DSSCs) have been intensively studied due to their straightforward production methods, affordability, ease of manufacturing, and low toxicity. This review aims to guide readers in constructing DSSCs, understanding their operating principles, and exploring efficient pathways for their success. Additionally, it addresses the future challenges of improving manufacturing processes, stability, and efficiency for these technologies to make a significant impact in the consumer electronics market. It also provides an overview of the current prototypes of DSSCs and products developed by leading companies.","During the 19th century, the industrial revolution was sparked by fossil fuels, which served as the primary source of energy. In recent years, scientists have been actively seeking alternatives to traditional silicon-based solar cells, with a particular focus on photovoltaic devices. Over the past three decades, researchers have extensively explored dye-sensitized solar cells (DSSCs), which offer a range of advantages, including ease of fabrication, low production costs, and minimal environmental impact. This review aims to guide readers in the assembly and operation of DSSCs, as well as provide an in-depth understanding of their underlying principles. Furthermore, it highlights the need for future advancements in manufacturing, stability, and efficiency to ensure the widespread adoption of these devices in the consumer electronics market. The review also features an overview of current DSSC prototypes and products developed by leading companies.","The dawn of the industrial revolution in the 19th century was fueled by fossil fuels, the dominant energy source of the era. This reliance on fossil fuels has spurred extensive research into alternative energy sources, particularly in the field of photovoltaics, seeking to replace traditional silicon-based solar cells. Dye-sensitized solar cells (DSSCs) have emerged as a promising alternative over the past thirty years, gaining widespread attention due to their straightforward fabrication, cost-effectiveness, simple production process, and minimal environmental impact. This review aims to guide readers through the construction of DSSCs, providing a comprehensive understanding of their operational mechanisms and underlying principles, while exploring potential avenues for enhancing their efficiency and propelling their advancement. Furthermore, the review highlights the critical need to address manufacturing challenges, enhance stability, and improve efficiency to solidify the position of DSSCs as a groundbreaking technology in the consumer electronics market. An analysis of ongoing DSSC prototype development and an overview of products from leading companies in the field are also presented.",acceptable,acceptable,acceptable,3.2,3.2,3.2
77,A Review on p-Type Tunnel Oxide Passivated Contact (TOPCon) Solar Cell,"The primary objectives of solar cell technology are high efficiency, long durability, mass manufacturing, cost effectiveness, and the use of environmentally benign components. Among high-efficiency crystalline silicon (c-Si)-based solar cell types, tunnel oxide passivated contact (TOPCon) solar cells have attracted particular attention because of a multitude of advantages. These include easy processing, high efficiency potential, and availability of raw materials. Due to cheaper wafer pricing, easily compatible with advanced and long-tested PERC solar cell manufacturing process, fabrication of TOPCon solar cells starting with p-type c-Si wafers are significantly more demanding from the standpoint of mass production of solar module. If cutting-edge high-efficiency technologies were used in industrial production, the quality of the p-type wafer may eventually become a bottleneck. Recent production lines elsewhere have developed p-type TOPCon solar cells with 25.19% conversion efficiency using monocrystalline Czochralski (CZ) c-Si wafers. This effectively proves the outstanding viability of p-type TOPCon solar cells for an industrial scale. This review article comprehensively discusses the history of high-efficiency p-type TOPCon solar cells, advancement in various areas to increase effective cell performance, state of commercialization, as well as potential future research opportunities and challenges.","The main goals of solar cell technology include achieving high efficiency, ensuring long-term durability, enabling mass production, maintaining cost-effectiveness, and using environmentally friendly materials. Among the high-performance crystalline silicon (c-Si)-based solar cells, tunnel oxide passivated contact (TOPCon) solar cells have garnered significant interest due to numerous benefits, such as easy processing, high efficiency potential, and abundant raw materials. Thanks to cheaper wafer prices and compatibility with the well-established PERC solar cell production process, manufacturing TOPCon solar cells from p-type c-Si wafers is quite challenging for large-scale solar module production. If innovative high-efficiency technologies were implemented in industrial settings, the quality of p-type wafers could become a limiting factor. Recently, production lines in other regions have developed p-type TOPCon solar cells with a conversion efficiency of 25.19% using monocrystalline Czochralski (CZ) c-Si wafers. This demonstrates the exceptional feasibility of p-type TOPCon solar cells for industrial application. This review article thoroughly examines the history of high-efficiency p-type TOPCon solar cells, advancements in various fields to enhance cell performance, the state of commercialization, and future research opportunities and challenges.","The paramount goals of solar cell technology encompass achieving exceptional energy conversion rates, prolonged lifespan, scalable production, economic viability, and the utilization of eco-friendly materials. Within the realm of high-performance crystalline silicon (c-Si) solar cells, tunnel oxide passivated contact (TOPCon) technology has garnered significant interest owing to its numerous benefits, including streamlined fabrication, high energy conversion potential, and abundant raw material availability. However, the mass production of TOPCon solar cells using p-type c-Si wafers poses substantial challenges due to the need for advanced manufacturing processes, which may be hindered by the quality of p-type wafers if cutting-edge technologies are employed. Notably, recent industrial-scale production lines have successfully developed p-type TOPCon solar cells with a remarkable 25.19% energy conversion efficiency using monocrystalline Czochralski (CZ) c-Si wafers, thereby demonstrating the feasibility of p-type TOPCon solar cells for large-scale industrial applications. This review provides a comprehensive examination of the evolution of high-efficiency p-type TOPCon solar cells, advancements in various areas to enhance cell performance, commercialization status, and potential future research avenues and obstacles.","The main goals of solar cell technology are achieving high efficiency and longevity, enabling mass production at low cost, and utilizing environmentally friendly materials. Among the various high-efficiency crystalline silicon (c-Si) solar cells, tunnel oxide passivated contact (TOPCon) cells have gained significant interest due to their numerous benefits, including ease of production, potential for high efficiency, and readily available raw materials. While p-type c-Si wafers offer cost advantages and compatibility with established PERC cell manufacturing processes, producing TOPCon cells from these wafers presents greater challenges for mass production. As cutting-edge technologies are implemented in industrial settings, the quality of p-type wafers might become a limiting factor. Notably, recent production lines have successfully fabricated p-type TOPCon solar cells with a 25.19% conversion efficiency using monocrystalline Czochralski (CZ) c-Si wafers, demonstrating the significant industrial potential of this technology. This review provides an extensive overview of the development of high-efficiency p-type TOPCon solar cells, exploring advancements in performance enhancement, the current state of commercialization, and future research prospects and challenges.",acceptable,acceptable,acceptable,3.2,3.2,3.2
78,Performance evaluation of monocrystalline and polycrystalline-based solar cell,"This paper exhibits the performance of crystalline-based solar cells (polycrystalline and monocrystalline) as well as the comparative analysis of these solar cells following various types of orientation in the solar plant. Since the global energy demand is increasing rapidly, different sorts of renewable energy have been used in the last decades to meet this massive demand all over the world. From recent studies, solar has been considered the most promising among these renewable sources. To analyze the performance, the geographical site (Savar, Dhaka) was selected which has a latitude of 23.8538° and a longitude of 90.2534°. In this study, the most effective polycrystalline and monocrystalline solar cell has been founded which is 440 and 370 wp, respectively. Regarding this, a grid-connected PV system (12.3 Kwp) has been simulated which showed the performance ratio of the monocrystalline cell was 83.55%, which was better than the polycrystalline-based solar cell which was 79.6%. In terms of different kinds of orientations, monocrystalline at dual-axis tracking planes showed the highest value of energy injection to the grid was 25.8 MWh/year, while the least value has been founded in the fixed orientation plane which was 20.6 MWh/year. In this perspective, polycrystalline showed 23.9 and 19.5 MWh/year for dual-axis tracking and fixed orientation planes, respectively. Monocrystalline showed more energy injected into the grid compared to polycrystalline technologies for every orientation in the plant as well as the highest value of performance ratio.","This study demonstrates the efficiency of crystalline solar cells (both polycrystalline and monocrystalline) alongside a comparative analysis based on various orientations within a solar facility. With the global energy demand escalating swiftly, a range of renewable energy sources have been utilized over the past decades to address this substantial need worldwide. Recent research has identified solar energy as the most promising among these sources. The performance evaluation was conducted at a geographic location in Savar, Dhaka, with coordinates of 23.8538° latitude and 90.2534° longitude. The study determined that the most efficient polycrystalline and monocrystalline solar cells had capacities of 440 wp and 370 wp, respectively. A simulation of a 12.3 Kwp grid-connected PV system revealed that the performance ratio for monocrystalline cells was 83.55%, surpassing that of polycrystalline cells, which was 79.6%. For different orientations, monocrystalline cells on dual-axis tracking planes achieved the highest energy injection to the grid at 25.8 MWh/year, whereas the fixed orientation plane recorded the lowest at 20.6 MWh/year. Correspondingly, polycrystalline cells showed energy injections of 23.9 MWh/year for dual-axis tracking and 19.5 MWh/year for fixed orientation planes. Monocrystalline cells consistently injected more energy into the grid compared to polycrystalline cells across all orientations, and they exhibited the highest performance ratio.","This study presents a comprehensive evaluation of the efficiency of crystalline-based photovoltaic cells, encompassing both polycrystalline and monocrystalline variants, in conjunction with a comparative assessment of their performance under diverse orientation configurations within a solar power plant. In response to the escalating global energy requirements, renewable energy sources have gained prominence over the past few decades, with solar energy emerging as the most promising alternative. To investigate the performance of these cells, a specific geographical location (Savar, Dhaka) with a latitude of 23.8538° and a longitude of 90.2534° was selected. The findings indicate that the most efficient polycrystalline and monocrystalline solar cells possess power outputs of 440 Wp and 370 Wp, respectively. A simulated grid-connected PV system (12.3 Kwp) revealed that the monocrystalline cell exhibited a superior performance ratio of 83.55%, surpassing the polycrystalline-based solar cell with a ratio of 79.6%. Furthermore, the analysis of various orientation types demonstrated that monocrystalline cells installed on dual-axis tracking planes achieved the highest energy injection into the grid, amounting to 25.8 MWh/year, whereas the fixed orientation plane yielded the lowest value of 20.6 MWh/year. In contrast, polycrystalline cells showed energy injection values of 23.9 MWh/year and 19.5 MWh/year for dual-axis tracking and fixed orientation planes, respectively. Notably, monocrystalline technology consistently outperformed polycrystalline technology in terms of energy injection and performance ratio across all orientation configurations within the plant.","This study investigates the efficacy of crystalline silicon solar cells (both polycrystalline and monocrystalline) and compares their performance under various orientations within a solar power plant. Driven by the surging global energy demand, diverse renewable energy sources have been explored in recent decades. Among these, solar energy has emerged as a frontrunner. To assess performance, a geographical location in Savar, Dhaka (latitude 23.8538°, longitude 90.2534°) was chosen. The research identified the most efficient polycrystalline and monocrystalline solar cells, yielding 440 Wp and 370 Wp, respectively. A simulation of a 12.3 kWp grid-connected photovoltaic system revealed that monocrystalline cells achieved a superior performance ratio of 83.55% compared to 79.6% for polycrystalline cells. In terms of orientation, dual-axis tracking maximized energy injection to the grid for monocrystalline cells at 25.8 MWh/year, while fixed orientation yielded the lowest at 20.6 MWh/year. Similarly, polycrystalline cells generated 23.9 MWh/year with dual-axis tracking and 19.5 MWh/year in a fixed orientation. Across all orientations, monocrystalline technology consistently injected more energy into the grid than polycrystalline technology and demonstrated a higher performance ratio.",acceptable,acceptable,acceptable,3.2,3.2,3.2
79,Blurring the lines: how AI is redefining artistic ownership and copyright,"The rapid advancement of AI technology has brought about significant changes across various industries, including the realm of art and creative endeavors. Presently, AI demonstrates the capability to produce high-quality works that closely resemble those crafted by humans. However, amidst these advancements, ownership rights remain ambiguous, given that existing copyright laws do not explicitly confer copyright protection to works not originating from human creators. The primary objective of this research is to present a spectrum of opinions and perspectives on a pivotal question: should the ownership of AI-generated works belong to individuals or AI entities? Simultaneously, the study aims to scrutinize the suitability of the existing copyright laws in addressing the complexities of AI-generated works. Additionally, this research paper endeavors to pinpoint the necessary adjustments and enhancements required within the current legal framework to harmonize with the contemporary landscape. To attain these objectives, two surveys were conducted. The first, a quantitative survey, involved a sample size of 100 participants, while the second, a qualitative survey, featured professionals within the creative field and legal experts. Each group comprised five individuals. The research findings gleaned from these surveys strongly suggest that AI-generated works exhibit quality on par with human creations and, therefore, merit classification as human works. Furthermore, there is a compelling argument that these works should be afforded copyright protection to provide clarity regarding their utilization by other individuals. Consequently, the prevailing copyright laws should undergo revision and amendment to reflect the demands of the modern era, establishing precise regulations tailored for AI-generated works.","The swift progress of AI technology has introduced substantial changes in numerous sectors, including the domain of art and creative activities. Nowadays, AI is capable of generating high-quality works that closely mimic those created by humans. Yet, alongside these developments, the question of ownership remains unclear, as current copyright laws do not specifically grant protection to works not made by human creators. This research primarily aims to explore various opinions and perspectives on a crucial issue: whether ownership of AI-created works should be ascribed to individuals or AI entities. Additionally, the study examines the adequacy of existing copyright laws in handling the intricacies of AI-generated creations. Furthermore, this paper seeks to identify the necessary revisions and improvements within the current legal framework to align with contemporary realities. To achieve these aims, two surveys were conducted. The first was a quantitative survey with a sample size of 100 participants, and the second was a qualitative survey involving five professionals from the creative field and five legal experts. Results from these surveys strongly indicate that AI-generated works are of comparable quality to human-made creations and therefore should be classified as such. Additionally, there is a strong case for granting copyright protection to these works to clarify their use by others. Consequently, current copyright laws need to be revised and updated to reflect modern needs, establishing explicit regulations for AI-generated works.","The exponential growth of artificial intelligence has triggered a paradigm shift across diverse sectors, notably in the realm of artistic expression and innovation. Currently, AI has demonstrated the ability to generate exceptional pieces that are virtually indistinguishable from those produced by human creatives. Nevertheless, the issue of ownership remains shrouded in uncertainty, as existing intellectual property laws fail to explicitly extend copyright protection to works not originating from human authors. This study seeks to present a kaleidoscope of viewpoints on a crucial question: should the proprietary rights of AI-generated works be vested in individuals or AI systems? Concurrently, it aims to examine the efficacy of current copyright laws in addressing the intricacies of AI-generated works. Furthermore, this research endeavors to identify the necessary refinements and augmentations required within the existing legal framework to align with the contemporary landscape. To achieve these objectives, two surveys were conducted: a quantitative survey involving 100 participants and a qualitative survey featuring five creative professionals and five legal experts. The findings of this research strongly indicate that AI-generated works exhibit a level of excellence comparable to human creations, thereby warranting their classification as human works. Moreover, a compelling case can be made for affording these works copyright protection to provide clarity regarding their utilization by other individuals. As a result, the prevailing copyright laws must undergo revision and amendment to reflect the demands of the modern era, establishing precise regulations tailored to AI-generated works.","The swift progress of artificial intelligence has revolutionized various sectors, notably the artistic and creative domains. AI now possesses the capacity to generate impressive outputs that mirror human creations. However, despite these developments, ownership rights remain unclear, as current copyright laws lack explicit provisions for works not originating from human creators. This study explores diverse viewpoints on a crucial question: should ownership of AI-produced works lie with individuals or AI entities? It also analyzes the adequacy of existing copyright laws in navigating the intricacies of AI-generated creations, proposing modifications to align the legal framework with contemporary realities. Two surveys were employed: a quantitative survey with 100 participants and a qualitative survey involving five creative professionals and five legal experts. Findings highlight the high quality of AI-generated works, suggesting they should be categorized as human creations and granted copyright protection to clarify their usage by others. Consequently, current copyright laws necessitate revision and amendment to meet modern demands, establishing specific regulations for AI-generated works.",acceptable,acceptable,acceptable,,,
80,Computer-aided digital media art creation based on artificial intelligence,"Driven by information technology, artificial intelligence (AI) has gradually become an important symbol of modern society. In digital media art creation, AI has unique advantages and can help artists create better works. The purpose of this research was to study digital media art creation based on AI’s computer-aided technology. This study analysed the possibility of combining digital media art with AI and the positive effects of combining it with digital media art creation are discussed. A support vector machine (SVM) algorithm based on AI is proposed, and computer-aided digital media art creation based on AI was analysed experimentally. The experimental results of this study showed that artistic works created based on AI computer-aided technology had a digital dynamic score of 80 to 90, a digital sound effect score of 82 to 92, a digital stunt score of 85 to 95, a digital texture score of 83 to 96, and a digital colour score of 86 to 93. These scores were higher than those of works of art created based on traditional technology, indicating that AI-based computer-aided technology can be well applied to the creation of digital media art.","Propelled by advancements in information technology, artificial intelligence (AI) has increasingly become a defining feature of contemporary society. In the realm of digital media art creation, AI offers distinct advantages that can aid artists in producing superior works. This research aimed to explore digital media art creation using AI-driven computer-aided techniques. It examined the feasibility of integrating digital media art with AI and highlighted the positive outcomes of this integration. A support vector machine (SVM) algorithm grounded in AI was suggested, and AI-based computer-aided digital media art creation was experimentally evaluated. The findings demonstrated that artworks generated with AI-assisted techniques achieved digital dynamic scores ranging from 80 to 90, digital sound effect scores from 82 to 92, digital stunt scores from 85 to 95, digital texture scores from 83 to 96, and digital color scores from 86 to 93. These scores surpassed those of artworks created using traditional methods, suggesting that AI-assisted technology can be effectively utilized in the creation of digital media art.","""Fuelled by the rapid advancements in information technology, artificial intelligence has emerged as a hallmark of contemporary society. In the realm of digital media art, AI's distinctive strengths enable artists to produce superior pieces. This research endeavour aimed to investigate the potential of AI-driven computer-aided technology in digital media art creation. The study explored the feasibility of integrating AI with digital media art and discussed the benefits of this synergy. A novel approach was proposed, leveraging an AI-based support vector machine algorithm, and the experimental results demonstrated that AI-assisted digital media art creation yielded remarkable outcomes, with scores ranging from 80 to 96 in digital dynamics, sound effects, stunts, texture, and colour, surpassing those achieved through traditional methods, thereby validating the efficacy of AI-based computer-aided technology in digital media art creation.""","The rise of artificial intelligence (AI), fueled by advancements in information technology, has positioned it as a key hallmark of contemporary society. AI offers distinct capabilities in the realm of digital media art, empowering artists to achieve new creative heights. This research explored the integration of AI-powered computer-aided technology within digital media art creation. The study investigated the feasibility and benefits of merging these two domains. An AI-driven support vector machine (SVM) algorithm was developed, and its application in computer-aided digital media art creation was empirically evaluated. Results demonstrated that AI-assisted artworks achieved superior scores across various digital aspects (dynamics, sound effects, stunts, texture, and color) compared to works created using conventional methods. The scores, ranging from 80 to 96, underscore the significant potential of AI-based computer-aided technology to enhance digital media art creation.",acceptable,acceptable,acceptable,3.6,3.2,3.2
81,Using machine learning to predict artistic styles: an analysis of trends and the research agenda,"In the field of art, machine learning models have been used to predict artistic styles in paintings. The foregoing is somewhat advantageous for analysts, as these tools can provide more valuable results and help reduce bias in the results and conclusions provided. Therefore, the objective of this research was to examine research trends in the use of machine learning to predict artistic styles from a bibliometric review based on the PRISMA methodology. From the search equations, 268 documents were found, out of which, following the application of inclusion and exclusion criteria, 128 documents were analyzed. Through quantitative analysis, a growing research interest in the subject is evident, progressing from user perception approaches to the utilization of tools like deep learning for art studies. Among the main results, it is possible to identify that one of the most used techniques in the field has been neural networks for pattern recognition. Also, a large part of the research focuses on the use of design software for image creation and manipulation. Finally, it is found that the number of studies focused on contemporary modern art is still limited, this is due to the fact that a large part of the investigations has focused on historical artistic styles.","In the realm of art, machine learning algorithms have been applied to forecast artistic styles in paintings. This practice benefits analysts by delivering more valuable insights and mitigating bias in the findings and conclusions. Consequently, the aim of this research was to scrutinize trends in utilizing machine learning for predicting artistic styles through a bibliometric review adhering to the PRISMA guidelines. From the search queries, 268 publications were identified, and after implementing inclusion and exclusion criteria, 128 documents were reviewed. The quantitative analysis reveals an increasing interest in the area, evolving from user perception methodologies to the employment of advanced tools like deep learning for art analysis. Neural networks are frequently used techniques for pattern recognition in this domain. In addition, a considerable portion of the research concentrates on using design software for creating and manipulating imagery. Finally, the number of studies focused on contemporary modern art is still scarce, mainly because much of the research has been dedicated to historical artistic styles.","Within the realm of artistic expression, the application of machine learning algorithms has enabled the forecasting of stylistic patterns in visual artworks, thereby offering a distinct advantage to art critics and historians by providing more accurate and unbiased insights. This study aimed to investigate the emerging trends in the utilization of machine learning for artistic style prediction through a systematic review grounded in the PRISMA framework. A comprehensive search yielded 268 relevant documents, which were subsequently filtered to 128 studies that met the inclusion criteria. Quantitative analysis revealed a burgeoning interest in this area, shifting from user-centric approaches to the integration of advanced techniques like deep learning in art historical research. Notably, neural networks have emerged as a dominant methodology for pattern recognition, while a significant proportion of studies have leveraged design software for image generation and manipulation. Furthermore, it was observed that research focused on contemporary modern art remains limited, largely due to the prevailing emphasis on historical artistic styles in existing investigations.","Utilizing machine learning algorithms to forecast artistic techniques in paintings has emerged as a significant development in the art world. This advancement proves beneficial for art analysts, as these intelligent tools can yield more insightful outcomes, mitigating potential bias. To delve deeper into this trend, a bibliometric review adhering to the PRISMA methodology was conducted, examining the evolving landscape of research on machine learning for artistic style prediction. After a comprehensive search, 268 documents were identified, and after applying rigorous inclusion and exclusion criteria, 128 were meticulously examined. Quantitative analysis revealed a burgeoning interest in this domain, with a noticeable shift from approaches based on user perception to the integration of sophisticated tools, notably deep learning, for art studies. The review highlights neural networks for pattern recognition as a dominant technique in this field. Notably, a significant portion of the research centers around employing design software for image generation and modification. However, studies concentrating on contemporary modern art remain scarce, primarily due to the prevailing focus on historical artistic styles in existing investigations.",acceptable,acceptable,acceptable,3.6,3.2,3.2
82,Creation mechanism of new media art combining artificial intelligence and internet of things technology in a metaverse environment,"The Metaverse is regarded as a brand-new virtual society constructed by deep media, and the new media art produced by new media technology will gradually replace the traditional art form and play an important role in the infinite Metaverse in the future. The maturity of the new media art creation mechanism must also depend on the help of artificial intelligence (AI) and Internet of Things (IoT) technology. The purpose of this study is to explore the image style transfer of digital painting art in new media art, that is, to reshape the image style by neural network technology in AI based on retaining the semantic information of the original image. Based on neural style transfer, an image style conversion method based on feature synthesis is proposed. Using the feature mapping of content image and style image and combining the advantages of traditional texture synthesis, a richer multi-style target feature mapping is synthesized. Then, the inverse transformation of target feature mapping is restored to an image to realize style transformation. In addition, the research results are analyzed. Under the background of integrating AI and IoT, the creation mechanism of new media art is optimized. Regarding digital art style transformation, the Tensorflow program framework is used for simulation verification and performance evaluation. The experimental results show that the image style transfer method based on feature synthesis proposed in this study can make the image texture more reasonably distributed, and can change the style texture by retaining more semantic structure content of the original image, thus generating richer artistic effects, and having better interactivity and local controllability. It can provide theoretical help and reference for developing new media art creation mechanisms.","The Metaverse is envisioned as a novel virtual society built by advanced media, with new media art generated through innovative media technologies expected to gradually replace traditional art forms and play a significant role in the limitless Metaverse of the future. The development of new media art creation mechanisms will also rely on the support of artificial intelligence (AI) and Internet of Things (IoT) technologies. This study aims to investigate the style transfer of digital painting in new media art, specifically by using neural network technology in AI to reshape image styles while preserving the original image's semantic information. An image style transformation method based on feature synthesis is proposed, leveraging the feature mapping of both content and style images, combined with traditional texture synthesis techniques, to create a richer multi-style feature mapping. The inverse transformation of this target feature mapping is then restored to an image to achieve style transformation. Additionally, the research results are analyzed, demonstrating that integrating AI and IoT optimizes new media art creation mechanisms. For digital art style transformation, the Tensorflow framework was employed for simulation and performance evaluation. Experimental outcomes indicate that the proposed feature synthesis-based image style transfer method can sensibly distribute image textures and alter style textures while retaining more of the original image's semantic structure, generating richer artistic effects, enhanced interactivity, and improved local controllability. It provides theoretical insights and references for the advancement of new media art creation mechanisms.","In the realm of the Metaverse, a novel virtual world crafted by cutting-edge media, innovative art forms spawned by new media technologies are poised to supplant traditional artistic expressions, assuming a pivotal role in the boundless expanse of the Metaverse. The evolution of new media art creation hinges on the synergy of artificial intelligence (AI) and Internet of Things (IoT) technologies. This investigation delves into the realm of digital painting art in new media, focusing on the neural network-driven image style transfer that preserves the original image's semantic essence. By harnessing the power of neural style transfer, a feature synthesis-based image style conversion method is proposed, which integrates the advantages of traditional texture synthesis to yield a richer, multi-style target feature mapping. This, in turn, enables the inverse transformation of the target feature mapping into an image, thereby achieving style transformation. Furthermore, the research outcomes are analyzed, optimizing the new media art creation mechanism under the umbrella of AI and IoT integration. The digital art style transformation is validated through simulation and performance evaluation using the Tensorflow program framework, demonstrating that the proposed feature synthesis-based image style transfer method can produce more reasonably distributed image textures, retain more semantic structure content, and generate richer artistic effects with enhanced interactivity and local controllability, thereby providing valuable theoretical insights for the development of new media art creation mechanisms.","The Metaverse, envisioned as a novel digital realm built upon advanced media technologies, is poised to witness a shift in artistic expression. New media art, powered by cutting-edge technologies, is expected to gradually supplant traditional art forms, assuming a pivotal role in the boundless expanse of the Metaverse. The evolution of this new creative landscape hinges on the integration of Artificial Intelligence (AI) and the Internet of Things (IoT). This study delves into the realm of style transfer in digital painting, aiming to reshape visual aesthetics using AI-driven neural networks while preserving the inherent meaning of the source image. A novel approach grounded in feature synthesis is introduced, leveraging the characteristics of both content and style images and drawing upon the strengths of conventional texture synthesis techniques to generate a multifaceted target feature map. Through inverse transformation, this map is then rendered into an image, effectively achieving style transfer. The integration of AI and IoT paves the way for an enhanced new media art creation mechanism. Utilizing the Tensorflow framework, the proposed style transfer method undergoes rigorous simulation and evaluation. Results demonstrate that this approach facilitates a more coherent distribution of image texture, allowing for style modification while faithfully retaining the semantic essence of the original image. Consequently, it yields a richer artistic output with enhanced interactivity and localized control, offering valuable insights and guidance for the future development of new media art creation mechanisms.",acceptable,acceptable,acceptable,3.6,3.2,3.2
83,Humans versus AI: whether and why we prefer human-created compared to AI-created artwork,"With the recent proliferation of advanced artificial intelligence (AI) models capable of mimicking human artworks, AI creations might soon replace products of human creativity, although skeptics argue that this outcome is unlikely. One possible reason this may be unlikely is that, independent of the physical properties of art, we place great value on the imbuement of the human experience in art. An interesting question, then, is whether and why people might prefer human-compared to AI-created artworks. To explore these questions, we manipulated the purported creator of pieces of art by randomly assigning a “Human-created” or “AI-created” label to paintings actually created by AI, and then assessed participants’ judgements of the artworks across four rating criteria (Liking, Beauty, Profundity, and Worth). Study 1 found increased positive judgements for human- compared to AI-labelled art across all criteria. Study 2 aimed to replicate and extend Study 1 with additional ratings (Emotion, Story, Meaningful, Effort, and Time to create) intended to elucidate why people more-positively appraise Human-labelled artworks. The main findings from Study 1 were replicated, with narrativity (Story) and perceived effort behind artworks (Effort) moderating the label effects (“Human-created” vs. “AI-created”), but only for the sensory-level judgements (Liking, Beauty). Positive personal attitudes toward AI moderated label effects for more-communicative judgements (Profundity, Worth). These studies demonstrate that people tend to be negatively biased against AI-created artworks relative to purportedly human-created artwork, and suggest that knowledge of human engagement in the artistic process contributes positively to appraisals of art.","In light of the burgeoning development of sophisticated artificial intelligence (AI) models that can replicate human-created art, AI-generated artworks might emerge as substitutes for human creativity. However, critics dispute the likelihood of this scenario, suggesting that the intrinsic value we place on the human experience within art plays a crucial role, irrespective of the art's physical attributes. This raises a compelling issue regarding whether and why individuals may favor human-produced over AI-generated art. To investigate, researchers conducted an experiment where they randomly assigned either a “Human-created” or “AI-created” label to AI-generated paintings and then evaluated participants' perceptions of the artworks based on four criteria: Liking, Beauty, Profundity, and Worth. The first study revealed that artwork labeled as human-made received more favorable evaluations across all criteria compared to those labeled as AI-made. The second study sought not only to replicate but also to expand on these results by including additional ratings (Emotion, Story, Meaningfulness, Effort, and Time to create) to understand why human-labeled art received higher appraisals. The replication confirmed the initial findings, showing that labels influenced sensory-level judgments (Liking, Beauty), with narrativity (Story) and perceived effort (Effort) acting as moderators. For more communicative judgments (Profundity, Worth), personal positive attitudes towards AI moderated the label effects. Overall, these studies indicate a prevalent bias against AI-generated art compared to human-labeled art, emphasizing that the perceived human involvement in the artistic process enhances the appraisal of artworks.","The rapid emergence of sophisticated artificial intelligence (AI) models that can replicate human artistic masterpieces has sparked debate about whether AI-generated creations will eventually supplant human innovations, although some doubters contend that this scenario is improbable. A potential explanation for this skepticism lies in the fact that, beyond the physical attributes of art, we assign significant importance to the infusion of human sentiment and experience in artistic expressions. This raises an intriguing question: do people exhibit a preference for human-generated versus AI-created artworks, and if so, why? To investigate this, we conducted an experiment where we randomly attributed ""Human-created"" or ""AI-created"" labels to AI-generated paintings and evaluated participants' assessments of the artworks across four dimensions (Aesthetic Appeal, Visual Attractiveness, Depth, and Monetary Value). The results of Study 1 revealed that human-labelled art received more favorable evaluations across all dimensions. Study 2 aimed to replicate and expand upon Study 1 by incorporating additional ratings (Emotional Resonance, Narrative, Significance, Creative Effort, and Time Invested) to elucidate the underlying reasons for the preference towards human-labelled artworks. The primary findings of Study 1 were replicated, with narrative richness and perceived creative effort influencing the label effects (""Human-created"" vs. ""AI-created"") solely for the sensory-level evaluations (Aesthetic Appeal, Visual Attractiveness). Furthermore, positive attitudes towards AI moderated label effects for more abstract judgements (Depth, Monetary Value). These studies demonstrate that people tend to harbor a negative bias against AI-generated artworks compared to those perceived as human-created, suggesting that awareness of human involvement in the creative process positively impacts art appreciation.","The rapid increase in sophisticated artificial intelligence (AI) models capable of generating art mimicking human styles raises concerns about the potential displacement of human creativity, despite skepticism regarding this possibility. One argument against this displacement emphasizes the inherent value we assign to art's reflection of human experiences, irrespective of its physical characteristics. This leads to a compelling inquiry into the potential preference for human-created art over AI-generated art and the underlying reasons for this preference. To investigate this, a series of studies examined participants' judgments of artwork across various criteria (e.g., liking, beauty, profundity, worth), manipulating the perceived creator by randomly labeling AI-generated paintings as either ""Human-created"" or ""AI-created."" Results consistently revealed a preference for ""Human-created"" labeled artwork, suggesting a bias against AI-generated art. Further exploration revealed that this bias was influenced by perceptions of the narrative quality and effort invested in the artwork, primarily for sensory-level judgments, while positive attitudes toward AI mitigated the bias for judgments related to the artwork's communicative aspects. These findings underscore the significant role of perceived human involvement in shaping art appreciation, highlighting a tendency to favor artwork attributed to human creators.",acceptable,acceptable,acceptable,3.2,3.6,3.2
84,Copyright and Artificial Creation: Does EU Copyright Law Protect AI-Assisted Output?,"This article queries whether and to what extent works produced with the aid of AI systems – AI-assisted output – are protected under EU copyright standards. We carry out a doctrinal legal analysis to scrutinise the concepts of “work”, “originality” and “creative freedom”, as well as the notion of authorship, as set forth in the EU copyright acquis and developed in the case-law of the Court of Justice. On this basis, we develop a four-step test to assess whether AI-assisted output qualifies as an original work of authorship under EU law, and how the existing rules on authorship may apply. Our conclusion is that current EU copyright rules are generally suitable and sufficiently flexible to deal with the challenges posed by AI-assisted output.","This paper investigates whether and to what degree creations produced with AI assistance – AI-generated content – receive protection under EU copyright regulations. We perform a doctrinal legal analysis to examine the notions of “work,” “originality,” and “creative freedom,” as well as the concept of authorship, as enshrined in the EU copyright framework and interpreted by the Court of Justice. Based on this analysis, we propose a four-step test to determine whether AI-generated content meets the criteria for original works of authorship under EU law and how existing authorship rules may be applied. Our findings indicate that current EU copyright legislation is generally adequate and adaptable to the challenges presented by AI-generated content.","""This study investigates the copyright protection afforded to creative content generated with the assistance of artificial intelligence systems under European Union legal frameworks, examining the extent to which such AI-facilitated productions meet the requisite standards. Through a rigorous examination of the legal doctrine, we deconstruct the fundamental concepts of 'authorial work', 'novelty', and 'artistic autonomy', as well as the principles of authorship, as established in EU copyright legislation and elucidated by the Court of Justice's jurisprudence. Building upon this analysis, we devise a quartet of evaluative criteria to determine whether AI-aided creations constitute original intellectual property under EU law, and how the prevailing authorship regulations may be applied. Ultimately, our findings suggest that the current EU copyright regime is adequately equipped and sufficiently adaptable to address the complexities arising from AI-aided creative output.""","This study explores the applicability and scope of European Union copyright law in relation to artistic creations generated with the assistance of artificial intelligence (AI). Employing a rigorous legal analysis, the research examines fundamental copyright principles such as ""work,"" ""originality,"" ""creative freedom,"" and ""authorship"" as defined by EU copyright regulations and interpreted by the Court of Justice. This analysis forms the basis for a four-stage assessment designed to determine whether AI-assisted creations meet the criteria for original works under EU law and how existing authorship rules might be applied. Ultimately, the study concludes that current EU copyright regulations possess the adaptability and flexibility to effectively address the unique challenges presented by AI-assisted creations.",acceptable,acceptable,acceptable,3.6,3.6,3.6
85,Artistic representations of data can help bridge the US political divide over climate change,"Visual art has been used to revamp the portrayal of climate change with the aims of engaging emotions and expanding nonexperts’ psychological capacity to perceive its relevance. However, empirical evidence supporting the effectiveness of artistic representation of data as a tool for public communication is lacking. Using controlled experiments with two national samples of U.S. adults (total N = 671), here we found that artistic visualizations elicited stronger positive emotions than informationally equivalent data graphs but did not differ in their perceived credibility or effectiveness as visual aids for learning. When used to prompt individual reflection, artistic visualizations appeared to mitigate the political division in viewers’ perceived relevance of climate change that could otherwise be exacerbated by exposure to data graphs.","Art has been employed to reshape the depiction of climate change with the goal of stirring emotions and enhancing the general public’s ability to recognize its significance. Nevertheless, there is a scarcity of empirical data confirming the efficacy of artistic data representation as a method for public outreach. Through controlled experiments involving two national samples of U.S. adults (total N = 671), we discovered that artistic visualizations evoked stronger positive emotions than data graphs with similar information content, although they did not differ in terms of perceived credibility or educational usefulness. When used to encourage personal reflection, artistic visualizations seemed to reduce the political divide in viewers' perceived importance of climate change, a divide that might otherwise be worsened by data graphs.","The representation of climate change through visual art has been employed to reinvigorate its depiction, seeking to evoke emotional responses and enhance the cognitive ability of non-specialists to recognize its significance. Nevertheless, concrete proof substantiating the efficacy of artistic data visualization as a means of public outreach remains scarce. Our study, involving controlled experiments with two nationally representative samples of American adults (N = 671), reveals that artistic renderings triggered more intense positive emotional reactions compared to data graphs conveying equivalent information, although no differences were observed in terms of perceived trustworthiness or instructional value. Furthermore, when utilized to stimulate personal introspection, artistic visualizations appeared to reduce the partisan polarization in viewers' perceptions of climate change relevance that might otherwise be intensified by exposure to data graphs.","To make climate change more relatable and emotionally impactful, visual art has been employed. However, there is limited empirical support for the efficacy of artistic data representation as a public communication tool. Controlled experiments with two nationally representative samples of U.S. adults (N = 671) revealed that while artistic visualizations evoked stronger positive emotions compared to data graphs conveying the same information, they did not exhibit differences in perceived credibility or effectiveness as learning aids. Interestingly, prompting personal reflection with artistic visualizations appeared to lessen the political divide in perceived climate change relevance, a divide that data graph exposure might otherwise widen.",acceptable,acceptable,acceptable,3.6,3.2,3.2
86,A New Study of AI Artists for Changing the Movie Industries,"Due to the rise of artificial intelligence (AI) in the arts, this paper aims to explore the use of AI for reducing film production costs through the creation of realistic images. Additionally, we investigate whether AI can recreate the same character at the same age. Without needing to replace the original actor, qualitative data collection tools were employed to study three distinct population groups within the film industry: film industry professionals, moviegoers, and technologists. Our research reveals that AI, or AI artists in film production, still face limitations in significantly reducing production costs. Furthermore, it is crucial to engage a text expert in the image production process for films who possesses a comprehensive understanding of film principles in order to achieve images that align with the project’s requirements. Moreover, the introduction of the AI artist technique allows for the recreation of a character at the same age portrayed by the same actor, even if that actor may have passed away. Consequently, obtaining consent from the relatives of the actor or actress becomes a necessary step. Furthermore, the aspect of audience acceptance does not hold significant interest, as it demands a greater level of realism in both the image and the actors, surpassing what AI can provide. Therefore, this paper underscores the increasing influence of AI in the arts, particularly within film production, and examines its potential to reduce costs and recreate characters.","With the emergence of artificial intelligence (AI) in creative disciplines, this paper seeks to investigate AI's potential to lower film production expenses by generating lifelike images. Moreover, the study examines AI's ability to reproduce characters at a consistent age without replacing the initial actor. Utilizing qualitative data collection methods, the research examines three specific groups within the film industry: professionals, audiences, and technology experts. Our findings indicate that AI, or AI-based artists in film creation, face significant challenges in drastically cutting costs. Additionally, it is essential to involve a text expert in the image creation process for films who has an extensive understanding of cinematic principles to ensure the images meet the project’s needs. The AI artist technique also enables the portrayal of a character at the same age by the same actor, even posthumously, thus necessitating consent from the actor's family. Furthermore, audience acceptance is not a predominant concern, as it demands a higher degree of realism in both visuals and performances, which currently surpasses AI's capabilities. This paper thus highlights the growing impact of AI in the arts, especially in film production, and evaluates its potential for cost reduction and character recreation.","The burgeoning presence of artificial intelligence (AI) in the creative sphere has prompted this study to delve into the potential of AI-driven image generation for cost-effective film production. Moreover, we examine whether AI can faithfully recreate a character at a specific age, eliminating the need for original actor replacement. To gauge industry perceptions, we utilized qualitative data collection methods to survey three distinct cohorts: film professionals, cinema enthusiasts, and technology experts. Our findings indicate that, despite its promise, AI-assisted filmmaking still encounters significant hurdles in substantially reducing production expenditures. The integration of a film-savvy expert with a deep understanding of cinematic principles is essential to ensure AI-generated images meet project requirements. Notably, the AI artist technique enables the recreation of a character at a specific age, even if the original actor is no longer alive, necessitating consent from their relatives. However, audience acceptance is not a primary concern, as it demands an unprecedented level of realism, surpassing current AI capabilities. Ultimately, this paper highlights the growing impact of AI on the arts, particularly in film production, and its potential to drive cost savings and character recreation.","This study delves into the burgeoning role of artificial intelligence (AI) in filmmaking, specifically its capacity to generate lifelike imagery and potentially lower production expenses. Utilizing qualitative data from film professionals, audiences, and technology experts, the research examines the feasibility of using AI to recreate characters at specific ages without replacing the original actor. Findings suggest that while AI artists offer some promise in film production, their ability to substantially cut costs remains limited. Achieving imagery that aligns with a project's vision necessitates the involvement of a text expert well-versed in cinematic principles. Interestingly, AI techniques enable the recreation of characters at any age using the original actor's likeness, even posthumously, raising ethical considerations around consent from the actor's family. However, audience acceptance appears less of a concern, as achieving the desired realism in both imagery and performance remains beyond current AI capabilities. Ultimately, this paper highlights the growing influence of AI in the arts, particularly film, and explores its potential for cost reduction and character recreation.",acceptable,acceptable,acceptable,3.2,3.2,3.2
87,Recent progress in organic waste recycling materials for solar cell applications,"Organic waste-derived solar cells (OWSC) are a classification of third-generation photovoltaic cells in which one or more constituents are fabricated from organic waste material. They are an inspirational complement to the conventional third-generation solar cell with the potential of revolutionizing our future approach to solar cell manufacture. This article provides a study and summary of solar cells that fall under the category of OWSC. OWSC own their merit to low cost of manufacturing and environmental friendliness. This review article reveals different organic waste raw materials, preparation-to-assembly methodologies, and novel approaches to solar cell manufacturing. Ideas for the optimization of the performance of OWSC are presented. The assembly configurations and photovoltaic parameters of reported OWSC are compared in detail. An overview of the trends in the research regarding OWSC in the past decade is given. Also, the advantages and disadvantages of the different solar cell technologies are discussed, and possible trends are proposed. Industrial organic waste raw materials such as paper, coal, and plastics are among the least explored and yet most attractive for solar cell fabrication. The power conversion efficiencies for the cited works are mentioned while emphasizing the products and functions of the organic waste raw materials used.Graphical Abstract","Organic waste-based solar cells (OWSC) belong to the category of third-generation photovoltaic cells, featuring one or more components derived from organic waste. These cells stand as an innovative alternative to traditional third-generation solar cells and hold the promise of transforming future solar cell production. This article reviews and examines solar cells classified as OWSC, highlighting their cost-effective manufacturing and eco-friendliness. The review discusses various organic waste materials, methods from preparation to assembly, and new manufacturing techniques. Strategies for enhancing the performance of OWSC are suggested. Detailed comparisons of the assembly structures and photovoltaic parameters of reported OWSC are provided. The article presents an overview of the research trends in OWSC over the last ten years and discusses the pros and cons of different solar cell technologies while proposing potential future directions. Industrial organic waste materials such as paper, coal, and plastics are identified as underexplored yet promising for solar cell production. The power conversion efficiencies of the referenced studies are detailed, focusing on the products and functions of the organic waste materials used. Graphical Abstract.","Here is a paraphrased version of the original text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""A novel breed of photovoltaic devices, dubbed Organic Waste-Derived Solar Cells (OWSC), leverages organic waste materials to fabricate one or more components, thereby offering a groundbreaking alternative to traditional third-generation solar cells. This innovative approach has the potential to transform the solar cell manufacturing landscape. This comprehensive review delves into the realm of OWSC, highlighting their dual benefits of cost-effectiveness and eco-friendliness. The article explores diverse organic waste sources, fabrication methodologies, and pioneering techniques for solar cell production. Strategies for optimizing OWSC performance are also presented. A detailed comparison of the assembly configurations and photovoltaic parameters of reported OWSC is provided, along with an overview of the past decade's research trends. The advantages and limitations of various solar cell technologies are discussed, and potential future directions are proposed. Industrial organic waste materials, such as paper, coal, and plastics, remain underutilized yet promising resources for solar cell fabrication. The power conversion efficiencies of the cited studies are reported, with a focus on the products and functions of the organic waste materials employed.""","Third-generation photovoltaic cells utilizing organic waste materials, termed organic waste-derived solar cells (OWSCs), represent a promising alternative to conventional third-generation solar cells. This review delves into the realm of OWSCs, exploring their fabrication from diverse organic waste sources, examining the methodologies employed in their construction, and evaluating their performance. The study highlights the distinct advantages of OWSCs, particularly their affordability and minimal environmental impact. A comparative analysis of various OWSC configurations and their corresponding photovoltaic parameters is provided, along with an assessment of research trends over the past ten years. The article further investigates the strengths and weaknesses of different solar cell technologies, projecting potential future directions. Notably, industrial organic waste materials like paper, coal, and plastics, though relatively unexplored, hold significant promise for solar cell production. The power conversion efficiencies achieved in existing research are discussed, with particular emphasis on the role and processing of the organic waste materials employed.",acceptable,acceptable,acceptable,3.2,3.2,3.2
88,A Comprehensive Survey of Silicon Thin-film Solar Cell: Challenges and Novel Trends,"Solar cells are commonly recognized as one of the most promising devices that can be utilized to produce energy from renewable sources. As a result of their low production costs, little material consumption, and projected increasing trajectory in terms of efficiency, thin-film solar cells have emerged as the technology of choice in the solar industry at present. This study aims to provide a comprehensive review of silicon thin-film solar cells, beginning with their inception and progressing up to the most cutting-edge module made in a laboratory setting. There is a review of the fantastic development of each technology, as well as its cell configuration, restrictions, equivalent circuit model, cell performance, and global market share. The dependability and availability of cell materials, in addition to the comparison of numerous characteristics, are both areas of research that are conducted concurrently for each of the distinct technologies. New advances in solar cells are also highlighted; these hold the potential to be significant variables and solutions in the process of the future's development. This abbreviated and brief version of the comprehensive analysis is provided to readers in the hope that it will aid them in evaluating potential research avenues about the proper applications and production of solar cells.","Solar cells are widely regarded as a highly promising means of generating energy from renewable sources. Due to their low manufacturing costs, minimal material usage, and anticipated improvements in efficiency, thin-film solar cells have become the preferred technology in today's solar industry. This paper aims to offer an in-depth review of silicon thin-film solar cells, tracing their development from initial creation to the latest advanced laboratory modules. It examines the remarkable progress of each technology, including their cell configurations, limitations, equivalent circuit models, performance metrics, and market share worldwide. Concurrently, the study investigates the reliability and availability of cell materials, comparing various characteristics across different technologies. The paper also highlights recent advancements in solar cells, which could play a crucial role in future developments. This concise overview is intended to help readers assess potential research directions concerning the optimal use and production of solar cells.","Renewable energy harnessing has solar cells as a frontrunner, and among these, thin-film variants have gained prominence in the industry due to their economical production, minimal material usage, and anticipated efficiency surge. This review delves into the evolution of silicon thin-film solar cells, from their genesis to the latest laboratory-crafted modules, examining each technology's milestones, architectural design, limitations, circuitry, performance, and market penetration. Concurrently, the study investigates the reliability and accessibility of constituent materials, as well as comparative analyses of diverse characteristics for each technology. Emerging breakthroughs in solar cells are also spotlighted, holding promise as pivotal factors and solutions in shaping the future. This condensed review aims to facilitate readers in identifying potential research pathways for optimal solar cell applications and manufacturing.","Widely acknowledged for their potential in harnessing renewable energy, solar cells, particularly thin-film variants, have garnered significant attention due to their cost-effectiveness, minimal material usage, and anticipated efficiency improvements. This investigation presents a thorough examination of silicon thin-film solar cells, tracing their evolution from initial concepts to state-of-the-art laboratory prototypes. The study delves into the remarkable progress of each technology, encompassing aspects like cell structure, limitations, electrical modeling, performance metrics, and market penetration. Furthermore, it concurrently explores the reliability and accessibility of cell materials, alongside a comparative analysis of various attributes for each technology. The review also spotlights recent breakthroughs in solar cell technology, recognizing their potential to shape future advancements. This concise and focused analysis aims to equip readers with insights to assess promising research directions concerning the optimal applications and fabrication of solar cells.",acceptable,acceptable,acceptable,3.2,3.2,3.2
89,A thorough review of the existing concentrated solar power technologies and various performance enhancing techniques,"Solar thermal power plants today are the most viable alternative to replace conventional thermal power plants to successfully combat climate change and global warming. In this paper, the reasons behind this imminent and inevitable transition and the advantages of solar thermal energy over other renewable sources including solar PV have been discussed. The current literature on different types of solar thermal power plants and their performance optimisation techniques is quite scattered. Efforts have been made in this paper to bring the scattered information together in one thorough review so that it helps researchers across the spectrum undertaking studies on concentrated solar power technologies. This paper has established a brief background of these technologies. Furthermore, it has put forth a comprehensive review of different concentrated solar power technologies implemented throughout the world. The review in its latter part has highlighted the current trends of various hybrid, performance enhancing techniques being employed with these technologies. A brief review of the importance of economic analysis of these technologies has also been done. The future scope and course of action adopted to keep this technology growing are also discussed.","Contemporary solar thermal power plants are currently the most promising alternative to traditional thermal power facilities in addressing climate change and global warming effectively. This paper explores the underlying reasons for this inevitable shift and the benefits of solar thermal energy over other renewable sources, such as solar PV. The existing literature on various solar thermal power plants and their performance optimization methods is highly dispersed. This work aims to compile this scattered information into a comprehensive review to assist researchers working on concentrated solar power technologies. The paper provides a concise background on these technologies and offers an extensive review of different concentrated solar power implementations worldwide. In its latter sections, the review examines current trends in hybrid and performance-enhancing techniques associated with these technologies. Additionally, it includes a brief review of the economic analysis's significance for these technologies. The discussion also covers the future directions and strategies required to foster ongoing growth in this field.","Here is a paraphrased version of the original text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""Conventional thermal power plants are on the cusp of being supplanted by solar thermal power plants, a development crucial for mitigating the pressing issues of climate change and global warming. This study delves into the rationale behind this impending paradigm shift and the benefits of solar thermal energy relative to other renewable sources, including solar photovoltaic systems. Despite the abundance of literature on various solar thermal power plant designs and optimization strategies, a comprehensive synthesis of this knowledge has been lacking. This paper seeks to bridge this gap by providing an exhaustive review of concentrated solar power technologies, encompassing their fundamental principles, global implementations, and cutting-edge hybrid approaches aimed at enhancing performance. Additionally, the importance of economic viability assessments for these technologies is underscored, and the future trajectory and necessary steps for their continued growth are outlined.""","As the most effective solution for mitigating climate change and global warming, solar thermal power plants present a compelling alternative to traditional thermal power plants. This paper examines the driving forces behind this unavoidable shift and explores the benefits of solar thermal energy compared to other renewable energy sources, including solar PV. Recognizing the fragmented nature of existing research on various solar thermal power plant types and their optimization strategies, this paper aims to consolidate this information into a comprehensive review. This compilation serves as a valuable resource for researchers investigating concentrated solar power technologies. The paper provides a concise overview of these technologies, followed by an extensive examination of different concentrated solar power technologies implemented globally. Additionally, it sheds light on current trends in hybrid and performance-enhancing techniques employed in conjunction with these technologies. The paper also briefly touches upon the significance of economic analysis for these technologies and concludes by discussing the future direction and actions required to sustain the growth of this technology.",acceptable,acceptable,acceptable,3.2,3.2,3.2
90,Socio-economic impacts of solar energy technologies for sustainable green energy: a review,"Although fossil fuels leave environmentally hazardous gases like carbon dioxide, to date, global energy production is mostly dependent on these sources. Depletion of fossil resource and changes in the price make it a major concert for the sustainable use in future and utilization of energy resources which is environmentally safe and sustainable. Therefore, an increase in the use natural sustainable energy like solar power observed to be increased recently. Effective use of solar energy depends on the proper knowledge on its use and techniques. This article reviews different solar storage technologies to obtain green sustainable energy generation. We discussed the variation, mechanism, effectiveness, and worth of greenhouse for solar heat storage and concentrated solar power technologies (CSP). The multi-level evaluation method establishes an evaluation index system, adopts the expert scoring method to determine the weight and score of the index, and combines qualitative and quantitative to obtain a comprehensive evaluation value. There is the evaluation of the socio-economic impact of the green power station construction. The detail of for socio-economic environmental factor for on large-scale operation applications dependence on the use and conditions both solar storage and technologies have advantage and disadvantages. Finally, directions for significant of waste to energy for safe environment are presented.","Despite the environmental hazards posed by fossil fuels, such as carbon dioxide emissions, global dependence on these energy sources remains predominant. The depletion of fossil resources and fluctuating prices raise concerns about their sustainable future and the need for eco-friendly and durable energy alternatives. Consequently, there has been a recent uptick in the adoption of natural, sustainable energy sources like solar power. The efficient use of solar energy hinges on comprehensive knowledge of its applications and methodologies. This article reviews various solar storage technologies to achieve eco-friendly, sustainable energy production. We explored the diversity, mechanisms, efficacy, and benefits of greenhouses for solar heat storage and concentrated solar power (CSP) technologies. The multi-level evaluation method develops an assessment index system, employs expert scoring to assign weights and scores to the indices, and integrates both qualitative and quantitative analyses to derive a comprehensive evaluation. We assess the socio-economic impact of constructing green power stations. The specifics of large-scale operational applications reveal that the effectiveness of solar storage technologies depends on their usage and conditions, each with its own set of advantages and disadvantages. Finally, we present significant directions for converting waste to energy to ensure a safe environment.","Despite the environmental risks associated with fossil fuels, including the release of harmful gases such as carbon dioxide, they remain the primary source of global energy production. However, the finite nature of fossil resources and price volatility have raised concerns about their long-term sustainability, prompting a shift towards environmentally friendly and sustainable energy alternatives. In recent years, there has been a notable increase in the adoption of natural, sustainable energy sources like solar power. The effective harnessing of solar energy relies on a thorough understanding of its applications and techniques. This review examines various solar storage technologies aimed at promoting eco-friendly energy generation. We analyze the differences, mechanisms, efficacy, and value of greenhouse-based solar heat storage and concentrated solar power (CSP) technologies. A multi-faceted evaluation approach is employed, incorporating expert assessments and a scoring system to determine the weight and score of each index, thereby providing a comprehensive evaluation. The socio-economic implications of constructing green power stations are also assessed. The suitability of solar storage and technologies for large-scale applications depends on various factors, including their advantages and disadvantages. Ultimately, the article highlights the importance of waste-to-energy conversion for a safe environment.","Despite the environmental hazards posed by fossil fuels, such as carbon dioxide emissions, these sources remain the cornerstone of global energy production. The dwindling reserves and fluctuating prices of fossil fuels raise serious concerns about sustainable energy practices for the future. Consequently, there's a growing trend toward environmentally friendly and renewable energy sources, particularly solar power. Optimizing solar energy utilization hinges on a deep understanding of its applications and associated technologies. This article delves into various solar storage technologies that contribute to green and sustainable energy generation. We examine the characteristics, operational principles, efficiency, and economic viability of greenhouse solar heat storage and concentrated solar power (CSP) technologies. A multi-faceted evaluation method is employed, encompassing an evaluation index system, expert scoring to weigh and score indices, and a blended qualitative and quantitative approach to arrive at a holistic evaluation. The socio-economic ramifications of green power station construction are also assessed. The specific socio-economic and environmental considerations for large-scale deployment depend on the utilization and conditions of both solar storage and technologies, each presenting advantages and disadvantages. Lastly, the article outlines promising avenues for converting waste into energy, promoting a cleaner and safer environment.",acceptable,acceptable,acceptable,3.2,3.2,3.2
91,A Review on Solar Photovoltaic System Efficiency Improving Technologies,"AbstractThe use of solar energy-based technologies has sparked increased interest in recent years to meet our society’s various energy demands. Photovoltaic (PV) cell efficiency is improved, and low-grade heat is generated by combining a PV and thermal system into a single unit. Researchers are working on improving the PVT system for the past two–three decades, but only a few effective PVT systems are currently available on the consumer scale. This paper reviews various tracking and cooling techniques that are being used to track maximum sun radiations and decrease the probability of increased temperature when attempting for improving PV solar panel performance. So, many research papers have been analyzed and classified based on their emphasis, contribution, and the technologies used to perform PV panel tracking and cooling. This research would be beneficial to new researchers who are interested in working in this area and technology.","Abstract The recent surge in interest surrounding solar energy technologies aims to satisfy diverse energy needs within our society. By merging a photovoltaic (PV) system with thermal components, both PV cell efficiency can be enhanced, and residual heat can be utilized. Over the past two to three decades, researchers have strived to optimize the PVT system, yet few effective consumer-scale PVT solutions exist. This paper delves into various tracking and cooling techniques employed to capture maximal sunlight and mitigate temperature increases, thereby enhancing PV solar panel performance. Numerous studies have been reviewed and categorized based on their focus, contributions, and the technologies deployed for PV panel tracking and cooling. This research will be valuable to newcomers interested in advancing this field and its associated technologies.","Here is a paraphrased version of the original text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""In recent years, the quest to satisfy our society's diverse energy needs has driven a surge in interest in solar energy-based solutions. By integrating photovoltaic and thermal systems, the efficiency of PV cells can be enhanced, and low-grade heat can be harnessed. Despite two to three decades of research focused on optimizing PVT systems, only a limited number of effective solutions are currently accessible to consumers. This review examines various strategies for tracking and cooling, designed to maximize solar radiation capture and mitigate temperature increases that can compromise PV solar panel performance. A comprehensive analysis of existing research papers has been conducted, categorizing them according to their focus, contributions, and technological approaches to PV panel tracking and cooling. This study aims to provide valuable insights for newcomers to the field, seeking to contribute to this area of technology.""","Driven by the imperative to address societal energy needs, solar energy technologies have garnered significant attention. Hybrid photovoltaic-thermal (PVT) systems, which enhance PV cell efficiency while capturing low-grade heat, represent a promising avenue. Despite decades of research and development, commercially viable PVT systems remain limited. This review examines prevalent tracking and cooling methodologies employed to optimize solar radiation capture and mitigate temperature increases in PV panels. Through a comprehensive analysis of existing research, this work categorizes studies based on their focus, contributions, and employed tracking and cooling technologies. This synthesis serves as a valuable resource for researchers venturing into the field of PVT systems.",acceptable,acceptable,acceptable,3.2,3.2,3.2
92,A Detailed Review on Wind and Solar Hybrid Green Energy Technologies for Sustainable Smart Cities,"Smart City development is a program for urban redevelopment and refurbishment. The main goal of a smart city is to stimulate economic growth and improve the quality of life of people by facilitating local area development and utilizing technology, particularly technology that leads to Smart results. Power generation is also a very crucial factor in the power management of smart cities. Most developing countries still use non-renewable energy sources as their conventional ones for power generation. The important problems arising from Non-Renewable energy sources are the depletion of natural resources, incremental greenhouse gases, pollution of the environment, and the rising cost of power consumption. Nowadays, the people and government are becoming more conscious of the significance of switching from conventional energy sources to renewable energy sources as we become more mindful of our impact on the environment. Green Energy or Renewable Energy is a way to make our Smart cities and Power Grid more sustainable. Hydroelectric, Solar, Tidal, Wind, and Bio-gas are a few of the important green energy sources used for power generation. Solar and wind power harvesting can be adopted and more suited for the Smart city-like urban environment. Since solar radiation and wind speed change throughout the year, neither a solar nor a wind-powered system can offer consistent electricity individually. By considering this condition, hybrid solar and wind power harvesting is suggested for sustainable Smart future cities. The present work explains solar power, wind power, and hybrid solar-wind power harvesting in detail with a Smart City power generation perspective.","Urban renewal and refurbishment are at the heart of Smart City initiatives. These endeavors aim primarily to drive economic expansion and elevate residents' quality of life by emphasizing local development and leveraging technology, particularly innovations that generate smart outcomes. Effective power management is a pivotal aspect of smart cities, where many developing nations still rely heavily on non-renewable energy sources for electricity. Challenges arising from these traditional sources include depletion of natural resources, increased greenhouse gas emissions, environmental pollution, and escalating energy costs. There is an increasing awareness among the public and governments about the importance of transitioning to renewable energy to mitigate environmental impacts. Embracing Green or Renewable Energy is essential for creating sustainable Smart Cities and Power Grids. Significant renewable energy sources include hydroelectric, solar, tidal, wind, and bio-gas energy. Solar and wind power, in particular, are well-suited for urban smart environments. However, due to the seasonal variability of solar radiation and wind speed, neither solar nor wind power alone can ensure a stable energy supply. Thus, hybrid systems combining solar and wind energy are recommended for a sustainable future in smart cities. This work provides a detailed exploration of solar, wind, and hybrid solar-wind power generation with a focus on smart city energy solutions.","Urban revitalization and modernization initiatives, collectively known as Smart City development, aim to catalyze economic prosperity and enhance citizens' well-being by leveraging technology and fostering local development. A pivotal aspect of smart urban planning is the strategic management of power generation, which is often reliant on non-renewable energy sources in developing nations, leading to resource depletion, environmental degradation, and escalating energy costs. However, there is a growing awareness among governments and citizens about the imperative to transition from conventional to renewable energy sources, thereby promoting eco-friendly and sustainable urban ecosystems. Green Energy, encompassing hydroelectric, solar, tidal, wind, and bio-gas power, offers a viable solution for creating resilient and environmentally conscious Smart Cities. While solar and wind power are well-suited for urban environments, their intermittent nature necessitates the adoption of hybrid solar-wind power harvesting systems to ensure a consistent and reliable energy supply. This study provides an in-depth examination of solar, wind, and hybrid solar-wind power generation in the context of Smart City energy infrastructure.","Urban renewal and revitalization initiatives fall under the umbrella of Smart City development. These programs aim to foster economic progress and enhance residents' quality of life by promoting localized development and leveraging technology, particularly that which yields intelligent outcomes. A key aspect of Smart City power management is energy production. Many developing nations still rely on traditional non-renewable energy sources, leading to significant concerns such as resource depletion, increased greenhouse gas emissions, environmental pollution, and escalating energy costs. Growing environmental awareness has led individuals and governments to prioritize the transition from conventional to renewable energy sources. Green or renewable energy presents a viable path toward creating more sustainable Smart Cities and power grids. Important green energy sources for electricity generation include hydro, solar, tidal, wind, and biogas. Solar and wind energy harvesting are particularly well-suited for urban Smart City environments. However, due to fluctuations in solar radiation and wind speed, neither can provide consistent power independently. Therefore, a hybrid approach combining solar and wind energy harvesting is proposed as a solution for sustainable power generation in future Smart Cities. This work provides a detailed exploration of solar, wind, and hybrid solar-wind power harvesting within the context of Smart City power generation.",acceptable,acceptable,acceptable,3.2,3.2,3.2
93,Integration of multi-criteria decision-making for performance evaluation of different solar batteries technologies,"The aim of this paper is to propose a new approach allowing the improvement of the operation, the performances and the lifetime of a photovoltaic system. This improvement concerns the energy storage system, and it is essentially ensured by a multi-criteria analysis integrating the dependability analysis tools. In this context, this approach is based on an evaluation focused on several selection criteria and several technical factors to properly determine the most relevant technology for solar batteries such as lead–acid battery, nickel–cadmium battery (Ni–Cd), nickel–metal hydride (Ni–MH) battery and lithium-ion battery. The factors that are taken into account by the authors in this multi-criteria analysis are reliability, security, size and cost. The assessment of the reliability of the available battery capacity is established using failure modes, effects and criticality analysis and a classification of failure modes by an appropriate calculation of the number risk priority (RPN). The analysis of the security criteria is based on the development of a preliminary risk analysis which shows the impact of different solar technologies batteries on the environment, human health and physical. This approach is also interested in the evaluation of the cost and the impact of the volume, the number and the mass of the batteries used in the photovoltaic system. Finally, this approach is completed by the utilization of the Preference Ranking Organization Method for Enrichment Evaluations (PROMETHEE) to develop a decision-making model and solve the problem of choosing solar battery technology.","This paper aims to introduce a novel method to enhance the operation, performance, and lifespan of photovoltaic systems. This enhancement focuses on the energy storage system and is primarily achieved through a multi-criteria analysis incorporating dependability analysis tools. In this context, the proposed method involves evaluating various selection criteria and technical factors to identify the most suitable technology for solar batteries, including lead–acid, nickel–cadmium (Ni–Cd), nickel–metal hydride (Ni–MH), and lithium-ion batteries. The factors considered in this analysis are reliability, safety, size, and cost. The reliability of available battery capacity is assessed using failure modes, effects, and criticality analysis, along with a classification of failure modes by calculating the risk priority number (RPN). Safety criteria are analyzed through a preliminary risk assessment that examines the impact of different solar battery technologies on the environment, human health, and physical safety. Additionally, the approach evaluates the cost and the impact of the volume, number, and mass of batteries used in the photovoltaic system. Finally, the Preference Ranking Organization Method for Enrichment Evaluations (PROMETHEE) is employed to develop a decision-making model and address the selection problem of solar battery technology.","This study's objective is to introduce an innovative methodology for enhancing the operational efficiency, performance, and lifespan of photovoltaic systems, with a specific focus on optimizing energy storage systems through a comprehensive multi-criteria evaluation. This approach incorporates dependability analysis tools to identify the most suitable solar battery technology, considering factors such as lead-acid, nickel-cadmium, nickel-metal hydride, and lithium-ion batteries. The selection process is guided by a set of technical criteria, including reliability, security, size, and cost, which are assessed through a combination of failure modes analysis, risk priority calculation, and environmental impact evaluation. Furthermore, the methodology takes into account the economic and spatial implications of battery selection, ultimately utilizing the PROMETHEE decision-making model to facilitate the choice of the most appropriate solar battery technology.","This study introduces a novel method for enhancing the operation, performance, and lifespan of photovoltaic systems by optimizing energy storage. The proposed approach utilizes a multi-criteria analysis incorporating dependability assessment tools to select the most suitable battery technology. This evaluation considers various selection criteria and technical factors, including reliability, safety, size, and cost, to determine the optimal choice among lead-acid, nickel-cadmium, nickel-metal hydride, and lithium-ion batteries. Reliability assessment is conducted through failure modes, effects, and criticality analysis, along with a risk priority number (RPN) calculation for failure mode classification. Safety analysis involves a preliminary risk assessment to examine the environmental, health, and physical impacts of different battery technologies. The approach also considers cost evaluation and the influence of battery volume, quantity, and weight on the photovoltaic system. Finally, the Preference Ranking Organization Method for Enrichment Evaluations (PROMETHEE) is employed to construct a decision-making model and facilitate informed selection of the most appropriate solar battery technology.",acceptable,acceptable,acceptable,3.6,3.2,3.2
94,A Review on p-Type Tunnel Oxide Passivated Contact (TOPCon) Solar Cell,"The primary objectives of solar cell technology are high efficiency, long durability, mass manufacturing, cost effectiveness, and the use of environmentally benign components. Among high-efficiency crystalline silicon (c-Si)-based solar cell types, tunnel oxide passivated contact (TOPCon) solar cells have attracted particular attention because of a multitude of advantages. These include easy processing, high efficiency potential, and availability of raw materials. Due to cheaper wafer pricing, easily compatible with advanced and long-tested PERC solar cell manufacturing process, fabrication of TOPCon solar cells starting with p-type c-Si wafers are significantly more demanding from the standpoint of mass production of solar module. If cutting-edge high-efficiency technologies were used in industrial production, the quality of the p-type wafer may eventually become a bottleneck. Recent production lines elsewhere have developed p-type TOPCon solar cells with 25.19% conversion efficiency using monocrystalline Czochralski (CZ) c-Si wafers. This effectively proves the outstanding viability of p-type TOPCon solar cells for an industrial scale. This review article comprehensively discusses the history of high-efficiency p-type TOPCon solar cells, advancement in various areas to increase effective cell performance, state of commercialization, as well as potential future research opportunities and challenges.","The main goals of solar cell technology are achieving high efficiency, ensuring long-term durability, enabling mass production, reducing costs, and using environmentally friendly materials. Among the different types of high-efficiency crystalline silicon (c-Si) solar cells, tunnel oxide passivated contact (TOPCon) cells have garnered significant attention due to their numerous benefits. These advantages include ease of processing, high-efficiency potential, and the ready availability of raw materials. The fabrication of TOPCon solar cells using p-type c-Si wafers, compatible with the well-established PERC solar cell manufacturing process, is more challenging in terms of large-scale solar module production because of the lower cost of wafers. If advanced high-efficiency technologies were incorporated into industrial production, the quality of the p-type wafer might become a limiting factor. Recently established production lines have achieved a 25.19% conversion efficiency for p-type TOPCon solar cells using monocrystalline Czochralski (CZ) c-Si wafers, demonstrating their excellent industrial-scale viability. This review article provides an in-depth examination of the development of high-efficiency p-type TOPCon solar cells, progress in various fields to enhance cell performance, the current state of commercialization, and explores potential future research directions and challenges.","The paramount goals of solar cell technology encompass achieving exceptional energy conversion rates, prolonged lifespan, scalable production, economic viability, and the utilization of eco-friendly materials. Within the realm of high-performance crystalline silicon (c-Si) solar cells, tunnel oxide passivated contact (TOPCon) technology has garnered significant interest owing to its numerous benefits, including streamlined fabrication, high energy conversion potential, and abundant raw material availability. However, the mass production of TOPCon solar cells using p-type c-Si wafers poses substantial challenges due to the need for advanced manufacturing processes, which may be hindered by the quality of p-type wafers if cutting-edge technologies are employed. Notably, recent industrial-scale production lines have successfully developed p-type TOPCon solar cells with a remarkable 25.19% energy conversion efficiency using monocrystalline Czochralski (CZ) c-Si wafers, thereby demonstrating the feasibility of p-type TOPCon solar cells for large-scale industrial applications. This review provides a comprehensive examination of the evolution of high-efficiency p-type TOPCon solar cells, advancements in various areas to enhance cell performance, commercialization status, and potential future research avenues and obstacles.","Solar cell technology aims to achieve high efficiency, longevity, scalability, cost-effectiveness, and environmental friendliness. TOPCon solar cells, a type of high-efficiency crystalline silicon (c-Si) solar cell, have gained significant interest due to their straightforward manufacturing process, potential for high efficiency, and readily available raw materials. While p-type c-Si wafers are cost-effective and easily integrated into existing PERC solar cell production lines, their use in TOPCon solar cell fabrication presents challenges for large-scale manufacturing. The quality of p-type wafers could limit the implementation of advanced high-efficiency technologies in industrial settings. Notably, recent production lines have successfully fabricated p-type TOPCon solar cells using monocrystalline Czochralski (CZ) c-Si wafers, achieving a conversion efficiency of 25.19%, demonstrating their potential for industrial-scale production. This review provides a detailed overview of the development of high-efficiency p-type TOPCon solar cells, exploring advancements in cell performance enhancement, commercialization status, and future research prospects and hurdles.",acceptable,acceptable,acceptable,3.2,3.2,3.2
95,A review of advanced architectural glazing technologies for solar energy conversion and intelligent daylighting control,"Efficient management of solar radiation through architectural glazing is a key strategy for achieving a comfortable indoor environment with minimum energy consumption. Conventional glazing consisting of a single or multiple glass pane(s) exhibits high visible light transmittance and solar heat gain coefficient, which can be a double-edged sword, i.e., it allows sufficient sunlight to enter the building interior space for passive heating and lighting; on the other hand, it can cause glare discomfort and large cooling energy consumption. Among the various advanced glazing technologies being developed, Building Integrated Photovoltaic (BIPV) glazing has a prominent position due to its ability to reduce cooling load and visual discomfort while simultaneously generating electricity from sunlight. Recent years have witnessed remarkable advances in low-concentration optics such as Dielectric based Compound Parabolic Concentrators (DiCPCs), with a growing interest in the development of Building Integrated Concentrating Photovoltaic (BICPV) glazing to improve light harvesting and electric power output. One of the challenges faced by traditional BIPV glazing systems is the lack of dynamic control over daylight and solar heat transmission to cope with variations in weather conditions and seasonal heating/cooling demands of buildings. A promising solution is to integrate an optically switchable smart material into a BIPV glazing system, which enables dynamic daylighting control in addition to solar power conversion. Thermotropic (TT) hydrogel materials such as poly(N-isopropylacrylamide) (PNIPAm) and Hydroxypropyl Cellulose (HPC) are potential candidates for hybrid BIPV smart glazing applications, due to their unique features such as high visible transparency (in the clear state), strong light-scattering capability (in the translucent state) and large solar energy modulation. This paper reviews various types of electricity-generating glazing technologies including BIPV glazing and BICPV glazing, as well as smart glazing technologies with a particular focus on TT hydrogel integrated glazing. The characteristics, benefits and limitations of hybrid BIPV smart glazing are also evaluated. Finally, the challenges and research opportunities in this emerging field are discussed.","Effective regulation of solar radiation through architectural glazing is crucial for creating a comfortable indoor atmosphere with minimal energy usage. Traditional glazing, made up of single or multiple glass layers, has high visible light transmittance and solar heat gain coefficient. This dual nature allows adequate sunlight for passive heating and lighting but also contributes to glare discomfort and high cooling energy requirements. Among modern glazing technologies, Building Integrated Photovoltaic (BIPV) glazing stands out for its capability to decrease cooling demands and visual discomfort while also generating electricity from sunlight. Recently, there have been significant advancements in low-concentration optics like Dielectric-based Compound Parabolic Concentrators (DiCPCs), driving interest in Building Integrated Concentrating Photovoltaic (BICPV) glazing to boost light collection and electrical output. Traditional BIPV glazing systems often struggle with dynamically controlling daylight and solar heat transmission to adapt to changing weather and seasonal heating or cooling needs. Integrating optically switchable smart materials into BIPV glazing systems offers a promising solution, providing dynamic daylight management along with solar power generation. Thermotropic (TT) hydrogel materials, such as poly(N-isopropylacrylamide) (PNIPAm) and Hydroxypropyl Cellulose (HPC), are ideal for hybrid BIPV smart glazing applications due to their high visible transparency in clear state, strong light-scattering ability in translucent state, and significant solar energy modulation. This review examines various types of electricity-generating glazing technologies including BIPV and BICPV glazing, as well as smart glazing technologies with a special emphasis on TT hydrogel integrated glazing. It assesses the properties, advantages, and limitations of hybrid BIPV smart glazing and discusses the challenges and research opportunities in this burgeoning field.","Optimizing solar radiation management through innovative glazing designs is crucial for creating a comfortable indoor atmosphere while minimizing energy expenditure. Traditional glazing systems, comprising single or multiple glass panes, exhibit high visible light transmission and solar heat gain coefficients, which can be both beneficial and detrimental, as they allow for natural lighting and passive heating but also lead to glare discomfort and increased cooling energy consumption. Among the cutting-edge glazing technologies being developed, Building Integrated Photovoltaic (BIPV) glazing stands out for its ability to reduce cooling loads and visual discomfort while generating electricity from sunlight. Recent breakthroughs in low-concentration optics, such as Dielectric-based Compound Parabolic Concentrators (DiCPCs), have sparked growing interest in the development of Building Integrated Concentrating Photovoltaic (BICPV) glazing to enhance light harvesting and electric power output. However, traditional BIPV glazing systems face the challenge of lacking dynamic control over daylight and solar heat transmission to adapt to changing weather conditions and seasonal heating/cooling demands. A promising solution lies in integrating optically switchable smart materials into BIPV glazing systems, enabling dynamic daylighting control and solar power conversion. Thermotropic (TT) hydrogel materials, such as poly(N-isopropylacrylamide) (PNIPAm) and Hydroxypropyl Cellulose (HPC), are potential candidates for hybrid BIPV smart glazing applications due to their unique features, including high visible transparency, strong light-scattering capability, and large solar energy modulation. This review examines various electricity-generating glazing technologies, including BIPV and BICPV glazing, as well as smart glazing technologies with a focus on TT hydrogel-integrated glazing, evaluating their characteristics, benefits, and limitations. Finally, the challenges and research opportunities in this emerging field are discussed.","Optimizing the use of sunlight through building windows is crucial for creating comfortable interiors while minimizing energy use. Traditional windows, whether single or multi-paned, let in a lot of light and heat from the sun. This can be both beneficial and detrimental: while it provides natural light and warmth, it can also lead to uncomfortable glare and increased need for air conditioning. Building Integrated Photovoltaic (BIPV) glazing has emerged as a leading-edge technology because it not only reduces cooling needs and glare but also generates electricity from sunlight. Recent advancements in light-concentrating materials like Dielectric based Compound Parabolic Concentrators (DiCPCs) have spurred interest in Building Integrated Concentrating Photovoltaic (BICPV) glazing, which further enhances light capture and energy production. However, conventional BIPV systems lack the ability to dynamically adjust light and heat transmission in response to changing weather or building needs. Integrating optically switchable smart materials into BIPV systems offers a promising solution for dynamic daylight control alongside solar energy conversion. Thermotropic (TT) hydrogels, such as poly(N-isopropylacrylamide) (PNIPAm) and Hydroxypropyl Cellulose (HPC), are well-suited for this purpose due to their transparency when clear, light-scattering ability when translucent, and significant solar energy modulation capabilities. This review examines various electricity-generating window technologies, including BIPV and BICPV, as well as smart window technologies, particularly those incorporating TT hydrogels. The paper analyzes the characteristics, advantages, and disadvantages of hybrid BIPV smart glazing. Finally, it addresses the challenges and future research directions in this rapidly evolving field.",acceptable,acceptable,acceptable,3.2,3.2,3.2
96,Performance evaluation of monocrystalline and polycrystalline-based solar cell,"This paper exhibits the performance of crystalline-based solar cells (polycrystalline and monocrystalline) as well as the comparative analysis of these solar cells following various types of orientation in the solar plant. Since the global energy demand is increasing rapidly, different sorts of renewable energy have been used in the last decades to meet this massive demand all over the world. From recent studies, solar has been considered the most promising among these renewable sources. To analyze the performance, the geographical site (Savar, Dhaka) was selected which has a latitude of 23.8538° and a longitude of 90.2534°. In this study, the most effective polycrystalline and monocrystalline solar cell has been founded which is 440 and 370 wp, respectively. Regarding this, a grid-connected PV system (12.3 Kwp) has been simulated which showed the performance ratio of the monocrystalline cell was 83.55%, which was better than the polycrystalline-based solar cell which was 79.6%. In terms of different kinds of orientations, monocrystalline at dual-axis tracking planes showed the highest value of energy injection to the grid was 25.8 MWh/year, while the least value has been founded in the fixed orientation plane which was 20.6 MWh/year. In this perspective, polycrystalline showed 23.9 and 19.5 MWh/year for dual-axis tracking and fixed orientation planes, respectively. Monocrystalline showed more energy injected into the grid compared to polycrystalline technologies for every orientation in the plant as well as the highest value of performance ratio.","This study demonstrates the efficiency of solar cells made from crystalline materials (both polycrystalline and monocrystalline) and provides a comparative analysis of their performance based on various orientations within a solar plant. Due to the rapidly increasing global energy demand, various renewable energy sources have been employed in recent decades to meet this growing need worldwide, with recent research identifying solar energy as the most promising. The performance analysis was conducted at a geographical location in Savar, Dhaka, with coordinates 23.8538° latitude and 90.2534° longitude. The study identified the most effective polycrystalline and monocrystalline solar cells, rated at 440 Wp and 370 Wp respectively. A grid-connected PV system of 12.3 kWp was modeled, revealing that monocrystalline cells achieved a performance ratio of 83.55%, surpassing the 79.6% ratio of polycrystalline cells. When considering various orientations, monocrystalline cells on dual-axis tracking systems injected the most energy into the grid at 25.8 MWh/year, compared to the 20.6 MWh/year from fixed orientation systems. For polycrystalline cells, the figures were 23.9 MWh/year and 19.5 MWh/year for dual-axis tracking and fixed orientation systems, respectively. Overall, monocrystalline cells consistently injected more energy into the grid and achieved a higher performance ratio across all orientations.","This study presents a comprehensive evaluation of the efficiency of crystalline-based photovoltaic cells, encompassing both polycrystalline and monocrystalline variants, in conjunction with a comparative assessment of their performance under diverse orientation configurations within a solar power plant. In response to the escalating global energy requirements, renewable energy sources have gained prominence over the past few decades, with solar energy emerging as the most promising alternative. To investigate the performance of these cells, a specific geographical location (Savar, Dhaka) with a latitude of 23.8538° and a longitude of 90.2534° was selected. The findings indicate that the most efficient polycrystalline and monocrystalline solar cells possess power outputs of 440 Wp and 370 Wp, respectively. A simulated grid-connected PV system (12.3 Kwp) revealed that the monocrystalline cell exhibited a superior performance ratio of 83.55%, surpassing the polycrystalline-based solar cell with a ratio of 79.6%. Furthermore, the analysis of various orientation types demonstrated that monocrystalline cells installed on dual-axis tracking planes achieved the highest energy injection into the grid, amounting to 25.8 MWh/year, whereas the fixed orientation plane yielded the lowest value of 20.6 MWh/year. In contrast, polycrystalline cells showed energy injection values of 23.9 MWh/year and 19.5 MWh/year for dual-axis tracking and fixed orientation planes, respectively. Notably, monocrystalline technology consistently outperformed polycrystalline technology in terms of energy injection and performance ratio across all orientation configurations within the plant.","This study investigates the efficiency of both polycrystalline and monocrystalline solar cells, comparing their performance under different orientations within a solar power plant. The increasing global energy demand has driven the adoption of renewable energy sources in recent decades, with solar energy emerging as a highly promising solution. The study focuses on a location in Savar, Dhaka (latitude 23.8538°, longitude 90.2534°) and identifies the most efficient polycrystalline and monocrystalline solar cells as having power outputs of 440 Wp and 370 Wp, respectively. A simulation of a 12.3 kWp grid-connected photovoltaic system reveals that monocrystalline cells achieve a superior performance ratio of 83.55%, compared to 79.6% for polycrystalline cells. Notably, dual-axis tracking orientation maximizes energy injection into the grid for both types, with monocrystalline cells yielding 25.8 MWh/year and polycrystalline cells generating 23.9 MWh/year. Conversely, fixed orientation results in the lowest energy injection, registering 20.6 MWh/year for monocrystalline and 19.5 MWh/year for polycrystalline systems. Across all orientations, monocrystalline technology consistently outperforms polycrystalline technology in terms of energy contribution to the grid and overall performance ratio.",acceptable,acceptable,acceptable,3.2,3.2,3.2
97,Geometrical Optimization of 2D MoS2-Ag Rectangular and Triangular Grating for Enhanced Solar Cell Efficiency,"Harnessing the full potential of solar energy technology requires innovative approaches to optimize light absorption in solar cells. This study introduces a novel investigation into the use of MoS2-Ag rectangular and triangular grating structures to achieve this goal. Performing finite element analysis with the COMSOL 5.3a RF module provides the possibility to explore the impact of various silver (Ag) grating configurations on the absorption of light in photovoltaic (PV) cells. In order to find the best combination of MoS2 thickness, slit width, and metallic grating while keeping the periodicity of the grating device unchanged, an optimum value is calculated. The zeroth-order transmission spectra and near-field plots of the Fano-resonance (dip) associated with the excitation of the SPPs are carefully analyzed. Our findings reveal that specific configuration of rectangular grating, MoS2 thickness of 50 nm, and a slit width approximately half or just over half of the periodicity significantly enhances the light absorption. This research not only demonstrates the critical role of grating geometry in improving solar cell efficiency but also lays the groundwork for future advancements in solar energy technologies. By employing both far and near field analyses and rigorous statistical validation, our study offers a robust model for the geometrical optimization of grating structures, presenting a clear, impactful insight into the potential of these technologies for solar energy enhancement.","Maximizing solar energy technology's capabilities necessitates innovative methodologies to enhance light absorption in solar cells. This research presents a groundbreaking exploration of MoS2-Ag rectangular and triangular grating structures to attain this objective. Utilizing finite element analysis via the COMSOL 5.3a RF module allows investigation into different silver (Ag) grating configurations' effects on light absorption in photovoltaic (PV) cells. To determine the optimal combination of MoS2 thickness, slit width, and metal grating while maintaining consistent grating periodicity, a precise value is calculated. The zeroth-order transmission spectra and near-field plots of the Fano-resonance associated with SPP elicitation are meticulously examined. Our results indicate that a specific rectangular grating configuration, with a MoS2 thickness of 50 nm and slit width around half or slightly more than half of the periodicity, significantly boosts light absorption. This study not only highlights the pivotal influence of grating geometry on solar cell performance but also sets the stage for future improvements in solar energy technologies. By conducting both far-field and near-field analyses and applying rigorous statistical verification, our research provides a solid model for the geometrical optimization of grating structures, offering profound insights into the potential of these technologies to enhance solar energy utilization.","""Unlocking the maximum capacity of solar energy technology necessitates pioneering strategies to maximize photon absorption in photovoltaic devices. This investigation pioneers an original exploration of MoS2-Ag grating structures, featuring rectangular and triangular geometries, to achieve this objective. Leveraging finite element simulations via the COMSOL 5.3a RF module enables the examination of diverse silver grating configurations on light absorption in solar cells. To identify the optimal combination of MoS2 layer thickness, slit dimensions, and metallic grating while maintaining a consistent grating periodicity, a precise value is determined. The transmission spectra and near-field plots of the Fano-resonance, associated with surface plasmon polariton excitation, are meticulously analyzed. Our results show that a specific rectangular grating configuration, accompanied by a 50 nm MoS2 layer and a slit width roughly half or slightly exceeding the periodicity, significantly boosts light absorption. This research not only highlights the crucial role of grating geometry in enhancing solar cell performance but also establishes a foundation for future breakthroughs in solar energy technologies. By integrating both far-field and near-field analyses with rigorous statistical validation, our study provides a robust framework for the geometrical optimization of grating structures, offering a clear, influential insight into the potential of these technologies for solar energy amplification.""","To fully unlock the power of solar energy, novel methods for maximizing light capture in solar cells are crucial. This work explores the use of MoS2-Ag gratings, both rectangular and triangular, to achieve this. Utilizing finite element analysis within the COMSOL 5.3a RF module, we investigate the influence of various silver (Ag) grating arrangements on light absorption in photovoltaic (PV) cells. By maintaining a constant grating periodicity, an optimal configuration is determined, considering factors like MoS2 thickness, slit width, and metallic grating parameters. A meticulous examination of the zeroth-order transmission spectra and near-field plots associated with Fano-resonance excitation of surface plasmon polaritons is conducted. Our results indicate that a specific rectangular grating design, with a 50 nm MoS2 layer and a slit width roughly half the periodicity, substantially boosts light absorption. This study not only underscores the significance of grating geometry in enhancing solar cell performance but also paves the way for future progress in solar technologies. Through a combination of far-field and near-field analyses, coupled with rigorous statistical validation, our research offers a reliable model for optimizing grating structures, providing compelling evidence for their potential in maximizing solar energy utilization.",acceptable,acceptable,acceptable,3.6,3.6,3.6
98,Can Conservatives Be Persuaded? Framing Effects on Support for Universal Basic Income in the US,"Universal basic income (UBI) has been proposed as a policy response to technological advances and structural inequality. Yet, recent data show that most conservatives in Europe and the US are strongly opposed to the welfare proposal. Can framing UBI as a policy that conforms to their ideological predispositions overcome such opposition? Exploiting the compatibility of UBI with core conservative ideals such as individualism and laissez-faire government, I design an original survey experiment that randomly exposes respondents to one of two frames: (1) an equalizing-opportunity frame which emphasizes that UBI creates a level playing field and promotes self-responsibility, or (2) a limiting-government frame which highlights UBI as a policy that limits government and reduces bureaucracy. I find that American conservatives—identified by using 10 policy statements—remained strongly opposed to UBI even after they were presented with such frames. Analyses of open-ended responses, which show that how conservatives explained their opposition to UBI remained unchanged regardless of framing, reinforce this conclusion. Conservatives’ opposition to UBI remained rigid, even after the key components of UBI that fit the conservative ideology were accentuated. These results shed light on the political feasibility of framing UBI, and the rigidity of welfare attitudes among American conservatives.","Universal basic income (UBI) has been suggested as a policy solution to address technological progress and structural inequity. However, current data reveals that a majority of conservatives in Europe and the United States are highly against this welfare proposal. Is it possible to mitigate this opposition by framing UBI in a way that aligns with their ideological beliefs? By aligning UBI with fundamental conservative principles like individualism and minimal government intervention, I developed a unique survey experiment. Respondents were randomly assigned one of two frames: (1) an equalizing-opportunity frame, which underscores UBI's role in creating fair opportunities and encouraging self-reliance, or (2) a limiting-government frame, which portrays UBI as a policy that curtails government and reduces bureaucracy. The findings indicate that American conservatives—identified through 10 policy statements—showed persistent opposition to UBI even after exposure to these frames. Analysis of open-ended responses revealed that conservatives' reasons for opposing UBI remained unchanged regardless of the framing. This inflexible stance highlights the challenges of framing UBI in a politically feasible manner and the persistent aversion to welfare policies among American conservatives.","A universal basic income has been touted as a solution to the societal ills spawned by technological progress and entrenched inequality, but it faces stiff resistance from conservatives in Europe and the US, according to recent findings. However, could reframing this welfare initiative in a way that resonates with conservative values such as personal autonomy and minimal government intervention help sway their opinion? To investigate, I devised a novel survey experiment that randomly presented participants with one of two distinct narratives: either a ""fair-start"" narrative emphasizing UBI's role in fostering a merit-based society and encouraging individual initiative, or a ""small-government"" narrative highlighting UBI's potential to curb bureaucratic excess and limit state intervention. Despite these efforts, American conservatives – identified through their responses to 10 policy statements – remained resolute in their opposition to UBI. Furthermore, an analysis of their open-ended responses revealed that their justifications for rejecting UBI remained unchanged, regardless of the framing used. The results suggest that conservatives' antipathy towards UBI is deeply ingrained, even when its core components are repackaged to align with their ideological leanings, and offer insights into the challenges of reframing UBI in a politically palatable way.","As automation and socioeconomic disparities increase, universal basic income (UBI) is often suggested as a solution. However, data reveals significant resistance to this welfare concept, especially among conservatives in Europe and the United States. This research investigates if reframing UBI through a conservative lens can mitigate this opposition. By aligning UBI with conservative values like individual liberty and limited government intervention, a unique survey experiment was designed. Participants were randomly presented with one of two perspectives: an ""equalizing-opportunity"" frame emphasizing UBI's potential to level the playing field and foster self-reliance, or a ""limiting-government"" frame highlighting its ability to streamline government and reduce bureaucracy. The study discovered that American conservatives, identified through their stance on 10 policy statements, remained strongly against UBI, even after exposure to these tailored frames. This conclusion is further bolstered by an analysis of open-ended responses, which demonstrated that conservative reasoning against UBI was consistent regardless of framing. Even when emphasizing aspects of UBI that aligned with conservative ideology, their opposition stayed firm. These findings provide valuable insights into the challenges of framing UBI for political acceptance and the entrenched nature of welfare attitudes among American conservatives.",acceptable,acceptable,acceptable,3.6,3.2,3.2
99,Are ‘red wall’ constituencies really opposed to progressive policy? Examining the impact of materialist narratives for Universal Basic Income,"Universal Basic Income (UBI) is often presented as desirable in theory, but unsaleable electorally. Policymakers fear intuitive, ‘values’-based opposition from socially conservative voters, whom the policy would benefit materially, but who might regard it as ‘giving others something for nothing’. We provide evidence from ‘red wall’ constituencies in Wales and the Midlands and North of England that indicates this presumption of voters is wrong. In Study 1, we find high levels of support for the policy, with different narrative framings more effective for different groups based on their material interests. In Study 2, we used a novel ‘adversarial collaboration’ method to show that simple narratives can strongly increase support for UBI even among respondents who initially see themselves as fundamentally opposed. The generated narratives stressed positive, material consequences of introducing UBI, rather than conformity with abstract values. This indicates that policymakers should exercise caution over ‘values’-based explanations for preferences.","Universal Basic Income (UBI), despite being theoretically appealing, is often considered politically unfeasible. Policymakers worry about instinctual, value-driven objections from socially conservative voters who would economically benefit from UBI but may view it as 'handing out freebies.' Research from ‘red wall’ areas in Wales, the Midlands, and Northern England, however, contradicts this assumption. Study 1 reveals substantial support for UBI, with narrative framings resonating differently based on individuals’ material needs. Study 2 employs a novel 'adversarial collaboration' approach, demonstrating that straightforward narratives emphasizing UBI's tangible benefits can significantly boost support, even among those initially opposed. This suggests policymakers should be wary of using value-based justifications to explain voter preferences.","While Universal Basic Income is frequently touted as an attractive concept in principle, its electoral viability is often doubted. Lawmakers assume that socially conservative constituents, who would actually gain financially from the policy, would instinctively resist it due to perceived unfairness. However, our research in Wales and the Midlands and North of England reveals that this assumption is misguided. We discovered significant backing for UBI, with varying narrative approaches resonating with different groups based on their practical needs. Furthermore, our innovative 'adversarial collaboration' approach demonstrated that straightforward, benefits-focused narratives can dramatically boost support even among initial skeptics. By emphasizing tangible advantages, these narratives proved more persuasive than appeals to abstract principles, suggesting that policymakers should be wary of overemphasizing 'values'-based explanations for public opinion.","While UBI is frequently lauded as theoretically sound, it is often perceived as politically impractical. Legislators anticipate resistance from socially conservative demographics who, despite standing to gain financially from the policy, might reject it as an unearned handout. However, research conducted in traditionally working-class regions of England and Wales challenges this assumption. Study 1 reveals significant public backing for UBI, with different narrative strategies resonating with various groups based on their economic circumstances. Study 2, employing an innovative collaborative approach, demonstrates that straightforward messaging can substantially boost support for UBI, even amongst those initially expressing strong opposition. Notably, these narratives emphasized the tangible, positive impacts of implementing UBI, rather than aligning with abstract values. This suggests that policymakers should reconsider relying on values-based arguments to explain policy preferences.",acceptable,acceptable,acceptable,3.2,3.2,3.2
100,"Robots, labor markets, and universal basic income","Automation is a big concern in modern societies in view of its widespread impact on many socioeconomic issues including income, jobs, and productivity. While previous studies have concentrated on determining the effects on jobs and salaries, our aim is to understand how automation affects productivity, and how some policies, such as taxes on robots or universal basic income, moderate or aggravate those effects. To this end, we have designed an experiment where workers make productive effort decisions, and managers can choose between workers and robots to do these tasks. In our baseline treatment, we measure the effort made by workers who may be replaced by robots, and also elicit firm replacement decisions. Subsequently, we carry out treatments in which workers have a universal basic income of about a fifth of the workers’ median wages, or where there is a tax levy on firms who replace workers by robots. We complete the picture of the impact of automation by looking into the coexistence of workers and robots with part-time jobs. We find that the threat of a robot substitution does not affect the amount of effort exerted by workers. Also, neither universal basic income nor a tax on robots decrease workers’ effort. We observe that the robot substitution tax reduces the probability of worker substitution. Finally, workers that benefit from managerial decisions to not substitute them by more productive robots do not increase their effort level. Our conclusions shed light on the interplay of policy and workers behavior under pervasive automation.","The extensive influence of automation on various socioeconomic factors, including income, employment, and productivity, raises significant concerns in contemporary societies. While earlier research has primarily focused on evaluating the effects on job markets and wages, this study seeks to explore automation's impact on productivity and the role of specific policies, such as robot taxes or universal basic income, in moderating these outcomes. To achieve this, an experiment was structured where workers decide on their productivity levels, while managers select between employing humans or robots for tasks. In the initial setup, the effort levels of employees at risk of being replaced by robots and the firms' decisions to replace them are assessed. Following this, additional scenarios are tested in which employees either receive a universal basic income equating to approximately 20% of the median wages or firms incur taxes for substituting workers with robots. The study also examines the dynamic of workers and robots coexisting in part-time roles to complete the analysis. Findings indicate that the potential threat of being replaced by robots does not alter the workers' effort levels. Furthermore, neither universal basic income nor a robot tax impacts worker effort. However, the imposition of a robot substitution tax diminishes the likelihood of workers being replaced. Lastly, employees who are retained over robots by managerial choice do not necessarily increase their effort. The conclusions shed light on how policy interventions can influence worker behavior amidst prevalent automation.","""In contemporary societies, the far-reaching consequences of automation on various socioeconomic aspects, including income, employment, and productivity, have sparked significant concern. Whereas prior research has primarily focused on the implications of automation on job security and remuneration, our investigation seeks to elucidate the impact of automation on productivity and how policy interventions, such as robot taxation or universal basic income, influence this relationship. To achieve this, we designed an experiment in which workers make decisions about their productive effort, while managers choose between human labor and robotic alternatives. Our baseline scenario assesses the effort exerted by workers facing potential robot replacement, as well as firms' substitution decisions. Subsequent treatments introduce a universal basic income equivalent to one-fifth of the median wage or a tax on firms that replace workers with robots. We also examine the coexistence of workers and robots in part-time employment arrangements. Our findings indicate that the threat of robot substitution does not influence workers' effort levels. Furthermore, neither universal basic income nor robot taxation leads to decreased worker effort. However, the robot substitution tax reduces the likelihood of worker replacement. Notably, workers who benefit from managers' decisions to retain them over more productive robots do not exhibit increased effort. Our conclusions provide valuable insights into the complex interplay between policy and worker behavior in an era of pervasive automation.""","The pervasive nature of automation in contemporary societies has sparked significant concern due to its impact on various socioeconomic facets, including income, employment, and productivity. While prior research has primarily focused on the effects of automation on jobs and wages, this study seeks to understand how automation influences productivity and how policies such as robot taxes or universal basic income might mitigate or exacerbate these effects. An experiment was conducted in which workers made decisions regarding their productive effort, while managers had the option of selecting either workers or robots for task completion. The baseline treatment measured the effort exerted by workers who faced potential replacement by robots and elicited firm replacement decisions. Subsequent treatments introduced a universal basic income equivalent to approximately one-fifth of the median worker wage or a tax levied on firms that replaced workers with robots. The impact of automation was further explored by examining the coexistence of workers and robots in part-time job scenarios. The findings revealed that the possibility of robot substitution did not influence the level of effort exerted by workers. Moreover, neither universal basic income nor a robot tax resulted in a decrease in worker effort. However, the robot substitution tax was found to reduce the likelihood of worker replacement. Interestingly, workers who benefited from managerial decisions to retain them despite the availability of more productive robots did not exhibit increased effort levels. These conclusions provide insights into the intricate relationship between policy and worker behavior in an era of widespread automation.",acceptable,acceptable,acceptable,3.2,3.2,3.2
101,A global conservation basic income to safeguard biodiversity,"Biodiversity conservation supporting a global sustainability transformation must be inclusive, equitable, just and embrace plural values. The conservation basic income (CBI), a proposed unconditional cash transfer to individuals residing in important conservation areas, is a potentially powerful mechanism for facilitating this radical shift in conservation. This analysis provides comprehensive projections for potential gross costs of global CBI using spatial analyses of three plausible future conservation scenarios. Gross costs vary widely, depending on the areas and populations included, from US$351 billion to US$6.73 trillion annually. A US$5.50 per day CBI in existing protected areas in low- and middle-income countries would cost US$478 billion annually. These costs are large compared with current government conservation spending (~US$133 billion in 2020) but represent a potentially sensible investment in safeguarding incalculable social and natural values and the estimated US$44 trillion in global economic production dependent on nature.","To support a global shift toward sustainable development, biodiversity conservation must be inclusive, equitable, just, and recognize diverse values. The Conservation Basic Income (CBI), an unconditional cash transfer to individuals living in key conservation regions, is proposed as a potent strategy for driving this transformative change in conservation efforts. This study offers detailed cost projections for implementing a global CBI, derived from spatial analyses of three potential future conservation scenarios. The estimated gross costs vary significantly, ranging from $351 billion to $6.73 trillion annually, based on the areas and populations covered. Implementing a $5.50 per day CBI in existing protected areas within low- and middle-income countries would amount to $478 billion annually. Although these figures are substantially higher compared to current governmental conservation expenditures (around $133 billion in 2020), they could be considered a prudent investment in preserving invaluable social and natural assets, as well as the roughly $44 trillion in global economic output that relies on nature.","""Fostering a sustainable future through biodiversity conservation demands an approach that is all-encompassing, fair, and respectful of diverse perspectives. The concept of a conservation basic income (CBI), which involves providing unconditional financial support to individuals living in crucial conservation zones, has the potential to drive a profound paradigm shift in conservation efforts. This study presents a thorough examination of the projected annual expenditures for a global CBI initiative, exploring three plausible future conservation scenarios through spatial analysis. The estimated costs vary significantly, ranging from $351 billion to $6.73 trillion, depending on the areas and populations targeted. Implementing a $5.50 daily CBI in existing protected areas within low- and middle-income countries would require an annual investment of $478 billion. While these figures are substantial compared to current government conservation expenditures (approximately $133 billion in 2020), they represent a potentially wise investment in preserving invaluable social and natural assets, as well as the estimated $44 trillion in global economic output reliant on natural resources.""","To achieve a truly sustainable future, biodiversity protection efforts must prioritize inclusivity, fairness, and the recognition of diverse values. The conservation basic income (CBI), a novel concept involving direct cash transfers to residents of critical conservation zones, could be instrumental in driving this fundamental change in our approach to conservation. This study offers a thorough cost analysis of implementing CBI globally, utilizing spatial modeling across three plausible future conservation scenarios. The projected gross costs exhibit significant variability based on the targeted areas and populations, ranging from US$351 billion to US$6.73 trillion per year. For example, providing a daily CBI of US$5.50 within existing protected areas in low- and middle-income nations would amount to US$478 billion annually. While these figures are substantial compared to current governmental conservation expenditures (approximately US$133 billion in 2020), they represent a potentially prudent investment in preserving the invaluable social and ecological benefits derived from nature, including the estimated US$44 trillion in global economic output reliant on natural resources.",acceptable,acceptable,acceptable,3.8,3.2,3.6
102,Utilization of spent nuclear fuel and transuranic actinides in a two-component nuclear power industry,"According to the strategy for the development of the nuclear power industry in Russia for the first half of the 21st century, the nuclear power industry complex should undergo the initial stage in the formation of a two-component nuclear power system and a closed nuclear fuel cycle (NFC) infrastructure. All elements of such a nuclear power system, including NPPs, facilities for the fabrication of uranium and uranium-plutonium fuel, processing of spent nuclear fuel, and radioactive waste management, must be organically linked for producing competitive electricity in both domestic and foreign markets. The present article demonstrates the systemic benefits from a large-scale introduction of fast reactors for the Russian nuclear power industry in terms of a sustainable resource provision and a solution to the key problems of the final NFC stage, which is associated with the accumulation of spent fuel and transuranic actinides. The study proposes an optimum NFC closure scenario, in which the described problems can be solved without increasing the high parameters of the BR in a fast reactor and using special burners.","As per Russia's nuclear power industry development strategy for the first half of the 21st century, the sector is expected to enter an initial phase of creating a dual-component nuclear power structure alongside a closed nuclear fuel cycle (NFC) infrastructure. This nuclear system should integrate all components, such as nuclear power plants (NPPs), uranium and uranium-plutonium fuel production facilities, spent nuclear fuel processing plants, and radioactive waste management setups, to ensure competitively priced electricity for both domestic and international markets. This article highlights the systemic advantages of widely adopting fast reactors within the Russian nuclear power sector by ensuring sustainable resource use and addressing key challenges at the final NFC stage, particularly the accumulation of spent fuel and transuranic actinides. The study proposes an optimal NFC closure scenario that resolves these issues without escalating the high parameters of the breeder reactor in a fast reactor and utilizing special burners.","Russia's nuclear power industry development strategy for the 21st century's first half envisions a two-pronged system and a self-sustaining nuclear fuel cycle infrastructure as its inaugural phase. A seamless integration of all components, including nuclear power plants, uranium and uranium-plutonium fuel fabrication facilities, spent fuel processing, and radioactive waste management, is crucial for producing cost-competitive electricity in both local and international markets. This article highlights the systemic advantages of large-scale fast reactor adoption in Russia's nuclear power industry, ensuring a sustainable resource supply and resolving key challenges in the final nuclear fuel cycle stage, particularly the accumulation of spent fuel and transuranic actinides. The proposed optimal scenario for closing the nuclear fuel cycle addresses these issues without compromising the high-performance parameters of fast reactors or relying on specialized burners.","Russia's nuclear power strategy for the first half of the 21st century envisions a two-component system with a closed nuclear fuel cycle (NFC). This system, encompassing nuclear power plants, fuel fabrication facilities, spent fuel processing, and radioactive waste management, aims to generate cost-effective electricity for domestic and international markets. This article highlights the advantages of widespread fast reactor implementation in the Russian nuclear power sector, emphasizing its contribution to sustainable resource management and addressing challenges associated with spent fuel and transuranic actinide accumulation in the final NFC stage. The study presents an optimal NFC closure scenario that tackles these issues without necessitating increased breeding ratios in fast reactors or relying on specialized burners.",acceptable,acceptable,acceptable,3.6,3.6,3.6
103,Ion-Plasma Technology for Nuclear Power Plants Deactivation,"AbstractTo solve the actual problem of nuclear power engineering the irradiated reactor graphite and metal structures of nuclear power plants deactivation, we have developed a new ion-plasma technology. For the first time we experimentally shown the ion-plasma technology efficiency on metal and reactor graphite samples under operating parameters.","Abstract: To address the current challenges in nuclear power engineering, specifically the deactivation of irradiated reactor graphite and metal structures in nuclear plants, we have created an innovative ion-plasma technology. This technology's effectiveness has been experimentally demonstrated on metal and reactor graphite samples under operational conditions for the first time.","""In addressing the pressing issue of decommissioning irradiated graphite and metal components in nuclear power facilities, we have pioneered an innovative ion-plasma approach. Notably, our experimental trials have successfully demonstrated the efficacy of this technology in treating both metal and reactor graphite specimens under realistic operational conditions.""","Addressing the critical issue of decommissioning irradiated graphite and metal components in nuclear power plants, a novel ion-plasma technology has been developed and its efficacy experimentally demonstrated under operational conditions using representative samples.",acceptable,acceptable,acceptable,5.0,3.6,4.2
104,Small Power Nuclear Plants: Technical Level and Prospects for Commercialization (Review),"AbstractThe active development of the Arctic and the Northern Sea Route determines the importance of the rapid development of energy-supply systems for remote regions. A key component of isolated power systems are low-power energy sources. The high cost of fossil fuels in remote regions, coupled with tightening environmental regulations, brings to the fore the challenge of implementing carbon-neutral energy generation technologies. Promising power plants, the performance of which is little dependent on weather conditions, and whose operation is not associated with the generation of greenhouse gas emissions, are low-power nuclear power plants. Currently, some countries are developing and implementing new types of reactor plants whose electrical power does not exceed 300 MW: according to the IAEA, there are more than 70 different projects. Modularity, versatility (in addition to power generation, many projects also provide for the production of thermal energy and hydrogen), increased compactness, and lower capital costs for construction compared to traditional high-power power units make it promising to create low-power reactor plants. This review presents an analysis of the current state of the problems in the design and implementation of such power plants. The technical level of domestic and foreign projects of small modular reactors (SMR) was assessed. Promising areas for the use of thermal energy from small modular installations have been identified, taking into account current trends in energy, including low-carbon and nuclear-hydrogen areas. Possible circuit solutions for the production of electricity based on advanced cycles, including the use of nontraditional working fluids, have been studied. The potential for commercialization of low-power nuclear power plant projects has been considered; the question of successful business implementation of power plants of this type remains open.","Abstract The ongoing expansion of the Arctic and the Northern Sea Route underscores the necessity for swift advancements in energy supply systems for secluded areas. Essential to these isolated power systems are small-scale energy sources. The steep expense of fossil fuels in remote locations, alongside stricter environmental policies, highlights the urgency of adopting carbon-neutral energy technologies. Low-power nuclear power plants, which are less influenced by weather variability and do not produce greenhouse gas emissions, are particularly promising. Currently, various countries are developing new reactor designs with electrical outputs of up to 300 MW: according to the IAEA, there are over 70 distinct projects underway. Features such as modularity, versatility (including capabilities for generating thermal energy and hydrogen), enhanced compactness, and reduced capital expenditure compared to conventional high-capacity power units make these low-power reactors attractive options. This review assesses the current challenges in designing and deploying these reactors. It examines the technical maturity of both domestic and international small modular reactor (SMR) projects. The review also identifies promising applications for the thermal energy produced by small modular units, considering present energy trends such as low-carbon and nuclear-hydrogen sectors. Moreover, it explores potential circuit configurations for electricity generation using advanced cycles and unconventional working fluids. The feasibility of commercializing small-scale nuclear power plant projects is discussed, though the issue of their successful business implementation remains unresolved.","The accelerated exploitation of the Arctic region and the Northern Sea Route necessitates the swift establishment of reliable energy infrastructure in remote areas, with a focus on decentralized power systems that incorporate low-capacity energy sources. The prohibitive cost of fossil fuels in these regions, exacerbated by increasingly stringent environmental protocols, underscores the imperative to adopt carbon-neutral energy generation technologies. A promising solution lies in the development of compact, low-power nuclear reactors that are resilient to weather fluctuations and emit no greenhouse gases. Over 70 international projects are currently underway to design and deploy reactors with capacities below 300 MW, leveraging advantages such as modularity, versatility, and reduced construction costs. This review examines the current challenges and opportunities in designing and implementing these small modular reactors, assessing their technical feasibility and potential applications in thermal energy and hydrogen production. It also explores innovative circuit solutions for electricity generation, including the use of non-traditional working fluids, and evaluates the commercial viability of these projects, highlighting the need for successful business models to ensure their widespread adoption.","The rapid development of the Arctic and Northern Sea Route necessitates efficient energy solutions for isolated regions. While fossil fuels remain costly and environmentally damaging in these areas, low-power nuclear plants offer a promising carbon-neutral alternative. Numerous countries are currently exploring innovative reactor designs with power outputs below 300 MW, characterized by modularity, adaptability for heat and hydrogen production, compact size, and reduced construction costs compared to traditional large-scale reactors. This review investigates the current landscape of designing and implementing such power plants, evaluating the technological advancement of domestic and international small modular reactor (SMR) projects. Promising applications for SMR-generated heat are identified, aligning with low-carbon and nuclear-hydrogen energy trends. The study also examines potential electricity generation circuits based on advanced cycles, including those utilizing unconventional working fluids. Finally, the commercial viability of low-power nuclear plants is considered, although the question of their successful market implementation remains unresolved.",acceptable,acceptable,acceptable,3.2,3.2,3.2
105,Alien Fish Species in Cooling Ponds of Nuclear Power Plants and State District Power Stations of Central Russia,"AbstractThe article presents an overview of alien fish species living in cooling ponds of nuclear power plants and state district power stations in Central Russia. A brief description of recipient reservoirs is given as a habitat for thermophilic fish species that are not characteristic of the native ichthyofauna of the region. The essays on the history of the appearance of these species, the peculiarities of biology, occurrence in catches, and fishery significance in six small reservoirs of special water management located within the borders of the Moscow, Smolensk, Ryazan, and Kursk oblasts of Russia are given. The main vectors of invasions of hydrobionts in cooling ponds for each alien species recorded as a result of ichthyological monitoring in this group of reservoirs are shown. The forecast of the dynamics of the number of alien fish species is given depending on changes in the thermal regime of reservoirs and the volume of stocking and the intensity of fishing in the cooling ponds of nuclear power plants and state district power plants of Central Russia.","The paper offers a comprehensive review of non-native fish species inhabiting cooling ponds at nuclear and state district power stations in Central Russia. It provides a succinct overview of the target reservoirs as habitats for thermophilic fish species uncommon to the native ichthyofauna in the area. The document narrates the history of these species introduction, their biological traits, their presence in catches, and their relevance to fisheries across six small, specially managed reservoirs within Moscow, Smolensk, Ryazan, and Kursk regions. It identifies the primary pathways through which these aquatic species have infiltrated cooling ponds and presents ichthyological monitoring data from the said reservoirs. Additionally, the forecast of the future population trends of these alien fish species is discussed, taking into account changes in the thermal environment of the reservoirs, stocking practices, and fishing pressure in the cooling ponds of nuclear and state district power stations in Central Russia.","This paper provides a comprehensive review of non-native fish populations thriving in the cooling systems of nuclear power plants and district power stations across Central Russia, highlighting the unique characteristics of the recipient water bodies that support these thermophilic species, which are foreign to the region's indigenous fish fauna. The study delves into the history of their introduction, biological distinctiveness, catch rates, and fisheries importance in six specially managed reservoirs spanning the Moscow, Smolensk, Ryazan, and Kursk regions. The primary pathways of hydrobiont invasions in these cooling systems are identified for each non-native species, based on ichthyological monitoring data. Furthermore, the paper predicts the future trajectory of alien fish species populations in response to shifts in reservoir thermal regimes, stocking volumes, and fishing intensities in Central Russia's nuclear and district power plants.","This study examines the presence of non-native fish species inhabiting cooling ponds at nuclear and district power plants in Central Russia. It details the characteristics of these reservoirs as habitats for warm-water fish atypical of the region's indigenous fish population. The paper investigates six specific reservoirs in the Moscow, Smolensk, Ryazan, and Kursk regions, exploring the history, biology, capture rates, and economic importance of these introduced species. Furthermore, it identifies the primary pathways of aquatic organism introduction into these cooling ponds, based on ichthyological monitoring data. Finally, the study predicts how fluctuations in water temperature, stocking practices, and fishing intensity might influence the future population dynamics of these non-native fish species within the power plant cooling ponds of Central Russia.",acceptable,acceptable,acceptable,3.2,3.2,3.2
106,Erosion and Corrosion of Pipelines and Equipment on the Power Uprate of Power Units at Nuclear Power Plants (NPP),"AbstractThe development of the modern nuclear industry is characterized by the conversion of operating power units to operation at a thermal power level above the current rated power level to enhance generation of electricity and reduce its cost. This process is referred to as a power uprate (PU). This can be done by increasing the thermal power of a reactor units and improving the efficiency of the turbine unit. In Russia and abroad, the thermal power of NPP power units is usually increased by 2–20% above the nominal level. Such measures are most widely implemented in the United States and Europe. Increasing the thermal power of a power unit above the rated value may require retrofitting of turbines, condensers, electric generators, and other equipment. The power uprate changes the operating conditions of equipment and pipelines of the power units, including such working fluid conditions as temperature, pressure, and steam wetness. This, in turn, can affect the erosion-corrosion rate of the metal of the working surfaces in the process circuit and decrease the residual service life until the maximum allowable thinning of the walls of equipment and pipelines is attained. Computational studies of foreign specialists demonstrate that the erosion-corrosion rate of individual pipelines and groups of equipment after the power uprate can increase by more than 50%. Because of this, obtaining a license for the power uprate of an NPP power unit in the United States requires computational studies using software tools to identify pipelines and equipment where the erosion-corrosion rate can increase. Since 2009, the RAMEK software code has been used at Russian nuclear power plants to predict the erosion-corrosion rate of pipeline and equipment elements. It is noted that, in practice, the power uprate of a power unit can enhance not only the erosion-corrosion rate in elements with a complex geometry in the flow path but also the effect of cavitation and droplet impact erosion. The expediency is pointed out of computational and experimental studies to assess the effect of changes in the operating conditions on the rate and distribution of erosion-corrosion wear of pipeline elements and equipment.","The evolution of the contemporary nuclear sector is marked by increasing the thermal power of functioning power units beyond the established rated levels to boost electricity production and cut costs. This practice is known as a power uprate (PU). It involves augmenting the thermal output of reactor units and enhancing the turbine unit's efficiency. Typically, the thermal power of NPP units in Russia and internationally is increased by 2–20% above the nominal level, a strategy predominantly adopted in the United States and Europe. Elevating a power unit's thermal power above the rated capacity may necessitate upgrades to turbines, condensers, electric generators, and other components. This power uprate alters the operating parameters of the equipment and pipelines, including working fluid conditions such as temperature, pressure, and steam moisture. Consequently, it may influence the erosion-corrosion rate of the metal on the working surfaces within the operational circuit, potentially reducing the residual service life until the maximum permissible thinning of equipment and pipeline walls is reached. Computational research by foreign experts indicates that, following a power uprate, the erosion-corrosion rate for certain pipelines and equipment groups can surge by over 50%. Therefore, in the United States, securing a license for the power uprate of an NPP unit necessitates computational analyses with software tools to pinpoint pipelines and equipment subject to increased erosion-corrosion rates. Since 2009, Russian nuclear power plants have utilized the RAMEK software code to forecast erosion-corrosion rates for pipeline and equipment components. It is acknowledged that practically, a power uprate can not only enhance the erosion-corrosion rate in intricately shaped elements within the flow path but also intensify the effects of cavitation and droplet impact erosion. The importance of computational and experimental studies is emphasized to evaluate the impact of altered operating conditions on the rate and distribution of erosion-corrosion wear in pipeline elements and equipment.","The modern nuclear industry's evolution is marked by the upscaling of operational power units to surpass their current rated thermal capacity, thereby boosting electricity generation and reducing costs. This process, known as power uprating, can be achieved by augmenting the reactor's thermal output and optimizing the turbine's efficiency. Globally, including in Russia, nuclear power plants (NPPs) typically undergo a 2-20% thermal power increase above their nominal level, with the United States and Europe being at the forefront of this trend. However, such upgrades may necessitate the retrofitting of turbines, condensers, generators, and other equipment. The resulting altered operating conditions of power unit equipment and pipelines, including changes in temperature, pressure, and steam humidity, can accelerate the erosion-corrosion rate of metal surfaces in the process circuit, ultimately reducing their residual lifespan. Foreign experts' computational simulations have shown that the erosion-corrosion rate of specific pipelines and equipment can surge by over 50% following a power uprate. Consequently, obtaining a license for an NPP power uprate in the United States requires computational assessments using specialized software to identify vulnerable equipment and pipelines. Since 2009, Russia's nuclear power plants have employed the RAMEK software code to predict erosion-corrosion rates in pipeline and equipment elements. In practice, power uprating can also exacerbate cavitation and droplet impact erosion in elements with complex geometries, highlighting the need for comprehensive computational and experimental studies to evaluate the impact of altered operating conditions on erosion-corrosion wear patterns in pipeline elements and equipment.","Modern nuclear power generation increasingly focuses on augmenting electrical output and cost efficiency by boosting the thermal power of existing reactors, a process known as power uprating (PU). This involves enhancing reactor thermal capacity and refining turbine efficiency. Typically, thermal power increases range from 2% to 20% above nominal levels, a practice particularly prevalent in the US and Europe. Power uprating often necessitates modifications to turbines, condensers, generators, and other components. These adjustments alter operational parameters such as temperature, pressure, and steam wetness, consequently influencing the rate of erosion-corrosion in working surfaces within the system. This accelerated wear can potentially shorten the remaining lifespan of equipment and pipelines by reducing the time to reach maximum allowable wall thinning. International computational analyses indicate that erosion-corrosion rates in specific pipelines and equipment groups can escalate by over 50% following power uprating. Consequently, US licensing for power uprating mandates computational assessments using specialized software to pinpoint areas susceptible to heightened erosion-corrosion. Since 2009, Russian nuclear facilities have employed the RAMEK software for predicting erosion-corrosion rates in pipeline and equipment components. Notably, practical experience reveals that power uprating can not only accelerate erosion-corrosion in intricate flow path geometries but also intensify cavitation and droplet impact erosion. This underscores the significance of computational and experimental investigations to evaluate the influence of modified operating conditions on the rate and distribution of erosion-corrosion wear in pipelines and equipment.",acceptable,acceptable,acceptable,3.6,3.2,3.2
107,The Concept of a Nuclear Power Unit on the Basis of a Low-Power Multipurpose Test Research Reactor with Supercritical Light-Water Coolant,"AbstractHerein is presented a preliminary concept of a nuclear power installation (NPI) based on a low-power multipurpose test research reactor with a supercritical pressure light water coolant (LMTRR-SCP), which can operate as a test or research reactor, and has the following capabilities: substantiation of operating conditions for a supercritical water-cooled power reactor in the fast neutron spectrum; adjustment of the design operating regimes of the reactor with supercritical coolant conditions (including reactor startup, attainment of the energy power level, switch-over between power levels, rated power operation, shutdown, etc.); reactor irradiation of promising types of nuclear fuel, absorbing and structural materials for nuclear installations with fast, intermediate, or thermal neutron spectrum; comprehensive experimental and numerical investigations to obtain information required for development and verification of numerical codes; evaluation of new types of equipment for various process systems (including elements of emergency cooling systems, steam generators, etc.), instruments, and control, monitoring, and diagnostics systems for power reactors of various types. Investigations into the closed nuclear fuel cycle (CNFC) problem; utilization of actinides and handling of long-lived fission products, including pilot demonstration closure of the fuel cycle; mastering of processes for the manufacture of radionuclide products for various applications; production of modified materials; and use of the reactor’s thermal energy for heat and power generation. A potential also exists for the development of international cooperation within the scope of joint research programs on the basis of LMTRR-SCP.","In this abstract, an initial design concept for a nuclear power installation (NPI) is introduced, centered around a low-power multipurpose test research reactor with a supercritical pressure light water coolant (LMTRR-SCP). This system is capable of functioning as either a test or research reactor and offers several capabilities: validating the operational conditions for a supercritical water-cooled power reactor within a fast neutron spectrum; refining the reactor’s design operational regimes under supercritical coolant conditions (including startup, power level attainment, transition between power levels, standard operation, shutdown, etc.); irradiating new types of nuclear fuel and materials for reactors with various neutron spectra, including fast, intermediate, and thermal; conducting thorough experimental and computational studies to gather data essential for the development and validation of numerical models; assessing new equipment for various system processes, including emergency cooling systems and steam generators, as well as instrumentation for control, monitoring, and diagnostics of different power reactor types. The project also includes research on the closed nuclear fuel cycle (CNFC) issue, management of actinides and long-lived fission products, and demonstration of fuel cycle closure on a pilot scale. Additionally, it encompasses the development of processes for manufacturing radionuclide products for diverse uses, production of modified materials, and leveraging the reactor’s thermal energy for heat and electricity generation. There is also the potential for international cooperation through joint research initiatives based on LMTRR-SCP.","This paper introduces a novel concept for a nuclear power facility centered around a low-power, multi-purpose test research reactor that utilizes supercritical pressure light water coolant (LMTRR-SCP), capable of functioning as either a test or research reactor. The proposed installation offers a range of capabilities, including: validation of operational parameters for supercritical water-cooled reactors in fast neutron spectra; optimization of reactor design and operating modes under supercritical coolant conditions, encompassing startup, power level transitions, and shutdown; irradiation testing of advanced nuclear fuels, absorbers, and structural materials for reactors with fast, intermediate, or thermal neutron spectra; comprehensive experimental and numerical studies to inform the development and validation of numerical codes; assessment of innovative equipment for various process systems, including emergency cooling, steam generation, and control systems for diverse reactor types. Furthermore, the facility enables research into the closed nuclear fuel cycle, actinide utilization, and long-lived fission product management, including pilot-scale fuel cycle closure demonstrations; development of radionuclide products for various applications; production of modified materials; and harnessing the reactor's thermal energy for heat and power generation. Additionally, the LMTRR-SCP concept presents opportunities for international collaboration through joint research initiatives.","This paper introduces a novel concept for a low-power, versatile nuclear power installation (NPI) centered around a test research reactor employing supercritical pressure light water coolant (LMTRR-SCP). This installation serves a dual purpose, functioning as both a research and testing platform. The LMTRR-SCP offers numerous capabilities, including: validating operational parameters for a fast-neutron spectrum power reactor cooled by supercritical water; optimizing reactor control strategies under supercritical coolant conditions across various operational phases (startup, power level transitions, steady-state operation, shutdown); irradiating diverse nuclear fuels, structural materials, and neutron absorbers for reactors spanning fast, intermediate, and thermal neutron spectra; facilitating comprehensive experimental and computational studies for developing and verifying numerical models; evaluating novel equipment for various process systems (e.g., emergency cooling systems, steam generators), instrumentation, and control, monitoring, and diagnostic systems for a range of reactor types. Furthermore, the LMTRR-SCP enables investigations into closed nuclear fuel cycles (CNFC), encompassing actinide utilization, long-lived fission product management, pilot-scale fuel cycle closure demonstrations, and the production of radioisotopes for diverse applications and modified materials. The reactor's thermal energy can also be harnessed for heat and power generation. The LMTRR-SCP holds significant potential as a platform for fostering international collaborations through joint research endeavors.",acceptable,acceptable,acceptable,3.6,3.6,3.6
108,Anomaly detection for early ransomware and spyware warning in nuclear power plant systems based on FusionGuard,"Securing critical infrastructure, particularly nuclear power plants, against emerging cyber threats necessitates innovative cybersecurity approaches. This research introduces FusionGuard, a hybrid machine learning-based anomaly detection system designed for early warnings of ransomware and spyware intrusions within nuclear power plant systems. Meticulously tailored to the unique characteristics of nuclear power plant networks, FusionGuard leverages diverse datasets encompassing normal operational behavior and historical threat data. Through cutting-edge machine learning algorithms, the system dynamically adapts to the network's baseline behavior, effectively identifying deviations indicative of ransomware or spyware activities. Rigorous experimentation and validation using real-world data and simulated attack scenarios affirm FusionGuard's proficiency in detecting anomalous behavior with remarkable accuracy and minimal false positives. The research also explores the system's scalability and adaptability to evolving attack vectors, fortifying the cybersecurity posture of nuclear power plant systems in a dynamic threat landscape. In summary, FusionGuard promises to fortify the security of nuclear power plant systems against ransomware and spyware threats by capitalizing on machine learning and anomaly detection. Serving as a sentinel, the system issues timely alerts and enables proactive responses, contributing substantively to the ongoing discourse on protecting essential systems in high-stakes environments.","Protecting critical infrastructure, especially nuclear power facilities, from new cyber threats requires cutting-edge cybersecurity strategies. This study presents FusionGuard, a hybrid anomaly detection system based on machine learning, created to provide early warnings of ransomware and spyware intrusions in nuclear power plant networks. Custom-designed to suit the specific features of these networks, FusionGuard utilizes varied datasets that capture normal operations and historical threats. Employing advanced machine learning algorithms, the system dynamically conforms to the network's typical behavior, effectively detecting deviations that signal ransomware or spyware activities. Thorough testing and validation with real-world data and simulated attacks demonstrate FusionGuard's capability to identify anomalies with high precision and low false positive rates. The research also examines the system's scalability and adaptability to changing attack methods, strengthening the cybersecurity framework of nuclear power plants in an evolving threat environment. Essentially, FusionGuard aims to enhance the security of nuclear power plant systems against ransomware and spyware by leveraging machine learning and anomaly detection, providing timely alerts and facilitating proactive measures, thus significantly contributing to the protection of critical infrastructure in high-stakes settings.","""Protecting vital infrastructure, such as nuclear power plants, from burgeoning cyber threats demands pioneering cybersecurity strategies. This study presents FusionGuard, a novel, adaptive anomaly detection system that harnesses machine learning to provide early warnings of ransomware and spyware breaches within nuclear power plant networks. Carefully calibrated to the distinct attributes of these networks, FusionGuard aggregates diverse datasets capturing normal operational patterns and historical threat intelligence. By employing advanced machine learning techniques, the system continuously refines its understanding of the network's baseline behavior, thereby accurately pinpointing aberrations indicative of malicious activities. Exhaustive testing and validation using real-world data and simulated attack scenarios confirm FusionGuard's exceptional ability to detect anomalies with high precision and minimal false alarms. Furthermore, the research examines the system's capacity to scale and adapt to emerging attack vectors, thereby bolstering the cybersecurity resilience of nuclear power plant systems in an ever-evolving threat environment. Ultimately, FusionGuard offers a robust solution to safeguard nuclear power plant systems against ransomware and spyware threats by leveraging machine learning and anomaly detection, providing timely alerts and enabling proactive responses that significantly contribute to the ongoing discussion on securing critical systems in high-risk settings.""","The evolving cyber threat landscape demands novel cybersecurity solutions to protect vital infrastructure, especially nuclear facilities. This study presents FusionGuard, a sophisticated anomaly detection system employing hybrid machine learning techniques to provide early warnings of ransomware and spyware attacks targeting nuclear power plant systems. Specifically designed for the intricacies of these networks, FusionGuard utilizes diverse datasets, including normal operational data and historical threat information. Advanced machine learning algorithms allow the system to continuously adapt to the network's baseline, effectively identifying deviations suggestive of malicious activities. Rigorous testing and validation, using both real-world data and simulated attack scenarios, demonstrate FusionGuard's exceptional ability to detect anomalous behavior with high accuracy and minimal false alarms. The research further examines the system's scalability and capacity to adapt to evolving attack vectors, bolstering the cybersecurity posture of nuclear power plant systems within a dynamic threat environment. Ultimately, FusionGuard offers a robust defense against ransomware and spyware threats by harnessing the power of machine learning and anomaly detection. Acting as a vigilant watchdog, the system provides timely alerts, enabling proactive responses and significantly contributing to the ongoing dialogue on safeguarding critical systems in high-risk environments.",acceptable,acceptable,acceptable,3.6,3.6,3.6
109,Intelligent planning of controllers for improved resilience in multi-area system involving nuclear power,"Increased innovation on finding new ways to generate energy from different sources to meet the growing demand of consumers has led to various challenges in controlling the power network when it faces different disruptions. To address these challenges, a new approach has been proposed in this research paper, which combines a controller with a soft computing technique called Particle Swarm Optimization (PSO). The study considers a power system with four units, where three different energy sources are utilized and distributed across two areas. Each area has two power sources, with one area having a combination of thermal and gas power plants, and the other area consisting of a nuclear power plant and a gas power plant. Transmitting power from the nuclear power plant is particularly complex due to its high sensitivity to disturbances. Therefore, an intelligent and efficient controller is needed to ensure robust control in this type of power network that includes nuclear power. The paper also conducts a thorough analysis of the harmful emissions associated with electricity generation from the different power plants considered. The goal is to reduce the carbon footprint associated with power generation. The proposed work and analysis in the paper are implemented using the MATLAB/SIMULINK environment.","The rise in innovative methods to produce energy from various sources to satisfy increasing consumer demands has brought about numerous challenges in managing the power grid amid disruptions. This research paper introduces a novel strategy that integrates a controller with a soft computing technique called Particle Swarm Optimization (PSO) to tackle these issues. The investigation focuses on a power system comprising four units, where three distinct energy sources are distributed between two regions. Each region houses two power sources: one region has a mix of thermal and gas power plants, while the other contains a nuclear power plant and a gas power plant. Transmitting power from the nuclear plant proves especially challenging due to its high susceptibility to disturbances, necessitating an intelligent and efficient controller for reliable control in such a network. Additionally, the paper provides an in-depth examination of the emissions from the various power plants, aiming to minimize the carbon impact associated with power generation. The proposed methodology and analyses are carried out using the MATLAB/SIMULINK platform.","The escalating quest for novel energy harvesting methods from diverse sources to satiate the burgeoning consumer demand has precipitated a plethora of complexities in stabilizing the power grid amidst disparate disruptions. To mitigate these hurdles, this research paper pioneers an innovative paradigm that synergistically integrates a controller with the soft computing methodology of Particle Swarm Optimization (PSO). The investigation focuses on a quad-unit power system, wherein three disparate energy sources are harnessed and distributed across two distinct zones. Each zone boasts two power sources, with one zone featuring a hybrid thermal and gas power plant configuration, and the other comprising a nuclear power plant and a gas power plant. The transmission of power from the nuclear facility is particularly intricate due to its heightened susceptibility to perturbations, necessitating an intelligent and efficient controller to ensure robust governance in this nuclear-integrated power network. Furthermore, the paper undertakes an exhaustive examination of the noxious emissions associated with electricity generation from the various power plants under consideration, with the ultimate objective of minimizing the carbon footprint attendant to power generation. The proposed framework and analysis are actualized within the MATLAB/SIMULINK environment.","To handle the complex power grid management issues arising from the diversification of energy sources driven by increasing consumer demand, this research proposes a novel control strategy. This strategy leverages a controller enhanced by Particle Swarm Optimization, a sophisticated computational technique. The study focuses on a four-unit power system, encompassing three energy types distributed across two zones. Each zone utilizes two power sources, with one zone featuring both thermal and gas plants, while the other comprises a nuclear and a gas plant. The inclusion of a nuclear power plant, with its inherent susceptibility to disruptions, introduces significant challenges for power transmission. Consequently, an intelligent and high-performance controller is crucial for maintaining reliable control within such a nuclear-integrated power grid. Furthermore, the paper meticulously examines the detrimental emissions linked to electricity generation from each power plant type, aiming to curtail the overall carbon footprint of power production. This proposed methodology and its associated analysis are executed and validated through the MATLAB/SIMULINK platform.",acceptable,acceptable,acceptable,3.6,3.2,3.2
110,Fire simulation in the main control room of Bushehr nuclear power plant using CFAST software,"Fire protection is one of the most important issues to ensure safety and reduce risks of nuclear power plants. The main control room (MCR) is one of the parts of a nuclear power plant that is often identified with a high risk of fire in safety assessments. Although robust programs to shut down commercial reactors in any fires have been successfully maintained, the purpose of this paper is to simulate the fire in the MCR of Bushehr nuclear power plant unit‑1 (BNPP-1) using CFAST software. CFAST is a two-zone fire model used to calculate the evolving distribution of smoke, fire gases, and temperature throughout the compartments of a building during a fire. The data required for simulation have been extracted from final safety analysis reports and operating documents of BNPP‑1 and NUREG6850 reports. The results showed that the highest recorded temperature was related to the upper part of the standing cabinet about 1013 °C, which is the result of flames as well as heat transfer through smoke. Also, the other highest recorded temperature was in the lower part of the standing cabinet about 700 °C. Finally, the first ventilation system was closed for about 350 s and the second ventilation system was closed for about 860 s after the fire started.","Ensuring fire protection is crucial for the safety and risk mitigation of nuclear power plants. Within the safety evaluations, the main control room (MCR) is flagged as an area with significant fire risk. Despite effective programs for reactor shutdowns in fire scenarios, this study aims to model a fire in the MCR of Bushehr nuclear power plant unit‑1 (BNPP-1) using CFAST software. CFAST is a two-zone fire model designed to predict the progression of smoke, fire gases, and temperatures within building compartments amid a fire. Data for the simulation were sourced from the final safety analysis reports, operational documents of BNPP‑1, and NUREG6850 reports. Findings indicated that the highest temperature, around 1013°C, occurred in the upper section of the standing cabinet due to flames and heat transfer via smoke. Another significant temperature reading was approximately 700°C in the lower section of the standing cabinet. Additionally, the first ventilation system was shut for roughly 350 seconds, and the second for about 860 seconds after the fire ignited.","Ensuring the safety and mitigating the risks of nuclear power plants is crucial, and fire protection is a paramount concern in this regard. The main control room, a critical area prone to fire hazards, is a focal point in safety evaluations of nuclear facilities. Despite the existence of reliable shutdown protocols for commercial reactors in the event of a fire, this study aims to simulate a fire scenario in the main control room of Bushehr nuclear power plant unit-1 using the CFAST software, a two-zone fire modeling tool that predicts the spread of smoke, fire gases, and temperature within a building's compartments during a fire. The necessary data for the simulation were gleaned from the final safety analysis reports, operating documents of BNPP-1, and NUREG6850 reports. The simulation results revealed that the upper section of the standing cabinet reached a scorching temperature of approximately 1013°C, attributed to the combined effects of flames and heat transfer via smoke, while the lower section recorded a temperature of around 700°C. Furthermore, the first ventilation system remained shut for approximately 350 seconds, and the second ventilation system was closed for around 860 seconds after the fire broke out.","Ensuring fire safety is paramount for nuclear power plants to minimize risks. The main control room (MCR) is frequently flagged as a high fire-risk area in safety evaluations. While effective protocols exist to shut down reactors in the event of a fire, this study employed CFAST software to model a fire scenario within the MCR of Bushehr nuclear power plant unit-1 (BNPP-1). CFAST, a two-zone fire model, calculates the dynamic distribution of smoke, fire gases, and temperature throughout a building during a fire. The simulation utilized data from BNPP-1's final safety analysis reports, operational documents, and NUREG6850 reports. Results indicated that the highest temperature, approximately 1013°C, was observed in the upper section of the standing cabinet due to flames and heat transfer via smoke. Another elevated temperature, around 700°C, was recorded in the cabinet's lower part. Notably, the initial ventilation system closed approximately 350 seconds after the fire began, followed by the second system's closure at around 860 seconds.",acceptable,acceptable,acceptable,3.2,3.2,3.2
111,On the Road to Justice: Some Selected Suggestions for the Future of Social Justice Research,"In this paper, several aspects of social justice research are reviewed to analyze the current state of the field and to suggest refinements and new directions. The micro–macro-levels problem is discussed, including the policy of affirmative action. A canon of relevant philosophers is proposed. The strong influence of justice principles on social change research, search conferences and group interventions are demonstrated. The information value of social justice theories can be strengthened in several ways. Expanded information value implies increased effectiveness of advice and interventions. Possibilities to integrate justice criteria in total quality management are discussed. Contemporary quality management focuses on triple-P criteria: people, planet, profit, highly relevant for basic and applied justice research. The current state of the social justice discipline is rather good, but there is room for improvement. Finally, interdisciplinary research is the future, in particular for studies to solve complex societal and global problems.","This article reviews various elements of social justice research to evaluate the field's current status and propose enhancements and directions for future exploration. The issue of micro–macro-level interactions, including affirmative action policies, is examined. A selection of pertinent philosophers is introduced. The significant impact of justice principles on social change investigations, search conferences, and group interventions is showcased. The theoretical value of social justice can be augmented in multiple ways, thereby enhancing the effectiveness of recommendations and interventions. The integration of justice criteria into total quality management processes is explored. Modern quality management emphasizes the triple-P criteria—people, planet, and profit—which are highly pertinent to foundational and applied justice research. While the social justice field is in a good state, there is potential for further improvement. Ultimately, interdisciplinary research is identified as crucial for addressing complex societal and global challenges.","This study undertakes a comprehensive examination of social justice research, assessing its current trajectory and proposing innovative avenues for growth. The intricate dynamics between micro- and macro-levels are explored, with a focus on the implications of affirmative action policies. A foundational framework of influential philosophers is established. The profound impact of justice principles on social transformation, conference facilitation, and group interventions is elucidated. The informational potency of social justice theories can be augmented through multiple strategies, leading to enhanced advisory efficacy and intervention outcomes. The integration of justice metrics into total quality management paradigms is discussed, with a focus on the triple-bottom-line approach prioritizing people, planet, and profit – a convergence highly pertinent to both fundamental and applied justice inquiry. While the discipline of social justice is in a relatively strong position, opportunities for refinement remain. Ultimately, interdisciplinary collaboration is poised to become the hallmark of future research, particularly in addressing complex, large-scale societal and global challenges.","This work examines the current landscape of social justice research, proposing refinements and charting potential paths forward. The authors delve into the micro–macro level challenge, including affirmative action policies, and suggest a foundational group of philosophers. They illustrate how justice principles significantly impact research on social change, participatory planning processes, and group-based interventions. The paper argues that the practical value of social justice theories can be enhanced, leading to more effective interventions and guidance. It explores incorporating justice criteria into total quality management, which currently prioritizes people, planet, and profit—all relevant to foundational and applied justice research. While the field of social justice is deemed healthy, the authors see opportunities for growth. Ultimately, the paper champions interdisciplinary research, particularly for tackling complex global and societal issues.",acceptable,acceptable,acceptable,3.2,3.2,3.2
112,The Organizational Underpinnings of Social Justice Theory Development,"Existing psychological theories about justice developed during a classic period when social justice was a core aspect of social psychology. These theories have gone on to have impact on a number of fields concerned with addressing social, political and economic issues. At the same time shifts in the field of psychology have increasingly marginalized social justice scholars, diminishing new theoretical developments. This paper identifies organizational changes that would encourage a new generation of social justice theory researchers, something made important by the increasing number and severity of the justice relevant problems arising in the world.","Traditional psychological frameworks regarding justice were established in an era when social justice was integral to social psychology. These frameworks have since influenced various disciplines focused on resolving social, political, and economic problems. However, changes within psychology have gradually sidelined social justice scholars, hindering the evolution of new theoretical advancements. This paper suggests structural adjustments to foster a new wave of researchers in social justice theory, a necessity given the rising prevalence and intensity of justice-related issues globally.","""During a seminal era, social psychology was deeply rooted in the concept of justice, yielding influential theories that have resonated across disciplines tackling societal, political, and economic challenges. However, subsequent paradigm shifts within psychology have led to the peripheralization of social justice scholars, stifling innovation in theoretical frameworks. This study proposes institutional reforms to foster a new wave of researchers dedicated to social justice theory, a pressing imperative given the escalating prevalence and gravity of justice-related issues globally.""","Early theories of justice emerged from a period where social psychology heavily emphasized fairness. These influential concepts have since informed various disciplines tackling socio-economic and political challenges. However, evolving trends within psychology have increasingly sidelined scholars focused on social justice, hindering further theoretical advancements. This work proposes structural modifications to foster a new cohort of researchers dedicated to justice theory, a crucial step given the escalating prevalence and complexity of justice-related issues globally.",acceptable,acceptable,acceptable,3.2,3.2,3.2
113,Basic social justice orientations—measuring order-related justice in the European Social Survey Round 9,"Individuals hold normative ideas about the just distribution of goods and burdens within a social aggregate. These normative ideas guide the evaluation of existing inequalities and refer to four basic principles: (1) Equality stands for an equal distribution of rewards and burdens. While the principle of (2) need takes individual contributions into account, (3) equity suggests a distribution based on merit. The (4) entitlement principle suggests that ascribed (e.g., gender) and achieved status characteristics (e.g., occupational prestige) should determine the distribution of goods and burdens. Past research has argued that preferences for these principles vary with social position as well as the social structure of a society. The Basic Social Justice Orientations (BSJO) scale was developed to assess agreement with the four justice principles but so far has only been fielded in Germany. Round 9 of the European Social Survey (ESS R9 with data collected in 2018/2019) is the first time; four items of the BSJO scale (1 item per justice principle) were included in a cross-national survey program, offering the unique opportunity to study both within and between country variation. To facilitate substantive research on preference for equality, equity, need, and entitlement, this report provides evidence on measurement quality in 29 European countries from ESS R9. Analyzing response distributions, non-response, reliability, and associations with related variables, we find supportive evidence that the four items of the BSJO scale included in ESS R9 produce low non-response rates, estimate agreement with the four distributive principles reliably, and follow expected correlations with related concepts. Researchers should, however, remember that the BSJO scale, as implemented in the ESS R9, only provides manifest indicators, which therefore may not cover the full spectrum of the underlying distributive principles but focus on specific elements of it.","Individuals maintain normative beliefs about the fair allocation of resources and responsibilities within a society. These beliefs influence the assessment of current inequalities and are based on four fundamental principles: (1) Equality, which advocates for an even distribution of benefits and responsibilities; (2) Need, which considers individual contributions; (3) Equity, which proposes distribution according to merit; and (4) Entitlement, which argues that both ascribed (e.g., gender) and achieved characteristics (e.g., job status) should influence the distribution. Previous research indicates that preferences for these principles vary depending on social position and societal structure. The Basic Social Justice Orientations (BSJO) scale was designed to measure agreement with the four principles, but it has only been used in Germany until recently. For the first time, four items from the BSJO scale—one for each principle—were included in an international survey with Round 9 of the European Social Survey (ESS R9, data collected in 2018/2019), providing a unique chance to examine variations within and between countries. This report supplies evidence on the measurement quality in 29 European countries from ESS R9, aiding substantive research on preferences for equality, equity, need, and entitlement. Analysis of response distributions, non-response rates, reliability, and correlations with related variables shows that the four BSJO items in ESS R9 exhibit low non-response rates, reliable agreement estimation with the four principles, and expected correlations. Researchers should note, however, that the BSJO scale in ESS R9 offers manifest indicators, which may not fully capture the entire spectrum of distributive principles but focus on their specific aspects.","People harbor conceptions of fairness regarding the allocation of resources and responsibilities within a collective entity, which influence their assessment of existing disparities and are rooted in four fundamental tenets. Firstly, the principle of egalitarianism advocates for uniform distribution of benefits and burdens. In contrast, the need principle considers individual inputs, while the merit-based principle of equity proposes allocation based on deservingness. Lastly, the entitlement principle suggests that distribution should be determined by inherent characteristics, such as gender, and acquired status, like occupational prestige. Previous studies have shown that preferences for these principles vary depending on social standing and societal structure. The Basic Social Justice Orientations scale was designed to measure adherence to these principles, but its application has been limited to Germany. The inclusion of four scale items, each representing a principle, in the 9th round of the European Social Survey provides a unique opportunity to examine both intra- and inter-country differences. This report presents evidence on the measurement quality of these items in 29 European countries, analyzing response patterns, non-response rates, reliability, and correlations with related variables. The findings indicate that the scale items exhibit low non-response rates, reliably estimate agreement with the principles, and display expected correlations with related concepts. However, researchers should be aware that the scale, as implemented, only provides surface-level indicators, which may not capture the full range of the underlying principles but rather focus on specific aspects.","People possess beliefs about how goods and responsibilities should be fairly allocated within a society. These beliefs, which inform judgments about existing disparities, are rooted in four fundamental principles: (1) Equality advocates for an even distribution of benefits and burdens. (2) Need considers individual contributions, while (3) equity proposes distribution based on merit. Lastly, (4) entitlement posits that inherent traits (like gender) and earned statuses (such as job prestige) should dictate the allocation of resources and obligations. Previous studies suggest that preferences for these principles are influenced by both individual social standing and the broader societal structure. A tool called the Basic Social Justice Orientations (BSJO) scale was created to gauge agreement with these four justice principles, but its use had been limited to Germany. Round 9 of the European Social Survey (ESS R9, with data gathered in 2018/2019) marked the first inclusion of four BSJO scale items (one per principle) in a multinational survey, providing a unique chance to examine variations within and across nations. This report contributes to substantive research on preferences for equality, equity, need, and entitlement by evaluating the measurement quality in 29 European countries using ESS R9 data. By analyzing response patterns, non-response rates, reliability, and relationships with relevant variables, we find encouraging evidence that the four BSJO items in ESS R9 yield low non-response, reliably gauge agreement with the four distributive principles, and exhibit anticipated correlations with related concepts. However, researchers should bear in mind that the BSJO scale, as implemented in ESS R9, offers only overt indicators, which might not encompass the full range of the underlying distributive principles but instead concentrate on specific facets.",acceptable,acceptable,acceptable,3.6,3.2,3.2
114,A systematic review and meta-analysis of procedural justice and legitimacy in policing: the effect of social identity and social contexts,"ObjectivesTo systematically review the effect of social identity and social contexts on the association between procedural justice and legitimacy in policing.MethodsA meta-analysis synthesising data from 123 studies (N = 200,966) addressing the relationship between procedural justice and legitimacy in policing. Random effects univariate and two-stage structural equation modelling meta-analyses were performed.ResultsBoth procedural justice and social identity are found to be significantly correlated with police legitimacy. Moreover, social identity significantly mediates, but does not moderate, the association between procedural justice and legitimacy. People of younger age and from more developed countries tend to correlate procedural justice stronger with police legitimacy.ConclusionThis study demonstrates that social identity is an important antecedent of legitimacy and a critical factor in the dynamics of procedural fairness in policing. It also shows that the extent to which procedural justice and legitimacy are correlated varies across social groups and contexts. The theoretical implications of our findings are discussed.","Aims: To conduct a systematic review examining how social identity and contexts influence the link between procedural justice and police legitimacy. Methods: This meta-analysis combines results from 123 studies (N = 200,966) exploring the relationship between procedural justice and police legitimacy. The analysis utilized random effects univariate and two-stage structural equation modeling techniques. Findings: There is a significant correlation between both procedural justice and social identity with police legitimacy. Social identity notably mediates but does not moderate the relationship between procedural justice and legitimacy. Younger individuals and those from more developed countries are more likely to perceive a strong connection between procedural justice and police legitimacy. Conclusion: The study highlights social identity as a crucial precursor to legitimacy and a key element in the dynamics of procedural justice within policing. It also indicates that the correlation between procedural justice and legitimacy varies among different social groups and contexts. The theoretical implications of these findings are explored.","""This study aimed to investigate the interplay between social identity, social environments, and the relationship between fair policing procedures and public trust in law enforcement. A comprehensive meta-analysis of 123 studies involving over 200,000 participants was conducted, employing advanced statistical models to examine the correlations. The findings revealed that both fair procedures and social identity have a significant impact on police legitimacy, with social identity playing a mediating role in this association. Notably, the strength of this correlation varied across different age groups and countries, with younger individuals and those from more developed nations exhibiting a stronger link. The study's conclusions underscore the critical role of social identity in shaping public perceptions of police legitimacy and highlight the need to consider the diverse social contexts in which policing takes place.""","This research synthesized data from 123 studies (encompassing 200,966 participants) to examine how social identity and societal factors influence the link between procedural fairness and perceived legitimacy in law enforcement. Employing advanced statistical methods, the study revealed significant correlations between procedural justice, social identity, and police legitimacy. Notably, social identity acts as a key mediator, but not a moderator, in the relationship between procedural justice and legitimacy. The strength of the correlation between procedural justice and legitimacy varied based on demographic factors like age and national development. This investigation underscores the crucial role of social identity in shaping perceptions of legitimacy and highlights its significance in the interplay between procedural fairness and policing. Furthermore, it demonstrates that the connection between procedural justice and legitimacy is not uniform but rather is influenced by social contexts and group affiliations. The study's theoretical implications are explored in detail.",acceptable,acceptable,acceptable,,3.2,3.2
115,Teachers’ Social Emotional Learning Competencies and Social Justice Teaching Beliefs and Associations with Children’s Prosocial Behavior and Community Engagement,"BackgroundIndividual and collective prosocial competence can be fostered through high-quality interactions with program staff in out-of-school time environments.ObjectiveWe explored whether the social-emotional competencies of teachers working in an out-of-school STEM program infused with social emotional learning content were associated with school children’s prosocial behavior, community engagement, and peer problems and whether these associations were moderated by social justice teaching beliefs and child gender.MethodParticipants were 126 students (72 male). Forty-one were White, 40 were Black, 34 were Latine, and 11 were Asian and most of them were third graders (Mage = 8.11 years). Teachers rated their emotional competence, commitment to social emotional learning, and social justice teaching beliefs. They also provided ratings of children’s prosocial behavior and peer problems. Students provided ratings of their community engagement.ResultsTeachers’ emotional competence was negatively associated with prosocial behavior, but only when their social justice teaching beliefs were low. However, teachers’ commitment to social emotional learning was positively related to prosocial behavior. Teachers’ emotional competence was associated positively with peer problems, but only for girls, and was also related positively to community engagement.ConclusionsResults demonstrate associations between STEM teachers’ social emotional learning competencies and social justice teaching beliefs in the development of students’ prosocial competence and community engagement and provide directions for future research.","Background: High-quality interactions with program staff in out-of-school environments can cultivate individual and collective prosocial skills. Objective: This study investigated if teachers' social-emotional skills in an out-of-school STEM program enriched with social-emotional learning content were linked to children's prosocial behavior, community involvement, and peer issues, and examined whether these connections were influenced by teachers' social justice teaching beliefs and the child's gender. Method: A total of 126 students (72 boys) participated in the study. The racial composition included 41 White students, 40 Black students, 34 Latine students, and 11 Asian students, with most being third graders (average age = 8.11 years). Teachers assessed their emotional competence, commitment to social-emotional learning, and beliefs about social justice teaching. They also evaluated the children's prosocial behavior and peer problems. Students rated their own community engagement. Results: Teachers' emotional competence was linked to lower prosocial behavior when their social justice teaching beliefs were low. On the other hand, teachers' commitment to social-emotional learning was associated with higher prosocial behavior. Girls showed a positive correlation between teachers' emotional competence and peer problems. Additionally, teachers' emotional competence was positively related to community engagement. Conclusions: The findings show connections between STEM teachers' social-emotional learning skills and social justice teaching beliefs in the development of students' prosocial behavior and community involvement, offering directions for future research.","""In out-of-school settings, high-quality interactions with program staff can cultivate individual and collective prosocial abilities. This study investigated whether the social-emotional skills of STEM teachers, who incorporated social-emotional learning into their curriculum, influenced students' prosocial behavior, community involvement, and peer relationships, and whether these effects were influenced by teachers' social justice beliefs and the gender of the students. The sample consisted of 126 students (72 boys) from diverse racial backgrounds, primarily in the third grade (average age: 8.11 years). Teachers evaluated their own emotional intelligence, commitment to social-emotional learning, and social justice teaching beliefs, as well as their students' prosocial behavior and peer relationships. Students also assessed their own community engagement. The findings revealed that teachers' emotional intelligence was negatively linked to prosocial behavior when their social justice beliefs were weak, but positively associated with community engagement. In contrast, teachers' commitment to social-emotional learning was positively correlated with prosocial behavior. Furthermore, teachers' emotional intelligence was linked to peer problems, but only among girls. These results highlight the significance of STEM teachers' social-emotional learning competencies and social justice beliefs in fostering students' prosocial abilities and community engagement, and provide avenues for future research.""","High-quality interactions with educators in extracurricular settings can cultivate prosocial skills in children. This study investigated the link between the social-emotional skills of instructors in a STEM program incorporating social-emotional learning and the prosocial conduct, civic participation, and peer interactions of elementary students. The research also examined the potential influence of educators' social justice beliefs and student gender on these relationships. Findings revealed that instructors' emotional intelligence was negatively correlated with prosocial behavior only when their belief in social justice education was weak. Conversely, instructors' dedication to social-emotional learning positively predicted prosocial behavior. Furthermore, instructors' emotional intelligence was positively associated with peer difficulties, but only among female students, and also positively correlated with community engagement. These results highlight the interconnectedness of educators' social-emotional learning capabilities and social justice pedagogy in nurturing prosocial competence and civic engagement in students, offering valuable insights for future research.",acceptable,acceptable,acceptable,3.8,3.6,3.2
116,Learning to Lead for Equity and Social Justice through Critical Reflection and Autobiography,"In this paper, the authors utilize critical reflection and autobiographical narratives as a pedagogical tool for aspiring school leaders to examine beliefs and assumptions on equity and social justice in an educational leadership preparation program. Comparative themes related to their developing social justice and equity orientations included: (a)Understanding heritage and lived experience in relation to inequity and injustice, (b) Positionality awareness as a meaning making tool for leadership development, and (c) Praxis: Aspiration for action in one’s leadership role. Incorporating pedagogical tools that engage in difficult conversations with the self and the world has the potential to provided avenues for students to become active interpreters of their past histories, current aspirations and heighten their capacity to be active agents of justice.","In this study, the authors use critical reflection and personal narratives as teaching strategies for future school leaders to scrutinize their beliefs and assumptions about equity and social justice within an educational leadership training program. Comparative themes concerning their evolving perspectives on social justice and equity included: (a) Understanding heritage and personal experiences in relation to inequity and injustice, (b) Recognizing positionality as a tool for making sense of leadership development, and (c) Praxis: Aspiration for action in leadership. Employing pedagogical tools that engage in challenging self-reflection and societal dialogue can provide pathways for students to actively interpret their past experiences, future goals, and enhance their ability to act as agents of justice.","This study leverages autobiographical storytelling and critical introspection as an instructional strategy within an educational leadership preparation program, empowering prospective school administrators to scrutinize their beliefs and presuppositions regarding equity and social justice. The emerging themes, which illuminate the evolution of their social justice and equity perspectives, encompass: (a) recognizing the interplay between personal heritage, lived experience, and systemic injustices, (b) cultivating self-awareness of one's positionality as a catalyst for informed leadership, and (c) translating vision into action through deliberate praxis. By integrating pedagogical approaches that facilitate candid self-reflection and engagement with the world, this method has the potential to enable students to reinterpret their past, reframe their current aspirations, and amplify their capacity to drive positive change as agents of justice.","This study explores the use of critical reflection and personal narratives as a pedagogical approach to foster the development of social justice and equity perspectives in aspiring school leaders. Through these reflective practices, participants engaged in a process of examining their own beliefs and assumptions about equity and social justice within the context of an educational leadership program. Three key themes emerged from their evolving understanding: (1) recognizing the interconnectedness of personal heritage, lived experiences, and systemic inequities, (2) developing awareness of their own positionality as a lens for understanding leadership, and (3) translating these insights into actionable plans for promoting justice in their leadership roles. By integrating pedagogical tools that encourage introspection and critical dialogue, the program aims to empower students to critically analyze their past experiences, define their aspirations for social change, and ultimately strengthen their ability to be active advocates for justice.",acceptable,acceptable,acceptable,3.6,3.2,3.2
117,Focusing on the “Social” in Social Justice Research,"I describe what I see as a very strong connection between fairness perceptions and reactions that show engagement with social entities and social relationships. A brief review of studies on perceived fairness and the fair process effects illustrates how very social is the reaction to fair or unfair treatment—that is, how perceptions of fairness have a strong impact on how people view their inclusion and safety in the social group or relationship in which the treatment occurs. I suggest that this much-observed connection between fairness and group engagement raises some interesting questions about how perceived fairness affects some traditional group process phenomena. I discuss research questions that arise with respect to fairness and social identity process, fairness and obedience to authority, and fairness and conformity. Investigations of these questions, I argue, would give the field a stronger foundation in the basic social psychology of fairness and it would re-invigorate the groups aspect of social psychology as a discipline.","I explore the significant link between perceptions of fairness and actions reflecting engagement with social entities and relationships. A brief review of research on perceived fairness and its effects on fair processes highlights the social nature of responses to fair or unfair treatment—demonstrating that perceptions of fairness greatly influence individuals' sense of inclusion and safety within their social groups or relationships. I propose that this well-documented relationship between fairness and group involvement prompts intriguing questions about the impact of perceived fairness on traditional group process phenomena. I examine research questions concerning fairness and social identity processes, fairness and obedience to authority, and fairness and conformity. Studying these questions, I argue, would strengthen the field's foundation in the basic social psychology of fairness and revitalize the focus on group dynamics in social psychology as a discipline.","I highlight the existence of a profound correlation between individuals' perceptions of fairness and their responses that demonstrate investment in social networks and interpersonal bonds. A concise examination of research on perceived fairness and the fair process effects reveals the deeply social nature of reactions to fair or unfair treatment, namely, how fairness perceptions significantly influence individuals' sense of belonging and security within the social context in which the treatment occurs. This well-documented link between fairness and group involvement prompts intriguing inquiries about the impact of perceived fairness on classic group dynamics phenomena. I explore potential research avenues related to fairness and social identity formation, fairness and deference to authority, and fairness and compliance with norms, arguing that investigating these questions would provide a more solid grounding in the fundamental social psychology of fairness and revitalize the group dynamics aspect of social psychology as a field of study.","My analysis reveals a powerful link between perceived fairness and individuals' engagement with social entities and relationships. Existing research on fairness perceptions and the ""fair process effect"" highlights the inherently social nature of responses to fair or unfair treatment, demonstrating how such perceptions profoundly influence individuals' feelings of belonging and security within the group or relationship where the treatment transpires. This well-documented connection between fairness and group engagement prompts intriguing questions regarding the impact of perceived fairness on established group dynamics. I propose research directions examining the interplay between fairness and social identity formation, obedience to authority, and conformity. Exploring these areas, I contend, would not only provide a deeper understanding of the fundamental social psychology underlying fairness but also revitalize the study of groups within the discipline of social psychology.",acceptable,acceptable,acceptable,3.6,3.2,3.2
118,AI ethics and ordoliberalism 2.0: towards a ‘Digital Bill of Rights’,"This article analyzes AI ethics from a distinct business ethics perspective, i.e., ‘ordoliberalism 2.0.’ It argues that the ongoing discourse on (generative) AI relies too much on corporate self-regulation and voluntary codes of conduct and thus lacks adequate governance mechanisms. To address these issues, the paper suggests not only introducing hard-law legislation with a more effective oversight structure but also merging already existing AI guidelines with an ordoliberal-inspired regulatory and competition policy. However, this link between AI ethics, regulation, and antitrust is not yet adequately discussed in the academic literature and beyond. The paper thus closes a significant gap in the academic literature and adds to the predominantly legal-political and philosophical discourse on AI governance. The paper’s research questions and goals are twofold: first, it identifies ordoliberal-inspired AI ethics principles that could serve as the foundation for a ‘digital bill of rights.’ Second, it shows how those principles could be implemented at the macro level with the help of ordoliberal competition and regulatory policy.","This paper examines AI ethics from a unique perspective rooted in business ethics, specifically 'ordoliberalism 2.0.' It contends that the current debate on (generative) AI overly depends on corporate self-regulation and voluntary guidelines, thereby lacking proper governance mechanisms. To remedy this, the paper proposes enacting stringent legislation with a more effective oversight system, in addition to integrating existing AI guidelines with an ordoliberal-based regulatory and competitive policy. However, the connection between AI ethics, regulation, and antitrust issues has not been sufficiently explored in scholarly literature or beyond. By doing so, the paper fills a crucial gap in academic research and contributes to the predominantly legal-political and philosophical discussions on AI governance. The research aims are twofold: first, to identify ordoliberal-inspired AI ethics principles that could form the basis for a 'digital bill of rights'; second, to demonstrate how these principles could be applied on a macro level through ordoliberal competition and regulatory policies.","This study examines the ethics of artificial intelligence through the lens of a unique business ethics framework, namely, 'ordoliberalism 2.0.' It contends that the current conversation surrounding AI, including generative AI, is overly reliant on self-policing by corporations and voluntary codes of conduct, resulting in inadequate governance structures. To rectify this, the paper proposes the introduction of stringent legislation with enhanced oversight mechanisms, as well as the integration of existing AI guidelines with an ordoliberal-influenced regulatory and competition policy. Notably, the connection between AI ethics, regulation, and antitrust policy remains underexplored in both academic and non-academic circles. This paper fills a significant knowledge gap in the literature, contributing to the predominantly legal, political, and philosophical discussions on AI governance. The research objectives are twofold: firstly, to establish ordoliberal-inspired AI ethics principles that could form the basis of a 'digital bill of rights,' and secondly, to demonstrate how these principles can be implemented on a large scale through ordoliberal competition and regulatory policies.","This study explores the ethical dimensions of artificial intelligence through the lens of 'ordoliberalism 2.0', a unique business ethics framework. It posits that the current dialogue surrounding (generative) AI overemphasizes self-regulation by corporations and voluntary ethical guidelines, leading to insufficient governance structures. To rectify this, the paper proposes not only the establishment of legally binding regulations with robust oversight mechanisms but also the integration of existing AI guidelines into a regulatory and competition policy informed by ordoliberal principles. This crucial connection between AI ethics, regulation, and antitrust remains underexplored in both scholarly and broader discussions. Consequently, this work addresses a significant void in the academic literature, enriching the predominantly legal, political, and philosophical discourse on AI governance. The paper's research objectives are twofold: firstly, it identifies ordoliberal-inspired ethical principles for AI that could underpin a 'digital bill of rights'. Secondly, it demonstrates how these principles can be applied at a systemic level through ordoliberal competition and regulatory policy.",acceptable,acceptable,acceptable,4.0,3.6,3.6
119,From AI Ethics Principles to Practices: A Teleological Methodology to Apply AI Ethics Principles in The Defence Domain,"This article provides a methodology for the interpretation of AI ethics principles to specify ethical criteria for the development and deployment of AI systems in high-risk domains. The methodology consists of a three-step process deployed by an independent, multi-stakeholder ethics board to: (1) identify the appropriate level of abstraction for modelling the AI lifecycle; (2) interpret prescribed principles to extract specific requirements to be met at each step of the AI lifecycle; and (3) define the criteria to inform purpose- and context-specific balancing of the principles. The methodology presented in this article is designed to be agile, adaptable, and replicable, and when used as part of a pro-ethical institutional culture, will help to foster the ethical design, development, and deployment of AI systems. The application of the methodology is illustrated through reference to the UK Ministry of Defence AI ethics principles.","This article outlines a method for interpreting AI ethics principles to determine specific ethical standards for developing and implementing AI systems in high-risk areas. The method involves a three-stage process conducted by an independent, diverse ethics committee to: (1) establish the appropriate abstraction level for modeling the AI lifecycle; (2) translate the given principles into detailed requirements for each stage of the AI lifecycle; and (3) develop criteria to guide the context- and purpose-specific balancing of these principles. The described methodology is meant to be flexible, adaptable, and reproducible, and when implemented within a pro-ethical institutional culture, it aims to promote the ethical creation, development, and use of AI systems. The methodology’s application is demonstrated using the AI ethics principles from the UK Ministry of Defence.","This paper outlines a framework for operationalizing AI ethics guidelines to establish clear benchmarks for the creation and implementation of artificial intelligence in high-stakes environments. The approach involves a tripartite process, overseen by a diverse, autonomous ethics committee, which: (1) determines the optimal level of granularity for mapping the AI development cycle; (2) distills core principles into actionable directives for each lifecycle stage; and (3) establishes guidelines for balancing competing principles in context-dependent scenarios. The proposed framework is intentionally flexible, scalable, and repeatable, and when integrated into an organization's ethical DNA, it facilitates the responsible design, development, and deployment of AI solutions, as exemplified by its application to the UK Ministry of Defence's AI ethics framework.","This paper outlines a three-step, adaptable process for translating broad AI ethics principles into practical, context-specific guidelines for creating and using AI systems in sensitive areas. This process, intended to be executed by an impartial committee of diverse stakeholders, first determines the appropriate level of detail needed to represent the AI system's lifespan. Then, it deciphers the given principles, extracting precise requirements for each stage of the AI lifecycle. Finally, it establishes criteria for achieving a balanced application of these principles based on the AI system's purpose and operational context. This agile and reproducible methodology, when embedded in an ethically-conscious organizational culture, can contribute to the development and implementation of AI systems that prioritize ethical considerations. Its practical application is exemplified through its alignment with the AI ethics principles of the UK Ministry of Defence.",acceptable,acceptable,acceptable,3.6,3.2,3.2
120,Reflections on Putting AI Ethics into Practice: How Three AI Ethics Approaches Conceptualize Theory and Practice,"Critics currently argue that applied ethics approaches to artificial intelligence (AI) are too principles-oriented and entail a theory–practice gap. Several applied ethical approaches try to prevent such a gap by conceptually translating ethical theory into practice. In this article, we explore how the currently most prominent approaches of AI ethics translate ethics into practice. Therefore, we examine three approaches to applied AI ethics: the embedded ethics approach, the ethically aligned approach, and the Value Sensitive Design (VSD) approach. We analyze each of these three approaches by asking how they understand and conceptualize theory and practice. We outline the conceptual strengths as well as their shortcomings: an embedded ethics approach is context-oriented but risks being biased by it; ethically aligned approaches are principles-oriented but lack justification theories to deal with trade-offs between competing principles; and the interdisciplinary Value Sensitive Design approach is based on stakeholder values but needs linkage to political, legal, or social governance aspects. Against this background, we develop a meta-framework for applied AI ethics conceptions with three dimensions. Based on critical theory, we suggest these dimensions as starting points to critically reflect on the conceptualization of theory and practice. We claim, first, that the inclusion of the dimension of affects and emotions in the ethical decision-making process stimulates reflections on vulnerabilities, experiences of disregard, and marginalization already within the AI development process. Second, we derive from our analysis that considering the dimension of justifying normative background theories provides both standards and criteria as well as guidance for prioritizing or evaluating competing principles in cases of conflict. Third, we argue that reflecting the governance dimension in ethical decision-making is an important factor to reveal power structures as well as to realize ethical AI and its application because this dimension seeks to combine social, legal, technical, and political concerns. This meta-framework can thus serve as a reflective tool for understanding, mapping, and assessing the theory–practice conceptualizations within AI ethics approaches to address and overcome their blind spots.","Critics argue that current methodologies in applied ethics for AI are overly focused on principles, creating a disconnect between theory and practice. Various applied ethics methods attempt to bridge this gap by conceptually translating ethical theories into practical applications. In this paper, we investigate how the leading contemporary AI ethics approaches translate ethical concepts into practice. We scrutinize three specific approaches: embedded ethics, ethically aligned approaches, and the Value Sensitive Design (VSD) approach. Our analysis evaluates how each approach conceptualizes theory and practice, highlighting their strengths and limitations: the embedded ethics approach is context-oriented but may be biased by specific contexts; ethically aligned approaches focus on principles but lack theories for resolving conflicts between principles; and the interdisciplinary Value Sensitive Design approach prioritizes stakeholder values but requires connections to political, legal, or social governance factors. From this analysis, we propose a meta-framework for applied AI ethics with three essential dimensions. Grounded in critical theory, we recommend these dimensions as starting points for scrutinizing the relationship between theory and practice. First, incorporating the dimension of affects and emotions in ethical decision-making can reveal vulnerabilities and marginalized experiences during AI development. Second, considering the dimension of justifying normative background theories provides benchmarks and criteria for prioritizing and evaluating conflicting principles. Third, considering governance in ethical decision-making illuminates power structures and supports the development of ethical AI by integrating social, legal, technical, and political concerns. This meta-framework serves as a tool for comprehending, mapping, and evaluating theory–practice conceptualizations in AI ethics to address their inherent gaps.","Present-day detractors contend that artificial intelligence (AI) ethics frameworks rooted in applied ethics are overly reliant on abstract principles, resulting in a disconnect between theoretical foundations and practical applications. To bridge this gap, various approaches attempt to operationalize ethical theories into tangible practices. This article delves into the ways in which prominent AI ethics frameworks – namely, embedded ethics, ethically aligned design, and Value Sensitive Design – translate ethical principles into actionable strategies. Through a critical examination of each approach, we identify their conceptual strengths and weaknesses: embedded ethics risks contextual bias, ethically aligned design lacks theoretical justification for resolving principle-based conflicts, and Value Sensitive Design requires integration with governance structures. Building upon these findings, we propose a meta-framework for applied AI ethics, comprising three key dimensions informed by critical theory. This framework encourages critical reflection on the interplay between theory and practice, highlighting the importance of incorporating affective and emotional considerations to address vulnerabilities and marginalization. Furthermore, it emphasizes the need for normative background theories to provide evaluative criteria and guidance for navigating conflicting principles. Finally, the framework underscores the significance of governance structures in revealing power dynamics and ensuring the ethical development and deployment of AI systems.","Contemporary critiques of applied ethics in artificial intelligence (AI) highlight an overreliance on abstract principles, leading to a disconnect between theoretical ideals and practical implementation. Various approaches attempt to bridge this divide by translating ethical theories into real-world applications. This article investigates how leading AI ethics approaches operationalize ethical principles in practice, focusing on three prominent frameworks: embedded ethics, ethically aligned design, and Value Sensitive Design (VSD). Each approach is analyzed based on its understanding and conceptualization of theory and practice, highlighting both strengths and weaknesses. Embedded ethics prioritizes context but risks being unduly influenced by it. Ethically aligned approaches emphasize principles but lack robust justification frameworks for navigating conflicts between competing values. The interdisciplinary VSD approach centers stakeholder values but requires stronger connections to political, legal, and social governance structures. To address these limitations, a meta-framework for applied AI ethics is proposed, comprising three key dimensions grounded in critical theory. These dimensions encourage critical reflection on the conceptualization of theory and practice. The first dimension emphasizes the integration of affects and emotions in ethical decision-making, promoting sensitivity to vulnerabilities, experiences of disregard, and marginalization during AI development. The second dimension calls for the consideration of normative background theories, providing standards and criteria for prioritizing and evaluating competing principles in conflict situations. Lastly, the governance dimension underscores the importance of revealing power dynamics and integrating social, legal, technical, and political considerations for realizing ethical AI applications. This meta-framework acts as a reflective tool for understanding, mapping, and evaluating the theory-practice nexus within AI ethics approaches, ultimately aiming to address and overcome their inherent limitations.",acceptable,acceptable,acceptable,3.6,3.2,3.2
121,A semi-automated software model to support AI ethics compliance assessment of an AI system guided by ethical principles of AI,"Compliance with principles and guidelines for ethical AI has a significant impact on companies engaged in the development of artificial intelligence (AI) systems. Specifically, ethics is a broad concept that continuously evolves over time and across cultural and geographical boundaries. International organisations (IOs), individual states, and private groups, all have an interest in defining the concept of ethics of AI. IOs, as well as regional and national bodies, have issued many decisions on AI ethics. Developing a system that complies with the ethical framework poses a complex challenge for companies, and the consequences of not complying with ethical principles can have severe consequences, making compliance with these requirements a key issue for companies. Furthermore, there is a shortage of technical tools to ensure that such AI systems comply with ethical criteria. The scarcity of ethics compliance checking tools for AI, and the current focus on defining ethical guidelines for AI development, has led us to undertake a proposal consisting in a semi-automated software model to verify the ethical compliance of an AI system’s code. To implement this model, we focus on the following important aspects: (1) a literature review to identify existing ethical compliance systems, (2) a review of principles and guidelines for ethical AI to determine the international and European views regarding AI ethics, and (3) the identification of commonly accepted principles and sub-principles of AI. These elements served to inform (4) our proposal for the design of a semi-automated software for verifying the ethical compliance of AI systems both at design-time (ethics-by-design perspective) and afterwards on the resulting software.","Adhering to ethical AI principles and guidelines profoundly affects companies involved in creating artificial intelligence (AI) systems. Ethics, a broad and ever-changing concept, varies across cultures and regions. International organizations (IOs), governments, and private entities all strive to define AI ethics. Numerous decisions on AI ethics have been issued by IOs, regional, and national bodies. Crafting a compliant system within this ethical framework presents a considerable challenge for companies, with significant repercussions for non-compliance, making adherence to these standards critically important. Additionally, there is a lack of technical tools to ensure AI systems meet ethical standards. The deficiency of such compliance-checking tools, coupled with the ongoing effort to define ethical guidelines for AI development, has prompted us to propose a semi-automated software model to verify the ethical adherence of AI system code. To develop this model, we consider: (1) a literature review to identify current ethical compliance systems, (2) an analysis of ethical AI principles and guidelines to capture international and European perspectives on AI ethics, and (3) the identification of widely accepted AI principles and sub-principles. These considerations informed (4) our design proposal for a semi-automated software to verify ethical compliance of AI systems during design (ethics-by-design approach) and post-development.","The adherence to fundamental tenets and directives governing the ethical development of artificial intelligence (AI) has a profound influence on organizations involved in creating AI systems. Ethics, a multifaceted and dynamic concept, undergoes continuous transformation across cultural, geographical, and temporal boundaries. A diverse range of stakeholders, including international organizations, nation-states, and private entities, strive to delineate the ethical paradigm for AI. Consequently, numerous regulatory bodies have issued decrees and guidelines pertaining to AI ethics. The development of AI systems that conform to ethical frameworks poses a formidable challenge for companies, and the repercussions of non-compliance can be severe, rendering adherence to these requirements a paramount concern. Moreover, a dearth of technical instruments exists to ensure AI systems conform to ethical standards. The scarcity of ethics auditing tools for AI, coupled with the prevailing emphasis on establishing ethical guidelines for AI development, has prompted us to propose a semi-automated software model for verifying the ethical compliance of AI system code. To actualize this model, we prioritize the following crucial aspects: (1) a comprehensive examination of existing ethical compliance systems through literature review, (2) an analysis of international and European perspectives on AI ethics, (3) the identification of universally accepted AI principles and sub-principles, and (4) the design of a semi-automated software for verifying AI systems' ethical compliance during both the design phase and post-development, adopting an ethics-by-design approach.","Adhering to ethical AI principles and guidelines is crucial for companies developing AI systems. However, the evolving nature of ethics, with variations across cultures and regions, complicates this process. Various stakeholders, including international organizations, national governments, and private entities, are actively shaping the ethical landscape of AI. Numerous pronouncements on AI ethics have emerged from these groups, creating a complex compliance challenge for companies. Failure to comply can lead to serious repercussions, highlighting the criticality of ethical adherence. Furthermore, a scarcity of technical tools for verifying ethical compliance in AI systems exacerbates this challenge. This lack of verification tools, coupled with the ongoing focus on defining ethical guidelines, motivated our development of a semi-automated software model for assessing the ethical compliance of AI system code. This model is grounded in a comprehensive review of existing ethical compliance systems, an analysis of international and European perspectives on AI ethics, and the identification of widely accepted ethical principles and sub-principles. These foundational elements informed the design of our proposed software, which aims to verify ethical compliance in AI systems both during the design phase (ethics-by-design) and post-development.",acceptable,acceptable,acceptable,3.2,3.2,3.2
122,Towards AI ethics’ institutionalization: knowledge bridges from business ethics to advance organizational AI ethics,"This paper proposes to generate awareness for developing Artificial intelligence (AI) ethics by transferring knowledge from other fields of applied ethics, particularly from business ethics, stressing the role of organizations and processes of institutionalization. With the rapid development of AI systems in recent years, a new and thriving discourse on AI ethics has (re-)emerged, dealing primarily with ethical concepts, theories, and application contexts. We argue that business ethics insights may generate positive knowledge spillovers for AI ethics, given that debates on ethical and social responsibilities have been adopted as voluntary or mandatory regulations for organizations in both national and transnational contexts. Thus, business ethics may transfer knowledge from five core topics and concepts researched and institutionalized to AI ethics: (1) stakeholder management, (2) standardized reporting, (3) corporate governance and regulation, (4) curriculum accreditation, and as a unified topic (5) AI ethics washing derived from greenwashing. In outlining each of these five knowledge bridges, we illustrate current challenges in AI ethics and potential insights from business ethics that may advance the current debate. At the same time, we hold that business ethics can learn from AI ethics in catching up with the digital transformation, allowing for cross-fertilization between the two fields. Future debates in both disciplines of applied ethics may benefit from dialog and cross-fertilization, meant to strengthen the ethical depth and prevent ethics washing or, even worse, ethics bashing.","This article aims to raise awareness about developing ethics for artificial intelligence (AI) by leveraging knowledge from other areas of applied ethics, notably business ethics, emphasizing organizations and institutional processes. As AI systems have rapidly evolved in recent years, a renewed and vigorous discussion on AI ethics has surfaced, concentrating on ethical concepts, theories, and application contexts. We propose that insights from business ethics can beneficially spill over into AI ethics, as discussions about ethical and social responsibilities have been implemented as voluntary or mandatory regulations in both national and international contexts. Consequently, business ethics can inform AI ethics in five key areas that have been explored and institutionalized: (1) stakeholder management, (2) standardized reporting, (3) corporate governance and regulation, (4) curriculum accreditation, and collectively (5) AI ethics washing, akin to greenwashing. By detailing these five knowledge transfers, we highlight prevailing challenges in AI ethics and suggest how business ethics insights can advance the discourse. Concurrently, we assert that business ethics can gain from AI ethics in adapting to the digital transformation, fostering mutual enrichment between the two fields. Future discussions in both realms of applied ethics could benefit from dialogue and mutual enrichment, enhancing ethical rigor and preventing practices such as ethics washing or, worse, ethics bashing.","This study advocates for fostering a deeper understanding of Artificial Intelligence (AI) ethics by leveraging the expertise of adjacent fields, notably business ethics, with a focus on the pivotal role of organizational frameworks and institutionalization processes. As AI systems have experienced exponential growth in recent years, a vibrant discussion on AI ethics has re-emerged, primarily centered around ethical principles, theoretical frameworks, and practical applications. We contend that the wealth of knowledge accumulated in business ethics can have a positive ripple effect on AI ethics, given the widespread adoption of voluntary and mandatory guidelines for corporate social responsibility across national and international jurisdictions. Specifically, business ethics can offer valuable insights to AI ethics in five key areas: (1) managing stakeholder expectations, (2) standardized disclosure practices, (3) governance and regulatory frameworks, (4) curriculum development and accreditation, and (5) the phenomenon of AI ethics posturing, analogous to greenwashing. By elaborating on these five knowledge transfer pathways, we highlight the current challenges in AI ethics and the potential contributions of business ethics to the ongoing discourse. Moreover, we believe that business ethics can also learn from AI ethics in navigating the complexities of digitalization, thereby facilitating a cross-pollination of ideas between the two fields. Ultimately, future discussions in both applied ethics disciplines can benefit from reciprocal exchange and cross-fertilization, aimed at enriching ethical understanding and preventing superficial or even hostile approaches to ethics.","This study advocates for raising awareness about ethical considerations in Artificial Intelligence (AI) by drawing parallels with established fields like business ethics. The recent surge in AI development has reignited discussions on its ethical implications, focusing on principles, theories, and practical applications. The paper posits that the longstanding dialogue on ethical and social responsibility in business, often resulting in regulations for organizations, can offer valuable insights for AI ethics. Five key areas of knowledge transfer are identified: stakeholder engagement, standardized reporting practices, corporate governance and regulatory frameworks, curriculum accreditation, and the emerging issue of AI ethics washing, mirroring similar concerns in sustainability (greenwashing). Each of these ""bridges"" highlights existing challenges in AI ethics and demonstrates how business ethics can offer potential solutions. The authors also acknowledge the reciprocal benefit, suggesting that AI ethics can contribute to business ethics by addressing challenges posed by digital transformation. Ultimately, the paper encourages ongoing dialogue and cross-pollination between these two domains of applied ethics to foster more robust ethical frameworks and prevent superficial or detrimental ethical practices.",acceptable,acceptable,acceptable,3.6,3.2,3.2
123,Unveiling public perception of AI ethics: an exploration on Wikipedia data,"Artificial Intelligence (AI) technologies have exposed more and more ethical issues while providing services to people. It is challenging for people to realize the occurrence of AI ethical issues in most cases. The lower the public awareness, the more difficult it is to address AI ethical issues. Many previous studies have explored public reactions and opinions on AI ethical issues through questionnaires and social media platforms like Twitter. However, these approaches primarily focus on categorizing popular topics and sentiments, overlooking the public’s potential lack of knowledge underlying these issues. Few studies revealed the holistic knowledge structure of AI ethical topics and the relations among the subtopics. As the world’s largest online encyclopedia, Wikipedia encourages people to jointly contribute and share their knowledge by adding new topics and following a well-accepted hierarchical structure. Through public viewing and editing, Wikipedia serves as a proxy for knowledge transmission. This study aims to analyze how the public comprehend the body of knowledge of AI ethics. We adopted the community detection approach to identify the hierarchical community of the AI ethical topics, and further extracted the AI ethics-related entities, which are proper nouns, organizations, and persons. The findings reveal that the primary topics at the top-level community, most pertinent to AI ethics, predominantly revolve around knowledge-based and ethical issues. Examples include transitions from Information Theory to Internet Copyright Infringement. In summary, this study contributes to three points, (1) to present the holistic knowledge structure of AI ethics, (2) to evaluate and improve the existing body of knowledge of AI ethics, (3) to enhance public perception of AI ethics to mitigate the risks associated with AI technologies.","Artificial Intelligence (AI) technologies have increasingly highlighted ethical concerns while delivering services to individuals. People often find it difficult to recognize the occurrence of these AI ethical dilemmas. Generally, the lower the level of public awareness, the more challenging it becomes to resolve AI ethical issues. Numerous prior studies have examined public reactions and opinions on AI ethics through surveys and social media platforms like Twitter. Nonetheless, these methods mainly emphasize identifying popular topics and sentiments, neglecting the public’s potential ignorance of these issues. Few studies have uncovered the comprehensive knowledge structure of AI ethical topics and the relationships among subtopics. As the world’s largest online encyclopedia, Wikipedia encourages collective contributions and knowledge sharing by adding new topics and adhering to a widely accepted hierarchical structure. Through public viewing and editing, Wikipedia acts as a proxy for knowledge dissemination. This study aims to examine how the public understands the corpus of AI ethical knowledge. We employed a community detection approach to identify the hierarchical structure of AI ethical topics and further identified AI ethics-related entities, such as proper nouns, organizations, and individuals. The findings indicate that the primary topics within the top-level community, most related to AI ethics, mainly focus on knowledge-based and ethical issues. Examples include shifts from Information Theory to Internet Copyright Infringement. In conclusion, this study contributes to three areas: (1) presenting the comprehensive knowledge structure of AI ethics, (2) evaluating and enhancing the existing body of knowledge on AI ethics, and (3) improving public understanding of AI ethics to mitigate risks associated with AI technologies.","""As AI technologies increasingly interact with humans, they have unveiled a multitude of ethical concerns. However, the general public often remains oblivious to these issues, and the lack of awareness hinders efforts to address them. Previous research has probed public sentiments and opinions on AI ethics through surveys and social media, but these studies have primarily focused on categorizing popular themes and emotions, neglecting the underlying knowledge gaps. Few investigations have delved into the comprehensive knowledge framework of AI ethics and the relationships between subtopics. Leveraging Wikipedia's collaborative knowledge-sharing platform, this study seeks to understand how the public grasps the complex body of knowledge surrounding AI ethics. By employing community detection methods, we identified a hierarchical network of AI ethical topics and extracted relevant entities, including proper nouns, organizations, and individuals. Our findings indicate that the core topics at the highest level of the community, most closely tied to AI ethics, predominantly center around knowledge-centric and ethical concerns, such as shifts from Information Theory to Internet Copyright Infringement. Ultimately, this study makes three key contributions: (1) mapping the comprehensive knowledge structure of AI ethics, (2) assessing and refining the existing body of knowledge on AI ethics, and (3) enhancing public understanding of AI ethics to mitigate the risks associated with AI technologies.""","The increasing integration of Artificial Intelligence (AI) into various services has brought about a surge in ethical concerns. Recognizing these ethical dilemmas often proves difficult for the general public, and this lack of awareness further complicates efforts to address them. While past research has investigated public sentiment on AI ethics through surveys and platforms like Twitter, these methods primarily focus on identifying popular themes and opinions, neglecting the potential knowledge gaps underpinning these issues. Consequently, there is limited understanding of the comprehensive structure of AI ethical topics and their interrelations. Leveraging Wikipedia's collaborative nature and its established hierarchical framework, this study explores public understanding of AI ethics. Employing community detection techniques, the research identifies the hierarchical arrangement of AI ethical topics and extracts relevant entities such as specific terms, institutions, and individuals. The results highlight that top-level topics, most closely linked to AI ethics, primarily center around knowledge-based and ethical concerns, illustrating a transition from theoretical concepts like Information Theory to practical dilemmas like Internet Copyright Infringement. In essence, this study makes three key contributions: it provides a comprehensive representation of the AI ethical knowledge structure, offers a means to assess and enhance the existing knowledge base on AI ethics, and ultimately seeks to raise public awareness to mitigate potential risks associated with AI technologies.",acceptable,acceptable,acceptable,3.6,3.2,3.2
124,How to design an AI ethics board,"The development and deployment of artificial intelligence (AI) systems poses significant risks to society. To reduce these risks to an acceptable level, AI companies need an effective risk management process and sound risk governance. In this paper, we explore a particular way in which AI companies can improve their risk governance: by setting up an AI ethics board. We identify five key design choices: (1) What responsibilities should the board have? (2) What should its legal structure be? (3) Who should sit on the board? (4) How should it make decisions? (5) And what resources does it need? We break each of these questions down into more specific sub-questions, list options, and discuss how different design choices affect the board’s ability to reduce societal risks from AI. Several failures have shown that designing an AI ethics board can be challenging. This paper provides a toolbox that can help AI companies to overcome these challenges.","The creation and implementation of artificial intelligence (AI) systems present substantial dangers to society. To mitigate these risks to an acceptable threshold, AI firms need a robust risk management strategy and solid risk governance frameworks. In this article, we delve into a specific method for enhancing risk governance in AI firms: establishing an AI ethics board. We outline five crucial design considerations: (1) What duties should the board undertake? (2) What legal configuration should it have? (3) Who should be included on the board? (4) What decision-making processes should it follow? (5) And what resources are necessary for its function? We address each of these queries with detailed sub-questions, provide various options, and evaluate how different design choices impact the board's efficacy in mitigating AI-related societal risks. Numerous failures highlight the complexities in devising an AI ethics board. This paper equips AI firms with a toolkit to navigate these challenges effectively.","""The integration and implementation of artificial intelligence (AI) systems entails substantial perils to societal well-being. To mitigate these threats to a tolerable threshold, AI corporations require a robust risk mitigation framework and prudent governance structures. This study examines a specific strategy for enhancing risk governance in AI companies: the establishment of an AI ethics committee. We delineate five pivotal design considerations: (1) What authority should the committee wield? (2) What legal framework should it operate within? (3) Who should comprise the committee's membership? (4) How should it arrive at decisions? (5) And what resources are necessary for its functioning? We deconstruct each of these inquiries into more nuanced sub-inquiries, catalog potential options, and analyze how disparate design decisions influence the committee's capacity to alleviate societal perils associated with AI. The history of failed attempts underscores the complexity of designing an AI ethics committee. This paper offers a comprehensive guide to aid AI corporations in surmounting these obstacles.""","The burgeoning field of artificial intelligence presents considerable societal dangers that must be mitigated. To ensure these risks are minimized, organizations developing AI technologies require robust risk management strategies and ethical oversight. This study proposes the establishment of dedicated AI ethics boards as a crucial step towards achieving responsible AI development. We delve into five critical aspects of board design: the scope of their duties, their legal constitution, the composition of their membership, their decision-making processes, and the resources they require to function effectively. Each of these facets is further deconstructed into specific sub-questions, presenting diverse options and analyzing how different configurations influence the board's capacity to mitigate AI-associated risks to society. Past shortcomings underscore the intricacies inherent in designing such boards; this paper furnishes a pragmatic framework to navigate these challenges and empower AI companies to navigate the ethical dimensions of their work.",acceptable,acceptable,acceptable,3.2,3.2,3.2
125,Embedding responsibility in intelligent systems: from AI ethics to responsible AI ecosystems,"Intelligent systems that are capable of making autonomous decisions based on input from their environment have great potential to do good, but they also raise significant social and ethical concerns. The discourse on ethics and artificial intelligence (AI) has covered these concerns in depth and developed an array of possible ways of addressing them. This article argues that a shortcoming of this discourse is that it concentrates on specific issues and their mitigation but neglects the nature of intelligent systems as socio-technical systems of systems that are often described as ecosystems. Building on the discussion of ethics and AI, the article suggests that it would be beneficial to come to an understanding of what would constitute responsible AI ecosystems. By introducing the concept of meta-responsibility or higher-level responsibility, the article proposes characteristics that an ecosystem would have to fulfil, in order to be considered a responsible ecosystem. This perspective is theoretically interesting because it extends the current AI ethics discourse. It furthermore offers a novel perspective for researchers and developers of intelligent system and helps them reflect on the way they relate to ethical issues.","Autonomous intelligent systems, capable of making decisions based on their environmental inputs, possess significant potential for positive impact but also pose substantial social and ethical challenges. The ethical discourse surrounding artificial intelligence (AI) has extensively explored these challenges and suggested various mitigation strategies. This article critiques this discourse, arguing that it tends to focus on specific issues and solutions while overlooking the broader context of intelligent systems as complex socio-technical ecosystems. Expanding upon the discussion of AI ethics, the article advocates for a better understanding of what defines a responsible AI ecosystem. By introducing the concept of meta-responsibility or a higher-level responsibility, the article delineates qualities that such an ecosystem must exhibit to be considered responsible. This viewpoint is theoretically intriguing as it broadens the current discussion on AI ethics and provides a fresh perspective for researchers and developers of intelligent systems, aiding their contemplation of ethical considerations.","Autonomous intelligent systems, which can make decisions based on environmental inputs, hold immense promise for positive impact, yet they also spark substantial social and ethical apprehensions. While the ongoing debate surrounding AI ethics has exhaustively explored these concerns and proposed various solutions, a notable oversight is its focus on isolated issues and mitigation strategies, neglecting the intrinsic nature of intelligent systems as complex, interconnected socio-technical ecosystems. This article contends that a crucial step forward would be to define the parameters of responsible AI ecosystems, introducing the concept of meta-responsibility to outline the essential characteristics of such ecosystems. This novel perspective not only enriches the theoretical landscape of AI ethics but also provides a valuable framework for researchers and developers of intelligent systems to re-examine their approach to ethical considerations.","While smart systems capable of independent decision-making based on environmental input hold immense promise for positive impact, they also spark considerable societal and ethical apprehensions. Extensive discussions surrounding ethics in artificial intelligence (AI) have delved into these anxieties and offered various approaches to tackle them. However, this discourse often focuses narrowly on specific problems and their solutions, overlooking the inherent nature of intelligent systems as complex socio-technical networks often likened to ecosystems. Expanding upon existing ethical considerations in AI, this article posits that understanding what constitutes responsible AI ecosystems is crucial. By introducing the notion of meta-responsibility, it outlines the essential attributes for such ecosystems, thereby enriching the ongoing dialogue on AI ethics. This novel perspective encourages researchers and developers to critically examine their role in addressing ethical implications within intelligent systems.",acceptable,acceptable,acceptable,3.2,3.2,3.2
126,The ethics of AI business practices: a review of 47 AI ethics guidelines,"Many AI ethics guidelines have recently been published that center the fairness, accountability, sustainability, and transparency of algorithmic decision-making. Relatively few guidelines center the ethics of the business practices and political economies in which AI systems are situated. We present the findings of a semi-systematic literature review and thematic analysis aimed at determining the extent to which the ethics of AI business practices are considered in a large sample of guidelines. Our review reveals that the political and economic implications of AI business practices are greatly underrepresented in AI ethics guidelines. In its current state, AI ethics guidelines focus disproportionately on issues of algorithmic decision-making, while the fairness, accountability, sustainability, and transparency of the business decision-making contexts in which AI systems are situated remain seriously undermined by competitive and speculative norms, ethics washing, corporate secrecy, and other harmful business practices. We discuss these challenges, and we suggest that the ontological and disciplinary scope of future AI ethics guidelines should be expanded to better contend with them.","Numerous recent publications on AI ethics concentrate on the fairness, accountability, sustainability, and transparency of algorithmic decision-making. However, a smaller number of guidelines address the ethical considerations within the business practices and political economies that host AI systems. Our semi-systematic literature review and thematic analysis aimed to evaluate the attention given to the ethics of AI business practices across numerous guidelines. The review indicates that the political and economic effects of AI business strategies are largely overlooked in current AI ethics guidelines. Presently, these guidelines are heavily biased towards algorithmic decision-making issues, while neglecting the ethical dimensions of business decision-making contexts influenced by competitive environments, speculative behaviors, ethics washing, corporate confidentiality, and other detrimental business practices. We explore these issues and propose that future AI ethics guidelines should broaden their ontological and disciplinary perspectives to more effectively address these concerns.","A plethora of AI ethics frameworks have emerged recently, prioritizing the virtues of fairness, accountability, sustainability, and transparency in algorithm-driven decision-making processes. However, a notable scarcity of guidelines exists that scrutinize the ethical implications of the commercial and political ecosystems in which AI systems operate. This study presents the outcomes of a comprehensive literature review and thematic analysis, which aimed to assess the degree to which AI business ethics are addressed in a substantial corpus of guidelines. The findings indicate that the political and economic repercussions of AI-driven commercial practices are significantly marginalized in AI ethics frameworks. Currently, AI ethics guidelines exhibit a disproportionate emphasis on algorithmic decision-making, while the ethical integrity of the business environments in which AI systems are embedded remains severely compromised by cutthroat and speculative norms, moral posturing, corporate opacity, and other detrimental business practices.","A plethora of ethical frameworks for AI have emerged, emphasizing equitable, responsible, sustainable, and transparent algorithmic processes. However, these frameworks often neglect the ethical dimensions of the commercial and political landscapes in which these systems operate. Through a rigorous analysis of existing guidelines, we find a significant gap in addressing the ethical implications of AI business practices. While algorithmic fairness dominates current ethical discourse, the broader context of business decision-making, often plagued by competitive pressures, ethical facades, and lack of transparency, receives inadequate attention. To comprehensively address these concerns, we propose broadening the scope of future AI ethical guidelines to encompass both ontological and disciplinary perspectives.",acceptable,acceptable,acceptable,3.2,3.2,3.2
127,Ethics in AI through the practitioner’s view: a grounded theory literature review,"The term ethics is widely used, explored, and debated in the context of developing Artificial Intelligence (AI) based software systems. In recent years, numerous incidents have raised the profile of ethical issues in AI development and led to public concerns about the proliferation of AI technology in our everyday lives. But what do we know about the views and experiences of those who develop these systems – the AI practitioners? We conducted a grounded theory literature review (GTLR) of 38 primary empirical studies that included AI practitioners’ views on ethics in AI and analysed them to derive five categories: practitioner awareness, perception, need, challenge, and approach. These are underpinned by multiple codes and concepts that we explain with evidence from the included studies. We present a taxonomy of ethics in AI from practitioners’ viewpoints to assist AI practitioners in identifying and understanding the different aspects of AI ethics. The taxonomy provides a landscape view of the key aspects that concern AI practitioners when it comes to ethics in AI. We also share an agenda for future research studies and recommendations for practitioners, managers, and organisations to help in their efforts to better consider and implement ethics in AI.","The concept of ethics is frequently invoked, examined, and contested in the realm of developing AI-driven software systems. In recent times, a variety of incidents have spotlighted the ethical challenges in AI development, prompting public apprehension regarding the widespread adoption of AI technology in daily life. However, what insights do we have into the perspectives and experiences of those who create these systems – the AI developers? We undertook a grounded theory literature review (GTLR) of 38 primary empirical studies featuring the views of AI practitioners on ethics in AI and classified them into five categories: practitioner awareness, perception, need, challenge, and approach. These categories are supported by various codes and concepts, which we elucidate with evidence drawn from the studies. We offer a taxonomy of AI ethics from the perspective of practitioners to aid AI developers in recognizing and comprehending the different facets of AI ethics. The taxonomy offers an overarching view of the primary concerns that AI practitioners have regarding ethics in AI. Additionally, we provide a research agenda and suggestions for practitioners, managers, and organizations to enhance their considerations and applications of ethics in AI.","The concept of ethics has become a pervasive theme in the development of Artificial Intelligence (AI) driven software systems, sparking intense scrutiny and debate. A surge in recent incidents has catapulted ethical concerns surrounding AI technology to the forefront of public consciousness, prompting questions about its integration into daily life. However, a crucial perspective remains largely unexplored: that of the AI developers themselves. To address this knowledge gap, we undertook a comprehensive grounded theory literature review of 38 empirical studies, distilling the views of AI practitioners on ethics into five core categories: awareness, perception, need, challenge, and approach. These categories are supported by a rich tapestry of codes and concepts, which we illustrate with evidence from the included studies. Our resulting taxonomy of AI ethics from a practitioner's vantage point provides a panoramic view of the critical aspects that AI developers grapple with when navigating ethical considerations. Additionally, we outline a roadmap for future research and offer actionable recommendations for practitioners, managers, and organisations seeking to better incorporate ethics into AI development.","The ethical considerations surrounding Artificial Intelligence (AI) software development are a subject of extensive discussion and scrutiny. Recent events have heightened public awareness of these issues, sparking anxieties about the pervasiveness of AI in daily life. To understand the perspectives of those building these systems, a grounded theory literature review analyzed 38 empirical studies capturing AI practitioners' views on ethical matters. This analysis yielded five key categories: practitioner awareness, perception, needs, challenges, and approaches, each supported by various codes and concepts illustrated with study findings. A taxonomy, built from these practitioner viewpoints, is presented to aid developers in recognizing and comprehending the diverse facets of AI ethics. This taxonomy provides a comprehensive overview of the crucial ethical aspects concerning AI practitioners. The paper also outlines a future research agenda and offers recommendations for practitioners, managers, and organizations to enhance the consideration and implementation of ethical practices in AI.",acceptable,acceptable,acceptable,3.2,3.2,3.2
128,AI ethics: from principles to practice,"Much of the current work on AI ethics has lost its connection to the real-world impact by making AI ethics operable. There exist significant limitations of hyper-focusing on the identification of abstract ethical principles, lacking effective collaboration among stakeholders, and lacking the communication of ethical principles to real-world applications. This position paper presents challenges in making AI ethics operable and highlights key obstacles to AI ethics impact. A preliminary practice example is provided to initiate practical implementations of AI ethics. We aim to inspire discussions on making AI ethics operable and focus on its impact on real-world applications.",A significant portion of contemporary research in AI ethics has become disconnected from tangible impacts by attempting to operationalize ethical standards. There are notable drawbacks in excessively focusing on abstract ethical concepts without fostering effective collaboration among stakeholders or effectively translating these principles into practical applications. This position paper outlines the challenges in operationalizing AI ethics and emphasizes major barriers to its real-world influence. An initial practical example is included to kick-start the implementation of AI ethics in practice. Our goal is to spark discussions on making AI ethics actionable and emphasizing its relevance to real-world scenarios.,"""A significant disconnect has emerged between the theoretical pursuits of AI ethics and their tangible consequences, largely due to an overemphasis on codifying abstract moral guidelines. This narrow approach neglects the crucial need for interdisciplinary cooperation and the translation of ethical frameworks into practical, real-world solutions. This paper identifies the hurdles hindering the effective integration of AI ethics and underscores the barriers to achieving meaningful, real-world outcomes. A pilot case study is offered to catalyze the development of actionable AI ethics strategies, with the ultimate goal of sparking a discourse on rendering AI ethics operational and impactful in everyday applications.""","The quest for operationalizing AI ethics has inadvertently distanced the field from its real-world implications. An excessive emphasis on abstract principles, coupled with insufficient collaboration among involved parties and inadequate translation of these principles into tangible applications, represents a substantial impediment. This paper delineates the hurdles encountered in bridging the gap between AI ethics theory and practice, underscoring the key barriers to its effective implementation. A preliminary practical illustration is offered to catalyze the tangible realization of AI ethics principles. Ultimately, this work seeks to stimulate discourse surrounding the operationalization of AI ethics and its tangible impact on real-world scenarios.",acceptable,acceptable,acceptable,4.0,3.2,3.2
129,Mitochondrial gene editing,"Mutations in mitochondrial DNA (mtDNA) are responsible for several severe diseases that have no available cures. The multicopy nature of the mitochondrial genome means that mutations often exist in a state known as heteroplasmy, where both mutant and wild-type mtDNA are present in the same cell. The wild-type mtDNA can functionally compensate for the mutant mtDNA until a mutation threshold is reached, beyond which disease symptoms begin to manifest. Despite the interest mitochondrial genetics has generated, the double mitochondrial membrane proved to be a formidable barrier to genetic manipulation. However, in the past two decades, scientists have discovered that mtDNA could be modified by importing gene editing proteins to target specific DNA sequences. Mitochondria-targeted nucleases specifically cleave and eliminate mutant mtDNA in heteroplasmic cells and in animal models. More recently, base editors have been adapted to modify mtDNA via precise C>T or A>G transitions. Therefore, tools to modify mtDNA are, finally, a reality with the promise to revolutionize the mitochondrial genetics field. This Primer delves into mitochondrial gene editing, providing details on the selection of mitochondrial gene editing tools, best practices for designing experiments, relevant types of analyses and specific applications and limitations pertaining to the different technologies and the field.","Mutations in mitochondrial DNA (mtDNA) cause numerous severe diseases for which there are currently no cures. Due to the mitochondrial genome's multicopy characteristic, these mutations typically occur in a condition termed heteroplasmy, where both mutant and normal mtDNA coexist within a single cell. Normal mtDNA can offset the function of mutant mtDNA until a certain mutation threshold is surpassed, leading to the onset of disease symptoms. Although mitochondrial genetics has captivated significant interest, the dual mitochondrial membrane posed a significant challenge to genetic modification. Nevertheless, over the past twenty years, researchers have identified methods to alter mtDNA by importing gene-editing proteins that target particular DNA sequences. Mitochondria-targeted nucleases can specifically cut and remove mutant mtDNA in cells with heteroplasmy and in animal models. More recently, base editors have been adapted to make exact C>T or A>G changes in mtDNA. Consequently, tools for mtDNA modification have become a reality, holding significant potential to transform the field of mitochondrial genetics. This Primer explores mitochondrial gene editing, detailing the selection of gene-editing tools for mitochondria, optimal practices for planning experiments, types of analyses to conduct, and specific uses and limitations of the various technologies in the field.","""Alterations to the mitochondrial DNA (mtDNA) genome are the root cause of numerous debilitating diseases that currently lack effective treatments. The presence of multiple copies of the mitochondrial genome leads to a phenomenon known as heteroplasmy, where cells harbor both normal and mutated mtDNA. While normal mtDNA can functionally counterbalance the effects of mutated mtDNA until a critical threshold is exceeded, beyond which disease symptoms emerge. Despite the significant attention devoted to mitochondrial genetics, the double membrane surrounding mitochondria has long posed a significant obstacle to genetic modification. However, breakthroughs in the past twenty years have enabled the manipulation of mtDNA through the introduction of gene editing proteins that target specific DNA sequences. Mitochondria-targeted nucleases have been shown to selectively eliminate mutated mtDNA in cells and animal models exhibiting heteroplasmy. Furthermore, base editors have been adapted to induce precise C>T or A>G transitions in mtDNA. As a result, the long-awaited tools for modifying mtDNA have finally become a reality, holding immense promise for transforming the field of mitochondrial genetics. This Primer provides an in-depth exploration of mitochondrial gene editing, covering the selection of optimal gene editing tools, experimental design best practices, relevant analytical approaches, and the applications, limitations, and challenges associated with these technologies and the field as a whole.""","Alterations in the genetic material of mitochondria are linked to numerous serious illnesses for which there are currently no effective treatments. The presence of multiple copies of the mitochondrial genome often results in a situation called heteroplasmy, where both normal and altered mitochondrial DNA coexist within a single cell. The normal DNA can compensate for the dysfunctional DNA until a certain level of mutation is reached, at which point disease symptoms emerge. Despite significant scientific interest in mitochondrial genetics, the double membrane surrounding mitochondria posed a substantial obstacle to genetic modification. Nevertheless, in recent decades, researchers have found ways to alter mitochondrial DNA by delivering gene editing proteins that target specific DNA sequences. Specifically, mitochondria-targeted enzymes can cut and remove mutated mitochondrial DNA in cells containing both normal and mutated DNA, as well as in animal models. More recently, base editors have been modified to precisely change specific DNA bases within mitochondria. As a result, tools for modifying mitochondrial DNA are now available, holding the potential to transform the field of mitochondrial genetics. This comprehensive overview explores mitochondrial gene editing, providing information on choosing appropriate tools, best practices for experimental design, relevant analysis methods, and the specific applications and limitations associated with various technologies in this field.",acceptable,acceptable,acceptable,3.2,3.2,3.2
130,Gene Editing for the Treatment of Hypercholesterolemia,"Purpose of ReviewHere, we summarize the key findings from preclinical studies that tested the concept that editing of hepatic genes can lower plasma low-density lipoprotein (LDL)-cholesterol levels to subsequently reduce atherosclerotic cardiovascular disease risk.Recent FindingsSelective delivery of clustered regularly interspaced short palindromic repeats (CRISPR)/CRISPR-associated protein 9 (Cas9)-mediated gene editing tools targeting proprotein convertase subtilisin/kexin type 9 (PCSK9) to hepatocytes, i.e., through encapsulation into N-acetylgalactosamine-coupled lipid nanoparticles, is able to induce a stable ~ 90% decrease in plasma PCSK9 levels and a concomitant 60% reduction in LDL-cholesterol levels in mice and non-humane primates. Studies in mice have shown that this state-of-the-art technology can be extended to include additional targets related to dyslipidemia such as angiopoietin-like 3 and several apolipoproteins.SummaryThe use of gene editors holds great promise to lower plasma LDL-cholesterol levels also in the human setting. However, gene editing safety has to be guaranteed before this approach can become a clinical success.","Review Objective: This review encapsulates essential discoveries from preclinical research that examined the hypothesis that modifying liver genes can decrease plasma low-density lipoprotein (LDL) cholesterol levels, thereby reducing the risk of atherosclerotic cardiovascular disease. Recent Discoveries: Targeted delivery of CRISPR/Cas9 gene editing tools to liver cells, specifically via encapsulation in N-acetylgalactosamine-conjugated lipid nanoparticles, has demonstrated the ability to achieve an approximately 90% reduction in plasma PCSK9 levels and a corresponding 60% decline in LDL cholesterol levels in both mice and non-human primates. Research in mice suggests this cutting-edge technology can be further applied to other dyslipidemia-related targets such as angiopoietin-like 3 and various apolipoproteins. Conclusion: Gene editing technology holds significant potential for decreasing plasma LDL cholesterol levels in humans. Nonetheless, ensuring the safety of gene editing is crucial before it can be considered a clinical success.","This review aims to distill the essential discoveries from preclinical investigations that explored the notion that modifying hepatic gene expression can lead to a decrease in plasma low-density lipoprotein (LDL) cholesterol concentrations, thereby mitigating the risk of atherosclerotic cardiovascular disease. Notably, recent research has demonstrated that targeted delivery of CRISPR/Cas9-mediated gene editing tools to hepatocytes, achieved through encapsulation in N-acetylgalactosamine-coupled lipid nanoparticles, can induce a sustained 90% reduction in plasma proprotein convertase subtilisin/kexin type 9 (PCSK9) levels, accompanied by a 60% decrease in LDL-cholesterol levels in both murine and non-human primate models. Furthermore, studies in mice have shown that this cutting-edge technology can be expanded to encompass additional targets implicated in dyslipidemia, including angiopoietin-like 3 and various apolipoproteins. In summary, the application of gene editing technologies holds significant potential for reducing plasma LDL-cholesterol levels in humans, although ensuring the safety of gene editing is a crucial prerequisite for its clinical success.","This review examines preclinical studies exploring hepatic gene editing as a means to reduce plasma low-density lipoprotein (LDL)-cholesterol and, consequently, the risk of atherosclerotic cardiovascular disease. Research demonstrates that precisely targeting hepatocytes with CRISPR/Cas9 gene editing tools, particularly those encapsulated in N-acetylgalactosamine-coupled lipid nanoparticles and aimed at proprotein convertase subtilisin/kexin type 9 (PCSK9), can achieve a sustained 90% reduction in plasma PCSK9 levels and a corresponding 60% decrease in LDL-cholesterol in both mice and non-human primates. Furthermore, studies in mice suggest this advanced technology could be expanded to include other targets implicated in dyslipidemia, such as angiopoietin-like 3 and various apolipoproteins. While gene editing shows considerable potential for lowering LDL-cholesterol in humans, ensuring its safety is paramount before clinical implementation can be considered.",acceptable,acceptable,acceptable,,3.6,3.2
131,Multiplexed gene editing in citrus by using a multi-intron containing Cas9 gene,"Several expression systems have been developed in clustered regularly interspaced short palindromic repeats (CRISPR)-associated protein 9 (CRISPR/Cas9) framework allowing for gene editing of disease-associated genes across diverse citrus varieties. In this study, we present a new approach employing a multi-intron containing Cas9 gene plus multiple gRNAs separated with tRNA sequences to target the phytoene desaturase gene in both ‘Carrizo’ citrange and ‘Duncan’ grapefruit. Notably, using this unified vector significantly boosted editing efficiency in both citrus varieties, showcasing mutations in all three designated targets. The implementation of this multiplex gene editing system with a multi-intron-containing Cas9 plus a gRNA-tRNA array demonstrates a promising avenue for efficient citrus genome editing, equipping us with potent tools in the ongoing battle against several diseases such as canker and huanglongbing.","Various expression platforms have been devised within the CRISPR/Cas9 framework to enable gene modification of disease-related genes in different citrus species. This research introduces a novel method utilizing a Cas9 gene with multiple introns along with several gRNAs separated by tRNA sequences to target the phytoene desaturase gene in both ‘Carrizo’ citrange and ‘Duncan’ grapefruit. Remarkably, this comprehensive vector substantially enhanced editing efficiency in both citrus species, resulting in mutations at all three intended sites. Adopting this multi-intron Cas9 and gRNA-tRNA array-based multiplex gene editing system signifies a promising strategy for effective citrus genome editing, providing valuable tools in the fight against diseases like canker and huanglongbing.","""A range of gene editing platforms have been engineered within the CRISPR/Cas9 framework, enabling the modification of disease-linked genes across a broad spectrum of citrus cultivars. This investigation introduces a novel strategy that leverages a Cas9 gene harboring multiple introns, accompanied by multiple guide RNAs interspersed with tRNA sequences, to target the phytoene desaturase gene in both 'Carrizo' citrange and 'Duncan' grapefruit. Remarkably, the utilization of this consolidated vector resulted in a substantial enhancement of editing efficacy in both citrus varieties, yielding mutations in all three designated targets. The deployment of this multiplex gene editing system, featuring a multi-intron-containing Cas9 and a gRNA-tRNA array, presents a promising route for efficient citrus genome modification, furnishing us with powerful tools in the ongoing struggle against diseases such as canker and huanglongbing.""","Utilizing the CRISPR/Cas9 system, researchers have devised numerous gene editing techniques for manipulating disease-related genes in various citrus cultivars. This research introduces a novel methodology that employs a Cas9 gene with multiple introns and several gRNAs interspersed with tRNA sequences to target the phytoene desaturase gene in ‘Carrizo’ citrange and ‘Duncan’ grapefruit. Remarkably, this integrated vector significantly enhanced editing efficacy in both citrus varieties, resulting in mutations in all three targeted sites. This multiplex gene editing system, featuring a multi-intron Cas9 gene and a gRNA-tRNA array, presents a promising strategy for effective citrus genome modification, providing powerful tools to combat diseases like canker and huanglongbing.",acceptable,acceptable,acceptable,3.6,3.2,3.2
132,Gene editing and therapy in acquired and inherited cardiovascular disorders,"Gene editing and therapy holds immense promise in addressing cardiovascular disorders by enabling precise modifications to the genetic groundworks of these conditions. This technology offers a targeted approach to correct or mitigate not only the genetic mutations that are responsible for inherited cardiovascular diseases, such as hypertrophic cardiomyopathy or familial hypercholesterolemia (FH), but also in controlling and regulating the genes in conditions that are age-related or that arise due to unnecessary gene activity, which often lack effective treatments. By editing the relevant genes, we aim to reduce disease severity, improve heart function, prevent future episodes and potentially improve the health span. Recent trials involving gene therapy and gene editing in cardiovascular disorders have revolutionized treatment strategies, offering hope for patients with genetic predispositions to heart and vessel-related ailments and advancing the pursuit for more personalized and effective therapies. In this review, we have consolidated the genetic mutations causing cardiovascular diseases (CVDs) followed by latest advancements in the gene editing technologies and their therapeutic implications along with involved ethical challenges and risk factors.Graphical Abstract","Gene editing and therapy present significant potential for addressing cardiovascular diseases by facilitating precise alterations to the genetic basis of these conditions. This technology provides a focused method for correcting or alleviating genetic mutations that lead to inherited cardiovascular disorders like hypertrophic cardiomyopathy or familial hypercholesterolemia (FH), as well as for managing genes involved in age-related conditions or those triggered by excessive gene activity, which frequently lack effective treatments. By modifying the pertinent genes, the goal is to lessen disease severity, enhance heart function, prevent future episodes, and potentially extend the health span. Recent gene therapy and editing trials in cardiovascular diseases have transformed treatment approaches, instilling hope for patients with genetic susceptibilities to heart and vascular issues and advancing the quest for more personalized and effective therapies. This review compiles the genetic mutations underlying cardiovascular diseases (CVDs), the latest progress in gene editing technologies and their therapeutic applications, along with associated ethical considerations and risk factors.","""Precision modification of the genetic underpinnings of cardiovascular diseases through gene editing and therapy offers unprecedented potential for tackling these debilitating conditions. By harnessing this technology, researchers can develop bespoke treatments that rectify inherited mutations responsible for disorders like hypertrophic cardiomyopathy and familial hypercholesterolemia, as well as modulate gene expression in age-related and aberrant gene activity-driven conditions that currently lack effective interventions. Through targeted gene editing, the goal is to alleviate disease severity, enhance cardiac function, prevent recurrent episodes, and potentially extend healthy lifespan. Recent breakthroughs in gene therapy and editing for cardiovascular disorders have transformed treatment paradigms, offering new hope for individuals with genetic propensities to heart and vascular diseases and driving the quest for more tailored and efficacious therapies. This review provides a comprehensive overview of the genetic mutations underlying cardiovascular diseases, the latest advancements in gene editing technologies, and their therapeutic implications, as well as the attendant ethical concerns and risk factors.""","The burgeoning field of genetic engineering offers revolutionary potential for tackling cardiovascular diseases. By precisely manipulating the genetic basis of these conditions, we can target and correct inherited mutations, like those responsible for hypertrophic cardiomyopathy and familial hypercholesterolemia, as well as regulate gene expression in age-related or unnecessarily active genes often lacking effective treatments. This approach aims to alleviate disease severity, enhance cardiac function, preemptively address future occurrences, and potentially extend healthy lifespans. Recent clinical studies employing gene-based therapies have transformed treatment paradigms for cardiovascular disorders, offering new hope for individuals genetically predisposed to heart and blood vessel ailments and driving the development of more tailored and impactful treatments. This comprehensive analysis delves into the genetic anomalies underlying cardiovascular diseases, explores cutting-edge gene editing techniques and their therapeutic applications, and examines the ethical considerations and potential risks associated with these advancements.",acceptable,acceptable,acceptable,4.2,3.6,3.2
133,Simulation of dual-purpose chicken breeding programs implementing gene editing,"BackgroundIn spite of being controversial and raising ethical concerns, the application of gene editing is more likely to be accepted when it contributes to improving animal welfare. One of the animal welfare and ethical issues in chicken breeding is chick culling, the killing of the male layer chicks after hatching due to the poor fattening performance. Although establishing dual-purpose chicken lines could solve this problem, unfavorable genetic correlations between egg and meat production traits hindered their competitiveness. Although it is also controversial in ethical terms, gene editing may accelerate genetic progress in dual-purpose chicken and alleviate the ethical concerns from chick culling.ResultsThe simulation compared the utility improvement in dual-purpose use under two breeding schemes: one consisting in the improvement of the laying hens, and the second in the improvement of a synthetic line obtained from a layer broiler cross. In each breeding scheme, the breeding programs were simulated with and without gene editing. Polygenic breeding values and 500 simulated quantitative trait loci (QTL) with different levels of pleiotropy caused negative correlations between egg production, meat production, and overall health. The results of the simulation demonstrated that genetic gain could be accelerated by at most 81% for several generations if gene editing was used. The actual increase in genetic gain depended on the number of single nucleotide polymorphisms (SNPs) being edited per animal. The rate of genetic improvement became equal in scenarios with and without gene editing after 20 generations. This is because the remaining segregating QTL had small effects and their edition would have negative overall health effects from potential off-target edits. Although gene editing can improve genetic gain in quantitative traits, it can only be recommended as long as QTL with reasonable effect sizes are segregating and detectable.ConclusionsThis simulation demonstrates the potential of gene editing to accelerate the simultaneous improvement of negatively correlated traits. When the risk of negative consequences from gene editing persists, the number of SNPs to be edited should be chosen carefully to obtain the optimal genetic gain.","Despite ongoing ethical debates, gene editing's use may garner acceptance when it improves animal welfare. A significant ethical issue in chicken breeding is chick culling, wherein male layer chicks are culled post-hatching due to low fattening efficiency. Dual-purpose chicken lines could address this issue, but unfavorable genetic correlations between egg and meat production have limited their effectiveness. Although ethically contentious, gene editing has the potential to enhance genetic progress in dual-purpose chickens and mitigate ethical issues related to chick culling. The simulation examined utility improvements in dual-purpose chickens under two breeding strategies: enhancing laying hens and developing a synthetic line from a layer-broiler hybrid. Each strategy was simulated with and without gene editing. Polygenic breeding values and 500 simulated quantitative trait loci (QTL) with varying pleiotropic effects created negative correlations between egg production, meat production, and overall health. Results indicated that gene editing could boost genetic gains by up to 81% over several generations, contingent on the number of single nucleotide polymorphisms (SNPs) edited per animal. After 20 generations, the rate of genetic improvement in scenarios with and without gene editing equalized, as remaining segregating QTL had minor impacts, and editing them could negatively affect overall health due to potential off-target edits. While gene editing can enhance genetic gains in quantitative traits, it should be employed with caution, ensuring QTL with significant effect sizes are segregating and detectable. In conclusion, the simulation highlights gene editing's potential to accelerate the improvement of negatively correlated traits. To minimize risks associated with gene editing, careful selection of the number of SNPs to be edited is crucial for achieving optimal genetic gain.","Despite the controversy and ethical dilemmas surrounding gene editing, its application is more palatable when it enhances animal welfare. A pressing concern in chicken breeding is the culling of male layer chicks due to their poor meat production capabilities, which could be addressed by developing dual-purpose chicken lines. However, unfavorable genetic correlations between egg and meat production traits hinder their viability. Gene editing, although ethically contentious, may expedite genetic progress in dual-purpose chickens and mitigate the ethical concerns associated with chick culling. A simulation was conducted to compare the utility improvement in dual-purpose use under two breeding schemes: enhancing laying hens and developing a synthetic line from a layer-broiler cross. The results showed that genetic gain could be accelerated by up to 81% over several generations with gene editing, depending on the number of edited single nucleotide polymorphisms (SNPs) per animal. However, the rate of genetic improvement equalized in scenarios with and without gene editing after 20 generations, as the remaining segregating QTL had minimal effects and their editing could have detrimental overall health consequences. Gene editing can improve genetic gain in quantitative traits, but its recommendation is contingent upon the presence of segregating QTL with significant effect sizes.","Despite ethical debates surrounding its use, gene editing is seen as more acceptable when it enhances animal welfare. One such welfare issue in poultry farming is the culling of male chicks due to their poor meat yield. While dual-purpose breeds could address this, the inherent trade-off between egg and meat production traits limits their effectiveness. Gene editing, though ethically contentious, could expedite the development of competitive dual-purpose chickens, mitigating the ethical concerns associated with culling. A simulated study evaluated the potential benefits of gene editing in dual-purpose chicken breeding, comparing two approaches: enhancing existing laying hens and creating a synthetic line from a broiler-layer cross. Each approach was simulated with and without gene editing. The simulations incorporated polygenic breeding values and 500 quantitative trait loci (QTL) with varying degrees of pleiotropy, resulting in negative correlations between egg production, meat production, and overall health. The results showed that gene editing could accelerate genetic gain by up to 81% for several generations, depending on the number of single nucleotide polymorphisms (SNPs) edited per animal. However, after 20 generations, the rate of genetic improvement became comparable in scenarios with and without gene editing. This convergence occurred because the remaining QTL had small effects, and editing them could negatively impact overall health due to potential off-target edits. This study highlights the potential of gene editing to simultaneously improve negatively correlated traits. However, given the inherent risks associated with gene editing, the number of SNPs targeted for editing should be carefully considered to maximize genetic gain while minimizing potential adverse effects.",acceptable,acceptable,acceptable,3.2,3.2,3.2
134,Gene editing tool kit in millets: present status and future directions,"Millets, the sixth most-grown group of crops in the drylands, support the livelihood of many small-holder farmers in the region. Being one of the most nutritious groups of crops, their production has been increasing since the last decade to meet the demands of the world’s ever-increasing population. Since its discovery, CRISPR/Cas-mediated gene editing technology has revolutionized trait improvement in numerous crops by enabling targeted insertions and deletions at specific gene sequences. With advancements like base editing and prime editing, which offer precise modifications at the nucleotide level, this technology holds great promise for enhancing millets by targeting genes responsible for key traits. The updated sequence information in the public domain makes it possible to modify certain genic regions using the CRISPR/Cas-mediated gene editing technology to develop millet crops with improved agronomical properties. The review explores each component of the editing toolbox in millets, including the gRNA designing tools, types of Cas nucleases, and promoters to be considered for enhanced and efficient gene editing in millets. We have discussed fundamental information available to successfully employ CRISPR/Cas-mediated gene editing in millets, such as the availability of genomic information and plant transformation methods. Finally, we have highlighted the limitations of employing this novel technology in millet crops by providing future directions and immediate candidate genes that could be targeted to improve various traits in millet crops.Graphical abstract","Millets, the sixth largest group of crops cultivated in arid regions, are crucial for the livelihood of numerous small-scale farmers in these areas. Known for their high nutritional value, millet cultivation has surged over the past decade to address the needs of the world's rapidly growing population. The advent of CRISPR/Cas gene editing has transformed the enhancement of traits in multiple crops by allowing precise insertions and deletions at specific gene sequences. With advanced techniques such as base editing and prime editing that enable exact nucleotide modifications, this technology shows significant promise in improving millets by targeting genes linked to important characteristics. The updated sequence data available publicly facilitates the modification of specific gene regions using CRISPR/Cas technology to develop millet varieties with superior agronomic traits. The review delves into each aspect of the gene editing toolkit for millets, including gRNA design tools, various types of Cas nucleases, and the promoters required for more effective and efficient gene editing. Fundamental information essential for the successful application of CRISPR/Cas gene editing in millets is discussed, such as genomic data availability and plant transformation techniques. Additionally, the review highlights the challenges of implementing this innovative technology in millets and outlines future directions and potential gene targets for enhancing various millet traits.","In arid regions, the sixth most widely cultivated crop category, millets, serves as a vital source of income for numerous small-scale farmers. As one of the most nutrient-dense crop groups, their cultivation has experienced a surge in recent years to cater to the escalating global population. The groundbreaking CRISPR/Cas-mediated gene editing technology has transformed crop trait enhancement by facilitating precise insertions and deletions at specific genetic loci. With the emergence of base editing and prime editing, which enable exact modifications at the nucleotide level, this technology holds immense potential for upgrading millets by targeting genes responsible for critical characteristics. The publicly available updated genomic sequence data enables the modification of specific genic regions using CRISPR/Cas-mediated gene editing to develop millet varieties with enhanced agronomic features. This review delves into each component of the gene editing toolkit in millets, encompassing gRNA design tools, types of Cas nucleases, and promoters for optimized gene editing. We have outlined the fundamental knowledge required to successfully implement CRISPR/Cas-mediated gene editing in millets, including genomic data availability and plant transformation methods. Lastly, we have underscored the limitations of employing this innovative technology in millet crops, providing future research directions and immediate candidate genes that could be targeted to enhance various traits in millet crops.","As a significant food source in arid regions, millets are cultivated extensively, sustaining a large population of small-scale farmers. Recognized for their nutritional value, millet production has seen a surge in recent years to cater to the demands of a growing global population. The advent of CRISPR/Cas gene editing has fundamentally altered crop improvement strategies, allowing for precise genetic modifications. Further innovations like base and prime editing, enabling nucleotide-level changes, hold immense potential for enhancing desirable characteristics in millets by manipulating genes associated with key traits. Utilizing publicly available genomic data, researchers can now leverage CRISPR/Cas technology to modify specific genetic regions, ultimately cultivating millets with superior agricultural attributes. This comprehensive review delves into the various aspects of the CRISPR/Cas editing toolkit for millets, examining guide RNA design tools, Cas nucleases, and promoters for optimized gene editing. Additionally, it provides essential information for the effective implementation of CRISPR/Cas in millets, including available genomic resources and plant transformation techniques. Finally, the review addresses the challenges associated with applying this cutting-edge technology to millet crops, suggesting future research directions and pinpointing promising candidate genes for enhancing various millet traits.",acceptable,acceptable,acceptable,3.2,3.2,3.2
135,TALE-based organellar genome editing and gene expression in plants,"Key messageTALE-based editors provide an alternative way to engineer the organellar genomes in plants. We update and discuss the most recent developments of TALE-based organellar genome editing in plants.AbstractGene editing tools have been widely used to modify the nuclear genomes of plants for various basic research and biotechnological applications. The clustered regularly interspaced short palindromic repeats (CRISPR)/Cas9 editing platform is the most commonly used technique because of its ease of use, fast speed, and low cost; however, it encounters difficulty when being delivered to plant organelles for gene editing. In contrast, protein-based editing technologies, such as transcription activator-like effector (TALE)-based tools, could be easily delivered, expressed, and targeted to organelles in plants via Agrobacteria-mediated nuclear transformation. Therefore, TALE-based editors provide an alternative way to engineer the organellar genomes in plants since the conventional chloroplast transformation method encounters technical challenges and is limited to certain species, and the direct transformation of mitochondria in higher plants is not yet possible. In this review, we update and discuss the most recent developments of TALE-based organellar genome editing in plants.","Primary insight: TALE-based editors offer a novel approach to modify plant organellar genomes. We review and examine the latest advancements in TALE-based genome editing for plant organelles. Overview: Gene editing technologies have been extensively utilized to alter plant nuclear genomes for fundamental research and various biotechnological purposes. Among these, CRISPR/Cas9 stands out for its simplicity, rapidity, and cost-effectiveness. However, its application faces challenges in delivering gene-editing tools to plant organelles. Alternatively, protein-centric editing mechanisms, such as those based on transcription activator-like effectors (TALEs), are more readily deliverable, expressible, and targetable to organelles within plants through Agrobacterium-mediated nuclear transformation. Consequently, TALE-based editors represent a viable option for engineering plant organellar genomes, especially since traditional chloroplast transformation methods confront technical obstacles and are restricted to specific species, and direct mitochondrial transformation in higher plants remains unachievable. This review highlights and deliberates the cutting-edge progress in TALE-based editing of plant organellar genomes.","Here is a paraphrased version of the text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""Novel approach: TALE-based editing tools offer a viable alternative for modifying plant organellar genomes, circumventing the limitations of traditional methods. This review provides an update on the latest advancements in TALE-based organellar genome editing in plants. Genome modification techniques have revolutionized plant research and biotechnology, with the CRISPR/Cas9 system being the most popular due to its efficiency, speed, and affordability. However, its application in plant organelles is hindered by delivery challenges. In contrast, protein-based technologies, such as TALE-based systems, can be easily introduced, expressed, and targeted to plant organelles via Agrobacterium-mediated nuclear transformation. Consequently, TALE-based editors provide a promising solution for engineering plant organellar genomes, overcoming the technical hurdles and species limitations associated with conventional chloroplast transformation and the currently impossible direct transformation of mitochondria in higher plants.""","Plant organellar genomes can be modified using TALE-based editors, offering a new approach to genetic engineering. While CRISPR/Cas9 is widely employed for nuclear genome editing due to its user-friendliness, speed, and affordability, its application to organellar editing is hampered by delivery challenges. Conversely, protein-based technologies like TALE readily reach plant organelles via Agrobacterium-mediated nuclear transformation, allowing for efficient expression and targeting. This makes TALE-based editors a viable alternative, particularly as traditional chloroplast transformation methods face technical limitations and species specificity, and direct mitochondrial transformation in higher plants remains unattainable. This review provides an updated analysis of the latest advancements in TALE-mediated organellar genome editing in plants.",acceptable,acceptable,acceptable,,3.6,3.6
136,Finely tuned ionizable lipid nanoparticles for CRISPR/Cas9 ribonucleoprotein delivery and gene editing,"Nonviral delivery of the CRISPR/Cas9 system provides great benefits for in vivo gene therapy due to the low risk of side effects. However, in vivo gene editing by delivering the Cas9 ribonucleoprotein (RNP) is challenging due to the poor delivery into target tissues and cells. Here, we introduce an effective delivery method for the CRISPR/Cas9 RNPs by finely tuning the formulation of ionizable lipid nanoparticles. The LNPs delivering CRISPR/Cas9 RNPs (CrLNPs) are demonstrated to induce gene editing with high efficiencies in various cancer cell lines in vitro. Furthermore, we show that CrLNPs can be delivered into tumor tissues with high efficiency, as well as induce significant gene editing in vivo. The current study presents an effective platform for nonviral delivery of the CRISPR/Cas9 system that can be applied as an in vivo gene editing therapeutic for treating various diseases such as cancer and genetic disorders.","The nonviral administration of the CRISPR/Cas9 system offers significant advantages for in vivo gene therapy, primarily because of the minimal risk of adverse effects. Nonetheless, delivering the Cas9 ribonucleoprotein (RNP) for in vivo gene editing presents difficulties due to inadequate targeting of tissues and cells. In this study, we present an efficient delivery technique for CRISPR/Cas9 RNPs by optimizing the formulation of ionizable lipid nanoparticles. The lipid nanoparticles carrying CRISPR/Cas9 RNPs (CrLNPs) are shown to achieve high gene editing efficiencies in various cancer cell lines in vitro. Moreover, we demonstrate that CrLNPs can be effectively delivered into tumor tissues, facilitating significant gene editing in vivo. This study offers a potent platform for the nonviral delivery of the CRISPR/Cas9 system that could be utilized for in vivo gene editing treatments for various ailments, including cancer and genetic disorders.","The utilization of nonviral vectors to deliver the CRISPR/Cas9 system offers a safer approach to in vivo gene therapy, minimizing the risk of adverse reactions. Nevertheless, the in vivo editing of genes via the delivery of Cas9 ribonucleoprotein complexes faces significant hurdles, primarily due to the inefficient targeting of specific tissues and cells. This study presents a novel, optimized formulation of ionizable lipid nanoparticles, which enables the effective delivery of CRISPR/Cas9 ribonucleoproteins. The resulting nanoparticles, termed CrLNPs, have been shown to facilitate high-efficiency gene editing in a range of cancer cell lines under in vitro conditions. Moreover, our findings demonstrate that CrLNPs can be successfully delivered to tumor tissues, resulting in substantial gene editing in vivo. This research provides a robust platform for the nonviral delivery of the CRISPR/Cas9 system, holding promise for the treatment of various diseases, including cancer and genetic disorders, through in vivo gene editing therapies.","Although the use of nonviral vectors for CRISPR/Cas9 delivery holds significant promise for in vivo gene therapy due to their favorable safety profile, efficient delivery of Cas9 ribonucleoproteins (RNPs) to target tissues and cells remains a major hurdle. This study presents a novel approach to overcome this challenge by optimizing the composition of ionizable lipid nanoparticles (LNPs) for RNP encapsulation. These CRISPR/Cas9 RNP-loaded LNPs (CrLNPs) exhibited remarkable gene editing efficacy in a variety of cancer cell lines in vitro. Moreover, CrLNPs demonstrated efficient tumor tissue penetration and significant in vivo gene editing activity. This work establishes a potent nonviral platform for CRISPR/Cas9 delivery, paving the way for its application as a therapeutic gene editing strategy for a spectrum of diseases, including cancer and genetic disorders.",acceptable,acceptable,acceptable,3.6,3.2,3.2
137,Application of genome editing techniques to regulate gene expression in crops,"BackgroundEnhanced agricultural production is urgently required to meet the food demands of the increasing global population. Abundant genetic diversity is expected to accelerate crop development. In particular, the development of the CRISPR/Cas genome editing technology has greatly enhanced our ability to improve crop’s genetic diversity through direct artificial gene modification. However, recent studies have shown that most crop improvement efforts using CRISPR/Cas techniques have mainly focused on the coding regions, and there is a relatively lack of studies on the regulatory regions of gene expression.ResultsThis review briefly summarizes the development of CRISPR/Cas system in the beginning. Subsequently, the importance of gene regulatory regions in plants is discussed. The review focuses on recent developments and applications of mutations in regulatory regions via CRISPR/Cas techniques in crop breeding.ConclusionFinally, an outline of perspectives for future crop breeding using genome editing technologies is provided. This review provides new research insights for crop improvement using genome editing techniques.","Background There is an urgent need to enhance agricultural output to address the food requirements of a growing global population. An extensive range of genetic diversity is anticipated to propel crop development forward. The emergence of CRISPR/Cas genome editing technology has significantly improved our capacity to augment genetic diversity in crops through direct artificial gene modification. Nevertheless, recent studies indicate that most crop improvement initiatives employing CRISPR/Cas techniques have concentrated predominantly on coding regions, with comparatively fewer investigations into the regulatory regions of gene expression. Results This review initially provides a brief overview of the evolution of the CRISPR/Cas system. It then delves into the significance of gene regulatory regions in plants. The review emphasizes recent advancements and the application of mutations in regulatory regions achieved through CRISPR/Cas techniques in crop breeding. Conclusion In conclusion, the review outlines future perspectives for crop breeding leveraging genome editing technologies. This compilation offers fresh research insights for enhancing crops using genome editing techniques.","""The pressing need to boost agricultural output to feed a burgeoning global population has sparked intense interest in harnessing genetic diversity to accelerate crop development. The advent of CRISPR/Cas genome editing has revolutionized our capacity to engineer crop genomes through precise gene modification. Notwithstanding, a closer examination of recent research reveals a disproportionate focus on coding regions, with a notable dearth of studies exploring the regulatory regions that govern gene expression. This review provides an overview of the CRISPR/Cas system, followed by a discussion on the pivotal role of gene regulatory regions in plant development. The primary focus lies in examining the latest breakthroughs and applications of CRISPR/Cas-mediated mutations in regulatory regions for crop improvement. Ultimately, the review offers a forward-looking perspective on the potential of genome editing technologies to shape the future of crop breeding, yielding valuable insights for researchers seeking to enhance crop yields.""","To address the escalating global food demand, amplifying agricultural yield is paramount. A rich genetic pool is key to expediting crop enhancement. CRISPR/Cas genome editing has revolutionized our capacity to modify genes directly, thereby boosting crop genetic diversity. However, current research leveraging CRISPR/Cas predominantly targets coding sequences, overlooking the crucial role of gene regulatory regions. This paper commences with a concise overview of CRISPR/Cas evolution. Subsequently, it underscores the significance of regulatory regions in plant genetics. The core emphasis lies on recent advancements and implementations of CRISPR/Cas-mediated mutations within these regions for crop improvement. Lastly, the review presents a roadmap for future crop breeding strategies employing genome editing tools, offering novel insights for harnessing these techniques to enhance crop production.",acceptable,acceptable,acceptable,3.6,3.2,3.2
138,Advances in miniature CRISPR-Cas proteins and their applications in gene editing,"The CRISPR-Cas system consists of Cas proteins and single-stranded RNAs that recruit Cas proteins and specifically target the nucleic acid. Some Cas proteins can accurately cleave the target nucleic acid under the guidance of the single-stranded RNAs. Due to its exceptionally high specificity, the CRISPR-Cas system is now widely used in various fields such as gene editing, transcription regulation, and molecular diagnosis. However, the huge size of the most frequently utilized Cas proteins (Cas9, Cas12a, and Cas13, which contain 950-1,400 amino acids) can limit their applicability, especially in eukaryotic gene editing, where larger Cas proteins are difficult to deliver into the target cells. Recently discovered miniature CRISPR-Cas proteins, consisting of only 400 to 800 amino acids, offer the possibility of overcoming this limitation. This article systematically reviews the latest research progress of several miniature CRISPR-Cas proteins (Cas12f, Cas12j, Cas12k, and Cas12m) and their practical applications in the field of gene editing.","The CRISPR-Cas mechanism comprises Cas enzymes and single-stranded RNAs that guide these enzymes to precisely target nucleic acids. Certain Cas enzymes can accurately cut the targeted nucleic acids under the direction of single-stranded RNAs. Owing to its remarkable precision, the CRISPR-Cas system has become widely employed in gene editing, transcriptional regulation, and molecular diagnostics. However, the large size of the commonly used Cas proteins (Cas9, Cas12a, and Cas13, which range from 950 to 1,400 amino acids) can restrict their utility, particularly in eukaryotic gene editing, where delivering larger Cas proteins into target cells is challenging. Recently identified smaller CRISPR-Cas proteins, containing only 400 to 800 amino acids, present a potential solution to this constraint. This article offers a comprehensive review of the latest advancements in research on several miniature CRISPR-Cas proteins (Cas12f, Cas12j, Cas12k, and Cas12m) and their practical applications in gene editing.","The CRISPR-Cas system is comprised of Cas enzymes and single-stranded RNA molecules that selectively bind to Cas enzymes and pinpoint specific nucleic acid sequences. Certain Cas enzymes can precisely excise targeted nucleic acid segments under the direction of these RNA molecules. Owing to its unparalleled precision, the CRISPR-Cas system has become a ubiquitous tool in diverse areas, including genetic modification, transcriptional control, and molecular diagnostics. However, the substantial size of commonly employed Cas enzymes (such as Cas9, Cas12a, and Cas13, which comprise 950-1,400 amino acid residues) can restrict their utility, particularly in eukaryotic gene editing, where the delivery of larger Cas enzymes into target cells poses significant challenges. The recent discovery of compact CRISPR-Cas enzymes, consisting of merely 400-800 amino acid residues, offers a potential solution to this limitation. This review provides a comprehensive overview of the latest advancements in several compact CRISPR-Cas enzymes (including Cas12f, Cas12j, Cas12k, and Cas12m) and their practical implications for gene editing applications.","Comprising Cas proteins and guiding single-stranded RNAs that direct the proteins to specific nucleic acid sequences, the CRISPR-Cas system enables precise cleavage of the targeted genetic material. This remarkable specificity has propelled its widespread adoption in diverse domains, including gene editing, transcriptional control, and molecular diagnostics. However, the substantial size of commonly employed Cas proteins like Cas9, Cas12a, and Cas13 (ranging from 950 to 1,400 amino acids) can hinder their application, particularly in eukaryotic gene editing, where introducing these large proteins into target cells proves challenging. Newly identified miniature CRISPR-Cas proteins, composed of a mere 400 to 800 amino acids, present a promising solution to this obstacle. This review provides a comprehensive overview of recent advances in the understanding and utilization of several miniature CRISPR-Cas proteins (Cas12f, Cas12j, Cas12k, and Cas12m), focusing on their potential for gene editing applications.",acceptable,acceptable,acceptable,3.6,3.2,3.2
139,Enabling regulatory policy globally will promote realization of the potential of animal biotechnology,"Animal biotechnologies have the potential to improve the sustainability and security of our global food systems. Government regulatory authorities are responsible for ensuring the safety of food their citizens consume, whether it is produced via conventional breeding methods or biotechnologies. While some countries have implemented animal biotechnology oversight policies, many countries have yet to develop theirs. Historically, regulatory approvals were required before products of biotechnology could enter the marketplace, and the high cost of the approval process limited the number and types of animal and plant products that sought approval. Only one biotech animal in the world that was developed for food production has reached the market under a GMO or rDNA approval process. The advent of genome editing techniques has revolutionized the scientific approach to introducing changes into DNA sequences and how biotechnology can be used to enhance agricultural breeding. Regulatory dialogs about biotechnology also have changed as a result of these new technologies. Regulatory agencies have begun to respond to these scientific advances, and a growing number of countries are looking to modernize regulatory approaches for these products, based on risk (or lack thereof) and similarity to organisms that could be produced via conventional breeding methods. Advances in animal biotechnology, especially genome editing, can accelerate the incorporation of valued phenotypes in animals, including enhanced yield, disease resistance, resilience to changing climate, and improved animal welfare, as well as food qualities valued by consumers. For animals with these biotechnology-introduced traits to enter agricultural production and reach consumers, clear risk-proportionate regulatory approaches must be in place, and to facilitate international trade of animal products, regulatory processes need to be aligned and compatible. Effective scientific public communication is crucial to build public trust in precision animal biotechnology and risk-proportionate regulatory approaches. An international workshop on regulatory approaches for animal biotechnology was convened in 2022 with 27 countries represented. We synthesize here technical progress, development of regulatory policy, and strategies for engagement with diverse publics on animal biotechnology reported in the workshop. Our goal is to encourage development and implementation of risk-proportionate regulatory approaches and policies in a global context.","Animal biotechnologies hold promise for enhancing the sustainability and security of global food systems. Government regulatory bodies must ensure the safety of food, regardless of whether it is generated through traditional breeding techniques or biotechnologies. Although some nations have initiated oversight policies for animal biotechnology, many others have not yet established such frameworks. Historically, regulatory approvals were mandated before biotechnological products could reach the market, and the expense of this process restricted the range and types of products seeking approval. To date, only one biotech animal designed for food production has been marketed under GMO or rDNA regulations. The advent of genome editing has dramatically transformed the scientific methodology for modifying DNA sequences and leveraging biotechnology to improve agricultural breeding. Consequently, regulatory discussions regarding biotechnology have evolved with these new advancements. Regulatory bodies are beginning to adapt to these scientific innovations, and an increasing number of countries aim to update their regulatory approaches based on risk assessment and the similarity to organisms produced through conventional breeding. Advances in animal biotechnology, especially in genome editing, can expedite the incorporation of valuable traits in animals, such as higher yields, disease resistance, climate resilience, improved animal welfare, and better food quality for consumers. For animals with these biotechnologically introduced characteristics to be integrated into agricultural production and reach consumers, clear, risk-based regulatory frameworks must be established, and international trade of animal products should be facilitated through aligned regulatory processes. Effective scientific communication with the public is essential to build trust in precision animal biotechnology and these regulatory frameworks. In 2022, an international workshop on regulatory approaches for animal biotechnology was held with representation from 27 countries. This synthesis presents the technical advancements, policy developments, and public engagement strategies on animal biotechnology discussed during the workshop, aiming to promote the development and implementation of risk-based regulatory approaches and policies globally.","The global food supply chain can be significantly enhanced through the application of animal biotechnologies, which hold great promise for bolstering sustainability and security. It is the duty of government regulatory bodies to guarantee the safety of food consumed by their citizens, regardless of whether it is produced using traditional breeding methods or cutting-edge biotechnologies. Although some nations have established guidelines for overseeing animal biotechnology, many others have yet to do so. Historically, regulatory clearance was required before biotechnology products could enter the market, but the exorbitant cost of this process limited the number and variety of animal and plant products seeking approval. To date, only one genetically engineered animal intended for human consumption has successfully navigated the approval process. The emergence of genome editing techniques has revolutionized the scientific approach to modifying DNA sequences, thereby transforming the potential of biotechnology in agricultural breeding. This shift has also prompted a reevaluation of regulatory discussions surrounding biotechnology. In response to these scientific breakthroughs, regulatory agencies are adapting their approaches, with an increasing number of countries seeking to modernize their regulatory frameworks based on risk assessment and similarity to conventionally bred organisms. Advances in animal biotechnology, particularly genome editing, can accelerate the integration of desirable traits in animals, such as improved yield, disease resistance, climate resilience, and enhanced animal welfare, as well as consumer-preferred food qualities. To facilitate the adoption of these biotechnology-enhanced animals in agricultural production and their entry into the consumer market, proportionate regulatory frameworks must be established, and international trade of animal products requires harmonized and compatible regulatory processes. Effective scientific communication with the public is essential for building trust in precision animal biotechnology and proportionate regulatory approaches. A 2022 international workshop on regulatory approaches to animal biotechnology, attended by 27 countries, provided a platform for discussing technical advancements, regulatory policy development, and strategies for engaging diverse publics on animal biotechnology. Our objective is to promote the development and implementation of proportionate regulatory approaches and policies globally.","The application of biotechnology in animal agriculture holds significant promise for enhancing the resilience and sustainability of global food production. Governments bear the responsibility of safeguarding the food consumed by their citizens, regardless of whether it originates from traditional breeding methods or biotechnological innovations. Although certain nations have established regulatory frameworks for animal biotechnology, many have yet to do so. Traditionally, products derived from biotechnology underwent a rigorous and expensive approval process before reaching the market, limiting the variety and quantity of such products. The emergence of genome editing techniques has fundamentally altered the scientific landscape of genetic modification, accelerating the potential of biotechnology to enhance agricultural breeding. This shift has also prompted a reevaluation of regulatory discussions surrounding biotechnology. Regulatory bodies are adapting to these scientific breakthroughs, with an increasing number of countries exploring modernized regulatory approaches that prioritize risk assessment and consider the similarity of biotech-derived organisms to those produced through conventional breeding. The advancements in animal biotechnology, particularly genome editing, offer expedited means of incorporating valuable traits into livestock, including enhanced productivity, disease resistance, resilience to climate change, improved animal welfare, and consumer-desired food qualities. To enable the integration of animals with such biotechnologically introduced traits into agricultural systems and subsequently reach consumers, transparent and risk-proportional regulatory frameworks are essential. Furthermore, harmonized and compatible regulatory processes are crucial to facilitate international trade of animal products. Open and effective communication between the scientific community and the public is paramount for fostering trust in precision animal biotechnology and risk-proportionate regulatory approaches. In 2022, an international workshop focusing on regulatory approaches for animal biotechnology, with representation from 27 countries, was conducted. This paper summarizes the technological advancements, regulatory policy developments, and public engagement strategies concerning animal biotechnology presented at the workshop. The ultimate objective is to advocate for the development and implementation of risk-proportionate regulatory approaches and policies within a global context.",acceptable,acceptable,acceptable,3.2,3.2,3.2
140,Can I benefit from laboratory automation? A decision aid for the successful introduction of laboratory automation,"The large volumes of samples to be analysed every day would be impossible to manage without laboratory automation. As laboratory procedures have progressed, so have the tasks of laboratory personnel. With this feature article, we would like to provide (bio)chemical practitioners with little or no knowledge of laboratory automation with a guide to help them decide whether to implement laboratory automation and find a suitable system. Especially in small- and medium-sized laboratories, operating a laboratory system means having bioanalytical knowledge, but also being familiar with the technical aspects. However, time, budget and personnel limitations allow little opportunity for personnel to get into the depths of laboratory automation. This includes not only the operation, but also the decision to purchase an automation system. Hasty investments do not only result in slow or non-existent cost recovery, but also occupy valuable laboratory space. We have structured the article as a decision tree, so readers can selectively read chapters that apply to their individual situation. This flexible approach allows each reader to create a personal reading flow tailored to their specific needs. We tried to address a variety of perspectives on the topic, including people who are either supportive or sceptical of laboratory automation, personnel who want or need to automate specific processes, those who are unsure whether to automate and those who are interested in automation but do not know which areas to prioritize. We also help to make a decision whether to reactivate or discard already existing and unused laboratory equipment.","Managing the high number of daily samples would be unfeasible without laboratory automation. As laboratory practices have advanced, the roles of lab staff have evolved accordingly. This article aims to offer (bio)chemical professionals with limited or no experience in laboratory automation a guide to help them decide on the implementation of automation and choose an appropriate system. In small to medium-sized labs, operating an automated system requires not just bioanalytical expertise, but also knowledge of technical aspects. However, constraints in time, budget, and staff leave little room for personnel to delve deeply into laboratory automation, including both operating and deciding to purchase an automation system. Rash investments can lead to slow or nonexistent returns on investment and take up valuable lab space. The article is organized as a decision tree, allowing readers to focus on chapters relevant to their situation. This adaptable method lets each reader customize their reading path based on their specific requirements. We aimed to cover diverse perspectives, targeting those who support or doubt laboratory automation, staff looking to automate specific tasks, those unsure about automation, and individuals intrigued by automation but uncertain about prioritizing areas. Additionally, we assist in deciding whether to reactivate or discard existing idle laboratory equipment.","The sheer quantity of daily samples necessitates the integration of automated laboratory systems, as manual management would be utterly unfeasible. As laboratory protocols have evolved, the responsibilities of laboratory staff have similarly expanded. This feature article aims to provide a comprehensive guide for (bio)chemical professionals with limited or no familiarity with laboratory automation, empowering them to make informed decisions about implementation and system selection. In smaller laboratories, where bioanalytical expertise is often coupled with technical proficiency, the constraints of time, budget, and personnel hinder the opportunity for in-depth exploration of laboratory automation, encompassing not only system operation but also procurement. Ill-conceived investments can lead to sluggish or non-existent returns, while occupying valuable laboratory real estate. To facilitate a personalized reading experience, we have organized the article as a decision tree, allowing readers to selectively engage with chapters relevant to their unique circumstances. By addressing diverse perspectives, including proponents and skeptics of laboratory automation, those seeking to automate specific processes, the undecided, and those uncertain about prioritization, we provide a tailored approach to inform decisions on whether to revive or retire underutilized laboratory equipment.","The sheer quantity of daily samples necessitates laboratory automation for efficient management. As laboratory techniques evolve, so do the roles of laboratory staff. This article aims to provide a roadmap for (bio)chemical practitioners with limited automation experience, guiding them through the implementation process and selection of appropriate systems. Particularly in smaller laboratories, operating automated systems demands both bioanalytical expertise and technical proficiency. However, time, budgetary, and personnel constraints often hinder in-depth exploration of automation, including operational aspects and purchasing decisions. Hasty investments can lead to delayed or absent returns on investment and consume valuable laboratory space. The article's decision-tree structure allows readers to selectively engage with relevant chapters, creating a personalized reading experience. Diverse viewpoints are addressed, encompassing automation proponents and skeptics, those seeking process automation, individuals unsure about implementation, and those interested in prioritizing automation areas. The article also provides guidance on deciding whether to revive or retire existing, unused laboratory equipment.",acceptable,acceptable,acceptable,3.6,3.2,3.2
141,Government size and automation,"This paper explores the consequences of automation for public finance. We find that as the automation rate increases, the government size, measured as the fiscal revenues to output ratio, declines. This is due to the substitution of traditional inputs, which bear the burden of taxes, by the new automatic technology. These results are explained by the effects of automation on labor, where taxation of labor income (including social security contributions) represents the most important source of fiscal revenues in most advanced economies. The paper conducts two additional counterfactual experiments. First, we calculate how individual tax rates should be changed in response to automation in order to maintain constant fiscal revenues from the different sources of taxes. This experiment reveals that this fiscal policy would have significantly detrimental effects on output and labor, and indicates that a comprehensive reform of the current tax mix is necessary to counterbalance the effects of automation on public finance. Second, we calculate the tax rate on capital, without modifying the other tax rates, required to keep constant the size of the government, resulting in a capital income tax rate of around 0.77 for an automation rate of \(45 \%\).","This study investigates the impact of automation on public finances. The findings indicate that as the automation rate rises, the government's size—defined by the ratio of fiscal revenues to output—diminishes. This trend results from the replacement of conventional, tax-bearing inputs with new automated technologies. The decline is primarily attributed to the effects of automation on labor, where labor income taxes (including social security contributions) constitute the main source of fiscal revenue in most developed countries. The research also conducts two further hypothetical scenarios. Firstly, it examines how individual tax rates would need to be adjusted in response to automation to maintain stable fiscal revenues from various tax sources. This scenario shows that such fiscal adjustments would have profoundly negative impacts on output and labor, suggesting that a thorough reform of the existing tax structure is essential to mitigate automation's effects on public finance. Secondly, the study calculates the capital tax rate necessary to preserve the government's size, assuming other tax rates remain unchanged, which results in a capital income tax rate of approximately 0.77 for an automation rate of 45%.","This study delves into the repercussions of automation on government finances, revealing that as automation intensifies, the ratio of fiscal revenues to output diminishes, primarily due to the replacement of traditional, tax-burdened inputs with novel automated technologies. The findings are attributed to automation's impact on labor, which is the primary source of fiscal revenues in advanced economies, largely comprising taxation of labor income and social security contributions. The paper presents two counterfactual scenarios: one examines the necessary adjustments to individual tax rates to maintain consistent fiscal revenues, highlighting the need for a comprehensive tax reform to mitigate automation's effects on public finance, and the other calculates the required capital income tax rate, approximately 0.77 at a 45% automation rate, to preserve the government's size without modifying other tax rates.","This study investigates the impact of automation on government finances. The findings suggest that as automation becomes more prevalent, the relative size of the government, as indicated by the ratio of fiscal revenue to economic output, shrinks. This trend arises from the replacement of conventional, taxable inputs with automated technologies. The authors attribute these results to the influence of automation on labor markets, given that taxes on labor income, encompassing social security contributions, constitute the primary source of government revenue in most developed economies. Two hypothetical scenarios are examined. In the first, the authors determine how individual tax rates would need to be adjusted in response to automation to maintain consistent fiscal revenue streams from various tax sources. This analysis reveals that such a fiscal policy would have significant negative consequences for both economic output and employment, emphasizing the need for a comprehensive overhaul of the existing tax structure to mitigate the effects of automation on government finances. In the second scenario, the authors calculate the capital tax rate necessary to preserve the size of the government without altering other tax rates. This calculation yields a capital income tax rate of approximately 0.77, assuming an automation rate of 45%.",acceptable,acceptable,acceptable,3.2,3.6,3.2
142,A conceptual framework for automation disengagements,"A better understanding of automation disengagements can lead to improved safety and efficiency of automated systems. This study investigates the factors contributing to automation disengagements initiated by human operators and the automation itself by analyzing semi-structured interviews with 103 users of Tesla’s Autopilot and FSD Beta. The factors leading to automation disengagements are represented by categories. In total, we identified five main categories, and thirty-five subcategories. The main categories include human operator states (5), human operator’s perception of the automation (17), human operator’s perception of other humans (3), the automation’s perception of the human operator (3), and the automation incapability in the environment (7). Human operators disengaged the automation when they anticipated failure, observed unnatural or unwanted automation behavior (e.g., erratic steering, running red lights), or believed the automation is not capable to operate safely in certain environments (e.g., inclement weather, non-standard roads). Negative experiences of human operators, such as frustration, unsafe feelings, and distrust represent some of the adverse human operate states leading to automation disengagements initiated by human operators. The automation, in turn, monitored human operators and disengaged itself if it detected insufficient vigilance or speed rule violations by human operators. Moreover, human operators can be influenced by the reactions of passengers and other road users, leading them to disengage the automation if they sensed discomfort, anger, or embarrassment due to the automation’s actions. The results of the analysis are synthesized into a conceptual framework for automation disengagements, borrowing ideas from the human factor's literature and control theory. This research offers insights into the factors contributing to automation disengagements, and highlights not only the concerns of human operators but also the social aspects of this phenomenon. The findings provide information on potential edge cases of automated vehicle technology, which may help to enhance the safety and efficiency of such systems.","A deeper comprehension of why automation ceases to function can enhance the safety and effectiveness of automated systems. This research explores the reasons behind automation being turned off by either human operators or the system itself by analyzing semi-structured interviews conducted with 103 Tesla Autopilot and FSD Beta users. The reasons for disengagement are categorized into five principal groups and thirty-five subgroups. These primary categories include the states of human operators (5), human operators' perceptions of the automation (17), their perceptions of other humans (3), how the automation perceives the human operator (3), and the automation's inability to function in certain environments (7). Human operators disengage automation when they predict system failure, notice strange or undesirable behavior (like erratic steering or ignoring traffic lights), or doubt the automation’s ability to function safely in certain situations (such as bad weather or unusual roads). Negative experiences of human operators, such as frustration, feelings of insecurity, and lack of trust, are significant factors leading to manual disengagements. Conversely, the automation itself monitors the operators and may disengage if it detects lapses in attention or speeding violations. Additionally, the reactions of passengers and other drivers can influence human operators to disconnect the automation if they sense discomfort, anger, or embarrassment due to the system's actions. The study integrates these findings into a conceptual model for understanding automation disengagements, drawing from human factors and control theory literature. This research sheds light on the various contributors to disengagements and underscores both the operators' concerns and the social dynamics involved, providing valuable insights into potential edge cases to improve the safety and efficiency of automated vehicle technology.","Enhancing the reliability and performance of autonomous systems hinges on gaining a deeper insight into the circumstances surrounding automation disconnections. This investigation delves into the root causes of human-initiated and automation-triggered disconnections by examining the responses of 103 Tesla Autopilot and FSD Beta users through semi-structured interviews. The analysis yields a categorization of the factors contributing to disconnections, comprising five primary categories and 35 subcategories. These categories encompass the psychological and emotional states of human operators (5), their trust and perception of the automation (17), their awareness of other road users (3), the automation's assessment of human operators (3), and its limitations in navigating diverse environments (7). Human operators tend to disconnect the automation when they foresee potential failures, observe aberrant behavior, or doubt its ability to operate safely in challenging conditions. Adverse emotional states, such as frustration and distrust, also prompt human operators to disconnect the automation. Conversely, the automation disengages itself when it detects human operator inattention or speeding violations. Furthermore, human operators are influenced by the reactions of passengers and other road users, leading to disconnections due to perceived discomfort or embarrassment. The study's findings are distilled into a conceptual framework for understanding automation disconnections, drawing on human factors and control theory principles. This research provides valuable insights into the multifaceted nature of automation disconnections, highlighting both human concerns and social implications, and offers guidance on potential edge cases to enhance the safety and efficiency of autonomous vehicle technology.","Enhanced comprehension of scenarios leading to automation deactivation can significantly bolster the safety and performance of automated technologies. This investigation delves into the reasons behind such deactivations, initiated by both human users and the automated system itself, by meticulously analyzing semi-structured interviews conducted with 103 individuals utilizing Tesla's Autopilot and FSD Beta systems. These reasons are systematically categorized, resulting in the identification of five primary categories and thirty-five subcategories. These overarching categories encompass the human operator's internal states (5 subcategories), their perception of the automation's behavior (17 subcategories), their understanding of other human reactions (3 subcategories), the automation's assessment of the human operator (3 subcategories), and limitations in the automation's capabilities within specific environments (7 subcategories). Human users deactivated the automation when they foresaw potential system errors, detected unusual or undesirable automation actions (e.g., erratic steering, disregarding traffic signals), or concluded that the automation lacked the capacity to function safely under certain conditions (e.g., adverse weather, unconventional road layouts). Negative user experiences, such as frustration, compromised safety perceptions, and a lack of trust, represent some of the detrimental human operator states prompting deactivations. Conversely, the automation continuously monitors user engagement and deactivates itself upon detecting inadequate user attention or violations of speed regulations. Furthermore, user behavior can be swayed by the responses of passengers and other road users, leading to deactivation if they perceive discomfort, anger, or embarrassment stemming from the automation's actions. This analysis culminates in a conceptual framework for understanding automation deactivations, integrating principles from human factors research and control theory. This study offers valuable insights into the factors contributing to automation deactivation, emphasizing not only the concerns of human users but also the social dynamics intertwined with this phenomenon. The findings provide critical information about potential edge cases within automated vehicle technology, which can contribute to enhancing both the safety and efficacy of such systems.",acceptable,acceptable,acceptable,3.6,3.6,3.6
143,Automation of Production Processes: Problems and Solutions,"AbstractAttention focuses on the automation of production processes at Russian enterprises within state programs for digitization, in an era of sanctions pressure. The current problems are analyzed. Software for the automation of production is investigated. A sequence of steps for the automation of production processes is proposed.","This abstract discusses the emphasis on automating production processes at Russian companies as part of national digitization initiatives amid sanctions. It examines existing challenges, reviews automation software, and outlines a step-by-step process for automating production workflows.","""Amidst the constraints of economic sanctions, AbstractAttention prioritizes the streamlining of manufacturing operations within Russian state-backed digital transformation initiatives, diagnosing existing challenges and scrutinizing specialized software solutions, ultimately outlining a phased approach to optimize production workflows.""","Under the constraints of international sanctions, this study examines the challenges and software solutions for automating production processes in Russian companies, within the framework of national digitalization initiatives. A phased approach to production automation implementation is presented.",acceptable,acceptable,acceptable,3.2,3.2,3.2
144,Does automation improve financial reporting? Evidence from internal controls,"Automation—such as machine learning, robotic process automation, and artificial intelligence—is the next major technological leap in accounting and financial reporting, and I empirically study whether public firms’ use of automation technology improves their financial reporting, specifically focusing on the internal control environment. I document two critical inferences. First, I find evidence which suggests that automation improves financial reporting quality. Specifically, firms’ use of automation in the financial reporting process is associated with a reduction in internal control material weaknesses. This association is consistent in a levels analysis with firm and year fixed effects, in a changes analysis, and in a propensity score matched difference-in-differences analysis. Second, I find evidence which suggests that monitoring of the financial reporting process decreases after automation, likely because of a perception that automation reduces the need for monitoring vis-à-vis stronger internal controls. Specifically, automation is associated with higher external audit fees and audit committee meetings in the initial years after a firm implements automation but associated with lower external audit fees and audit committee meetings in subsequent years. I also find evidence which suggests that this decreased monitoring may be costly: when internal control failures do happen for firms with automation, the failures are more material, as proxied by stronger negative market reactions. In aggregate, my evidence provides nuanced insights regarding whether automation technology improves financial reporting.","The advent of automation—including machine learning, robotic process automation, and artificial intelligence—represents the forthcoming significant technological advancement in accounting and financial reporting. My empirical investigation assesses whether the deployment of automation by public firms enhances the quality of their financial reporting, with a specific emphasis on the internal control environment. I derive two key conclusions. Firstly, evidence indicates that automation enhances financial reporting quality, as demonstrated by a reduction in internal control material weaknesses in firms utilizing automation. This relationship holds true across various analyses, including a levels analysis with firm and year fixed effects, a changes analysis, and a propensity score matched difference-in-differences analysis. Secondly, the findings suggest a decline in financial reporting process monitoring post-automation, likely due to the perception that automation fortifies internal controls, diminishing the need for monitoring. Initially, automation correlates with increased external audit fees and audit committee meetings, but these parameters decrease after the initial implementation period. Additionally, decreased monitoring might have associated costs: when firms with automated processes experience internal control failures, the failures tend to be more severe, as indicated by stronger negative market reactions. Overall, the evidence offers detailed insights into the impact of automation technology on financial reporting enhancements.","The integration of innovative technologies, including machine learning, robotic process automation, and artificial intelligence, is poised to revolutionize the accounting and financial reporting landscape, and this study empirically examines the impact of automation adoption on the financial reporting quality of publicly traded companies, with a particular emphasis on the internal control framework. The analysis yields two key findings. Firstly, the results indicate that the implementation of automation technology is linked to enhanced financial reporting quality, as evidenced by a decrease in material weaknesses in internal controls. This correlation is robust across various analytical approaches, including levels analysis with firm and year fixed effects, changes analysis, and propensity score matched difference-in-differences analysis. Secondly, the study reveals that the oversight of financial reporting processes tends to diminish following automation, likely due to the perception that automation mitigates the need for monitoring, given the strengthened internal controls. Specifically, automation is associated with increased external audit fees and audit committee meetings in the initial post-implementation period, but this trend reverses in subsequent years. Furthermore, the findings suggest that this reduced oversight may come at a cost, as internal control failures in automated firms are more severe, as reflected in stronger negative market responses. Overall, this research provides a nuanced understanding of the impact of automation technology on financial reporting quality.","Cutting-edge technologies like machine learning, robotic process automation, and artificial intelligence are poised to revolutionize accounting and financial reporting. My research explores the impact of these automation tools on public companies' financial reporting quality, specifically focusing on internal controls. My findings reveal two key insights. First, evidence suggests that automation enhances financial reporting quality, as evidenced by a decrease in material weaknesses in internal control among firms that leverage automation in their financial reporting processes. This relationship holds true across various analytical approaches, including fixed effects models, changes analysis, and propensity score matching difference-in-differences analysis. Second, the study reveals a decline in monitoring efforts following automation implementation, likely due to the perception that automated processes bolster internal controls and reduce the need for oversight. This is supported by the observation of initially higher external audit fees and audit committee meetings after automation adoption, followed by a subsequent reduction in these metrics. However, the research also suggests potential drawbacks of decreased monitoring, as internal control failures in companies using automation tend to be more severe, reflected in more pronounced negative market reactions. Collectively, this evidence offers a nuanced understanding of the implications of automation technology for financial reporting quality.",acceptable,acceptable,acceptable,3.6,3.2,3.6
145,Automation in business research: systematic literature review,"Automation has profoundly transformed the operational landscape of companies across various industries. As organizations strive to adapt to this rapidly evolving technology, it becomes crucial for practitioners worldwide to identify the most suitable automation tools and solutions for their unique business needs. A systematic literature review serves as a valuable tool to gain a deeper understanding of the historical context of automation and to explore previous findings in this field. This study aims to provide an extensive literary overview of the history of automation spanning the years from 1966 to 2021. In this research, a combination of bibliometric, conceptual, and theoretical network analysis methodologies are employed, with the aid of VOSviewer software, to analyze and visualize the patterns within the existing body of automation literature. By utilizing bibliometric analysis, this study will map the key scholarly contributions and identify the main research themes and concepts. The findings of this systematic literature review will provide insights into the historical progression of automation research and its interdisciplinary nature, highlighting the significant milestones, emerging trends, and knowledge gaps in the field. Building upon these findings, the study will propose a research agenda to advance the scholarly debate on automation.","Automation has significantly altered the business landscape across various sectors. As organizations endeavor to keep pace with this swiftly advancing technology, it is essential for industry professionals to determine the most appropriate automation tools and solutions tailored to their specific business demands. A systematic review of the literature is an invaluable resource to gain in-depth insights into the historical background of automation and to investigate previous research in this area. This study intends to deliver a comprehensive literary review of the history of automation from 1966 to 2021. Employing a mix of bibliometric, conceptual, and theoretical network analysis methods with the assistance of VOSviewer software, the research will analyze and depict the trends within the existing literature on automation. Through bibliometric analysis, the study aims to chart the key scholarly contributions and recognize the primary themes and concepts within the research. The outcomes of this systematic literature review will shed light on the historical development of automation research and its interdisciplinary aspects, pinpointing pivotal milestones, emerging trends, and existing knowledge gaps in the field. Based on these findings, the study will suggest a research agenda to further the academic discussion on automation.","""The corporate operational terrain has undergone a seismic shift in response to automation, necessitating that businesses across diverse sectors pinpoint the most apt technological solutions to cater to their distinctive requirements. As the pace of technological advancement accelerates, it is essential for professionals globally to develop a nuanced understanding of the automation landscape. A meticulous examination of existing literature serves as a vital instrument for contextualizing the historical trajectory of automation and synthesizing prior research in this domain. This investigation seeks to provide a comprehensive bibliographical survey of automation's evolution from 1966 to 2021. By leveraging a triangulated methodology that incorporates bibliometric, conceptual, and theoretical network analysis, facilitated by VOSviewer software, this study will dissect and visualize the patterns embedded within the extant automation literature. Through bibliometric analysis, this research will chart the seminal academic contributions, distill the primary research foci, and elucidate the underlying concepts. The outcomes of this systematic literature review will offer a longitudinal perspective on automation research, underscoring its interdisciplinary character, and highlighting pivotal milestones, nascent trends, and knowledge deficits in the field. Ultimately, this study will propose a research roadmap to propel the academic discourse on automation forward.""","The pervasive impact of automation has revolutionized company operations across diverse sectors. To navigate this technological shift, organizations globally must discern optimal automation tools aligned with their specific requirements. A comprehensive examination of existing literature offers valuable historical context and insights into prior research on automation. This investigation presents a thorough literary review of automation's evolution from 1966 to 2021, employing a mixed-method approach involving bibliometric, conceptual, and theoretical network analyses, facilitated by VOSviewer software, to dissect and visually represent patterns within the automation literature. By mapping key scholarly contributions and pinpointing dominant research themes and concepts, this study sheds light on the historical trajectory and interdisciplinary nature of automation research, illuminating significant advancements, emerging trends, and areas ripe for further exploration. Grounded in these findings, a future research agenda is proposed to propel scholarly discourse on automation forward.",acceptable,acceptable,acceptable,4.0,3.2,3.2
146,How do humans learn about the reliability of automation?,"In a range of settings, human operators make decisions with the assistance of automation, the reliability of which can vary depending upon context. Currently, the processes by which humans track the level of reliability of automation are unclear. In the current study, we test cognitive models of learning that could potentially explain how humans track automation reliability. We fitted several alternative cognitive models to a series of participants’ judgements of automation reliability observed in a maritime classification task in which participants were provided with automated advice. We examined three experiments including eight between-subjects conditions and 240 participants in total. Our results favoured a two-kernel delta-rule model of learning, which specifies that humans learn by prediction error, and respond according to a learning rate that is sensitive to environmental volatility. However, we found substantial heterogeneity in learning processes across participants. These outcomes speak to the learning processes underlying how humans estimate automation reliability and thus have implications for practice.","In various contexts, individuals make decisions supported by automated systems, whose dependability can fluctuate based on the situation. Currently, the methods by which people monitor automation reliability remain unclear. This study evaluates cognitive learning models that might explain how humans monitor the dependability of automation. We applied several different cognitive models to analyze participants' judgments of automation reliability during a maritime classification task, where they received automated guidance. The study encompassed three experiments with eight different conditions and a total of 240 participants. Our findings favored a two-kernel delta-rule learning model, indicating that humans learn through prediction error and adjust their learning rates in response to environmental uncertainty. However, we observed significant variation in the learning processes among participants. These findings shed light on the cognitive mechanisms behind human estimation of automation reliability and offer practical implications.","Across diverse contexts, humans rely on automated systems to inform their decision-making, yet the trustworthiness of these systems can fluctuate significantly depending on the situation. Despite this, the cognitive mechanisms underlying human assessments of automation reliability remain poorly understood. This study aimed to investigate cognitive learning theories that could shed light on how humans calibrate their trust in automation. We applied multiple cognitive models to participants' evaluations of automated guidance in a maritime classification task, involving 240 individuals across eight distinct experimental conditions. Our findings supported a two-kernel delta-rule learning model, which suggests that humans update their trust based on prediction errors and adapt their learning rate according to environmental uncertainty. Notably, however, we observed considerable individual differences in learning patterns, with important implications for the development of effective automation strategies.","Across various domains, human decision-making is often supported by automated systems, whose dependability can fluctuate based on situational factors. However, the mechanisms through which individuals monitor this fluctuating reliability remain poorly understood. This investigation aims to evaluate cognitive learning models that might elucidate how people assess the trustworthiness of automation. We fitted different cognitive models to a dataset of human judgments regarding automation reliability, collected during a maritime classification task where participants received automated guidance. Three separate experiments were conducted, encompassing eight distinct experimental conditions and a total of 240 participants. Our findings suggest that a two-kernel delta-rule learning model best explains the observed behavior. This model posits that individuals learn from discrepancies between their expectations and actual outcomes, adjusting their learning rate in response to environmental instability. Notably, we also observed significant individual differences in the learning processes employed. These results shed light on the learning mechanisms underpinning human estimation of automation reliability, offering valuable insights for practical applications.",acceptable,acceptable,acceptable,3.2,3.2,3.2
147,Driver behavior while using Level 2 vehicle automation: a hybrid naturalistic study,"Vehicle automation is becoming more prevalent. Understanding how drivers use this technology and its safety implications is crucial. In a 6–8 week naturalistic study, we leveraged a hybrid naturalistic driving research design to evaluate driver behavior with Level 2 vehicle automation, incorporating unique naturalistic and experimental control conditions. Our investigation covered four main areas: automation usage, system warnings, driving demand, and driver arousal, as well as secondary task engagement. While on the interstate, drivers were advised to engage Level 2 automation whenever they deemed it safe, and they complied by using it over 70% of the time. Interestingly, the frequency of system warnings increased with prolonged use, suggesting an evolving relationship between drivers and the automation features. Our data also revealed that drivers were discerning in their use of automation, opting for manual control under high driving demand conditions. Contrary to common safety concerns, our data indicated no significant rise in driver fatigue or fidgeting when using automation, compared to a control condition. Additionally, observed patterns of engagement in secondary tasks like radio listening and text messaging challenge existing assumptions about automation leading to dangerous driver distraction. Overall, our findings provide new insights into the conditions under which drivers opt to use automation and reveal a nuanced behavioral profile that emerges when automation is in use.","The prevalence of vehicle automation is on the rise, making it important to understand driver interactions with this technology and its safety consequences. We conducted a 6-8 week naturalistic study using a hybrid research design to assess driver behavior with Level 2 automation, incorporating both naturalistic and controlled experimental settings. Our investigation focused on four key areas: the use of automation, system warnings, driving demands, and driver arousal, in addition to secondary task engagement. On the interstate, drivers were instructed to enable Level 2 automation whenever they felt it was safe, and they did so over 70% of the time. Notably, the number of system warnings increased with extended use, indicating an evolving relationship between drivers and the automation. Our data also showed that drivers selectively used manual control in high-demand driving situations. Contrary to prevalent safety concerns, our findings did not show a significant increase in driver fatigue or fidgeting when automation was used, compared to a control condition. Additionally, observed patterns of secondary task engagement, such as listening to the radio and text messaging, challenge existing assumptions about automation leading to heightened driver distraction. In summary, our study offers new insights into when drivers choose to use automation and reveals a complex behavioral pattern associated with its use.","The increasing adoption of autonomous vehicles necessitates a thorough examination of how drivers interact with this technology and its impact on road safety. A comprehensive 6-8 week study employing a mixed-methods approach to naturalistic driving research was conducted to assess driver behavior in Level 2 autonomous vehicles, featuring both naturalistic and controlled experimental conditions. The investigation explored four primary domains: automation adoption, warning system efficacy, driving complexity, and driver alertness, as well as secondary task involvement. When driving on highways, participants were encouraged to activate Level 2 autonomy at their discretion, resulting in over 70% usage. Notably, the frequency of warning system alerts increased with prolonged autonomy use, suggesting a dynamic interplay between drivers and autonomous features. The data revealed that drivers exercised discernment in autonomy use, preferring manual control in high-demand driving scenarios. Contrary to prevailing safety concerns, the findings indicated no significant increase in driver fatigue or restlessness when using autonomy compared to a controlled environment. Furthermore, observed patterns of secondary task engagement, such as listening to the radio or texting, challenged common assumptions about autonomy-induced driver distraction. Ultimately, the study's results offer novel insights into the circumstances under which drivers opt for autonomy and uncover a complex behavioral profile that emerges when autonomy is engaged.","The increasing prevalence of vehicle automation necessitates a thorough understanding of driver interaction with this technology and its associated safety implications. Utilizing a hybrid naturalistic driving research methodology, a 6-8 week study was conducted to examine driver behavior in the context of Level 2 vehicle automation, employing a blend of natural driving scenarios and controlled experimental conditions. The investigation focused on four key aspects: automation utilization, system alerts, driving task demands, and driver alertness, along with secondary task engagement. Drivers were instructed to activate Level 2 automation on interstate highways whenever they perceived it as safe, resulting in an adoption rate exceeding 70%. Notably, the frequency of system warnings exhibited an upward trend with extended automation usage, indicating a dynamic interplay between drivers and the automated features. The study revealed that drivers displayed judicious automation usage, choosing manual control in situations characterized by elevated driving demands. Contrary to prevailing safety concerns, the data did not demonstrate a significant increase in driver fatigue or restlessness during automation usage compared to a controlled setting. Furthermore, observed patterns of secondary task engagement, such as radio listening and text messaging, challenge existing hypotheses suggesting that automation fosters hazardous driver distraction. In conclusion, these findings offer valuable insights into the circumstances under which drivers choose to engage automation and unveil a complex behavioral profile that manifests during its utilization.",acceptable,acceptable,acceptable,3.6,3.6,3.6
148,Automation and unemployment: help is on the way,"This paper examines the evolution of unemployment in a task-based model that allows for two types of technical change. One is automation, which turns labor tasks into mechanized ones. The second is addition of new labor tasks, which increases specialization, as in the expanding variety literature. The paper shows that in equilibrium the unemployment caused by automation converges to zero over time.","This study explores the progression of unemployment within a task-oriented framework that incorporates two categories of technological advancements. The first category, automation, involves converting manual tasks into automated processes. The second category introduces new labor tasks, thereby enhancing specialization, akin to the principles found in the literature on diversified expansion. The research indicates that, in equilibrium, the unemployment resulting from automation gradually diminishes to zero over time.","This study delves into the transformation of joblessness within a task-oriented framework, accommodating dual forms of technological advancements. Firstly, it explores the automation phenomenon, where manual tasks are replaced by mechanized counterparts. Secondly, it investigates the introduction of novel labor tasks, fostering greater specialization, akin to the expanding product variety paradigm. Ultimately, the research reveals that, in a state of equilibrium, the unemployment triggered by automation asymptotically approaches zero as time progresses.","Utilizing a framework that incorporates two distinct forms of technological advancement, this study investigates the trajectory of unemployment. The first, automation, transforms tasks previously performed by humans into machine-operated processes. The second involves the introduction of novel tasks, fostering specialization akin to the principles observed in studies on expanding product variety. The research demonstrates that, in a state of equilibrium, unemployment stemming from automation ultimately diminishes over time.",acceptable,acceptable,acceptable,3.6,3.6,3.2
149,The impact of automation and optimization on customer experience: a consumer perspective,"The adoption of digital technologies has significantly transformed businesses and society as a whole. The automation of tasks is leading to changes in organizational structures and strategies. Due to technological growth, users are able to identify the benefits and risks that technology can entail in the purchasing process. Specifically, robotic process automation (RPA) can improve efficiency and agility in a company, which in turn can positively impact consumer satisfaction and engagement. However, automation can also negatively affect the consumer experience and service quality if not applied correctly. Therefore, this research focuses on analyzing the impact of automation technologies on purchasing processes and consumer satisfaction. For this purpose, a survey was developed by means of the Likert 5-point scale, which allowed for obtaining 215 valid responses from consumers in the Community of Madrid. The data were processed through the SPSS tool, which enabled the analysis of the data and the proposed model. Consequently, the results show that potential RPA-based automation and optimization of processes can be of great utility for businesses to better address investment for improving consumer satisfaction. In addition, it should be highlighted that this research contributes in an original way to the area of information and communication technologies by allowing for the development of proactive technological implementation plans that consider end-user satisfaction.","The integration of digital technologies has profoundly altered both businesses and society. Task automation is prompting modifications in organizational structures and strategies. As technology advances, users can discern the advantages and risks technology may bring in the purchasing process. Specifically, robotic process automation (RPA) has the potential to enhance a company's efficiency and adaptability, which can positively influence customer satisfaction and engagement. However, if not implemented correctly, automation may adversely affect the consumer experience and service quality. This study aims to examine the effects of automation technologies on purchasing processes and consumer satisfaction. To this end, a survey utilizing a Likert 5-point scale was conducted, yielding 215 valid responses from consumers in the Community of Madrid. The data were analyzed using the SPSS tool, facilitating the evaluation of the data and the proposed model. The findings indicate that RPA-based process automation and optimization can significantly benefit businesses in improving consumer satisfaction. Furthermore, this research makes a unique contribution to the field of information and communication technologies by enabling the formulation of proactive technology implementation plans that prioritize end-user satisfaction.","The integration of digital solutions has brought about a profound paradigm shift in the business landscape and society at large, prompting a reevaluation of organizational frameworks and strategies. As technological advancements continue to accelerate, consumers are increasingly aware of the benefits and drawbacks associated with technology in the purchasing process. Notably, the strategic deployment of robotic process automation (RPA) can yield significant gains in operational efficiency and adaptability, ultimately enhancing customer satisfaction and loyalty. However, if misapplied, automation can have detrimental effects on the customer experience and service quality. This study seeks to investigate the influence of automation technologies on purchasing processes and customer satisfaction, relying on a 5-point Likert scale survey that garnered 215 valid responses from consumers in the Community of Madrid. The data analysis, facilitated by the SPSS tool, revealed that the judicious implementation of RPA-based automation and process optimization can be a valuable asset for businesses seeking to optimize investments in customer satisfaction. Furthermore, this research makes a novel contribution to the field of information and communication technologies by enabling the development of forward-thinking technological implementation plans that prioritize end-user satisfaction.","The integration of digital tools has revolutionized both commerce and society at large. This shift towards automated processes necessitates adaptations in organizational frameworks and plans. Technological advancements empower users to discern both the advantages and pitfalls of technology in their purchasing decisions. Robotic process automation (RPA), for instance, can enhance a company's efficiency and responsiveness, ultimately boosting customer contentment and engagement. However, if implemented incorrectly, automation can also negatively impact the consumer experience and service delivery. This study, therefore, investigates the influence of automation technologies on purchasing processes and customer satisfaction. A five-point Likert scale survey was administered, generating 215 valid responses from consumers in the Community of Madrid. Data analysis was facilitated by SPSS, enabling the examination of the data and the proposed model. The findings indicate that harnessing the potential of RPA-driven automation and process optimization can be highly beneficial for businesses seeking to optimize investments aimed at enhancing customer satisfaction. Furthermore, this research makes a novel contribution to the field of information and communication technologies by facilitating the creation of proactive technological implementation strategies that prioritize end-user satisfaction.",acceptable,acceptable,acceptable,3.6,3.2,3.2
150,The fine line between automation and augmentation in website usability evaluation,"Artificial Intelligence (AI) systems are becoming widespread in all aspects of society, bringing benefits to the whole economy. There is a growing understanding of the potential benefits and risks of this type of technology. While the benefits are more efficient decision processes and industrial productivity, the risks may include a potential progressive disengagement of human beings in crucial aspects of decision-making. In this respect, a new perspective is emerging that aims at reconsidering the centrality of human beings while reaping the benefits of AI systems to augment rather than replace professional skills: Human-Centred AI (HCAI) is a novel framework that posits that high levels of human control do not contradict high levels of computer automation. In this paper, we investigate the two antipodes, automation vs augmentation, in the context of website usability evaluation. Specifically, we have analyzed whether the level of automation provided by a tool for semi-automatic usability evaluation can support evaluators in identifying usability problems. Three different visualizations, each one corresponding to a different level of automation, ranging from a full-automation approach to an augmentation approach, were compared in an experimental study. We found that a fully automated approach could help evaluators detect a significant number of medium and high-severity usability problems, which are the most critical in a software system; however, it also emerged that it was possible to detect more low-severity usability problems using one of the augmented approaches proposed in this paper.","Artificial Intelligence (AI) systems are increasingly prevalent across all areas of society, bringing economic benefits. There is a growing recognition of the potential advantages and risks associated with this technology. While it offers improved decision-making processes and greater industrial efficiency, it also raises concerns about the possible decline in human involvement in important decision-making areas. In response, a new approach called Human-Centred AI (HCAI) is gaining traction, which seeks to maintain human centrality while leveraging AI to enhance, rather than replace, professional skills. HCAI asserts that high human oversight is compatible with significant computer automation. This study explores the dichotomy of automation versus augmentation in the realm of website usability evaluation. We analyzed whether semi-automated usability evaluation tools can help evaluators identify usability issues. The study compared three different visualization methods, each representing varying degrees of automation, from fully automated to augmented approaches. The findings indicate that fully automated methods effectively identify a significant number of medium and high-severity usability issues. However, augmented approaches were more successful in identifying low-severity usability problems.","The pervasive integration of Artificial Intelligence (AI) across various societal domains is yielding economic benefits, accompanied by a growing awareness of its potential advantages and drawbacks. While AI-driven efficiencies in decision-making and industrial productivity are undeniable, there is a risk of incremental human disconnection from critical decision-making processes. In response, a novel paradigm, Human-Centred AI (HCAI), is emerging, which reconciles high levels of human oversight with advanced computer automation. This paper explores the dichotomy between automation and augmentation in the context of website usability assessment, examining whether varying levels of automation in a semi-automatic evaluation tool can aid evaluators in identifying usability issues. An experimental study compared three visualization approaches, ranging from full automation to augmentation, revealing that while full automation facilitated the detection of severe usability problems, an augmented approach was more effective in identifying minor issues.","The pervasive integration of AI technologies across societal domains offers substantial economic advantages, accompanied by a growing awareness of their potential benefits and drawbacks. While AI-driven systems can enhance decision-making efficiency and boost industrial output, they also carry the risk of gradually marginalizing human involvement in critical decision processes. To address this concern, the burgeoning field of Human-Centred AI (HCAI) advocates for a paradigm shift that prioritizes human oversight and leverages AI capabilities to complement rather than supplant human expertise. This research delves into the dichotomy of automation versus augmentation within the realm of website usability assessment, examining how varying levels of automation in evaluation tools impact the identification of usability issues. An empirical study comparing three distinct visualizations, each representing a different degree of automation, from fully automated to augmentation-based, revealed that a fully automated approach facilitated the detection of significant medium and high-severity usability problems, which are paramount in software development. However, it was also observed that one of the proposed augmented approaches enabled the identification of a greater number of low-severity usability issues.",acceptable,acceptable,acceptable,3.2,3.2,3.2
151,IoT based applications for healthcare and home automation,"The Internet of Things (IoT) is a paradigm that involves connecting the virtual world of the Internet to the real world through so-called smart objects. Indeed, Internet of Things (IoT) devices are extensively employed in a wide range of applications, including healthcare field and home automation. These objects are equipped with communication capabilities and can exchange data over the Internet. In recent times, the healthcare sector has witnessed a surge of growth and transformation. The integration of IoT-enabled devices has revolutionized remote monitoring in healthcare, empowering healthcare providers to keep their patients safe and healthy while delivering exceptional care. On the other hand, the home automation system is becoming increasingly popular due to its many benefits, which involve remotely monitoring and controlling household appliances. In fact, the main challenges faced by home automation systems are poor manageability, rigidity, difficulty in achieving security, and high ownership costs. As the internet and its applications continue to grow, there is enormous potential for remotely accessing, controlling and monitoring network-enabled devices. With this context in mind, the objective of this project is to develop two IoT-based models. These models are based on Arduino and Raspberry pi boards, cloud, Bluetooth and ZigBee protocols. The first model is an IoT healthcare system that employs various sensors to collect heart rate and motion data. The second model is a home automation system that utilizes a DHT11 sensor to measure temperature and humidity levels, a MQ2 sensor to detect gas leaks, and an ultrasonic sensor to control the garage door's opening and closing. Both systems are built around an Arduino or a Raspberry pi microcontrollers integrated with an Android mobile application to process and transmit data via Bluetooth or Zigbee ensuring that the mobile app receives real-time updates.","The Internet of Things (IoT) is a concept that bridges the gap between the digital realm of the Internet and the physical world via smart devices. IoT devices are widely utilized across various sectors including healthcare and home automation. These devices are capable of communication and data exchange over the Internet. Recently, the healthcare industry has experienced significant growth and transformation, largely due to the integration of IoT-enabled devices, which have revolutionized remote patient monitoring and enhanced the quality of care. Simultaneously, home automation systems are gaining popularity owing to their benefits, such as the ability to remotely monitor and control home appliances. However, these systems face several challenges including poor manageability, inflexibility, security issues, and high costs of ownership. As Internet applications continue to expand, there is great potential for remote access, control, and monitoring of network-enabled devices. In this context, the aim of this project is to develop two IoT-based models utilizing Arduino and Raspberry Pi boards, cloud services, Bluetooth, and ZigBee protocols. The first model is an IoT healthcare system that uses various sensors to gather heart rate and motion data. The second model is a home automation system that employs a DHT11 sensor for temperature and humidity, an MQ2 sensor for gas leak detection, and an ultrasonic sensor for garage door operation. Both systems are built using Arduino or Raspberry Pi microcontrollers and are integrated with an Android mobile application to process and transmit data via Bluetooth or ZigBee, ensuring real-time updates to the mobile app.","The convergence of the physical and digital realms is facilitated by the Internet of Things (IoT) paradigm, which bridges the gap between the virtual Internet and the tangible world through the agency of intelligent devices. IoT devices have found widespread adoption across a diverse spectrum of applications, including healthcare and home automation. These devices are imbued with communication capabilities, enabling them to exchange data over the Internet. In recent years, the healthcare sector has experienced a significant transformation, with the integration of IoT-enabled devices revolutionizing remote patient monitoring and empowering healthcare providers to deliver exceptional care while ensuring patient safety and well-being. Meanwhile, home automation systems are gaining popularity due to their numerous benefits, including remote monitoring and control of household appliances. However, these systems face challenges such as poor manageability, inflexibility, security concerns, and high maintenance costs. As the Internet and its applications continue to evolve, there exists vast potential for remote access, control, and monitoring of network-enabled devices. In this context, the objective of this project is to develop two IoT-based prototypes. These prototypes, built around Arduino and Raspberry pi boards, cloud infrastructure, and Bluetooth and ZigBee protocols, comprise an IoT healthcare system that leverages various sensors to collect heart rate and motion data, and a home automation system that utilizes a range of sensors, including DHT11, MQ2, and ultrasonic sensors, to monitor and control temperature, humidity, gas leaks, and garage door operations. Both systems are integrated with an Android mobile application, enabling real-time data processing and transmission via Bluetooth or Zigbee.","The convergence of the physical and digital realms is exemplified by the Internet of Things (IoT), where objects are imbued with internet connectivity, enabling data exchange. This paradigm has found widespread adoption across various domains, notably healthcare and home automation. IoT-equipped devices in healthcare have revolutionized remote patient monitoring, enhancing both patient well-being and care quality. Concurrently, home automation systems, driven by their ability to remotely control appliances, are gaining popularity. However, these systems grapple with challenges such as manageability, inflexibility, security vulnerabilities, and high costs. Recognizing the burgeoning potential of remotely managing internet-enabled devices, this project aims to develop two IoT models. Leveraging Arduino and Raspberry Pi boards, cloud services, Bluetooth, and ZigBee protocols, the models focus on healthcare and home automation respectively. The healthcare system utilizes sensors to gather heart rate and movement data, while the home automation system employs a DHT11 sensor for temperature and humidity monitoring, a MQ2 sensor for gas leak detection, and an ultrasonic sensor for garage door control. Both systems are built upon Arduino or Raspberry Pi microcontrollers, seamlessly integrated with an Android mobile application that facilitates data processing and transmission via Bluetooth or Zigbee, ensuring real-time updates.",acceptable,acceptable,acceptable,3.2,3.2,3.2
152,Speed of environmental change frames relative ecological risk in climate change and climate intervention scenarios,"Stratospheric aerosol injection is a potential method of climate intervention to reduce climate risk as decarbonization efforts continue. However, possible ecosystem impacts from the strategic design of hypothetical intervention scenarios are poorly understood. Two recent Earth system model simulations depict policy-relevant stratospheric aerosol injection scenarios with similar global temperature targets, but a 10-year delay in intervention deployment. Here we show this delay leads to distinct ecological risk profiles through climate speeds, which describe the rate of movement of thermal conditions. On a planetary scale, climate speeds in the simulation where the intervention maintains temperature are not statistically distinguishable from preindustrial conditions. In contrast, rapid temperature reduction following delayed deployment produces climate speeds over land beyond either a preindustrial baseline or no-intervention climate change with present policy. The area exposed to threshold climate speeds places different scenarios in context to their relative ecological risks. Our results support discussion of tradeoffs and timescales in future scenario design and decision-making.","Injecting aerosols into the stratosphere is a proposed climate intervention tactic aimed at mitigating climate risks as decarbonization efforts go on. Nonetheless, the impacts on ecosystems from such hypothetical interventions are not well comprehended. Two simulations using Earth system models explore policy-relevant scenarios of stratospheric aerosol injection aimed at achieving similar global temperature goals, with one involving a 10-year delay in implementation. Our findings indicate that this delay results in varied ecological risk profiles due to different climate speeds, which refer to the rate at which thermal conditions shift. Globally, in the simulation where the intervention stabilizes temperatures, climate speeds are statistically similar to preindustrial levels. However, swiftly reducing temperatures after a delayed deployment leads to climate speeds over land that exceed both preindustrial baselines and scenarios without intervention under current policies. Evaluating the extent of areas exposed to these threshold climate speeds provides context for comparing the ecological risks of different scenarios. These results inform discussions about the trade-offs and timelines in designing future intervention strategies and making decisions.","""Implementing stratospheric aerosol injection as a climate mitigation strategy while pursuing decarbonization could help minimize climate-related hazards. However, the potential ecological consequences of designing and executing such interventions remain unclear. A recent comparison of two Earth system model simulations reveals that delaying the deployment of aerosol injection by 10 years, despite achieving similar global temperature goals, yields divergent environmental risk profiles due to varying rates of climate change. Notably, the simulation with prompt intervention maintains climate velocities comparable to preindustrial levels on a global scale, whereas rapid cooling following delayed deployment results in climate velocities over land that exceed both preindustrial and business-as-usual climate change scenarios. The areas affected by critical climate velocities provide a framework for evaluating the relative ecological risks associated with different scenarios, highlighting the need to consider tradeoffs and timelines in future scenario development and decision-making.""","Manipulating the stratosphere to disperse aerosols presents a possible way to mitigate climate change while societies work towards decarbonization. However, the potential ecological consequences of different intervention strategies remain largely unknown. Recent simulations of two policy-relevant stratospheric aerosol injection scenarios, both aiming for similar global temperature targets but with a 10-year deployment delay, reveal distinct ecological risks based on the pace of temperature shifts. When intervention maintains temperature, global climate velocity doesn't statistically deviate from preindustrial conditions. Conversely, rapid cooling after the delayed intervention results in terrestrial climate velocities surpassing both preindustrial norms and projected climate change under current policies. Comparing the areas exposed to critical climate velocity thresholds helps contextualize the relative ecological risks of different scenarios. These findings underscore the importance of considering tradeoffs and timescales when designing and deciding on future interventions.",acceptable,acceptable,acceptable,3.6,3.2,3.2
153,Increase in concerns about climate change following climate strikes and civil disobedience in Germany,"Climate movements have gained momentum in recent years, aiming to create public awareness of the consequences of climate change through salient climate protests. This paper investigates whether concerns about climate change increase following demonstrative protests and confrontational acts of civil disobedience. Leveraging individual-level survey panel data from Germany, we exploit exogenous variations in the timing of climate protests relative to survey interview dates to compare climate change concerns in the days before and after a protest (N = 24,535). Following climate protests, we find increases in concerns about climate change by, on average, 1.2 percentage points. Further, we find no statistically significant evidence that concerns of any subpopulation decreased after climate protests. Lastly, the increase in concerns following protests is highest when concern levels before the protests are low.","In recent years, climate movements have experienced a surge in activity, seeking to raise public awareness of the impacts of climate change through prominent protests. This study examines whether apprehensions about climate change are heightened following demonstrative protests and acts of civil disobedience. Using individual-level survey panel data from Germany, the study takes advantage of exogenous variations in the timing of climate protests relative to survey interview dates to compare climate change concerns in the days preceding and following a protest (N = 24,535). The findings reveal that, on average, concerns about climate change increase by 1.2 percentage points following climate protests. Additionally, no statistically significant decline in concerns among any subpopulation was observed after the protests. Notably, the rise in concerns is greatest when initial concern levels are low before the protests.","In recent years, environmental activism has surged, seeking to heighten societal consciousness about the far-reaching repercussions of global warming through high-profile demonstrations. This study examines whether anxieties regarding climate change intensify subsequent to dramatic displays of civil unrest and confrontational acts of defiance. Utilizing a unique dataset of individual survey responses from Germany, we capitalize on the natural experiment of protest timing to contrast climate change apprehensions in the periods preceding and following a protest (N = 24,535). Our findings indicate a notable uptick in climate change anxieties, averaging a 1.2 percentage point increase, in the aftermath of protests. Moreover, we uncover no empirical evidence suggesting that any demographic subgroup experienced a decline in concerns post-protest. Notably, the greatest surge in concerns occurs when pre-protest apprehension levels are relatively low.","Recent years have witnessed a surge in climate activism, with movements employing high-profile protests to raise public consciousness regarding the repercussions of climate change. This study delves into whether such demonstrative actions, including confrontational civil disobedience, amplify climate change apprehensions. Utilizing longitudinal survey data from Germany, we capitalize on the fortuitous timing of climate protests relative to survey interviews to juxtapose climate change concerns in the days preceding and succeeding a protest (N = 24,535). Our findings reveal that climate protests are associated with an average increase of 1.2 percentage points in climate change anxieties. Moreover, we observe no statistically significant evidence of diminished concern among any subgroup following protests. Notably, the most substantial surge in concern post-protest occurs when pre-protest anxiety levels are low.",acceptable,acceptable,acceptable,3.6,3.2,3.2
154,"AI-enabled strategies for climate change adaptation: protecting communities, infrastructure, and businesses from the impacts of climate change","Climate change is one of the most pressing global challenges we face today. The impacts of rising temperatures, sea levels, and extreme weather events are already being felt around the world and are only expected to worsen in the coming years. To mitigate and adapt to these impacts, we need innovative, data-driven solutions. Artificial intelligence (AI) has emerged as a promising tool for climate change adaptation, offering a range of capabilities that can help identify vulnerable areas, simulate future climate scenarios, and assess risks and opportunities for businesses and infrastructure. With the ability to analyze large volumes of data from climate models, satellite imagery, and other sources, AI can provide valuable insights that can inform decision-making and help us prepare for the impacts of climate change. However, the use of AI in climate change adaptation also raises important ethical considerations and potential biases that must be addressed. As we continue to develop and deploy these solutions, it is crucial to ensure that they are transparent, fair, and equitable. In this context, this article explores the latest innovations and future directions in AI-enabled climate change adaptation strategies, highlighting both the potential benefits and the ethical considerations that must be considered. By harnessing the power of AI for climate change adaptation, we can work towards a more resilient, sustainable, and equitable future for all.","Addressing climate change stands as one of today's most urgent global challenges. The effects of increasing temperatures, rising sea levels, and severe weather events are currently evident across the globe and are anticipated to escalate in the future. To mitigate and adapt to these changes, innovative, data-driven solutions are essential. Artificial intelligence (AI) has become a valuable tool for climate change adaptation, offering diverse capabilities to identify vulnerable regions, simulate future climate scenarios, and evaluate risks and opportunities for businesses and infrastructure. AI’s ability to process extensive data from climate models, satellite imagery, and other sources yields critical insights that support informed decision-making and preparedness for climate impacts. Nonetheless, AI application in climate change adaptation also entails significant ethical considerations and potential biases that must be addressed. As development and deployment of these solutions continue, transparency, fairness, and equity are paramount. This article examines recent innovations and future prospects in AI-driven climate change adaptation strategies, emphasizing both the potential benefits and ethical issues to be considered. Utilizing AI for climate change adaptation can contribute to a more resilient, sustainable, and equitable future for all.","""Among the most critical planetary threats confronting humanity today is climate change, whose far-reaching consequences, including escalating temperatures, sea-level rise, and intense weather patterns, are already manifesting globally and projected to intensify in the years ahead. To counter and adapt to these devastating effects, novel, evidence-based approaches are essential. Artificial intelligence has emerged as a potent ally in the fight against climate change, offering a suite of capabilities that can pinpoint susceptible regions, forecast future climate scenarios, and evaluate risks and opportunities for industries and infrastructure. By processing vast amounts of data from climate simulations, satellite imaging, and other sources, AI can furnish actionable intelligence that informs decision-making and enables proactive preparation for climate change's impacts. However, the integration of AI in climate change adaptation also raises vital ethical concerns and potential biases that demand attention. As we advance and implement these solutions, it is imperative to ensure their transparency, fairness, and equity. This article delves into the latest breakthroughs and future trajectories in AI-driven climate change adaptation strategies, underscoring both the potential advantages and the ethical imperatives that must be acknowledged. By leveraging AI's capabilities for climate change adaptation, we can strive towards a more robust, environmentally conscious, and just future for all.""","Among the most critical global issues confronting humanity, climate change stands out. The consequences of escalating temperatures, rising sea levels, and amplified extreme weather phenomena are evident worldwide and projected to intensify in the coming years. Innovative, data-driven approaches are essential to mitigate and adapt to these effects. Artificial intelligence (AI) presents a promising solution, offering diverse capabilities for identifying vulnerable regions, modeling future climate scenarios, and evaluating risks and opportunities for businesses and infrastructure. By processing vast amounts of data from climate models, satellite imagery, and other sources, AI delivers valuable insights that can guide decision-making and facilitate preparedness for climate change impacts. Nonetheless, the application of AI in climate change adaptation raises ethical concerns and potential biases that necessitate careful consideration. Ensuring transparency, fairness, and equity in the development and implementation of AI-powered solutions is crucial. This article delves into the latest advancements and future trajectories of AI-driven climate change adaptation strategies, emphasizing both the potential advantages and the ethical implications that demand attention. By leveraging the power of AI, we can strive for a more resilient, sustainable, and equitable future for everyone.",acceptable,acceptable,acceptable,3.6,3.6,3.6
155,Changing how you look at climate change: attention bias modification increases attention to climate change,"Mitigating the negative impacts of anthropogenic climate change is among the most serious and pressing challenges facing the global community. Despite the severity of the issue, there seems to be a lack of attention paid to climate change in our daily lives. Yet, climate change-related information can capture observers’ attention, and when attention is drawn to a particular environmental risk, the perceived severity of this attended risk is enhanced. The question then is whether attention to climate change-related information can be modified or enhanced. Here, we report the results of two experiments using single-session attention bias modification training procedures designed to increase attentional focus on climate change-related information. In Experiment 1, attention training to emotionally positive images of climate change (e.g., potential solutions such as windmills and solar panels) increased attention to these images, but not emotionally negative images of climate change (e.g., air pollution, natural disasters, and melting ice). In Experiment 2, this effect was replicated. In addition, Experiment 2 revealed that training to emotionally negative images of climate change increased attention to negative images of climate change, and there was a trend for this enhanced attention to generalize to positive images of climate change. Furthermore, attention training towards negative images of climate change enhanced self-reported levels of concern about climate change. Collectively, our results suggest that attention training can increase the allocation of attention to climate change-related information and, under certain training conditions, concern for climate change increases.","Addressing the adverse effects of human-induced climate change remains one of the gravest and most urgent issues confronting the international community. Despite the critical nature of the problem, there appears to be insufficient focus on climate change in our everyday lives. Nevertheless, climate change-related information has the potential to attract attention, and when focus is directed toward a specific environmental hazard, the perceived seriousness of that hazard is amplified. Thus, the question arises whether it is possible to alter or enhance attention to climate change-related information. We present findings from two experiments employing single-session attention bias modification training procedures aimed at increasing focus on information related to climate change. In the first experiment, training attention towards emotionally positive images of climate change (such as potential solutions like wind turbines and solar panels) heightened attention to these images but not to the emotionally negative ones (such as air pollution, natural disasters, and melting ice). This effect was replicated in the second experiment. Additionally, the second experiment demonstrated that training focus on negative images of climate change heightened attention to these negative images, with a trend indicating this enhanced focus may extend to positive climate-related images. Moreover, training to attend to negative images of climate change led to increased self-reported concern about climate change. Overall, our findings indicate that attention training can augment the focus on climate change-related information, and under specific training conditions, this can also elevate concern about climate change.","Addressing the devastating consequences of human-induced global warming is a paramount and urgent imperative confronting the international community, yet it appears to be relegated to the periphery of our daily consciousness. However, research has shown that information related to climate change can captivate people's attention, and when focus is directed towards a specific environmental threat, the perceived gravity of that risk intensifies. The crucial question, therefore, is whether it is possible to modify or amplify attention towards climate change-related information. This study presents the findings of two experiments employing single-session attention bias modification training protocols designed to heighten attentional focus on climate change-related stimuli. The results of Experiment 1 revealed that attention training using emotionally uplifting images of climate change (such as renewable energy sources) increased attention towards these images, but not towards emotionally distressing images of climate change (such as environmental degradation and natural disasters). Experiment 2 replicated this effect and further demonstrated that training using emotionally distressing images of climate change increased attention towards these images, with a trend towards generalization to uplifting images. Moreover, attention training directed towards negative images of climate change was found to enhance self-reported levels of anxiety about climate change. Overall, our findings suggest that attention training can effectively redirect attention towards climate change-related information and, under specific training conditions, amplify concern about climate change.","Addressing the detrimental consequences of human-induced climate change stands as a paramount global challenge. However, despite its gravity, this issue often fails to permeate our daily consciousness. While climate-related data can undoubtedly capture interest, the perception of environmental threats intensifies when focused upon. This raises the question: can we manipulate and amplify attention towards climate change information? Our research explores this through two experiments employing single-session attention bias modification training, aiming to heighten focus on climate change-related stimuli. In the initial experiment, training attention towards positive climate imagery (e.g., renewable energy solutions) successfully increased focus on such images, yet did not extend to negative climate imagery (e.g., pollution, climate disasters). The second experiment replicated these findings, additionally revealing that training with negative climate imagery heightened attention towards such imagery, with a trend towards generalization to positive imagery. Notably, training with negative imagery also augmented self-reported climate change concern. Our findings collectively suggest that attention training can elevate focus on climate change information, and under specific training conditions, amplify concern for this global crisis.",acceptable,acceptable,acceptable,3.6,3.2,3.6
156,Are transport networks in low-income countries prepared for climate change? Barriers to preparing for climate change in Africa and South Asia,"Climate change, through extreme weather events and slow onset climatic changes, disrupts the operation of transport networks, and those in low-income countries (LICs) across Africa and South Asia are particularly vulnerable to climate change. This paper explores the barriers that LICs face across Africa and South Asia regarding preparedness of transport infrastructure to climate change, with the intent of addressing the knowledge gaps and consequential needs of LICs to support the delivery of more climate-resilient transport. Literature on climate change adaptation and transport resilience among LICs is reviewed to identify the broad challenges and barriers regarding climate change adaptation. Semi-structured interviews with 13 transport stakeholders across Africa and South Asia were also conducted to understand the challenges specific to the transport sector in the regions. Several barriers were identified, including a lack of data and knowledge on climate change impacts, design and prioritisation of remedial actions, budgeting and planning for climate change, and identifying and engaging with stakeholders. Findings from this paper and the wider research project it comprises inform policy guidance that calls for greater national and international coordination to develop practical, relevant and usable data, tools, advice and support for some of the most at-risk transport networks to climate change in the world.","This study investigates the obstacles that low-income countries (LICs) in Africa and South Asia encounter in preparing their transport infrastructure for climate change impacts. Climate change, through extreme weather and gradual climatic shifts, disrupts transport systems, especially in LICs in these regions. The paper aims to fill knowledge gaps and address the needs of LICs to facilitate the implementation of more climate-resilient transport solutions. By reviewing literature on climate change adaptation and transport resilience in LICs and conducting semi-structured interviews with 13 transport stakeholders from Africa and South Asia, the research identifies several barriers. These include insufficient data and knowledge on climate change impacts, challenges in designing and prioritizing responses, budgetary and planning obstacles, and difficulties in stakeholder identification and engagement. The findings inform policy recommendations that emphasize the need for enhanced national and international cooperation to develop useful data, tools, advice, and support for the world's most climate-vulnerable transport networks.","The devastating impacts of climate change, manifested through catastrophic weather events and gradual climatic shifts, severely impede the functioning of transportation systems, with those in low-income countries across Africa and South Asia being disproportionately susceptible to its effects. This study delves into the obstacles faced by these nations in preparing their transportation infrastructure to withstand the challenges posed by climate change, aiming to bridge the knowledge gaps and address the pressing needs of these countries to develop more climate-resilient transportation systems. A comprehensive review of existing literature on climate change adaptation and transportation resilience in low-income countries reveals the overarching challenges and barriers hindering climate change adaptation efforts. Additionally, in-depth interviews with 13 transportation stakeholders across Africa and South Asia provide insight into the sector-specific challenges in these regions. The findings highlight several key barriers, including inadequate data and knowledge on climate change impacts, ineffective design and prioritization of remedial measures, insufficient budgeting and planning for climate change, and difficulties in identifying and engaging relevant stakeholders. The results of this study and the broader research project inform policy recommendations that emphasize the need for enhanced national and international collaboration to develop practical, relevant, and accessible data, tools, guidance, and support for the world's most climate-vulnerable transportation networks.","The effects of climate change, ranging from sudden extreme weather to gradual shifts in climate patterns, significantly impact transportation systems. Developing nations in Africa and South Asia are especially susceptible to these disruptions. This study investigates the obstacles these countries face in preparing their transportation infrastructure for climate change, aiming to fill knowledge gaps and address their specific needs for building more resilient transportation systems. Existing research on climate adaptation and transport resilience in these regions is analyzed to pinpoint overarching challenges and barriers. To gain a deeper understanding of the transport sector's unique challenges, in-depth interviews were conducted with thirteen transport stakeholders across both continents. The study revealed several key obstacles, including insufficient data and knowledge about the impact of climate change, difficulties in designing and prioritizing remedial actions, inadequate budgeting and planning for climate change, and challenges in identifying and engaging with relevant stakeholders. The findings of this research, part of a larger project, contribute to policy recommendations advocating for increased national and international collaboration. This collaborative effort aims to develop practical, relevant, and user-friendly data, tools, guidance, and support for some of the world's most vulnerable transportation networks facing the impacts of climate change.",acceptable,acceptable,acceptable,3.6,3.6,3.6
157,Leveraging neuroscience for climate change research,"Anthropogenic climate change poses a substantial threat to societal living conditions. Here, we argue that neuroscience can substantially contribute to the fight against climate change and provide a framework and a roadmap to organize and prioritize neuroscience research in this domain. We outline how neuroscience can be used to: (1) investigate the negative impact of climate change on the human brain; (2) identify ways to adapt; (3) understand the neural substrates of decisions with pro-environmental and harmful outcomes; and (4) create neuroscience-based insights into communication and intervention strategies that aim to promote climate action. The paper is also a call to action for neuroscientists to join broader scientific efforts to tackle the existential environmental threats Earth is currently facing.","Human-induced climate change presents a significant danger to societal living standards. In this context, we propose that neuroscience can play a crucial role in combating climate change and offer a structured plan to guide neuroscience research in this area. We describe how neuroscience can be leveraged to: (1) examine the adverse effects of climate change on the human brain; (2) find adaptation strategies; (3) explore the neural mechanisms behind decisions that either support or hinder environmental sustainability; and (4) develop neuroscience-informed communication and intervention techniques to encourage climate action. This paper also calls on neuroscientists to join the wider scientific community in addressing the critical environmental challenges facing our planet.","Human societies face a significant menace from climate change, which is largely driven by human activities. This paper makes the case for neuroscience playing a pivotal role in mitigating the effects of climate change, and presents a structured approach and a clear direction for guiding and prioritizing research in this area. We demonstrate how neuroscience can be harnessed to: (1) examine the detrimental effects of climate change on human cognition; (2) uncover strategies for resilience; (3) elucidate the neural mechanisms underlying environmentally conscious and destructive behaviors; and (4) develop evidence-based recommendations for effective communication and intervention tactics that foster climate-resilient behaviors. Furthermore, this paper serves as a rallying cry for neuroscientists to collaborate with other scientific disciplines in addressing the pressing environmental perils that threaten the very survival of our planet.","Human-induced global warming significantly endangers societal well-being. This paper posits that brain research can meaningfully contribute to climate change mitigation efforts. We propose a structured approach, including a prioritized research agenda, to guide neuroscientific investigations in this critical area. Our framework elucidates how neuroscience can: (1) examine the detrimental effects of climate change on brain function; (2) explore adaptive strategies; (3) decipher the neural mechanisms underlying both environmentally responsible and detrimental choices; and (4) generate brain-based insights for communication and intervention tactics aimed at fostering climate action. We urge neuroscientists to actively participate in the broader scientific community's endeavors to address the pressing environmental challenges confronting our planet.",acceptable,acceptable,acceptable,3.6,3.2,3.6
158,Maritime cybersecurity: protecting digital seas,"Increasing digitisation in the maritime domain and the intensive use of information technologies have become essential for the effective functioning of systems that manage navigation, communications, sensors and weapons throughout the maritime chain. In this context, the issuance and enforcement of international standards and policies are seeking to mitigate the appearance of threats and vulnerabilities that aim to compromise access to functionalities, on-board systems and network integrity. Thus, in this article, we first review the main proposals for guidelines, frameworks and other solutions related to cybersecurity in the maritime environment. Subsequently, we analyse the way in which cybersecurity challenges specific to systems and equipment in this particular environment are addressed, identifying the main cybersecurity weaknesses and needs in the maritime environment that are not completely addressed. Based on this analysis, we then propose the structure of POSEIDON, a comprehensive framework for managing cybersecurity in maritime environments that addresses the identified gaps. This cybersecurity management framework takes into account existing proposals and is complemented by a set of new elements to provide a comprehensive approach to addressing the weaknesses identified.","The growing digitization in the maritime sector and the extensive deployment of information technologies are critical for the efficient operation of systems overseeing navigation, communication, sensors, and weaponry along the maritime supply chain. Within this framework, the implementation and enforcement of global standards and regulations aim to reduce the emergence of threats and vulnerabilities targeting functionality access, on-board systems, and network integrity. Consequently, this article initially examines the key proposed guidelines, frameworks, and solutions pertinent to cybersecurity in the maritime sector. Thereafter, it delves into how specific cybersecurity challenges related to systems and equipment in this domain are addressed, pinpointing the main cybersecurity vulnerabilities and requirements that remain inadequately covered. Following this assessment, we introduce the structure of POSEIDON, an all-encompassing framework designed to manage cybersecurity within maritime environments, aimed at filling identified gaps. This proposed cybersecurity management framework considers current proposals and integrates new elements to offer a thorough approach to tackling the highlighted deficiencies.","The maritime sector's growing reliance on digital technologies and information systems has made it crucial to ensure the seamless operation of navigation, communication, sensor, and weapon systems across the entire maritime supply chain. To counter the emerging threats and vulnerabilities that could disrupt system access, onboard functionality, and network security, international standards and policies are being developed and enforced. This article provides an overview of the key guidelines, frameworks, and solutions proposed for maritime cybersecurity, followed by an examination of how the unique challenges facing systems and equipment in this environment are being addressed. The analysis identifies the primary weaknesses and unmet needs in maritime cybersecurity, which informs the development of POSEIDON, a holistic framework for managing cybersecurity in maritime environments. This comprehensive framework builds upon existing proposals and incorporates novel elements to provide a thorough approach to mitigating the identified vulnerabilities.","The growing reliance on digital technologies within the maritime sector has become critical for the optimal operation of systems encompassing navigation, communication, sensors, and weaponry across the entire maritime chain. Consequently, international standards and policies are being established and enforced to minimize the emergence of threats and vulnerabilities targeting access to functionalities, onboard systems, and network integrity. This article first examines prominent cybersecurity guidelines, frameworks, and solutions within the maritime context. It then analyzes how cybersecurity challenges specific to this environment's systems and equipment are being tackled, highlighting key weaknesses and unmet needs. Based on this analysis, the article proposes POSEIDON, a comprehensive framework for maritime cybersecurity management that addresses these identified gaps. This framework builds upon existing proposals while incorporating novel elements to offer a holistic approach to mitigate identified vulnerabilities.",acceptable,acceptable,acceptable,3.6,3.2,3.2
159,More than malware: unmasking the hidden risk of cybersecurity regulations,"Cybersecurity investments are made within a complex and ever-evolving environment, where regulatory changes represent a significant risk factor. While cybersecurity regulations aim to minimize cyber risks and enhance protection, the uncertainty arising from frequent changes or new regulations can significantly impact organizational response strategies. This paper explores the determinants and implications of regulatory risks associated with cybersecurity, aiming to provide a deeper understanding of how these risks influence strategic decision-making. The study delves into the suggestion of preventive and mitigative controls that enable businesses to adapt to and mitigate potential disruptions caused by regulatory changes, thereby preserving their established cybersecurity practices. Another key contribution of this study is the introduction of a stochastic econometric model that illustrates how regulatory risks and uncertainties can affect investment behaviors, often prompting a “wait-and-see” stance. This model synthesizes the complex relationship among investment choices, regulatory changes, and cybersecurity risks, providing insights into the dynamic nature of cybersecurity investment strategies. The research findings offer valuable guidance for risk management and strategic planning in cybersecurity investments. By comprehensively understanding the drivers and impacts of regulatory risks, businesses and policymakers can develop more effective risk evaluation and management approaches. This is essential for sustaining a strong cybersecurity posture while navigating the changing regulatory environment.","Investments in cybersecurity occur in a multifaceted and continually changing context, where modifications in regulations pose significant risks. Although these regulations aim to reduce cyber threats and bolster security, the unpredictability from frequent updates or new rules can profoundly affect how organizations develop their response strategies. This paper investigates the factors and outcomes of regulatory risks tied to cybersecurity, offering deeper insights into how these risks shape strategic decisions. The study examines suggested preventive and mitigative measures that help companies adjust to and mitigate disruptions due to regulatory shifts, thus maintaining their cybersecurity frameworks. Additionally, this research introduces a stochastic econometric model that demonstrates how regulatory uncertainties and risks influence investment decisions, often resulting in a “wait-and-see” approach. This model encapsulates the intricate relationship between investment choices, regulatory modifications, and cyber risks, shedding light on the dynamic aspects of cybersecurity investment strategies. The findings provide crucial guidance for risk management and strategic planning in cybersecurity investments. By gaining a thorough grasp of the drivers and effects of regulatory risks, businesses and policymakers can devise more effective risk assessment and management strategies, which are crucial for upholding robust cybersecurity in a fluid regulatory landscape.","In the intricate and perpetually shifting landscape of cybersecurity investments, regulatory fluctuations pose a substantial threat, as they can significantly influence an organization's response tactics. Although cybersecurity regulations strive to reduce cyber threats and bolster defenses, the ambiguity stemming from frequent revisions or novel regulations can have a profound impact on strategic planning. This study examines the underlying factors and consequences of regulatory risks tied to cybersecurity, seeking to provide a more nuanced understanding of how these risks shape strategic decision-making processes. The research investigates the proposal of proactive and mitigating measures that enable businesses to adapt to and counter potential disruptions triggered by regulatory changes, thereby preserving their established cybersecurity protocols. A key innovation of this study is the development of a probabilistic econometric model that demonstrates how regulatory risks and uncertainties can influence investment behaviors, often prompting a cautious ""wait-and-see"" approach. This model distills the intricate interplay among investment decisions, regulatory shifts, and cybersecurity risks, offering insights into the dynamic nature of cybersecurity investment strategies. The research findings provide actionable guidance for risk management and strategic planning in cybersecurity investments. By gaining a comprehensive understanding of the drivers and impacts of regulatory risks, businesses and policymakers can develop more effective risk assessment and management strategies, which is crucial for maintaining a robust cybersecurity stance amidst the evolving regulatory landscape.","Investing in cybersecurity takes place amidst a dynamic and intricate landscape where shifting regulatory frameworks pose a considerable challenge. Although cybersecurity regulations seek to curb cyber threats and bolster security, the ambiguity stemming from their frequent modifications or emergence can substantially influence how organizations respond. This research examines the factors driving and the consequences of regulatory risks in cybersecurity, striving to provide a more nuanced comprehension of how such risks shape strategic choices. The study probes into proactive and reactive measures that empower businesses to acclimate to and alleviate potential disruptions caused by regulatory shifts, thus safeguarding their established cybersecurity protocols. Furthermore, this work introduces a probabilistic economic model illustrating how regulatory risks and ambiguities can impact investment conduct, often encouraging a cautious approach. This model captures the intricate interplay between investment decisions, regulatory adjustments, and cybersecurity threats, offering insights into the dynamic character of cybersecurity investment strategies. The results provide valuable direction for risk mitigation and strategic planning in cybersecurity investments. By thoroughly grasping the drivers and repercussions of regulatory risks, businesses and policymakers can formulate more effective risk assessment and management methodologies. This is crucial for maintaining a robust cybersecurity stance while navigating the evolving regulatory landscape.",acceptable,acceptable,acceptable,3.6,3.6,3.6
160,Cybersecurity knowledge graphs construction and quality assessment,"Cyber-attack activities are complex and ever-changing, posing severe challenges to cybersecurity personnel. Introducing knowledge graphs into the field of cybersecurity helps depict the intricate cybersecurity landscape and provides technical support for threat identification and situational awareness. However, during the process of constructing knowledge graphs, inevitable noise and conflicts may be introduced, leading to misleading inferences and decisions. This paper aims to address the issues of constructing and assessing the quality of cybersecurity knowledge graphs. We manually constructed a dataset of cybersecurity knowledge graphs (CS13K) and expanded the existing cybersecurity ontology, building a more versatile ontology applicable to existing data features. Building upon this, we utilized Neo4j to construct the cybersecurity knowledge graph. Furthermore, we propose an AttTucker model, based on Transformer, for assessing the quality of knowledge graphs. By employing numerous self-attention heads, this model captures latent information among entities and relations. While reducing the dimensionality of knowledge embeddings, the model achieves evaluation results comparable to high-dimensional embeddings. Finally, we incorporate the path-level information between entities in the knowledge graph into the evaluation of knowledge graph quality based on the AttTucker model. Experimental analysis on both generic datasets and cybersecurity datasets demonstrates that our model significantly improves F1 value and accuracy in knowledge graph quality assessment tasks, outperforming other models.","Cyber-attacks are intricate and constantly evolving, presenting significant challenges to cybersecurity professionals. Implementing knowledge graphs in cybersecurity aids in mapping out the complex cybersecurity environment and offers technical support for threat detection and situational understanding. However, building these graphs often introduces unavoidable noise and inconsistencies, which can result in erroneous inferences and decisions. This study focuses on the creation and quality assessment of cybersecurity knowledge graphs. We manually created a dataset named CS13K and expanded the current cybersecurity ontology to develop a more adaptable ontology suitable for existing data characteristics. Using Neo4j, we constructed the cybersecurity knowledge graph. Additionally, we introduce the AttTucker model, based on the Transformer architecture, for evaluating the quality of knowledge graphs. This model leverages multiple self-attention heads to uncover hidden information among entities and relationships. By reducing the dimensionality of knowledge embeddings, it achieves evaluation results on par with high-dimensional embeddings. Moreover, we integrate path-level information among entities within the knowledge graph into the quality assessment using the AttTucker model. Experimental results on both general and cybersecurity-specific datasets show that our model considerably enhances the F1 score and accuracy in knowledge graph quality assessment tasks, surpassing other models.","The dynamic and intricate nature of cyber-attack operations creates substantial hurdles for cybersecurity experts, necessitating innovative solutions to navigate the labyrinthine cybersecurity terrain. The integration of knowledge graphs into cybersecurity frameworks facilitates a more nuanced understanding of the threat landscape, enabling enhanced threat detection and situational awareness capabilities. However, the construction of these graphs can be marred by the introduction of errors and inconsistencies, leading to flawed inferences and decisions. This study seeks to address the challenges of building and evaluating the quality of cybersecurity knowledge graphs. To this end, we created a manually curated dataset of cybersecurity knowledge graphs (CS13K) and expanded an existing cybersecurity ontology, yielding a more adaptable ontology that can be applied to diverse data features. Leveraging Neo4j, we constructed a comprehensive cybersecurity knowledge graph. Moreover, we developed an AttTucker model, grounded in Transformer architecture, to assess the quality of knowledge graphs. This model harnesses multiple self-attention mechanisms to uncover latent relationships between entities and relations, achieving comparable performance to high-dimensional embeddings while reducing dimensionality. Furthermore, we incorporated path-level information between entities into the knowledge graph quality evaluation framework, leveraging the AttTucker model. Experimental results on both generic and cybersecurity datasets demonstrate that our model yields significant improvements in F1 score and accuracy, outperforming existing models in knowledge graph quality assessment tasks.","The dynamic and intricate nature of cyberattacks presents significant hurdles for cybersecurity experts. Knowledge graphs offer a powerful tool to visualize and understand this complex landscape, providing valuable support for recognizing threats and gaining situational awareness. However, the construction of these knowledge graphs can introduce inaccuracies and inconsistencies, potentially leading to flawed conclusions and actions. This work focuses on tackling the challenges of creating and evaluating the reliability of cybersecurity knowledge graphs. A manually curated dataset of cybersecurity knowledge graphs (CS13K) was developed, and the existing cybersecurity ontology was broadened to enhance its applicability to existing data characteristics. Leveraging Neo4j, a cybersecurity knowledge graph was then constructed. To assess the quality of these graphs, an innovative AttTucker model based on the Transformer architecture is proposed. This model employs multiple self-attention mechanisms to discern hidden relationships between entities and relations. Remarkably, it achieves comparable evaluation results to high-dimensional embeddings while effectively reducing dimensionality. Furthermore, path-level information between entities is integrated into the AttTucker model for enhanced knowledge graph quality assessment. Rigorous testing on both general and cybersecurity datasets reveals that this model significantly enhances F1 value and accuracy in evaluating knowledge graph quality, surpassing the performance of other models.",acceptable,acceptable,acceptable,3.2,3.2,3.2
161,Cybersecurity knowledge graphs,"Cybersecurity knowledge graphs, which represent cyber-knowledge with a graph-based data model, provide holistic approaches for processing massive volumes of complex cybersecurity data derived from diverse sources. They can assist security analysts to obtain cyberthreat intelligence, achieve a high level of cyber-situational awareness, discover new cyber-knowledge, visualize networks, data flow, and attack paths, and understand data correlations by aggregating and fusing data. This paper reviews the most prominent graph-based data models used in this domain, along with knowledge organization systems that define concepts and properties utilized in formal cyber-knowledge representation for both background knowledge and specific expert knowledge about an actual system or attack. It is also discussed how cybersecurity knowledge graphs enable machine learning and facilitate automated reasoning over cyber-knowledge.","Cybersecurity knowledge graphs, employing a graph-based data framework to depict cyber-information, provide comprehensive strategies for handling large volumes of intricate cybersecurity data from various origins. They aid security analysts in acquiring cyberthreat intelligence, enhancing cyber-situational awareness, discovering novel cyber-insights, visualizing networks, data movements, and attack trajectories, and discerning data relationships through the integration and amalgamation of information. This paper examines the foremost graph-based data frameworks utilized in this field and the knowledge organization systems that define the concepts and attributes employed in formal cybersecurity knowledge representation for both foundational knowledge and specialized expert insight regarding actual systems or attacks. Additionally, it explores how cybersecurity knowledge graphs support machine learning and bolster automated reasoning in relation to cyber-information.","Graph-structured cybersecurity repositories, which encapsulate complex cyber-information within a network-based framework, offer comprehensive solutions for handling enormous amounts of heterogeneous cybersecurity data emanating from varied sources. By leveraging these repositories, security experts can glean actionable threat insights, attain enhanced situational awareness, uncover novel cyber-insights, illustrate network topologies, data trajectories, and attack vectors, and discern correlations among data points through aggregation and fusion. This study surveys the most influential graph-based frameworks employed in this realm, alongside knowledge taxonomy systems that delineate concepts and attributes utilized in formal cyber-knowledge codification for both foundational knowledge and specialized expertise pertaining to specific systems or attacks. Furthermore, it explores how cybersecurity knowledge graphs facilitate machine learning applications and enable automated inference across cyber-knowledge domains.","Cybersecurity knowledge graphs, employing a graph-structured data model to depict cyber-related information, offer comprehensive methodologies for managing vast amounts of intricate cybersecurity data originating from various sources. These graphs empower security professionals to extract cyberthreat intelligence, attain heightened cyber-situational awareness, uncover novel cyber insights, generate visualizations of networks, data flows, and attack vectors, and discern data correlations through aggregation and fusion. This study examines the prevailing graph-based data models employed in the cybersecurity realm, alongside knowledge organization systems that delineate concepts and attributes employed in formal cyber-knowledge representation, encompassing both foundational knowledge and specialized expert knowledge concerning specific systems or attacks. Additionally, the paper explores how cybersecurity knowledge graphs enable machine learning applications and streamline automated reasoning processes applied to cyber-knowledge.",acceptable,acceptable,acceptable,4.2,3.2,3.6
162,Recommender Systems in Cybersecurity,"With the growth of CyberTerrorism, enterprises worldwide have been struggling to stop intruders from obtaining private data. Despite the efforts made by Cybersecurity experts, the shortage of skillful security teams and the usage of intelligent attacks have slowed down the enhancement of defense mechanisms. Furthermore, the pandemic in 2020 forced organizations to work in remote environments with poor security, leading to increased cyberattacks. One possible solution for these problems is the implementation of Recommender Systems to assist Cybersecurity human operators. Our goal is to survey the application of Recommender Systems in Cybersecurity architectures. These decision-support tools deal with information overload through filtering and prioritization methods, allowing businesses to increase revenue, achieve better user satisfaction, and make faster and more efficient decisions in various domains (e-commerce, healthcare, finance, and other fields). Several reports demonstrate the potential of using these recommendation structures to enhance the detection and prevention of cyberattacks and aid Cybersecurity experts in treating client incidents. This survey discusses several studies where Recommender Systems are implemented in Cybersecurity with encouraging results. One promising direction explored by the community is using Recommender Systems as attack predictors and navigation assistance tools. As contributions, we show the recent efforts in this area and summarize them in a table. Furthermore, we provide an in-depth analysis of potential research lines. For example, the inclusion of Recommender Systems in security information event management systems and security orchestration, automation, and response applications could decrease their complexity and information overload.","As CyberTerrorism expands, businesses globally are grappling with thwarting unauthorized access to confidential information. Although Cybersecurity professionals have exerted considerable effort, a lack of skilled security personnel and the deployment of sophisticated attacks have hindered advancements in defense strategies. Additionally, the 2020 pandemic compelled organizations to operate remotely with inadequate security, resulting in a surge of cyberattacks. One potential remedy to these challenges is the adoption of Recommender Systems to support Cybersecurity personnel. Our objective is to review the use of Recommender Systems within Cybersecurity frameworks. These decision-support mechanisms manage information overload through filtering and prioritization techniques, enabling companies to boost revenue, enhance user satisfaction, and make quicker, more effective decisions across various sectors such as e-commerce, healthcare, and finance. Several studies highlight the promise of employing these recommendation systems to improve cyberattack detection and prevention, as well as to assist Cybersecurity experts in managing client incidents. This review examines various research where Recommender Systems have been successfully incorporated into Cybersecurity with positive outcomes. A notable direction investigated by the field is the application of Recommender Systems as tools for predicting attacks and facilitating navigation. Our contributions include presenting recent advances in this domain and summarizing them in a table. Additionally, we offer a comprehensive analysis of potential research directions. For instance, integrating Recommender Systems into security information and event management systems and security orchestration, automation, and response applications could reduce their complexity and information burden.","As the menace of CyberTerrorism escalates, global enterprises are grappling to thwart unauthorized access to sensitive information. Despite the endeavors of Cybersecurity specialists, the scarcity of adept security professionals and the employment of sophisticated attack vectors have hindered the advancement of defensive countermeasures. The 2020 pandemic further exacerbated the issue, as organizations were compelled to operate in remote settings with inadequate security infrastructure, thereby precipitating a surge in cyberattacks. A potential panacea for these challenges lies in the integration of Recommender Systems to augment the capabilities of human Cybersecurity operators. Our objective is to conduct a comprehensive review of the applications of Recommender Systems within Cybersecurity frameworks. These decision-support tools mitigate information overload by leveraging filtering and prioritization techniques, thereby enabling businesses to boost revenue, enhance user experience, and make swift and informed decisions across diverse domains, including e-commerce, healthcare, finance, and others. Various reports have demonstrated the efficacy of these recommendation structures in bolstering the detection and prevention of cyberattacks, as well as facilitating the incident response capabilities of Cybersecurity experts. This survey examines multiple studies that have successfully implemented Recommender Systems in Cybersecurity, yielding promising outcomes. A notable area of exploration involves the utilization of Recommender Systems as predictive tools for attack forecasting and navigational aids. Our contributions include a summary of recent advancements in this field, presented in a tabular format, as well as an in-depth examination of potential avenues for future research, such as the incorporation of Recommender Systems into security information event management systems and security orchestration, automation, and response applications to alleviate complexity and information overload.","The rise of cyber threats poses a significant challenge for organizations globally, as they strive to safeguard sensitive information. Despite the expertise of cybersecurity professionals, the scarcity of skilled security personnel and the increasing sophistication of cyberattacks have hindered the development of robust defense strategies. The shift to remote work environments during the 2020 pandemic, often characterized by inadequate security measures, further exacerbated the vulnerability to cyberattacks. A promising approach to address these challenges lies in the integration of recommender systems to support cybersecurity experts. This review explores the implementation of recommender systems within cybersecurity frameworks. These decision-support tools effectively manage information overload through filtering and prioritization techniques, empowering businesses across various sectors, including e-commerce, healthcare, and finance, to enhance revenue, improve user satisfaction, and expedite decision-making processes. Numerous studies highlight the potential of recommender systems in bolstering cyberattack detection and prevention efforts, providing valuable assistance to cybersecurity professionals in handling security incidents. This survey examines various research endeavors where recommender systems have been successfully applied in cybersecurity, demonstrating promising outcomes. Notably, the use of recommender systems for attack prediction and navigation assistance has emerged as a significant area of exploration within the research community. This review provides a comprehensive overview of recent advancements in this field, summarizing key findings in a table format. Additionally, it delves into potential avenues for future research, such as the integration of recommender systems into security information and event management systems and security orchestration, automation, and response applications, aiming to mitigate their complexity and address information overload challenges.",acceptable,acceptable,acceptable,3.2,3.2,3.2
163,Design tactics for tailoring transformer architectures to cybersecurity challenges,"In the rapidly evolving landscape of cyber threats, effective defense strategies are crucial for safeguarding sensitive information and critical systems. Deep learning methods, notably the Transformer architecture, have shown immense potential in addressing cybersecurity challenges. However, customizing, and adapting Transformer architectures for cybersecurity applications presents a challenge, demanding the utilization of effective strategies to achieve optimal performance. This study presents a comprehensive analysis of design tactics employed in tailoring Transformer architectures specifically for cybersecurity problems. Design tactics, defined as strategic solutions to architectural challenges based on well-justified design decisions, are explored in-depth within the context of cybersecurity. By examining the modifications and adaptations made to the original Transformer architecture, this study unveils the design decisions and strategies crucial for successful implementation in diverse cybersecurity domains. The findings emphasize the significance of aligning design tactics with the unique business requirements and quality factors of each specific application domain. This study contributes valuable insights into the utilization of design tactics for customizing Transformer architectures in cybersecurity, paving the way for enhanced defense strategies against the dynamic and evolving nature of cyber threats.","In the swiftly changing realm of cyber threats, robust defense tactics are essential for protecting sensitive data and critical infrastructure. Deep learning techniques, particularly the Transformer model, have demonstrated vast promise in tackling cybersecurity issues. Nevertheless, personalizing and fine-tuning Transformer models for cybersecurity purposes is challenging, necessitating the deployment of impactful strategies to attain peak performance. This research offers an extensive review of the design approaches used to customize Transformer models specifically for cybersecurity challenges. Defined as strategic solutions to architectural issues grounded in well-reasoned design choices, design approaches are thoroughly examined within the cybersecurity context. Through scrutinizing the adjustments and modifications applied to the original Transformer model, this research reveals the design choices and strategies vital for effective implementation across different cybersecurity sectors. The findings underscore the importance of aligning design approaches with the distinct business needs and quality aspects of each application area. This research provides crucial insights into employing design strategies for adapting Transformer models in cybersecurity, thus laying the foundation for improved defensive mechanisms against the ever-changing and dynamic nature of cyber threats.","In the face of escalating cyber threats, robust defense mechanisms are vital for protecting sensitive data and critical infrastructure. The application of deep learning techniques, particularly the Transformer model, has demonstrated remarkable promise in mitigating cybersecurity risks. Nevertheless, adapting and fine-tuning Transformer models for cybersecurity purposes poses a significant hurdle, necessitating the development of innovative approaches to achieve peak performance. This research undertakes a thorough examination of the design strategies employed in modifying Transformer models to tackle cybersecurity issues. By delving into the modifications and refinements made to the original architecture, this study reveals the pivotal design decisions and tactics essential for successful deployment across diverse cybersecurity domains. The findings underscore the importance of tailoring design strategies to the distinct business needs and quality metrics of each specific application domain, ultimately informing the development of more effective defense mechanisms against the ever-evolving landscape of cyber threats.","Within the swiftly changing world of digital security risks, robust defense mechanisms are vital to protect confidential data and essential infrastructure. Advanced machine learning techniques, particularly the Transformer model, have demonstrated significant promise in tackling cybersecurity issues. Nevertheless, tailoring and refining Transformer models for specific security applications poses a significant hurdle, requiring the implementation of effective strategies to reach peak performance. This research offers a thorough examination of design approaches employed in customizing Transformer architectures specifically for cybersecurity challenges. These design approaches, defined as strategic solutions to architectural issues grounded in well-supported design choices, are explored in detail within the cybersecurity context. Through analyzing the adjustments and modifications made to the original Transformer model, this study reveals the design choices and strategies vital for successful deployment across various cybersecurity domains. The results underscore the importance of aligning design approaches with the specific business needs and quality standards of each individual application area. This research provides valuable knowledge about using design approaches to personalize Transformer architectures for cybersecurity purposes, ultimately strengthening defense strategies against the ever-changing landscape of cyber threats.",acceptable,acceptable,acceptable,3.8,3.6,3.6
164,Spreading cybersecurity awareness via gamification: zero-day game,"This research project aims to increase the employees' cybersecurity awareness by proposing a training program that consists of pre-game and post-game phishing attacks, pre-game and post-game surveys, and an interactive zero-day game with embedded threat scenarios. Furthermore, we propose five flowcharts that simulate common cyberattacks. The zero-day game consists of five levels. The first level trains employees in using complex passwords. Two levels cover the social engineering attacks: one level trains employees about suspicious links and online survey tricks, while the other level trains players about the organization's security policies. The fourth level educates employees about malware spread via repackaged fake applications. The last level educates employees about phishing email attacks. Furthermore, we developed a chatbot inside the game to aid users in playing the different game levels. Additionally, two surveys and two phishing attacks are carried out to assess the employees' knowledge level of cybersecurity threats. The zero-day cybersecurity awareness program is applied to twenty-three employees. Experimental results indicate that the zero-day cybersecurity awareness program is more engaging and effective than traditional awareness programs. Results also indicate that the proposed program accurately measures and improves the employees' cybersecurity awareness level.","This study seeks to enhance employee cybersecurity awareness by implementing a training initiative that includes pre- and post-game phishing simulations, surveys, and an interactive zero-day game featuring embedded threat scenarios. Additionally, we introduce five flowcharts to illustrate typical cyberattacks. The zero-day game comprises five stages: the initial stage teaches complex password usage; two stages focus on social engineering, instructing employees on identifying suspicious links, online survey scams, and understanding the organization's security policies; the fourth stage addresses malware dissemination through repackaged fake apps; and the final stage covers phishing email training. We also integrated a chatbot within the game to support users through the different stages. Moreover, two surveys and phishing attempts are conducted to evaluate the employees' cybersecurity threat awareness. This zero-day program was applied to twenty-three employees, with experimental data showing it to be more engaging and effective compared to traditional training methods. The findings also show that the program effectively measures and enhances the employees' cybersecurity awareness.","This study seeks to enhance workforce cybersecurity literacy by introducing a comprehensive training initiative, comprising pre- and post-intervention phishing simulations, surveys, and an immersive zero-day gaming experience featuring embedded threat scenarios. Additionally, five flowcharts are proposed to mimic prevalent cyber threats. The zero-day game is structured into five tiers, with the inaugural level focusing on complex password management, followed by two levels addressing social engineering tactics, including suspicious links and organizational security protocols. The fourth tier educates participants about malware dissemination through repackaged fake applications, while the final tier concentrates on phishing email attacks. A built-in chatbot is integrated into the game to facilitate user navigation. To evaluate employee knowledge of cybersecurity threats, two surveys and two phishing simulations are conducted. The zero-day cybersecurity awareness program is piloted among twenty-three employees, with experimental findings suggesting that this approach is more captivating and effective than traditional awareness initiatives, accurately assessing and improving employee cybersecurity awareness.","This study endeavors to enhance employee cybersecurity awareness through a novel training program. This program utilizes a multi-faceted approach, incorporating simulated phishing attacks both before and after training, pre- and post-training surveys to gauge knowledge, and an interactive, multi-level ""zero-day"" game designed to immerse employees in realistic threat scenarios. Five distinct flowcharts are also introduced to illustrate common cyberattack methods. The zero-day game is structured across five levels, each addressing specific cybersecurity skills. The initial level focuses on building robust password practices. Two levels are devoted to social engineering, with one emphasizing suspicious link and online survey recognition, and the other highlighting organizational security policies. The fourth level tackles malware dissemination through deceptive applications, while the final level centers on recognizing and avoiding phishing emails. An in-game chatbot provides support and guidance to players navigating the various levels. To evaluate the program's impact on cybersecurity knowledge, two phishing exercises and surveys are conducted. This zero-day awareness program was implemented with a group of 23 employees. Findings suggest this program fosters greater engagement and effectiveness compared to conventional awareness training, accurately measuring and enhancing employee cybersecurity awareness.",acceptable,acceptable,acceptable,3.6,3.2,3.2
165,Should firms invest more in cybersecurity?,"We combine unique survey data on IT use and administrative tax record data on Dutch firms to understand how cybersecurity investments relate to the probability of cyber incidents and firm profitability. This dataset allows us to control for firm size, industry, and IT organization. We construct a new indicator to measure the degree of cyber maturity of firms and find that this maturity level tends to increase with firm size. Regression analyses suggest that the relation between maturity level and probability of a cyber incident is inverted U-shaped: a higher maturity level is initially associated with a higher incident probability, but the highest maturity level is associated with fewer reported incidents. This finding is consistent with the hypothesis that basic cybersecurity measures enable better detection of incidents and more sophisticated measures help to prevent incidents. We do not find, however, evidence for a positive relation between cybersecurity measures and profits.","We integrate distinct survey data regarding IT usage with administrative tax record data on Dutch companies to investigate the link between cybersecurity investments, the likelihood of cyber incidents, and company profitability. This dataset permits us to adjust for factors such as company size, industry, and IT infrastructure. We create a novel metric to gauge firms' cyber maturity and observe that larger firms typically exhibit higher levels of maturity. Our regression analysis indicates an inverted U-shaped relationship between cyber maturity and the likelihood of a cyber incident: as maturity levels increase, the probability of an incident initially rises but subsequently declines at the highest maturity levels. This observation aligns with the hypothesis that basic cybersecurity measures improve incident detection, whereas advanced measures contribute to incident prevention. However, we do not find evidence to support a positive correlation between cybersecurity measures and profitability.","By integrating distinctive survey insights on IT adoption with administrative tax records for Dutch companies, we examine the correlation between investments in cybersecurity and the likelihood of cyber breaches, as well as their impact on business profitability. This comprehensive dataset enables us to account for variations in company scale, sector, and IT infrastructure. We develop a novel metric to assess the cybersecurity sophistication of firms, revealing a positive correlation with company size. Our regression models indicate that the relationship between cybersecurity sophistication and incident probability follows an inverted U-curve, where higher maturity initially corresponds to increased incident likelihood, but the most advanced maturity levels are associated with fewer reported breaches. This outcome supports the notion that fundamental cybersecurity measures facilitate improved incident detection, while more advanced measures contribute to incident prevention. However, our analysis does not uncover a significant link between cybersecurity investments and enhanced profitability.","Leveraging a novel dataset that integrates survey responses regarding IT utilization with administrative tax records of Dutch companies, this study investigates the connection between cybersecurity expenditures, the likelihood of cyberattacks, and firm profitability. The dataset's richness enables us to account for variations in firm scale, industry, and IT infrastructure. A novel metric, quantifying the level of cyber preparedness within firms, was developed, revealing a positive correlation between this maturity level and firm size. Regression models indicate an inverted U-shaped relationship between cyber maturity and the probability of cyber incidents: initial increases in maturity correspond with a heightened incident probability, but the most mature firms report fewer incidents. This aligns with the theory that rudimentary cybersecurity practices enhance incident detection, while sophisticated measures focus on prevention. However, our analysis fails to identify a positive association between cybersecurity investments and profitability.",acceptable,acceptable,acceptable,3.2,3.2,3.2
166,Perceptions of organizational responsibility for cybersecurity in Saudi Arabia: a moderated mediation analysis,"The study aims to explore the crucial interaction between organizational responsibility and employee behavior in cybersecurity, particularly in the distinct setting of Saudi Arabia. It investigates how organizational responsibility perceptions impact employee attitudes and practices towards cybersecurity. The research utilizes a mixed theoretical framework, incorporating stewardship theory, protection motivation theory, and the theory of planned behavior. It examines the intricate link between organizational leadership, policies, and individual responses to cybersecurity threats through a comprehensive survey conducted among Saudi employees. The study discovers that employees’ perceptions of organizational responsibility greatly influence their cybersecurity behavior. It also finds that employee attitudes towards cybersecurity act as a mediator in this relationship. Contrary to expectations, personal experiences with cybersecurity incidents do not significantly moderate these relationships. This underlines the complex and culture-specific nature of cybersecurity compliance in organizational contexts. This research uniquely contributes to the understanding of cybersecurity behavior within organizations, particularly highlighting the need for policies that align with both organizational objectives and individual behaviors in culturally specific environments like Saudi Arabia. It offers novel insights into the less pronounced impact of personal cybersecurity experiences on organizational-employee dynamics in cybersecurity compliance.","The research aims to delve into the essential relationship between organizational responsibility and employee behavior in cybersecurity, focusing specifically on the unique context of Saudi Arabia. It examines how perceptions of organizational responsibility affect employee attitudes and actions towards cybersecurity. The study employs a combined theoretical framework, including stewardship theory, protection motivation theory, and the theory of planned behavior. It investigates the complex relationship between organizational leadership, policies, and individual reactions to cybersecurity threats through an extensive survey conducted among Saudi employees. The findings reveal that how employees perceive organizational responsibility significantly influences their cybersecurity behavior. It also reveals that employee attitudes toward cybersecurity act as a mediator in this relationship. Surprisingly, personal experiences with cybersecurity incidents do not significantly moderate these relationships, highlighting the intricate and culturally specific nature of cybersecurity compliance in organizational settings. This research offers a unique contribution to the understanding of cybersecurity behavior within organizations, emphasizing the necessity for policies that harmonize organizational goals with individual behaviors in culturally specific environments like Saudi Arabia. It provides new insights into the less significant impact of personal cybersecurity experiences on the dynamics between organizations and employees regarding cybersecurity compliance.","This investigation delves into the pivotal dynamic between an organization's sense of accountability and its employees' conduct in the realm of cybersecurity, with a specific focus on the Saudi Arabian context. It analyzes how employees' perceptions of their organization's responsibility shape their outlook and actions regarding cybersecurity. By integrating elements of stewardship theory, protection motivation theory, and the theory of planned behavior, this research provides a nuanced understanding of the intricate relationships between organizational governance, policies, and individual reactions to cybersecurity threats. A comprehensive survey of Saudi employees reveals that their perceptions of organizational accountability exert a profound influence on their cybersecurity practices. Furthermore, employee attitudes towards cybersecurity are found to play a mediating role in this relationship. Notably, personal experiences with cybersecurity breaches do not significantly affect these dynamics. This underscores the culturally contingent and complex nature of cybersecurity adherence within organizational settings. This study makes a distinctive contribution to our comprehension of cybersecurity behavior within organizations, emphasizing the need for policies that reconcile organizational goals with individual behaviors in culturally specific environments like Saudi Arabia. It also offers fresh perspectives on the relatively limited impact of personal cybersecurity experiences on organizational-employee interactions in cybersecurity compliance.","This research delves into the dynamic interplay between organizational accountability for cybersecurity and the resulting actions of employees within the unique cultural context of Saudi Arabia. Employing a multifaceted theoretical lens, drawing from stewardship, protection motivation, and planned behavior theories, the study examines how employee perceptions of organizational responsibility shape their cybersecurity attitudes and practices. Through an extensive survey of Saudi employees, the intricate connections between organizational leadership, policies, and individual responses to cyber threats are investigated. The findings reveal a strong influence of perceived organizational responsibility on employee cybersecurity behavior, with attitudes towards cybersecurity serving as a mediating factor. Unexpectedly, personal encounters with cybersecurity incidents did not demonstrably alter these relationships. This highlights the nuanced and culturally-shaped nature of cybersecurity adherence within organizational settings. This work offers a fresh perspective on cybersecurity behavior in organizations, emphasizing the necessity for policies that harmonize organizational goals with individual actions, particularly within culturally distinct environments such as Saudi Arabia. The study's novel contribution lies in illuminating the surprisingly limited impact of personal cybersecurity experiences on the interplay between organizational responsibility and employee behavior in maintaining cybersecurity.",acceptable,acceptable,acceptable,3.6,3.6,3.2
167,How the three lines of defense can contribute to public firms’ cybersecurity effectiveness,"This interpretative field study examines how public firms deal with cybersecurity-related issues, emphasizing how the three lines of defense can contribute to cybersecurity effectiveness. Sixteen interviews were conducted with 18 participants, including 13 executives/senior managers in internal audit, information technology (IT), and information security (IS) in 13 different public firms. The many cybersecurity structures, processes, or relational mechanisms established by the three lines of defense in the participating organizations are identified. These governance mechanisms are used as a baseline for analyzing how teams in internal audit, IT, IS, cybersecurity, legal, finance, corporate communications, and environmental, social and governance (ESG) are engaged and collaborate in dealing with cybersecurity-related issues. This study entered into the “black box” to document how different organizational functions are involved in IT/IS governance mechanisms associated with cybersecurity. Findings can help board of directors and management reflect on the nature of cybersecurity activities that could be implemented to enhance cybersecurity effectiveness. Regulators may consider the issues raised by participants to clarify regulations about cybersecurity disclosure.","This interpretive field study explores the management of cybersecurity issues within public companies, focusing on the role of the three lines of defense in enhancing cybersecurity efficiency. The research included 16 interviews with 18 participants, notably 13 executives and senior managers across internal audit, IT, and information security sectors from 13 different public firms. The study identifies various cybersecurity frameworks, procedures, and relational mechanisms put in place by the three lines of defense within these organizations. These governance frameworks serve as a foundation for assessing the involvement and cooperation of teams from internal audit, IT, IS, cybersecurity, legal, finance, corporate communications, and ESG sectors in addressing cybersecurity challenges. The research delves into the organizational intricacies to document the participation of various functions in IT/IS governance mechanisms pertinent to cybersecurity. The findings offer insights for board members and management to contemplate potential cybersecurity measures to boost effectiveness. Moreover, regulators may consider the participants' concerns to refine cybersecurity disclosure regulations.","This in-depth, qualitative investigation delves into the strategies employed by publicly traded companies to address cybersecurity concerns, with a particular focus on the pivotal role of the three-tiered defense framework in bolstering cybersecurity resilience. Through a series of 16 in-depth interviews with 18 key stakeholders, including 13 high-ranking executives and senior managers from internal audit, IT, and IS departments across 13 distinct public firms, this study uncovers the diverse range of cybersecurity architectures, protocols, and relational dynamics established by the three lines of defense within participating organizations. By examining these governance structures as a benchmark, this research analyzes the collaborative efforts and engagement of cross-functional teams from internal audit, IT, IS, cybersecurity, legal, finance, corporate communications, and ESG in responding to cybersecurity threats. This study provides a rare glimpse into the inner workings of IT/IS governance mechanisms related to cybersecurity, shedding light on the intricate dynamics of organizational functions involved in these processes. The findings of this study offer valuable insights for boards of directors and management to reassess the scope of cybersecurity initiatives that can be implemented to enhance cybersecurity effectiveness, while also providing regulators with a framework to refine disclosure regulations related to cybersecurity.","This qualitative research explores how publicly traded companies address cybersecurity concerns, focusing on the role of the three lines of defense model in achieving effective cybersecurity posture. Through in-depth interviews with eighteen individuals, including thirteen executives and senior managers from internal audit, IT, and IS departments across thirteen distinct public companies, this study identifies various cybersecurity structures, processes, and relational mechanisms established by the three lines of defense within these organizations. Utilizing these governance mechanisms as a foundation, the research analyzes the engagement and collaboration of teams from various functions, such as internal audit, IT, IS, cybersecurity, legal, finance, corporate communications, and ESG, in managing cybersecurity challenges. By delving into the inner workings of these organizations, the study reveals how diverse organizational functions participate in IT/IS governance mechanisms related to cybersecurity. The findings provide valuable insights for boards of directors and management to consider in implementing cybersecurity measures to enhance organizational resilience. Additionally, regulators can leverage the concerns raised by participants to refine regulations concerning cybersecurity disclosure.",acceptable,acceptable,acceptable,3.6,3.2,3.6
168,Towards NICE-by-Design Cybersecurity Learning Environments: A Cyber Range for SOC Teams,"Cybersecurity has become an increasingly important field as cyber threats continue to grow in number and complexity. The NICE framework, developed by NIST, provides a structured approach to cybersecurity education. Despite the publication of cybersecurity frameworks, scenario design in cybersecurity is not yet governed by structured design principles, leading to ambiguous learning outcomes. This research uses the NICE framework to provide structure design and development of a cyber range and the relevant scenarios. The proposed methodology and research results can assist the scenario design in cybersecurity and as a methodological procedure for evaluation. Finally, the research provides a better understanding of the NICE framework and demonstrates how it can assist in creating practical cybersecurity scenarios.","The field of cybersecurity has gained critical importance due to the rising number and complexity of cyber threats. The NICE framework created by NIST offers a systematic method for cybersecurity education. Despite available cybersecurity frameworks, the design of scenarios in this field lacks structured design principles, resulting in unclear learning outcomes. This study utilizes the NICE framework for the structured design and development of a cyber range and relevant scenarios. The proposed methodology and findings can aid in crafting cybersecurity scenarios and serve as a procedural guide for evaluation. Ultimately, this research enhances the understanding of the NICE framework and illustrates its role in developing effective cybersecurity scenarios.","The escalating menace of cyber attacks has catapulted cybersecurity to the forefront of critical concerns, necessitating a systematic approach to education and training. The NIST-developed NICE framework offers a cohesive blueprint for cybersecurity education, yet the design of scenario-based learning experiences remains largely unstandardized, resulting in unclear learning objectives. This study leverages the NICE framework to establish a structured methodology for developing cyber ranges and associated scenarios, yielding a novel approach to evaluating scenario design in cybersecurity. The findings of this research contribute to a deeper understanding of the NICE framework's applicability in crafting practical, real-world cybersecurity scenarios, while also providing a procedural roadmap for assessment and evaluation.","With the rising prevalence and sophistication of cyber threats, the importance of cybersecurity has skyrocketed. NIST's NICE framework offers a systematic approach to cybersecurity education. However, despite the existence of such frameworks, scenario design in cybersecurity lacks structured principles, resulting in unclear learning outcomes. This study utilizes the NICE framework to guide the structured design and development of a cyber range and its corresponding scenarios. The proposed methodology and research findings can inform cybersecurity scenario design and serve as an evaluation procedure. Ultimately, this research deepens our comprehension of the NICE framework and showcases its applicability in crafting practical cybersecurity scenarios.",acceptable,acceptable,acceptable,3.6,3.2,3.6
169,Cybersecurity considerations for radiology departments involved with artificial intelligence,"AbstractRadiology artificial intelligence (AI) projects involve the integration of integrating numerous medical devices, wireless technologies, data warehouses, and social networks. While cybersecurity threats are not new to healthcare, their prevalence has increased with the rise of AI research for applications in radiology, making them one of the major healthcare risks of 2021. Radiologists have extensive experience with the interpretation of medical imaging data but radiologists may not have the required level of awareness or training related to AI-specific cybersecurity concerns. Healthcare providers and device manufacturers can learn from other industry sector industries that have already taken steps to improve their cybersecurity systems. This review aims to introduce cybersecurity concepts as it relates to medical imaging and to provide background information on general and healthcare-specific cybersecurity challenges. We discuss approaches to enhancing the level and effectiveness of security through detection and prevention techniques, as well as ways that technology can improve security while mitigating risks. We first review general cybersecurity concepts and regulatory issues before examining these topics in the context of radiology AI, with a specific focus on data, training, data, training, implementation, and auditability. Finally, we suggest potential risk mitigation strategies. By reading this review, healthcare providers, researchers, and device developers can gain a better understanding of the potential risks associated with radiology AI projects, as well as strategies to improve cybersecurity and reduce potential associated risks.Clinical Relevance StatementThis review can aid radiologists’ and related professionals’ understanding of the potential cybersecurity risks associated with radiology AI projects, as well as strategies to improve security.Key Points• Embarking on a radiology artificial intelligence (AI) project is complex and not without risk especially as cybersecurity threats have certainly become more abundant in the healthcare industry.• Fortunately healthcare providers and device manufacturers have the advantage of being able to take inspiration from other industry sectors who are leading the way in the field.• Herein we provide an introduction to cybersecurity as it pertains to radiology, a background to both general and healthcare-specific cybersecurity challenges; we outline general approaches to improving security through both detection and preventative techniques, and instances where technology can increase security while mitigating risks.Graphical Abstract","AbstractArtificial intelligence (AI) initiatives in radiology necessitate the integration of various medical devices, wireless technologies, data repositories, and social networks. Although cybersecurity threats in healthcare are longstanding, their frequency has surged with the ascension of AI applications in radiology, positioning them as one of the primary healthcare risks in 2021. Radiologists, while adept at interpreting medical imaging data, may lack sufficient awareness or training regarding the unique cybersecurity issues posed by AI. Healthcare professionals and device manufacturers can benefit from the cybersecurity advancements made in other industries to bolster their own security measures. This review introduces essential cybersecurity concepts specific to medical imaging and provides foundational knowledge on both general and healthcare-related cybersecurity challenges. We explore strategies for enhancing security through detection and prevention methods, and discuss how technology can augment security while reducing risk. Initially, we cover broad cybersecurity principles and regulatory aspects, then delve into their implications within radiology AI, emphasizing data handling, training, implementation, and auditability. Finally, we propose risk mitigation techniques. This review aims to enhance the understanding of healthcare providers, researchers, and device developers regarding the cybersecurity risks affiliated with radiology AI projects and suggests strategies for improving security and minimizing associated risks. Clinical Relevance StatementThis review is designed to help radiologists and associated professionals comprehend the potential cybersecurity threats linked to radiology AI projects and the strategies to enhance security. Key Points • Initiating a radiology AI project is intricate and fraught with risks, particularly as cybersecurity threats have proliferated in the healthcare sector. • Fortunately, healthcare professionals and device manufacturers can leverage lessons learned from other industries that are at the forefront of cybersecurity. • This document offers an overview of cybersecurity as it applies to radiology, a discussion on general and healthcare-specific cybersecurity challenges, and outlines methods to enhance security through both detection and prevention, along with how technology can safeguard against risks.","Here is a paraphrased version of the text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""The development of artificial intelligence (AI) projects in radiology necessitates the convergence of diverse medical devices, wireless technologies, data repositories, and social media platforms. As AI research in radiology continues to expand, the healthcare sector is confronted with an escalating threat landscape, with cybersecurity breaches emerging as a major risk in 2021. While radiologists possess extensive expertise in interpreting medical imaging data, they may lack the requisite knowledge and training to address AI-specific cybersecurity concerns. Healthcare providers and device manufacturers can draw valuable lessons from other industries that have successfully enhanced their cybersecurity infrastructure. This review seeks to elucidate cybersecurity principles in the context of medical imaging, providing an overview of general and healthcare-specific cybersecurity challenges. We explore strategies for bolstering security through detection and prevention mechanisms, as well as technological innovations that can mitigate risks while enhancing security. Following a review of general cybersecurity concepts and regulatory issues, we examine these topics in the context of radiology AI, focusing on data, training, implementation, and auditability. Finally, we propose potential risk mitigation strategies. By engaging with this review, healthcare providers, researchers, and device developers can gain a deeper understanding of the potential risks associated with radiology AI projects, as well as strategies to improve cybersecurity and reduce associated risks.""","The implementation of artificial intelligence (AI) in radiology necessitates the interconnection of diverse medical technologies, encompassing devices, wireless networks, data repositories, and social platforms. This surge in AI-driven radiology research has amplified cybersecurity vulnerabilities within the healthcare domain, elevating them to a critical concern in recent years. While radiologists possess vast expertise in medical image interpretation, they may lack sufficient awareness and training regarding the unique cybersecurity risks associated with AI. Fortunately, healthcare stakeholders can draw valuable insights from other sectors that have proactively fortified their cybersecurity infrastructure. This analysis aims to elucidate cybersecurity principles within the realm of medical imaging, providing a foundational understanding of broader cybersecurity concerns and those specific to healthcare. We explore methodologies to bolster security effectiveness through detection and prevention mechanisms, while also examining how technology can enhance security while mitigating risks. Our exploration begins with a review of fundamental cybersecurity concepts and regulatory frameworks, subsequently delving into their implications for radiology AI, emphasizing data security, training, implementation, and auditability. Lastly, we propose potential risk mitigation strategies. Through this comprehensive review, healthcare practitioners, researchers, and device manufacturers can cultivate a deeper comprehension of the potential hazards inherent in radiology AI projects, along with strategies to fortify cybersecurity and minimize associated risks.",acceptable,acceptable,acceptable,3.2,3.2,3.2
170,Cybersecurity disclosure in the banking industry: a comparative study,"The recurrence of cyberattacks on businesses in the last decade has attracted significant attention from policy makers and market participants to the importance of corporations’ responsibility and transparency on cybersecurity. In this study, we investigate cybersecurity disclosure made by the 48 largest Canadian and US banks from 2014 to 2020, using an exploratory qualitative approach. The banking industry has been a major target of cyberattacks due to the critical data that it contains. We first develop an index based on previous literature, current policies on cybersecurity disclosure and consultation with academics and practitioners. We then use the index to manually code bank reports related to cybersecurity. Afterward, we investigate the content of the disclosures in detail and discuss the level of compliance with the index. We then critically discuss banks’ disclosure behaviors using proprietary cost, signaling and legitimacy theories and provide recommendations for policy makers and other stakeholders.","Over the past ten years, the frequent cyberattacks on businesses have drawn significant attention from policymakers and market participants to the crucial aspects of corporate responsibility and transparency in cybersecurity. This research examines the cybersecurity disclosures of the 48 largest Canadian and US banks from 2014 to 2020, utilizing an exploratory qualitative methodology. The banking sector, holding critical information, has been a primary target for cyberattacks. Initially, we create an index based on prior studies, current cybersecurity disclosure policies, and consultations with academics and industry professionals. This index is then applied to manually encode the banks' cybersecurity reports. Subsequently, we analyze the disclosures in detail, assessing their compliance with the index. Finally, we critique the banks' disclosure practices through the lenses of proprietary cost, signaling, and legitimacy theories, and offer recommendations for policymakers and stakeholders.","Over the past decade, the persistent threat of cyberattacks on corporate entities has sparked intense scrutiny from regulatory bodies and market stakeholders, highlighting the imperative need for companies to prioritize accountability and openness in their cybersecurity practices. This research undertakes an in-depth examination of cybersecurity reporting practices among the 48 largest Canadian and US banking institutions between 2014 and 2020, employing a qualitative, exploratory methodology. As a prime target of cybercriminals due to the sensitive nature of their data holdings, the banking sector has been disproportionately affected. We establish a comprehensive framework, informed by existing literature, current policy directives, and expert consultations, to assess the quality of cybersecurity disclosures in bank reports. A detailed content analysis and evaluation of compliance with the framework follow, with a critical discussion of banks' disclosure patterns through the lens of proprietary cost, signaling, and legitimacy theories, ultimately providing actionable guidance for policymakers and other stakeholders.","Over the past ten years, the persistent threat of cyberattacks on companies has prompted both policymakers and market actors to focus on the crucial role of corporate accountability and openness in cybersecurity. Utilizing an exploratory qualitative methodology, this research analyzes cybersecurity disclosures from the 48 largest banks in Canada and the United States between 2014 and 2020. Given the sensitive data they possess, banks have become prime targets for cyberattacks. Drawing upon existing research, prevailing cybersecurity disclosure policies, and insights from academics and practitioners, an index was constructed. This index was then employed to manually code bank reports pertaining to cybersecurity. A detailed examination of the content of these disclosures was conducted, assessing their level of adherence to the index. Finally, the study critically evaluates banks' disclosure practices through the lenses of proprietary cost, signaling, and legitimacy theories, culminating in recommendations for policymakers and other relevant stakeholders.",acceptable,acceptable,acceptable,3.8,3.2,3.2
171,Deep learning techniques to detect cybersecurity attacks: a systematic mapping study,"ContextRecent years have seen a lot of attention into Deep Learning (DL) techniques used to detect cybersecurity attacks. DL techniques can swiftly analyze massive datasets, and automate the detection and mitigation of a wide variety of cybersecurity attacks with superior results. However, no systematic study exists that summarizes these DL techniques since most studies are informal literature surveys or focus on different subjects.ObjectiveTo deliver a comprehensive and systematic summary of the existing DL techniques used to detect cybersecurity attacks as they are described in the literature. To identify open challenges for future research.MethodWe conducted a systematic mapping study about DL techniques to detect cybersecurity attacks driven by eleven research questions. We followed existing guidelines when defining our research protocol to increase the repeatability and reliability of our results.ResultsFrom an initial set of 1839 papers, we identified 116 relevant primary studies, primarily published in the last three years. We investigated multiple aspects of the DL techniques, such as the cybersecurity attack types to detect, their application domains, the programming languages, libraries, operating systems, and frameworks used to implement the DL techniques, the datasets used to train the DL models, the types of research carried out (academic or industrial), the performance of the techniques, and the advantages and disadvantages of each technique. We present a new taxonomy comprising 36 different DL techniques. We identified 14 application domains, eight cybersecurity attacks, and 93 publicly available datasets, among other results.ConclusionsWe provide six lessons learned along with recommendations for future research directions. The most active research areas in DL techniques for the identification of cybersecurity attacks discuss CNN and LSTM techniques. DL techniques in cybersecurity is a rapidly growing and developing research area, with many open challenges, including the lack of (a) research conducted in industrial settings, (b) real-time datasets, (c) studies focusing on promising DL techniques and relevant cybersecurity attacks.","Over recent years, substantial focus has been directed towards the use of Deep Learning (DL) methods to identify cybersecurity threats. These approaches are capable of rapidly processing vast amounts of data and autonomously detecting and addressing a variety of cyber attacks with high efficiency. Nonetheless, a systematic review that consolidates these DL methods is lacking, as most existing studies are informal surveys or concentrate on different topics.ObjectiveTo construct a comprehensive and methodical overview of current DL methods for identifying cybersecurity threats as documented in the literature, highlighting areas needing further research.MethodWe performed a systematic mapping study on DL techniques for identifying cybersecurity threats, guided by eleven research questions. We adhered to current guidelines to develop our research protocol, which aimed at enhancing the reproducibility and reliability of our findings.ResultsOut of an initial pool of 1839 papers, we pinpointed 116 pertinent primary studies, mainly from the past three years. We examined various facets of the DL methods, such as the types of cybersecurity threats they address, their fields of application, the programming languages, libraries, operating systems, and frameworks used in their implementation, the datasets for training DL models, the nature of the research (academic or industrial), the efficacy of the techniques, and the pros and cons of each method. We introduce a novel taxonomy that categorizes 36 distinct DL techniques. Our findings include 14 application domains, eight types of cybersecurity threats, and 93 publicly accessible datasets, among other insights.ConclusionsWe offer six key insights along with suggestions for future research directions. The most actively researched areas in DL techniques for cybersecurity focus on CNN and LSTM methods. The field of DL in cybersecurity is rapidly expanding, with numerous unresolved challenges, such as insufficient industrial research, lack of real-time datasets, and a need for studies on promising DL methods and relevant cybersecurity threats.","In recent times, the realm of cybersecurity has witnessed a surge in the application of Deep Learning (DL) methodologies for detecting and mitigating cyber threats. The allure of DL lies in its ability to rapidly process vast datasets and automate the identification of a broad spectrum of cyber attacks with unparalleled accuracy. Despite this, a comprehensive and systematic review of these DL techniques is conspicuously absent, with existing studies often taking the form of informal literature surveys or focusing on disparate topics. This study aims to bridge this knowledge gap by providing an exhaustive and structured overview of DL techniques employed in cybersecurity, as described in the literature, and identifying areas that warrant further investigation. Through a systematic mapping study guided by eleven research questions, we analyzed 1839 papers, yielding 116 pertinent primary studies, predominantly published within the last three years. Our investigation encompassed various facets of DL techniques, including the types of cyber attacks detected, application domains, programming languages, and datasets utilized. We propose a novel taxonomy comprising 36 distinct DL techniques and highlight 14 application domains, eight cyber attack types, and 93 publicly available datasets, among other findings. Our conclusions distill into six key takeaways, accompanied by recommendations for future research directions, with a focus on CNN and LSTM techniques, and the need to address the lack of industrial research, real-time datasets, and studies exploring promising DL techniques and relevant cyber threats.","The domain of cybersecurity has witnessed a surge in Deep Learning (DL) applications for attack detection. While DL excels in rapid analysis of large datasets and automated threat mitigation, a cohesive understanding of these techniques remains absent, with existing studies often fragmented or lacking systematic review. This work addresses this gap by conducting a rigorous mapping study guided by eleven research questions to provide a comprehensive overview of DL-based cybersecurity attack detection techniques. From an extensive pool of publications, 116 primary studies were meticulously selected, primarily from recent years. This analysis delved into various facets of DL techniques, encompassing attack types, application domains, implementation tools, training datasets, research nature, performance metrics, and advantages and disadvantages. The outcome is a novel taxonomy encompassing 36 distinct DL techniques, alongside the identification of 14 application domains, 8 cybersecurity attack categories, and 93 publicly accessible datasets. The study culminates in six key insights and recommendations for future research trajectories, highlighting CNN and LSTM as prominent areas within DL-driven cybersecurity. Despite its rapid evolution, the field faces notable challenges, including the scarcity of industrial research, real-time datasets, and investigations focusing on emerging DL techniques and pertinent cyber threats.",acceptable,acceptable,acceptable,3.2,3.2,3.2
172,The Role of Culture on Islamic Finance: A Comparative Analysis from Islamic Finance Permitting Countries,"Despite the inclusion of cultural elements in hundreds of business and management research studies, there have been relatively few studies in finance, and Islamic finance just recently seems to have discovered the impact of culture. Through this study, culture has been proposed as the next possible means to improve the Islamic finance industry. By utilizing data from 2012 to 2019, this paper aims to empirically examine the effects of culture, proxied by education, on Islamic finance in 45 Islamic finance-permitting countries by using generalized method of moments (GMM) estimators. We find significant effects of culture in Islamic finance in all regions except for developed countries and other Arab countries, which are still in their infancy in the field of Islamic finance. Developed countries need to change their educational system in Islamic finance to reflect the real, Shariah-based ethics of Islam rather than secular humanism, while other Arab countries should pay more attention to the Islamic finance industry. Thus, it is important to consider the culture and open the door to the new discipline of “Islamic cultural finance” in the development of the Islamic finance industry.","While numerous business and management research studies have integrated cultural elements, finance studies have been comparatively scarce, with Islamic finance only recently acknowledging culture's influence. This research suggests culture as a potential avenue for enhancing the Islamic finance sector. By analyzing data from 2012 to 2019, the paper empirically investigates the cultural impacts, represented by education, on Islamic finance across 45 countries permitting such financial practices, using generalized method of moments (GMM) estimators. The findings reveal significant cultural effects on Islamic finance across most regions, except in developed and some Arab countries, where Islamic finance is nascent. Developed nations need to revamp their Islamic finance education systems to align with genuine Shariah ethics rather than secular humanism. Meanwhile, other Arab nations should focus more on advancing their Islamic finance sectors. Consequently, it is crucial to integrate cultural considerations and explore the emerging field of “Islamic cultural finance” for the industry's growth.","Although cultural factors have been incorporated into numerous business and management research investigations, the finance sector, including Islamic finance, has only recently begun to acknowledge the significance of cultural influences. This study proposes that cultural considerations could be the key to enhancing the Islamic finance industry. By analyzing data from 2012 to 2019, this paper seeks to investigate the relationship between cultural values, as reflected in educational systems, and Islamic finance outcomes in 45 countries that permit Islamic finance, employing generalized method of moments estimators. The findings indicate that cultural factors have a substantial impact on Islamic finance in most regions, with the notable exceptions of developed countries and certain Arab nations, where the industry is still in its early stages. To foster growth, developed countries must reform their Islamic finance education systems to align with Shariah-based principles rather than secular values, while other Arab countries should prioritize the development of their Islamic finance sectors. Ultimately, recognizing the importance of cultural context and embracing the emerging field of ""Islamic cultural finance"" is crucial for the advancement of the Islamic finance industry.","While cultural dimensions have been integrated into numerous business and management studies, finance, particularly Islamic finance, has only recently begun to acknowledge the significant influence of culture. This research proposes that culture, represented by education levels, can serve as a catalyst for enhancing the Islamic finance sector. Utilizing data spanning from 2012 to 2019, this study employs generalized method of moments (GMM) estimators to empirically investigate the impact of culture on Islamic finance across 45 countries that permit Islamic financial practices. The findings reveal a notable influence of culture on Islamic finance in most regions, except for developed nations and some Arab countries where Islamic finance is still in its nascent stages. Developed countries need to reform their Islamic finance education systems to embody authentic, Shariah-compliant ethical principles instead of secular humanism, while other Arab countries should prioritize the Islamic finance industry. Therefore, integrating cultural considerations and fostering the emerging field of ""Islamic cultural finance"" is crucial for the advancement of the Islamic finance industry.",acceptable,acceptable,acceptable,3.6,3.2,3.2
173,Islamic finance and governance indicators: empirical evidence from Islamic finance-permitting countries,"Despite being greatly progressive for more than 45 years covering even Muslim minority countries, the development of Islamic finance in some countries is not supported by well-established governance. This paper aims to empirically re-examine the effects of the governance components on Islamic finance in 45 Islamic finance-permitting countries. The study utilizes the dynamic panel GMM approach from the data spanning from 2012 to 2019. We find insignificant effect of regulation in Islamic finance in the region of developed countries, Muslim minority countries, and other Arab countries. We also find that corporate governance is not statistically significant in MENA and non-Asian countries. These results reinforce the need for a new type of regulation based on product requirements, policies, and procedures. Thus, the governance indicators can be understood by the wider world and assist in gaining more acceptance for the Islamic finance industry.","Although Islamic finance has seen notable progress over the past 45 years, even in countries with Muslim minorities, some nations lack robust governance structures. This paper aims to empirically reassess the influence of governance elements on Islamic finance across 45 countries where it is permitted. Utilizing the dynamic panel GMM approach on data from 2012 to 2019, the study finds that regulation has an insignificant impact on Islamic finance in developed countries, Muslim minority nations, and other Arab countries. Additionally, corporate governance shows no statistically significant effect in MENA and non-Asian countries. These findings highlight the necessity for a new regulatory framework centered on product requirements, policies, and procedures, enabling broader understanding and acceptance of governance indicators in the Islamic finance sector.","""Notwithstanding its remarkable 45-year trajectory, which has encompassed even Muslim-minority nations, the evolution of Islamic finance in certain countries has been hindered by the absence of robust governance frameworks. This study seeks to reassess, through empirical analysis, the impact of governance components on Islamic finance across 45 countries that permit Islamic finance activities. Employing a dynamic panel GMM approach, our research draws on data from 2012 to 2019. Our findings indicate that regulatory measures have a negligible effect on Islamic finance in developed, Muslim-minority, and Arab countries. Furthermore, we observe that corporate governance is not statistically significant in the MENA region and non-Asian countries. These results underscore the need for a novel regulatory paradigm centered on product specifications, policies, and procedures, thereby enabling the global community to better comprehend governance indicators and fostering greater acceptance of the Islamic finance sector.""","While Islamic finance has seen considerable progress over the past four and a half decades, extending its reach to nations with Muslim minorities, its growth in certain regions is hampered by inadequate governance frameworks. This study empirically investigates the impact of governance elements on Islamic finance across 45 countries where it is permitted, using a dynamic panel Generalized Method of Moments (GMM) approach on data from 2012 to 2019. The findings reveal that regulation has an insignificant influence on Islamic finance in developed nations, countries with Muslim minorities, and other Arab countries. Additionally, corporate governance is statistically insignificant in Middle Eastern and North African (MENA) and non-Asian countries. These results underscore the necessity for a novel regulatory approach focused on product specifications, policies, and procedures. Consequently, enhanced clarity in governance indicators can foster global comprehension and promote wider acceptance of the Islamic finance industry.",acceptable,acceptable,acceptable,3.6,3.6,3.2
174,Does green finance policy promote green total factor productivity? Evidence from a quasi-natural experiment in the green finance pilot zone,"The establishment of Green Finance Reform and Innovation Pilot Zones represents a novel endeavor aimed at paving a “bottom-up” pathway for the advancement of green finance and, consequently, holds immense significance in fostering economic growth that is environmentally sustainable. Drawing on data spanning the years 2013–2019 from 278 prefecture-level cities across China, we delve into the influence of the Green Finance Reform and Innovation Pilot policy on urban Green Total Factor Productivity. We found that: Firstly, the Green Finance Reform and Innovation Pilot policy has demonstrated a discernible enhancement in Green Total Factor Productivity within the designated pilot regions. Secondly, there is heterogeneity in the promotion effect of this pilot policy on Green Total Factor Productivity. As the geographical advantage and economic development level decrease, this promotional effect gradually diminishes. Thirdly, it is evident that the Green Finance Reform and Innovation Pilot policy primarily elevates Green Total Factor Productivity in the pilot regions by improving resource allocation efficiency, fostering innovation in green technologies, and facilitating the upgrading of industrial structures. This research not only underscores the efficacy of green finance in the context of economic transition but also provides empirical substantiation for the strategic utilization of pilot zones to propel nationwide initiatives aimed at sustainable green development.Graphical abstract","The creation of Green Finance Reform and Innovation Pilot Zones signifies a groundbreaking effort to establish a grassroots approach to advancing green finance, which is highly important for promoting environmentally sustainable economic growth. Utilizing data from 278 prefecture-level cities in China between 2013 and 2019, this study explores the impact of the Green Finance Reform and Innovation Pilot policy on urban Green Total Factor Productivity. The findings are as follows: Firstly, the Green Finance Reform and Innovation Pilot policy has significantly boosted Green Total Factor Productivity in the designated pilot areas. Secondly, the policy’s effect on Green Total Factor Productivity varies, with a decrease in promotional impact corresponding to lower geographical advantages and levels of economic development. Thirdly, the Green Finance Reform and Innovation Pilot policy primarily enhances Green Total Factor Productivity in these regions by improving resource allocation efficiency, encouraging green technology innovation, and promoting industrial structure upgrades. This research highlights the effectiveness of green finance in economic transitions and provides empirical evidence supporting the strategic use of pilot zones to drive nationwide sustainable green development initiatives.","The creation of Green Finance Reform and Innovation Pilot Zones embodies a pioneering initiative designed to forge a grassroots approach to green finance development, thereby playing a pivotal role in catalyzing environmentally conscious economic expansion. By analyzing a comprehensive dataset covering 278 prefecture-level cities in China from 2013 to 2019, we investigate the impact of the Green Finance Reform and Innovation Pilot policy on urban green productivity. Our findings reveal that: Firstly, the policy has yielded a tangible improvement in green productivity within the designated pilot areas. Secondly, the policy's promotional effect on green productivity exhibits regional disparities, with the impact diminishing as geographical advantages and economic development levels decrease. Thirdly, the policy primarily boosts green productivity in pilot regions by optimizing resource allocation, driving innovation in eco-friendly technologies, and facilitating industrial upgrading. This study not only highlights the potency of green finance in facilitating economic transformation but also provides empirical evidence for the strategic deployment of pilot zones to drive nationwide initiatives towards sustainable green growth.","China's groundbreaking initiative to establish Green Finance Reform and Innovation Pilot Zones is a localized approach designed to propel the growth of environmentally responsible financial practices. Utilizing data from 278 Chinese cities between 2013 and 2019, this study explores the impact of this policy on urban Green Total Factor Productivity. The research reveals that the pilot program demonstrably boosts Green Total Factor Productivity in participating regions, although this effect varies based on geographic and economic factors, diminishing in areas with fewer advantages. Notably, the policy primarily enhances Green Total Factor Productivity by optimizing resource allocation, stimulating green technology innovation, and driving industrial upgrades. This investigation not only confirms the vital role of green finance in economic transformation but also provides concrete evidence supporting the strategic use of pilot zones to advance nationwide sustainable development goals.",acceptable,acceptable,acceptable,3.6,3.6,3.2
175,Green digital finance and technology diffusion,"Technology diffusion is essential for sustainable development. However, traditional financing faces structural problems in supporting technological innovation and diffusion. Fortunately, greening and digitalisation have become important directions for the financial development. It’s well worth examining whether green digital finance would promote the diffusion of technology among regions. Therefore, this study explores the causal relationship between green digital finance and technology diffusion using the panel data of 35,532 ‘citing city-cited city’ pair observations from 2002 to 2015. Considering different spatial spillover effects of administrative boundaries and geographic distances, it applies and extends the classic spatial Dubin model with a dual-weighted boundary and distance. The main findings of this study are as follows. First, green digital finance shows significant and considerable spatial stimulus effects, particularly in terms of spatial diffusion across cities. A slight cumulative phenomenon is revealed for different technology diffusion durations. Green digital credit, investment, and support have better stimulating effects on technology diffusion. Second, digital economy and market integration are effective mechanism pathways during this stimulating process of green digital finance on technology diffusion. Digitalisation innovation has a better mechanism effect than others. Third, considering the direction of technology diffusion, the diffusion effect from the east-region cities was better than that from the central-west-region cities.","The spread of technology is crucial for sustainable progress. Nonetheless, conventional funding methods struggle with inherent issues in backing technological innovation and dissemination. Thankfully, the trends of greening and digitalisation are becoming vital for financial growth. Investigating whether green digital finance enhances the regional spread of technology is vital. This research examines the link between green digital finance and technology dissemination, using panel data from 35,532 city pairs observed between 2002 and 2015. By accounting for various spatial spillover effects of administrative boundaries and geographic distances, it extends the traditional spatial Dubin model through dual-weighted boundary and distance measures. Key discoveries include the following: firstly, green digital finance exhibits significant and substantial effects on spatial diffusion, especially among cities, with a minor cumulative phenomenon observed over different technology dissemination periods. Green digital credit, investment, and support have more pronounced effects on technology spread. Secondly, the digital economy and market integration act as effective pathways in this process, with digital innovation having a superior mechanism effect. Lastly, in terms of technology spread direction, eastern cities show a better diffusion effect compared to central-western cities.","The dissemination of technology is a crucial component of sustainable development, but conventional financing methods are hindered by inherent limitations in fostering innovation and adoption. Fortunately, the convergence of environmental sustainability and digital advancements has emerged as a promising trajectory for financial growth. It is thus imperative to investigate whether the integration of green and digital finance can facilitate the widespread adoption of technology across regions. This research endeavors to elucidate the causal link between green digital finance and technology diffusion, leveraging a comprehensive panel dataset of 35,532 'citing city-cited city' pair observations spanning 2002-2015. By accounting for the disparate spatial spillover effects of administrative boundaries and geographic distances, this study adapts and extends the classic spatial Dubin model with a dual-weighted boundary and distance approach. The key findings of this study reveal that green digital finance exhibits substantial and significant spatial stimulus effects, particularly in terms of inter-city technology diffusion, with a moderate cumulative phenomenon observed across varying technology diffusion periods. Green digital credit, investment, and support demonstrate superior stimulating effects on technology diffusion. Furthermore, the digital economy and market integration emerge as effective mechanisms facilitating the stimulating impact of green digital finance on technology diffusion, with digital innovation exhibiting a more pronounced mechanism effect. Finally, the direction of technology diffusion indicates that cities in the eastern region exhibit a more pronounced diffusion effect compared to those in the central-western region.","The spread of technology is crucial for achieving lasting progress, but conventional funding methods struggle to adequately support innovation and its adoption. The rise of environmentally conscious practices and digital advancements in finance offers a promising avenue. This research investigates if green digital finance can effectively bridge the technology gap between regions. Utilizing data from over 35,000 city-to-city technology transfer instances between 2002 and 2015, the study employs a refined spatial model accounting for both administrative and geographical distances. The findings highlight the significant positive impact of green digital finance, particularly its role in facilitating technology spread across cities. This effect strengthens over time, with green digital credit, investment, and support showing the most pronounced influence. Furthermore, the study identifies a digital economy and market integration as key facilitators in this process, with digital innovation demonstrating the strongest mediating role. Finally, the analysis reveals that technology originating from eastern cities exhibits a stronger diffusion effect compared to that from central and western regions.",acceptable,acceptable,acceptable,3.2,3.2,3.2
176,"Households’ coping mechanisms with droughts and floods using finance, non-finance and the social safety net measures: evidence from Kenya","This study analysed households’ use of formal and informal finance, non-finance livelihood diversification and the social safety net measures in coping with droughts and floods. It employed a cross-sectional survey of 1370 households across 27 counties in Kenya that are prone to droughts and floods. Bivariate probit regressions reveal that households employ multiple coping measures related to finance, the social safety net and non-finance choices. The use of coping measures vary by household income, household dependency ratio, geographic and agro-climatic contexts, as well as the household head’s age and educational attainment. Further, the findings reveal that the use of the social safety net and non-finance coping mechanisms demonstrate complementarities in coping with droughts, suggesting that opportunities to benefit from the social safety net do not dampen livelihood diversification initiatives by the households. Additionally, households in arid and semi-arid lands (ASALs) depend to a large extent on the social safety net and non-finance livelihood diversification coping mechanisms, signalling the need to explore ways that encourage private sector development in promoting market-oriented coping strategies.","This research explored how households utilize both formal and informal financial options, diversify their livelihoods beyond financial means, and employ social safety net strategies to cope with droughts and floods. The study was based on a cross-sectional survey involving 1,370 households from 27 counties in Kenya susceptible to these environmental challenges. Using bivariate probit regressions, the analysis indicated that households adopt a variety of coping mechanisms involving finance, social safety nets, and non-financial strategies. The choice of coping mechanism is influenced by factors such as household income, dependency ratio, geographic setting, agro-climatic conditions, as well as the age and educational level of the household head. Moreover, the results show that social safety nets and non-financial coping strategies work complementarily in managing droughts, implying that access to social safety nets does not hinder households' diversification of livelihoods. Significantly, households in arid and semi-arid regions predominantly rely on social safety nets and non-financial diversification strategies, underscoring the importance of initiatives that foster private sector involvement in encouraging market-based coping mechanisms.","This research examined the strategies employed by households to mitigate the impacts of droughts and floods, including their utilization of formal and informal financial instruments, diversified livelihoods, and social protection programs. A comprehensive survey of 1370 households across 27 drought- and flood-prone counties in Kenya was conducted to gather insights. The analysis, which utilized bivariate probit regressions, revealed that households adopt a multifaceted approach to coping, combining financial, social, and non-financial measures. The adoption of these strategies varies significantly depending on factors such as household income, dependency ratio, geographical location, agro-climatic conditions, and the age and education level of the household head. Notably, the findings suggest that social protection programs and non-financial coping mechanisms exhibit synergies in responding to droughts, implying that access to social safety nets does not hinder households' efforts to diversify their livelihoods. Furthermore, households in arid and semi-arid regions rely heavily on social protection and non-financial diversification strategies, highlighting the need to explore initiatives that promote private sector growth and market-driven coping approaches.","This research investigated how households in drought and flood-prone regions of Kenya navigate these climatic shocks through various strategies. Utilizing data from a comprehensive survey of 1370 households across 27 counties, the study explored the utilization of formal and informal financial resources, engagement in non-financial livelihood diversification, and reliance on social safety net programs. Statistical analyses highlighted that households adopt a multifaceted approach to coping, drawing on a combination of financial, social, and non-financial mechanisms. The specific strategies employed were found to differ based on factors such as household income, the number of dependents, geographic location, agro-climatic conditions, and the age and education level of the household head. Notably, the study revealed a complementary relationship between social safety net programs and non-financial coping mechanisms, indicating that access to social support does not discourage households from diversifying their livelihoods. Furthermore, the research emphasized the significant dependence of households in arid and semi-arid lands (ASALs) on both social safety nets and non-financial diversification, underscoring the importance of exploring approaches that foster private sector growth to encourage market-driven coping strategies in these vulnerable regions.",acceptable,acceptable,acceptable,3.6,3.6,3.2
177,How does digital finance encourage the use of renewable energy in China? Inverse relationships from green finance,"A promising approach forfacilitating China’s shift towards renewable energy sources entails combining digital finance and green financing. The present research investigates the supply chains and reverse logistics of significant financial indices, including the S&P Green Bond Index, the MSCI Global Markets Index, and the S&P Global Renewable Energy Index. The analysis encompasses the period from the creation of these indices on September 28, 2008, through January 12, 2022. To minimize risk, portfolios have increasingly adopted diverse indices, such as the S&P Global Clean Energy Index and the S&P Green Bond Index. This study investigates the intricate relationship between green financing and digital finance, shedding light on their combined impact on the uptake of renewable energy in China. This study examines the role of digital financial technologies, including blockchain, mobile payment systems, and big data analytics, in enhancing the accessibility of green financing choices for renewable energy projects. A comprehensive analysis of existing literature and empirical research is conducted to achieve this objective. The results emphasize the significant progress in improving financial inclusion, risk management, and transparency by integrating green financing and digital finance. As mentioned earlier, the enhancements have significantly enhanced the level of trust and assurance among investors operating within the renewable energy industry. Moreover, the report highlights the crucial need for continuous governmental backing and financial investments in digital financial infrastructure to drive China towards a more environmentally friendly and sustainable energy framework.","An effective strategy to advance China's transition to renewable energy involves merging digital finance with green financing. This study examines the supply chains and reverse logistics of key financial indices, such as the S&P Green Bond Index, the MSCI Global Markets Index, and the S&P Global Renewable Energy Index, from their inception on September 28, 2008, to January 12, 2022. With the aim of reducing risk, portfolios have increasingly embraced a range of indices, including the S&P Global Clean Energy Index and the S&P Green Bond Index. The research delves into the complex interplay between green financing and digital finance, exploring their joint effect on the adoption of renewable energy in China. It explores the role of digital financial technologies like blockchain, mobile payment systems, and big data analytics in broadening access to green financing for renewable energy initiatives. A thorough review of current literature and empirical studies is performed to achieve this goal. The findings underscore significant advancements in financial inclusion, risk management, and transparency brought about by integrating green financing with digital finance. These enhancements have notably increased the trust and confidence of investors in the renewable energy sector. Additionally, the report underscores the vital importance of ongoing governmental support and investment in digital financial infrastructure to propel China towards a more sustainable and eco-friendly energy future.","""Unlocking China's transition to renewable energy sources requires a synergistic approach that converges digital financial innovations with sustainable investment strategies. This study delves into the supply chain dynamics and reverse logistics of prominent financial benchmarks, including the S&P Green Bond Index, MSCI Global Markets Index, and S&P Global Renewable Energy Index, spanning from their inception on September 28, 2008, to January 12, 2022. To mitigate risk, investors have increasingly turned to diversified indices, such as the S&P Global Clean Energy Index and S&P Green Bond Index. This research explores the complex interplay between green financing and digital finance, illuminating their joint impact on the adoption of renewable energy in China. By examining the role of digital financial tools, including blockchain, mobile payment systems, and big data analytics, in expanding access to green financing options for renewable energy projects, this study provides a comprehensive analysis of existing literature and empirical research. The findings underscore the substantial advancements in enhancing financial inclusion, risk management, and transparency through the integration of green financing and digital finance, thereby fostering trust and confidence among investors in the renewable energy sector. Furthermore, the report emphasizes the imperative need for sustained government support and investments in digital financial infrastructure to propel China towards a more eco-friendly and sustainable energy paradigm.""","One potential strategy for advancing China's transition to renewable energy sources is the integration of digital finance and green financing. This research delves into the financial supply chains and reverse logistics of key indices, including the S&P Green Bond Index, MSCI Global Markets Index, and S&P Global Renewable Energy Index, spanning from their inception on September 28, 2008, to January 12, 2022. To mitigate risk, investment portfolios have increasingly incorporated diversified indices like the S&P Global Clean Energy Index and S&P Green Bond Index. This study explores the complex interplay between green and digital financing, illuminating their joint influence on the adoption of renewable energy in China. Specifically, it investigates how digital financial technologies such as blockchain, mobile payment systems, and big data analytics can improve access to green financing options for renewable energy initiatives. Through an extensive review of existing literature and empirical studies, the research highlights the significant advancements in financial inclusion, risk mitigation, and transparency achieved through this integration. These improvements have substantially bolstered investor confidence within the renewable energy sector. Furthermore, the study underscores the critical importance of ongoing governmental support and financial investment in digital financial infrastructure to propel China towards a more sustainable and environmentally conscious energy system.",acceptable,acceptable,acceptable,3.6,3.6,3.6
178,"Applications of Explainable Artificial Intelligence in Finance—a systematic review of Finance, Information Systems, and Computer Science literature","Digitalization and technologization affect numerous domains, promising advantages but also entailing risks. Hence, when decision-makers in highly-regulated domains like Finance implement these technological advances—especially Artificial Intelligence—regulators prescribe high levels of transparency, assuring the traceability of decisions for third parties. Explainable Artificial Intelligence (XAI) is of tremendous importance in this context. We provide an overview of current research on XAI in Finance with a systematic literature review screening 2,022 articles from leading Finance, Information Systems, and Computer Science outlets. We identify a set of 60 relevant articles, classify them according to the used XAI methods and goals that they aim to achieve, and provide an overview of XAI methods used in different Finance areas. Areas like risk management, portfolio optimization, and applications around the stock market are well-researched, while anti-money laundering is understudied. Researchers implement both transparent models and post-hoc explainability, while they recently favored the latter.","The impact of digitalization and technologization spans numerous areas, offering significant benefits while also posing potential risks. Consequently, decision-makers in highly-regulated sectors such as Finance must adhere to stringent transparency requirements set by regulators when applying technological advancements, particularly Artificial Intelligence. Ensuring the traceability of decisions for third parties is crucial. Explainable Artificial Intelligence (XAI) plays a critical role here. This paper reviews contemporary research on XAI in Finance by systematically examining 2,022 articles from leading journals in Finance, Information Systems, and Computer Science. We select 60 pertinent articles, categorize them based on their XAI methods and intended objectives, and summarize the XAI methods employed across various finance domains. Areas such as risk management, portfolio optimization, and stock market applications are extensively explored, whereas anti-money laundering remains inadequately studied. Researchers implement both transparent models and post-hoc explainability, although there has been a recent preference for the latter.","The pervasive impact of digital transformation and technological innovation spans multiple sectors, offering benefits while also introducing potential pitfalls. Consequently, when policymakers in heavily regulated fields such as Finance adopt cutting-edge technologies, including Artificial Intelligence, regulatory bodies stipulate stringent transparency requirements to ensure the accountability of decision-making processes to external stakeholders. In this context, the significance of Explainable Artificial Intelligence (XAI) cannot be overstated. This study presents a comprehensive survey of current research on XAI in Finance, drawing on a systematic review of 2,022 articles from top-tier Finance, Information Systems, and Computer Science journals. Our analysis yields a curated set of 60 pertinent articles, categorized by their employed XAI approaches and objectives, and provides an overview of XAI techniques applied across various Finance domains. While areas like risk mitigation, portfolio optimization, and stock market applications have received considerable attention, anti-money laundering remains an underexplored territory. Researchers have employed both inherently transparent models and post-hoc explanatory methods, with a recent shift towards the latter approach.","The pervasiveness of digital and technological advancements across various sectors offers both opportunities and challenges. Consequently, in heavily regulated fields like Finance, the adoption of such innovations, particularly Artificial Intelligence, necessitates stringent transparency standards from regulatory bodies to ensure accountability and auditability. Explainable AI (XAI) emerges as a critical factor in this scenario. A comprehensive review of 2,022 articles from prominent Finance, Information Systems, and Computer Science journals provides insights into the current state of XAI research in Finance. The analysis, focusing on 60 pertinent articles, categorizes them based on the employed XAI techniques and their intended objectives, and subsequently presents an overview of XAI methodologies utilized in diverse financial domains. While areas such as risk assessment, portfolio management, and stock market applications exhibit considerable research activity, anti-money laundering remains comparatively underexplored. Although both inherently transparent models and post-hoc explanations are implemented, recent trends indicate a preference for the latter.",acceptable,acceptable,acceptable,3.2,3.2,3.2
179,Intelligent finance and change management implications,"Change management is the embodiment of an enterprise’s core competence. It provides competitive differentiation and effectively adapts to the ever-changing world. This paper explores the implications of intelligent finance on change management and provides insights into how organizations can effectively manage change to achieve the desired outcomes. The study examines the case of Ping An (Ping An Insurance (Group) Company of China, Ltd.), a leading insurance company in China that has successfully implemented intelligent finance and change management strategies. The paper begins with a literature review that provides an overview of the concept of intelligent finance, the relevance of change management in the context of intelligent finance, models, and frameworks for intelligent finance, and approaches to change management. The study then presents a case analysis of Ping An, including descriptive statistics, inferential statistics, regression analysis, and qualitative findings. The paper concludes with implications for practice and theory, contributions of the study, and recommendations for future research. Overall, this paper contributes to the growing literature on intelligent finance and change management and provides practical insights for organizations seeking to adopt intelligent finance.","Change management represents the foundational competence of a business, offering a distinct competitive edge and efficiently adjusting to a constantly evolving environment. This paper delves into how intelligent finance impacts change management and provides guidance on managing change effectively to achieve desired results. The research focuses on Ping An Insurance (Group) Company of China, Ltd., a prominent insurance firm that has adeptly applied intelligent finance and change management methodologies. The paper starts with a literature review, giving an overview of intelligent finance, its significance in relation to change management, and existing models and frameworks. It then moves on to a detailed case study of Ping An, including both descriptive and inferential statistics, regression analysis, and qualitative data. The study concludes by discussing the practical and theoretical implications, the contributions made by the research, and suggestions for future studies. In summary, this paper enriches the existing body of knowledge on intelligent finance and change management and offers actionable insights for businesses looking to implement intelligent finance.","""An organization's capacity for change management serves as the cornerstone of its competitive prowess, enabling it to thrive in a dynamic environment. This research delves into the interplay between intelligent finance and change management, offering actionable guidance for businesses to navigate transformation and achieve their objectives. A case study of Ping An, a Chinese insurance giant that has successfully harnessed intelligent finance and change management, is presented, featuring a comprehensive literature review, statistical analysis, and qualitative findings. The paper culminates in practical recommendations, theoretical implications, and avenues for future investigation, thereby enriching the existing body of knowledge on intelligent finance and change management and providing valuable lessons for organizations embarking on intelligent finance adoption.""","At the heart of an organization's success lies its ability to manage change, a key differentiator in today's dynamic landscape. This research delves into the intersection of intelligent finance and change management, illuminating how companies can navigate this transformation for optimal results. Focusing on Ping An, a pioneering Chinese insurance firm, the study analyzes its successful implementation of intelligent finance and associated change management tactics. Through a comprehensive literature review, the paper first establishes the foundations of intelligent finance, its relationship with change management, relevant models and frameworks, and various change management approaches. Subsequently, a detailed case study of Ping An is presented, employing descriptive and inferential statistics, regression analysis, and qualitative insights. The paper concludes by outlining practical and theoretical implications, highlighting the study's contributions, and suggesting avenues for further investigation. Ultimately, this work enriches the existing body of knowledge on intelligent finance and change management, offering valuable guidance for organizations looking to embrace intelligent finance.",acceptable,acceptable,acceptable,3.2,3.2,3.2
180,Measurement and spatiotemporal characteristics of China’s green finance,"To study the extent of green finance development in China, this article constructs a green finance index system and employs the entropy value method to measure China’s green finance by using a yearly provincial panel data from 2001 to 2020. The Thiel and Moran indices are then used to systematically analyze the temporal and spatial distribution of China’s regional green finance. The findings are summarized as follows. Firstly, the overall green finance index in China experiences an upward trend. The development of green finance in the eastern region is superior to that in other regions in terms of absolute value and growth rate. Moreover, the differences in China’s green finance index have shown an increasing trend over the last two decades, which is mostly contributed by the intra-regional differences. Finally, the inter-regional distribution of green finance index demonstrates that green finance development has a spatial spillover effect.","To investigate the progression of green finance in China, this article develops a green finance index framework and utilizes the entropy value method to assess China's green finance through annual provincial panel data spanning from 2001 to 2020. The Thiel and Moran indices are applied to systematically examine the temporal and spatial distribution of regional green finance in China. The results indicate that, firstly, the green finance index across China shows an increasing trend overall. In absolute terms and growth rate, green finance development in the eastern region outperforms other regions. Additionally, disparities in the green finance index across China have increased over the past two decades, largely due to intra-regional variations. Lastly, the inter-regional distribution analysis reveals that the development of green finance exhibits a spatial spillover effect.","""This research assesses the progression of China's green finance sector by devising a comprehensive index framework and applying the entropy value approach to a 20-year provincial dataset spanning 2001-2020. A systematic examination of the temporal and spatial patterns of regional green finance in China is conducted using the Thiel and Moran indices. The key takeaways are as follows: China's overall green finance index exhibits a steady ascent. The eastern region outperforms other areas in terms of both absolute value and growth rate, indicating a superior development trajectory. Furthermore, the disparities in China's green finance index have widened over the past two decades, primarily driven by intra-regional variations. Lastly, the spatial distribution of the green finance index reveals a significant spillover effect, underscoring the importance of regional coordination in green finance development.""","This study investigates the progress of green finance in China by developing a comprehensive index system and utilizing the entropy value method to quantify it using annual provincial panel data spanning two decades (2001-2020). The temporal and spatial patterns of regional green finance in China are then systematically examined using the Thiel and Moran indices. Key findings reveal a consistent upward trajectory in China's overall green finance index, with the eastern region exhibiting superior development in both absolute terms and growth rate compared to other regions. Furthermore, disparities in China's green finance index have widened over the past twenty years, primarily driven by intra-regional variations. Finally, the spatial distribution of the green finance index suggests the presence of a spillover effect in the development of green finance across regions.",acceptable,acceptable,acceptable,3.6,3.2,3.6
181,Entrepreneurial finance and regional ecosystem emergence,"We present a novel framework for studying the evolving role of entrepreneurial finance over the stages of emergence for a regional entrepreneurial ecosystem. Drawing on entrepreneurial ecosystems, entrepreneurial finance, and territorial servitization, we explore how three different finance sources impact firm survival and how they relate to each other during ecosystem emergence. We analyze entrepreneurial firms in one industry and region over 36 years. We find that firm survival is differentially affected by funder type based on the stage of ecosystem emergence. Finance sources also have different interrelations depending on the stage of emergence. Based on our results, we abductively articulate a framework for stage-dependent ecosystem emergence microfoundations. This rectifies contradictory results that examine single sources of finance and use cross-sectional data. Had we not measured the emergence process, the results would have led to markedly different theoretical implications and practical takeaways for entrepreneurial finance and ecosystem emergence.","We introduce an innovative framework for examining how entrepreneurial finance evolves with the stages of development in a regional entrepreneurial ecosystem. By integrating concepts from entrepreneurial ecosystems, finance, and territorial services, we investigate the impact of three distinct financial sources on firm survival and their interrelations during the ecosystem's formation. Our study spans 36 years and focuses on entrepreneurial firms within a specific industry and region. Our findings suggest that the influence of different financial sources on firm survival varies with the ecosystem's emergence stage. Additionally, the relationships among these financial sources change depending on the stage of development. Using our findings, we propose a framework outlining the microfoundations for stage-dependent ecosystem emergence. This approach resolves conflicting results from studies that consider single finance sources and rely on cross-sectional data. Without accounting for the emergence process, our theoretical and practical implications for entrepreneurial finance and ecosystem development would have been significantly different.","Here is a paraphrased version of the original text, exhibiting both syntactic and lexical diversity while preserving semantic similarity: ""This study introduces an innovative paradigm for examining the dynamic influence of entrepreneurial finance across the developmental phases of a regional entrepreneurial ecosystem. By integrating insights from entrepreneurial ecosystems, entrepreneurial finance, and territorial servitization, we investigate how three distinct funding sources affect firm viability and interact with one another during ecosystem evolution. Our analysis focuses on entrepreneurial ventures within a single industry and region over a 36-year period. The findings reveal that firm survival is disproportionately impacted by the type of funder, contingent upon the ecosystem's stage of development. Furthermore, the interdependencies between finance sources vary according to the emergence stage. Based on our results, we inductively develop a framework for stage-contingent ecosystem emergence microfoundations, thereby resolving inconsistencies in previous research that examined individual finance sources using cross-sectional data. The omission of emergence process measurement would have led to substantially different theoretical and practical implications for entrepreneurial finance and ecosystem development.""","This study introduces a new approach to understanding the dynamic relationship between entrepreneurial finance and the development of regional entrepreneurial ecosystems. By integrating theories of entrepreneurial ecosystems, entrepreneurial finance, and territorial servitization, we investigate the influence of three distinct funding sources on firm survival and their interplay across various ecosystem development stages. Our longitudinal analysis of entrepreneurial firms within a specific industry and region over 36 years reveals that the impact of funding type on firm survival varies according to the ecosystem's stage of emergence. Moreover, the relationships between these funding sources also differ depending on the stage of development. These findings inform the development of a framework that illuminates the stage-specific microfoundations of ecosystem emergence, addressing inconsistencies found in previous studies that focused on single funding sources and cross-sectional data. Examining the emergence process longitudinally was crucial, as neglecting it would have resulted in significantly different theoretical interpretations and practical implications for both entrepreneurial finance and ecosystem development.",acceptable,acceptable,acceptable,3.6,3.6,3.2
182,Municipal finance shapes urban climate action and justice,"Implementing climate policies and programmes in cities requires substantial investments that inevitably entangle climate action with urban climate finance—the mechanisms and practices city governments use to pay for climate efforts. Here we use US cities as a case study to examine how climate finance impacts, and is impacted by, the pursuit of urban climate action and climate justice. Drawing on 34 expert interviews, we show how municipal financial decisions and budgetary practices are shaping how, when and for whom cities are responding to climate change. We demonstrate how public spending decisions are intertwined with the logics of debt financing and examine the impacts of these relationships on cities’ climate investments. We showcase the structuring impacts of finance on climate action and the built environment, and we introduce pathways through which climate and justice considerations are already being integrated into, and potentially transforming, municipal finance in the United States.","Implementing climate initiatives and programs within urban settings necessitates significant investments, inherently linking climate actions with municipal climate finance—the strategies and operations through which city administrations fund their climate endeavors. In this study, we use U.S. cities as a focal point to investigate the reciprocal effects between climate finance and the execution of urban climate actions along with climate justice. By analyzing 34 expert interviews, our findings reveal how municipal fiscal decisions and budgetary methodologies influence the timing, manner, and demographic targeting of climate responses by cities. We highlight the critical role of public expenditure choices and their connection to debt financing principles, examining how these interactions affect urban climate funding. Our study demonstrates the determining influence of financial structures on climate initiatives and urban infrastructure, and it presents avenues where climate and justice factors are being, and have the potential to be, integrated into, and thus transform, city finance in the United States.","""Effecting meaningful climate initiatives in urban centers necessitates significant outlays, inextricably linking climate mitigation with municipal financial strategies—the fiscal frameworks and instruments employed by city administrations to fund climate-related endeavors. This study utilizes US cities as a paradigm to investigate the reciprocal influences between climate finance and the quest for urban climate resilience and social equity. Through an analysis of 34 in-depth expert consultations, we reveal how local budgetary allocations and fiscal policies are dictating the pace, scope, and beneficiaries of urban climate responses. We elucidate the intricate relationships between public expenditure decisions and debt financing modalities, and assess the implications of these dynamics on municipal climate investments. Furthermore, we highlight the profound impact of financial structures on climate action and the built environment, while identifying avenues through which climate and social justice considerations are being incorporated into, and potentially revolutionizing, municipal financial practices in the United States.""","Navigating the financial complexities of climate action in urban environments necessitates a deep dive into the mechanisms that underpin climate finance. Taking US cities as an illustrative example, this study explores the symbiotic relationship between climate finance and the pursuit of both climate action and climate justice. By synthesizing insights from 34 expert interviews, we illuminate how municipal budget allocation and financial practices profoundly influence the timing, nature, and beneficiaries of urban climate responses. Furthermore, we unpack the intricate interplay between public expenditure and debt financing, shedding light on its implications for climate-related investments. Our analysis reveals the significant influence of financial frameworks on both climate action and the physical characteristics of cities. Finally, we identify avenues through which considerations of climate and justice are being interwoven into municipal finance, highlighting their potential to reshape financial practices in the US.",acceptable,acceptable,acceptable,3.6,3.2,3.2
183,Emerging new themes in green finance: a systematic literature review,"There is a need for an extensive understanding of the emerging themes and trends within the domain of green finance, which is still evolving. By conducting a systematic literature review on green finance, the purpose of this study is to identify the emerging themes that have garnered significant attention over the past 12 years. In order to identify the emerging themes in green finance, bibliometric analysis was performed on 978 publications that were published between 2011 and 2023 and were taken from the databases of Scopus and Web of Science. The author examined annual scientific production, journal distribution, countries scientific production, most relevant authors, most frequent words, areas where empirical research is lacking, words' frequency over time, trend topics, and themes of green finance. The outcome of the review identified the following seven themes: (i) green finance and environmental sustainability; (ii) green finance and investments; (iii) green finance and innovation; (iv) green finance policy/green credit guidelines; (v) green finance and economy; (vi) green finance and corporate social responsibility; (vii)trends/challenges/barriers/awareness of green finance. The analysis of these emerging themes will contribute to the existing corpus of knowledge and provide valuable insights into the landscape of green finance as it evolves.","An in-depth comprehension of the burgeoning themes and trends in the field of green finance, which is still in its developmental phase, is essential. This study aims to uncover the key emerging themes that have drawn considerable interest over the last 12 years by performing a systematic literature review on green finance. To pinpoint these emerging themes, a bibliometric analysis was executed on 978 publications sourced from the Scopus and Web of Science databases, covering the period from 2011 to 2023. The author assessed various metrics including annual scientific output, distribution of journals, scientific contributions by country, top authors, most prevalent terms, gaps in empirical research, temporal word frequency, trending topics, and principal themes within green finance. The review identified seven main themes: (i) green finance and environmental sustainability; (ii) green finance and investments; (iii) green finance and innovation; (iv) green finance policy/green credit guidelines; (v) green finance and the economy; (vi) green finance and corporate social responsibility; and (vii) challenges, barriers, and awareness in green finance. Analyzing these themes will enrich the current body of knowledge and offer valuable insights into the evolving landscape of green finance.","""A comprehensive grasp of the burgeoning concepts and patterns within the realm of sustainable financial practices is essential, given its ongoing development. This research aims to pinpoint the prominent areas of focus that have garnered substantial interest over the past dozen years through a meticulous examination of existing literature on green finance. To achieve this, a bibliometric analysis was conducted on 978 publications from 2011 to 2023, sourced from Scopus and Web of Science databases, examining annual research output, journal distribution, national contributions, influential authors, frequently occurring keywords, knowledge gaps, temporal keyword frequency, trending topics, and thematic areas in green finance. The review's outcome revealed seven distinct categories: (i) environmental stewardship through green finance; (ii) investment opportunities in green finance; (iii) innovative applications of green finance; (iv) regulatory frameworks and credit guidelines for green finance; (v) the economic implications of green finance; (vi) corporate social responsibility in green finance; and (vii) challenges, barriers, and awareness surrounding green finance. The analysis of these emerging categories will enrich the existing body of knowledge and offer valuable perspectives on the evolving landscape of green finance.""","This study delves into the evolving field of green finance, aiming to uncover prominent themes and trends that have emerged over the past twelve years. To achieve this, the authors conducted a comprehensive review of 978 publications from 2011 to 2023, sourced from reputable databases like Scopus and Web of Science. Using bibliometric analysis, the study explored various aspects such as publication trends, influential authors, and key terminology. This examination also revealed areas where empirical research is needed. The study ultimately identifies seven core themes within green finance, including its connection to environmental sustainability, investments, innovation, policy and guidelines, economic impact, corporate social responsibility, and the trends, challenges, and awareness surrounding its development. By shedding light on these emerging themes, the study enriches the existing understanding of green finance and provides valuable insights into its dynamic landscape.",acceptable,acceptable,acceptable,3.6,3.2,3.2
184,"Digital finance, innovation transformation, and resilient city growth","Digital finance is a pivotal catalyst for a contemporary economic system and assumes a significant auxiliary function in the establishment of resilient urban centers. This study empirically examines the enabling influence of digital finance on resilient cities using panel data from 287 prefecture-level cities and above in China between 2011 and 2020. The analysis is based on the mechanisms of innovation and transformation. The importance of digital finance in facilitating the development of resilient cities has been observed, with a specific emphasis on its impact on enhancing the adaptive capacity and growth resilience of urban areas. The utilization of digital finance has the potential to expedite the process of transforming urban industrial structures, invigorating innovation and entrepreneurial activities, and serving as a significant catalyst for the development of resilient cities. The analysis of heterogeneity reveals that various aspects of digital finance have varying degrees of influence on urban resilience. Specifically, the depth of utilization of digital finance exerts the most significant impact, followed by the level of digitalization, while the extent of coverage has the least effect. Furthermore, when considering regional distribution, the promotion effect of digital finance on resilient cities diminishes gradually from the eastern to the central and western regions.","Digital finance plays a crucial role as a catalyst in today's economic system and significantly contributes to the development of robust urban centers. This research investigates the impact of digital finance on city resilience using panel data from 287 prefecture-level cities and higher across China between 2011 and 2020, focusing on mechanisms of innovation and transformation. The study highlights the importance of digital finance in fostering resilient cities by enhancing cities' adaptive capabilities and growth resilience. Digital finance can accelerate the transformation of urban industrial structures, stimulate innovation and entrepreneurial activities, and act as a key driver for building resilient cities. The heterogeneity analysis indicates that different facets of digital finance influence urban resilience to varying extents, with depth of utilization having the greatest effect, followed by the level of digitalization, and coverage breadth having the least. Additionally, the positive impact of digital finance on resilient cities decreases progressively from the eastern to the central and western regions.","The modern economy relies heavily on digital finance as a key driver of growth and a crucial supporting factor in the creation of robust metropolitan hubs. This research undertakes an empirical investigation into the empowering role of digital finance in fostering resilient urban ecosystems, leveraging a comprehensive dataset of 287 prefecture-level cities and above in China spanning 2011-2020. By dissecting the underlying mechanisms of innovation and transformation, the study highlights the pivotal contribution of digital finance to the development of resilient cities, with a particular focus on its capacity to enhance adaptive capabilities and growth resilience. The strategic deployment of digital finance can accelerate the transformation of urban industrial landscapes, stimulate innovation and entrepreneurship, and serve as a powerful catalyst for resilient city development. A nuanced analysis of heterogeneous effects reveals that different facets of digital finance exert varying levels of influence on urban resilience, with the intensity of digital finance utilization having the most profound impact, followed by the degree of digitalization, and the scope of coverage having the least effect. Moreover, a regional breakdown indicates that the promotional impact of digital finance on resilient cities gradually diminishes from the eastern to the central and western regions.","As a crucial driver of modern economic progress, digital finance plays a vital supporting role in fostering resilient urban environments. This empirical study, utilizing panel data spanning 2011 to 2020 from 287 Chinese cities at or above the prefectural level, explores how digital finance empowers resilience in these urban centers. Focusing on the mechanisms of innovation and transformation, the research highlights the significant role of digital finance in bolstering urban resilience, particularly its impact on boosting adaptability and growth resilience within cities. Leveraging digital finance can accelerate the evolution of urban industrial structures, stimulate innovation and entrepreneurship, and serve as a powerful engine for resilient city development. The heterogeneity analysis reveals that different facets of digital finance exert varying levels of influence on urban resilience. Depth of digital finance utilization exhibits the most pronounced effect, followed by the degree of digitalization, while breadth of coverage demonstrates the weakest impact. Furthermore, the study observes a geographical gradient in the promotional influence of digital finance on resilient cities, gradually weakening from eastern to central and western regions.",acceptable,acceptable,acceptable,3.6,3.6,3.6
185,Breaking the chains of traditional finance: A taxonomy of decentralized finance business models,"Recently, the looming bankruptcy of Credit Suisse, which ultimately led to its merger with UBS, has intensified the discussion surrounding the need for more transparent and democratic financial markets. Decentralized finance (DeFi) represents a departure from traditional financial intermediation by leveraging blockchain technology and smart contracts. Despite its growing importance, limited research has been conducted on the business models of DeFi services. This study aims to address this gap by examining the business models of various DeFi services, identifying key drivers of innovation, differentiation, and value creation. Using a rigorous taxonomy development framework, we identify 12 dimensions and 47 characteristics that operationalize business models in DeFi. Our findings contribute to a better understanding of the transformation of financial services through blockchain technology and provide valuable insights for DeFi entrepreneurs, investors, and policymakers.","The recent threat of Credit Suisse’s insolvency, which culminated in its merger with UBS, has heightened the debate over the necessity for more open and democratic financial markets. Decentralized finance (DeFi) stands apart from conventional financial intermediation by utilizing blockchain technology and smart contracts. Although its significance is increasing, there is a lack of extensive research on DeFi business models. This study seeks to fill this void by analyzing the business models of different DeFi services, pinpointing major drivers of innovation, differentiation, and value creation. Through a comprehensive taxonomy development framework, we identify 12 dimensions and 47 characteristics essential for DeFi business models. Our results enhance the understanding of financial service transformation via blockchain technology and offer critical insights for DeFi entrepreneurs, investors, and policymakers.","The recent collapse of Credit Suisse, culminating in its acquisition by UBS, has sparked a renewed debate about the necessity for more open and participatory financial systems. DeFi, which harnesses blockchain and smart contracts to revolutionize traditional financial brokerage, has emerged as a promising alternative. However, despite its increasing significance, there is a dearth of research on the revenue streams and value propositions of DeFi platforms. This investigation seeks to bridge this knowledge gap by analyzing the business strategies of diverse DeFi providers, pinpointing the primary catalysts of innovation, distinctiveness, and value generation. Through the application of a systematic typology development framework, we uncover 12 key facets and 47 attributes that define DeFi business models. Our discoveries offer fresh insights into the blockchain-driven transformation of financial services, providing actionable guidance for DeFi startups, investors, and regulatory bodies.","The recent near-collapse and subsequent absorption of Credit Suisse by UBS has ignited debate on the imperative for greater clarity and inclusivity within financial systems. As a disruptive force in finance, DeFi bypasses conventional intermediaries, utilizing blockchain technology and automated contracts. Despite its burgeoning relevance, there's a dearth of research on DeFi's operational models. This investigation seeks to rectify this by scrutinizing the business structures of various DeFi services, pinpointing the core factors driving innovation, distinctiveness, and value generation. Employing a robust taxonomic framework, we define 12 dimensions and 47 attributes that operationalize DeFi business models. Our discoveries enhance comprehension of blockchain-powered financial service transformation, offering valuable insights to DeFi stakeholders – entrepreneurs, investors, and policymakers alike.",acceptable,acceptable,acceptable,3.6,3.2,3.2
186,Modelling Climate Finance Flows in Sub-Saharan Africa,"Climate finance stakeholders across Africa have long sought to understand the complex nature of the climate cash flow architecture. Distribution models are critical mathematical tools for generating the general characteristics of the cash flow that are used to inform policy decisions. In this paper, we undertake a comprehensive investigation of the climate funds flowing into sub-Saharan Africa (SSA) by suggesting candidate climate finance models that can be used by policy makers to design simulations that can aid in assessing climate risks, identify more efficient climate finance schemes, and obtain optimal control parameter settings under different scenarios. This is achieved by considering climate finance as a form of insurance. Different dimensions of the data are examined following four distinct groupings of the data set. This is to account for different views of risk by the various climate finance participants. The frequency and severity of the approved funds are analyzed with the aid of various mathematical distribution models and regression analyses. The dynamics of a given variable relative to varying scenarios are examined. The findings obtained confirm the presence of emerging risks induced by the nature of the flow. Central Africa for instance records the lowest theme-specific projects and mitigation finance accounts for more than half of all the climate funds while sectoral-wise, adaptation finance is majorly concentrated in the energy sector. The perpetuation of the observed inequalities across the themes, subregions and sector-specific climate-related projects portends grave consequences as these risks begin to accumulate over time. The Burr mixture model best fitted the approved projects’ cost distribution and the factors driving the frequency and severity of approved projects ranged from Central Africa to projects in the general environment sector. One of the policy recommendations emphasized was the need to adopt a risk-adjusted distribution model for climate finance allocation in SSA.","Stakeholders involved in climate finance across Africa have long strived to comprehend the intricate nature of the climate cash flow framework. Distribution models serve as essential mathematical instruments for generating the general characteristics of cash flow, which are crucial for policy-making. This paper conducts an exhaustive analysis of climate funds directed towards sub-Saharan Africa (SSA), proposing candidate climate finance models for policymakers. These models can be deployed to design simulations that assist in evaluating climate risks, identifying more efficient climate finance schemes, and determining optimal control parameters under varying scenarios. This is approached by treating climate finance as a form of insurance. Different data dimensions are reviewed through four distinct categorizations to account for varying risk perspectives among climate finance stakeholders. The frequency and severity of approved funds are assessed using various mathematical distribution models and regression analyses, examining the dynamics of a given variable under different scenarios. The findings reveal emerging risks attributable to the nature of the cash flow, with Central Africa exhibiting the fewest theme-specific projects and mitigation finance comprising over half of all climate funds. Sector-wise, adaptation finance is predominantly concentrated in the energy sector. The persistence of observed disparities across themes, subregions, and sector-specific climate-related projects signals serious consequences as these risks accumulate over time. The Burr mixture model was found to most accurately represent the cost distribution of approved projects, with drivers of project frequency and severity ranging from Central Africa to projects in the general environment sector. Among the policy recommendations, adopting a risk-adjusted distribution model for allocating climate finance in SSA was highlighted.","Across Africa, stakeholders in climate finance have persistently endeavored to decipher the intricate framework of climate-related financial flows. Mathematical distribution models serve as vital instruments for policymakers, as they provide a comprehensive understanding of cash flow patterns, thereby informing strategic decisions. This study undertakes an exhaustive examination of climate finance inflows into sub-Saharan Africa, proposing novel models that enable policymakers to simulate climate risk assessments, identify optimized financing schemes, and determine ideal control parameters under diverse scenarios. By conceptualizing climate finance as a form of risk management, this research explores multiple dimensions of the data, categorized into four distinct groups, to accommodate varied risk perceptions among stakeholders. Frequency and severity analyses of approved funds, facilitated by mathematical distribution models and regression techniques, reveal the dynamics of variables under different scenarios. The findings confirm the emergence of risks inherent to the flow of climate finance, with notable disparities observed across themes, subregions, and sector-specific projects. For instance, Central Africa exhibits the lowest number of theme-specific projects, while mitigation finance dominates the climate fund allocation, and adaptation finance is predominantly concentrated in the energy sector. The perpetuation of these inequalities poses significant long-term consequences. The Burr mixture model is identified as the best fit for the cost distribution of approved projects, with factors influencing project frequency and severity ranging from Central Africa to projects focused on the general environment sector. A key policy recommendation is the adoption of a risk-adjusted distribution model for climate finance allocation in sub-Saharan Africa.","African stakeholders in climate finance have consistently aimed to decipher the intricate mechanisms governing climate-related financial flows. Mathematical distribution models play a crucial role in delineating the general characteristics of these flows, which subsequently inform policy decisions. This study offers a detailed exploration of climate funds directed towards sub-Saharan Africa (SSA), proposing candidate models that policymakers can utilize for simulations. These simulations, conceptualizing climate finance as a form of insurance, can facilitate climate risk assessment, identify superior finance schemes, and determine optimal control parameters under varying scenarios. To account for diverse perspectives on risk among stakeholders, the data is categorized into four distinct groups and analyzed across different dimensions. Through mathematical distribution models and regression analyses, the frequency and magnitude of approved funds are scrutinized, alongside the dynamic behavior of variables in various scenarios. The results highlight emerging risks inherent in the nature of climate finance flows. For example, Central Africa exhibits the lowest number of theme-specific projects, mitigation finance constitutes over half of all climate funds, and adaptation finance is heavily concentrated in the energy sector. The persistence of observed inequalities across themes, subregions, and sector-specific climate projects poses significant future risks if allowed to accumulate. The Burr mixture model was found to best fit the cost distribution of approved projects, with factors influencing project frequency and severity ranging from Central Africa to initiatives within the general environment sector. One key policy recommendation underscores the need for a risk-adjusted distribution model for allocating climate finance in SSA.",acceptable,acceptable,acceptable,3.2,3.2,3.2
187,Advancing green finance: a review of climate change and decarbonization,"This paper comprehensively reviews the interconnections between climate change, decarbonization, and green finance. The urgency of addressing climate change and its catastrophic consequences needs to focus on green finance as a vital tool in the global struggle against environmental damage. Green finance involves supplying investments, loans, or capital to support environmentally friendly activities, facilitating the transition to a more sustainable future. This review explores the theoretical frame of reference for green finance, including its impacts on climate change, decarbonization of economies, carbon-stranded assets, risk management, renewable energy, and sustainable economic growth. Additionally, it examines regional focuses in Asia, such as the importance of green finance in China and the beliefs and challenges of green finance in Bangladesh. The review also discusses future directions and recommendations for advancing green finance. The review examines the current research in green finance and how it can address environmental challenges and promote sustainable development. More research needs to be conducted in mainstream economics and finance journals to bridge the knowledge gap and foster broader scholarly engagement in green finance. Researchers, policymakers, investors, and stakeholders will receive help from the study's reliable and robust insights into combating climate change and promoting sustainable development.","This article thoroughly examines the links between climate change, decarbonization, and green finance. The critical necessity of mitigating climate change and its severe consequences highlights green finance as an essential instrument in the global fight against environmental harm. Green finance entails providing investments, loans, or capital to back eco-friendly initiatives, thus enabling the shift toward a more sustainable future. This examination delves into the theoretical framework surrounding green finance, addressing its effects on climate change, economic decarbonization, carbon-stranded assets, risk management, renewable energy, and sustainable economic growth. Furthermore, it analyzes regional focuses within Asia, such as the significance of green finance in China and the perspectives and obstacles faced in Bangladesh. The review also outlines future pathways and suggestions for the progression of green finance. It scrutinizes current research on how green finance can overcome environmental challenges and encourage sustainable development. There is a need for more studies published in prominent economics and finance journals to close the knowledge gap and boost wider academic interest in green finance. The study's substantial and dependable insights offer valuable support to researchers, policymakers, investors, and stakeholders in the quest to tackle climate change and endorse sustainable development.","This study undertakes an exhaustive examination of the intricate relationships between climate change mitigation, decarbonization strategies, and the emergence of sustainable financial systems. The imperative to tackle the devastating repercussions of climate change necessitates a concerted emphasis on green finance as a crucial instrument in the global quest to mitigate ecological degradation. By channeling investments, credit facilities, and capital towards eco-friendly initiatives, green finance facilitates a paradigm shift towards a more environmentally conscious future. This comprehensive review delves into the conceptual underpinnings of green finance, encompassing its influence on climate change mitigation, low-carbon economic transitions, stranded asset risks, risk management frameworks, renewable energy integration, and sustainable economic expansion. Furthermore, it scrutinizes regional hotspots in Asia, including the pivotal role of green finance in China's development and the perceptions, obstacles, and opportunities surrounding green finance in Bangladesh. The review also charts future trajectories and policy prescriptions for green finance advancement. By synthesizing existing research in green finance, this study provides actionable guidance on addressing environmental imperatives and promoting sustainable development, underscoring the need for further inquiry in mainstream economic and financial journals to bridge knowledge gaps and stimulate interdisciplinary dialogue among scholars, policymakers, investors, and stakeholders.","This comprehensive analysis explores the intricate relationship between climate change mitigation, economic decarbonization, and the burgeoning field of green finance. Highlighting the critical need to address the potentially devastating impacts of climate change, the paper positions green finance as a crucial instrument in the global fight against environmental degradation. Green finance, which encompasses the provision of funding, credit, and investment for environmentally sustainable initiatives, plays a pivotal role in facilitating the shift towards a more sustainable future. This review delves into the theoretical underpinnings of green finance, examining its influence on climate change mitigation, economic decarbonization, the issue of carbon-stranded assets, risk management strategies, renewable energy development, and sustainable economic growth. Furthermore, the analysis provides regional insights, specifically focusing on the significance of green finance in China and exploring the perspectives and obstacles surrounding green finance in Bangladesh. Future trajectories and recommendations for propelling the advancement of green finance are also discussed. The review critically assesses the existing research landscape in green finance, emphasizing its potential to tackle environmental challenges and foster sustainable development. The authors advocate for increased research within mainstream economics and finance publications to bridge existing knowledge gaps and encourage wider academic engagement in the field of green finance. This study's reliable and comprehensive insights aim to provide valuable guidance to researchers, policymakers, investors, and stakeholders in their collective efforts to combat climate change and promote sustainable development.",acceptable,acceptable,acceptable,3.2,3.2,3.6
188,Advancing green finance: a review of sustainable development,"This study comprehensively reviews the relationship between green finance and sustainable development, specifically focusing on combatting climate change and achieving carbon neutrality. Utilizing a narrative review methodology, the study examines a range of scholarly articles and publications to identify key themes, findings, and future directions in green finance. The review emphasizes the crucial role of substantial investments in green and low-carbon initiatives to address climate change effectively and promote sustainable economic growth. It highlights the necessity of robust regulatory frameworks that facilitate the availability of green finance and the integration of carbon–neutral practices. Additionally, the paper explores the potential of impact investing, wherein investors accept lower financial returns in exchange for non-financial benefits in green finance. It underscores the influential role of institutional ownership in guiding companies toward enhanced environmental and social performance. Moreover, integrating environmental, social, and governance (ESG) factors in investment decisions is critical for sustainable finance. Addressing the intersection of climate change and risk management, the review highlights the implications of environmental risks on financial decision-making. Effective communication strategies can raise public awareness and support for climate policies. The study concludes by calling for collaboration, further research, and policy measures to advance green finance and foster sustainable economic growth. It recommends aligning financial incentives with sustainable outcomes, fostering transparency, and incorporating social equity in green finance initiatives to contribute towards achieving sustainable development goals and promoting a greener future.","This research thoroughly examines the connection between green finance and sustainable development, with a particular emphasis on mitigating climate change and attaining carbon neutrality. Adopting a narrative review methodology, the study analyzes various academic papers and publications to pinpoint key themes, discoveries, and future directions in green finance. The review underscores the essential role of significant investments in green and low-carbon projects to address climate change effectively and stimulate sustainable economic growth. It stresses the need for strong regulatory frameworks to facilitate access to green finance and the adoption of carbon-neutral practices. Furthermore, the paper investigates the potential of impact investing, where investors accept reduced financial returns in exchange for non-financial benefits in green finance. It highlights the key role of institutional ownership in driving companies toward improved environmental and social performance. Additionally, the integration of environmental, social, and governance (ESG) factors in investment decisions is deemed crucial for sustainable finance. By addressing the nexus of climate change and risk management, the review underscores the influence of environmental risks on financial decision-making. Effective communication strategies are identified as a means to elevate public awareness and support for climate policies. The study concludes with a call for collaboration, further research, and policy interventions to progress green finance and encourage sustainable economic growth. It advocates aligning financial incentives with sustainable goals, promoting transparency, and incorporating social equity within green finance initiatives to aid in achieving sustainable development goals and fostering a greener future.","This comprehensive analysis delves into the intricate connection between environmentally responsible financial practices and long-term sustainability, with a particular emphasis on mitigating the impacts of climate change and realizing a carbon-neutral economy. Through a meticulous narrative review of existing literature, the study distills key patterns, insights, and future research avenues in the realm of green finance. The authors stress the imperative of substantial investments in eco-friendly and low-carbon projects to combat climate change effectively and drive sustainable economic expansion. They also underscore the need for robust regulatory frameworks that facilitate access to green finance and the adoption of carbon-neutral practices. Furthermore, the paper explores the potential of socially responsible investing, where investors trade off financial returns for non-monetary benefits in the green finance sector. It highlights the pivotal role of institutional investors in guiding companies toward enhanced environmental stewardship and social responsibility. The integration of environmental, social, and governance considerations into investment decisions is deemed crucial for sustainable financial practices. The review also examines the nexus between climate change and risk management, emphasizing the far-reaching implications of environmental risks on financial decision-making. Effective communication strategies can galvanize public support for climate policies. Ultimately, the study advocates for collaborative efforts, further research, and policy interventions to propel green finance and foster sustainable economic growth, recommending the alignment of financial incentives with sustainable outcomes, enhanced transparency, and the incorporation of social equity in green finance initiatives to contribute to the attainment of sustainable development goals and a more environmentally conscious future.","This in-depth analysis explores the interconnectedness of green finance and sustainable development, particularly in mitigating climate change and achieving carbon neutrality. Employing a narrative review approach, the study delves into a wide array of academic literature to discern key patterns, insights, and potential trajectories within the field. It stresses the vital importance of substantial financial commitments to environmentally friendly and low-carbon projects to effectively tackle climate change and drive sustainable economic progress. The analysis underscores the need for robust regulatory structures that streamline access to green financing and the incorporation of carbon-neutral practices. Furthermore, the paper probes the promise of impact investing, where investors prioritize environmental and social benefits over maximized financial returns. It emphasizes the significant influence of institutional investors in steering corporations towards improved environmental and social responsibility. The integration of ESG principles into investment strategies is also deemed crucial for sustainable finance. Examining the nexus of climate change and risk management, the review illuminates the impact of environmental risks on financial decision-making. The study emphasizes the need for effective communication strategies to enhance public understanding and support for climate-related policies. The analysis concludes by advocating for collaborative efforts, expanded research, and policy interventions to propel green finance and stimulate sustainable economic growth. It proposes aligning financial incentives with sustainable outcomes, promoting transparency, and embedding social equity within green finance initiatives to contribute to the realization of sustainable development goals and a more environmentally sound future.",acceptable,acceptable,acceptable,3.6,3.6,3.2
189,Astronomy and Culture,"Modern astronomy as a field of inquiry may be shaped by what we consider the “scientific” ways of knowing. However, the history of astronomy as a human endeavour dates back millennia before the “modern” notions of “science”. This long history means that astronomy is, at its core, built on a rich cultural diversity and history. This offers a rich potential that, while having been examined in various studies, has yet to be explored from a contextual pedagogical perspective. This paper offers an initial exploratory theoretical perspective on how social semiotics can be used to inform a conceptual framework. This approach not only brings notions of culture into the teaching and learning of astronomy but uses culture as the starting point in a way that does justice to the cultural diversity of the discipline and the world. In doing so, this paper develops two frameworks: (i) the Conceptual Framework for Culture in Astronomy Education and (ii) the Pedagogical Framework for Culture in Astronomy Education, both of these offer a novel approach to astronomy education.","While modern astronomy is often framed by “scientific” methods of understanding, the discipline's roots stretch back thousands of years, long before contemporary definitions of “science” were established. This extensive history signifies that astronomy fundamentally relies on a vast cultural and historical foundation. Despite various studies examining this rich cultural potential, it has not yet been fully investigated from a contextual pedagogical standpoint. This paper introduces an initial theoretical exploration of how social semiotics can contribute to shaping a conceptual framework. By integrating cultural elements into the pedagogy of astronomy, this approach acknowledges and utilizes the cultural diversity inherent in the field and the broader world. The paper proposes two innovative frameworks: (i) the Conceptual Framework for Culture in Astronomy Education and (ii) the Pedagogical Framework for Culture in Astronomy Education, offering a fresh perspective on astronomy education.","The pursuit of astronomical knowledge is often framed by contemporary notions of scientific inquiry, yet the discipline's ancient roots span thousands of years, predating modern conceptions of science. This extensive heritage has woven a tapestry of diverse cultural influences, which, despite being touched upon in various research, remains to be fully explored from a pedagogical standpoint. This study pioneers a theoretical exploration of how social semiotics can illuminate a conceptual structure, effectively integrating cultural considerations into astronomy education. By doing so, it establishes a cultural foundation that acknowledges the discipline's rich diversity and that of the world at large. The outcome is the development of two innovative frameworks: the Conceptual Framework for Cultural Integration in Astronomy Education and the Pedagogical Framework for Cultural Relevance in Astronomy Education, collectively offering a fresh approach to teaching and learning astronomy.","The influence of contemporary scientific paradigms on the field of astronomy is undeniable. Yet, the human quest to understand the cosmos predates modern scientific thought by millennia. This rich and diverse cultural heritage, though acknowledged in various research, remains largely unexplored in pedagogical contexts. This paper proposes a theoretical framework, grounded in social semiotics, to integrate culture into the teaching and learning of astronomy. By prioritizing culture, this approach not only acknowledges its significance in astronomy education but also honors the discipline's inherent cultural richness. Consequently, two innovative frameworks are introduced: the Conceptual Framework for Culture in Astronomy Education and the Pedagogical Framework for Culture in Astronomy Education, both offering a fresh perspective on astronomical pedagogy.",acceptable,acceptable,acceptable,3.2,3.2,3.2
190,Direct and Indirect Opportunities to Learn Astronomy Within the Chilean Science Curriculum,"Astronomy has great potential to attract children toward science and improve their scientific literacy. However, it has a relatively small presence within the school curricula worldwide. In Chile, home of the world’s largest telescopes, astronomy is even more relevant in science education, but the presence of astronomical content within the national curriculum was not studied yet. In this context, this article characterizes the opportunities to learn astronomy within the Chilean science curriculum from grades 1 to 12. A mixed descriptive design with documental analysis is conducted to determine which science learning objectives (LOs) are directly or indirectly related to astronomy and classify them according to astronomical topics, cognitive processes, and Big Ideas in Astronomy. The proportion of LOs related to astronomy within the whole science curriculum and the categories of interest are calculated and compared over the school grades. The results show that the LOs directly related to astronomy are present only in a third of the grades and include a small variety of astronomical topics. Meanwhile, LOs indirectly related to astronomy appear in all grades and include more topics and higher cognitive processes. We discuss the implications of the outcomes and raise some possibilities to promote astronomy literacy through interdisciplinary work.","Astronomy holds significant promise for engaging children in science and enhancing their scientific understanding, yet it occupies a limited role in global school curricula. In Chile, renowned for its large telescopes, astronomy's importance in science education is heightened, though the extent of its inclusion in the national curriculum has not been thoroughly examined. This study investigates the presence of astronomical education in Chilean science curricula from grades 1 to 12. Utilizing a mixed descriptive model and document analysis, the study identifies and classifies science learning objectives (LOs) related to astronomy based on topics, cognitive processes, and overarching astronomical concepts. The analysis determines the proportion of astronomy-related LOs within the entire science curriculum, comparing them across different grade levels. Findings indicate that directly astronomy-related LOs are found in only a third of the grades and cover a limited range of topics. Conversely, indirectly related LOs are present in all grades, encompassing a broader array of topics and more complex cognitive processes. The paper discusses the implications of these findings and suggests ways to enhance astronomy literacy through cross-disciplinary approaches.","The field of astronomy possesses immense capacity to captivate young minds and foster a deeper understanding of scientific concepts, yet its representation in educational curricula globally remains limited. In Chile, a nation renowned for its colossal telescopes, the significance of astronomy in science education is amplified, although the extent of its incorporation into the national curriculum has not been explored. This study delves into the opportunities for astronomy education within Chile's science curriculum, spanning grades 1-12, employing a mixed descriptive design and document analysis to identify science learning objectives linked to astronomy, categorized by astronomical themes, cognitive processes, and fundamental astronomy concepts. The proportion of astronomy-related objectives within the broader science curriculum and their distribution across grade levels are calculated and compared. The findings reveal that direct astronomy-related objectives are confined to a third of the grades, encompassing a narrow range of topics, whereas indirect connections to astronomy are present throughout all grades, incorporating a broader spectrum of topics and higher-order cognitive skills. The implications of these outcomes are discussed, and potential avenues for promoting astronomy literacy through interdisciplinary approaches are proposed.","While astronomy holds immense promise for engaging children in science and fostering scientific understanding, its integration into school curricula globally remains limited. This is particularly noteworthy in Chile, a nation housing some of the world's most advanced telescopes, where astronomy's educational significance is paramount. Despite this, the extent to which astronomical content features in the Chilean national curriculum remains unexplored. This study, therefore, endeavors to identify opportunities for learning astronomy within the Chilean science curriculum from primary to secondary education (grades 1 to 12). Employing a mixed descriptive methodology with document analysis, the research identifies science learning objectives that have direct or indirect links to astronomy. These objectives are then categorized based on astronomical themes, cognitive processes involved, and fundamental astronomical concepts. The study quantifies and compares the proportion of astronomy-related learning objectives within the broader science curriculum across different grade levels, focusing on specific categories of interest. Findings reveal that learning objectives directly addressing astronomy are found only in a limited number of grades and encompass a restricted range of astronomical topics. Conversely, learning objectives indirectly related to astronomy are present throughout all grades and encompass a wider array of topics and demand more sophisticated cognitive processes. The implications of these results are discussed, along with potential avenues for enhancing astronomy literacy through interdisciplinary approaches.",acceptable,acceptable,acceptable,3.2,3.2,3.2
191,Status of the TAIGA Experiment: Gamma Astronomy,"AbstractThe status of the TAIGA experiment (Tunka Advanced Instrument for cosmic-ray physics and Gamma-ray Astronomy) located in the Tunka Valley is presented. The paper presents mainly the tasks, developed approaches for their solution, and first results on high-energy gamma-ray astronomy (10 TeV and higher) obtained from a two- to three-year exposure. The current tasks of gamma-ray astronomy and plans for development of the installation are discussed.","AbstractThe TAIGA experiment (Tunka Advanced Instrument for cosmic-ray physics and Gamma-ray Astronomy) situated in the Tunka Valley is outlined. This paper primarily outlines the objectives, the methodologies implemented to address them, and the initial findings in high-energy gamma-ray astronomy (10 TeV and above) derived from two to three years of observation. The ongoing challenges in gamma-ray astronomy and the future development plans for the facility are also discussed.","""This report provides an update on the TAIGA project, situated in the Tunka Valley, outlining its objectives, methodologies, and preliminary findings in high-energy gamma-ray astronomy, specifically above 10 TeV, garnered from a two- to three-year observational period. The ongoing challenges and future expansion plans for the facility are also explored.""","This paper outlines the current state of the TAIGA experiment, situated in the Tunka Valley, which investigates cosmic rays and gamma-ray astronomy. It focuses on the project's objectives, the strategies employed to achieve them, and preliminary findings in high-energy gamma-ray astronomy (above 10 TeV) derived from a two-to-three-year observational period. The article concludes with a discussion of ongoing challenges in gamma-ray astronomy and future prospects for the TAIGA facility.",acceptable,acceptable,acceptable,3.6,3.2,3.2
192,Subterahertz Astronomy in the Russian Federation: Prospects and Directions,"AbstractThis paper addresses the scientific and technical prospects and potential directions for the development of subterahertz astronomy in the Russian Federation. The concept of creating subterahertz instruments in the form of a universal compact antenna array for placement on the territory of the Russian Federation is proposed. It is possible to implement several space projects in the subterahertz range using such an antenna array, including a space interferometer and a telescope on the surface of the Moon. Ground-based compact antenna arrays will be able to act as a support for the very long baseline interferometer mode of the Millimetron observatory.","This study explores the scientific and technological possibilities and future directions for the advancement of subterahertz astronomy in Russia. It proposes developing versatile compact antenna arrays for subterahertz instruments, to be situated in Russia. These arrays could facilitate several space projects within the subterahertz spectrum, such as a space interferometer and a lunar surface telescope. Additionally, ground-based compact antenna arrays could support the Millimetron observatory's very long baseline interferometer mode.","""This study explores the scientific and technological opportunities and future trajectories for advancing subterahertz astronomy in Russia, introducing a novel concept for a versatile, compact antenna array deployable across the country. This innovative infrastructure could facilitate multiple space-based initiatives in the subterahertz spectrum, including a lunar-surface telescope and a space-based interferometer. Furthermore, ground-based compact arrays could serve as a supplementary system for the Millimetron observatory's very long baseline interferometer mode.""","This article explores the future possibilities and advancements in subterahertz astronomy within Russia. It presents the idea of developing versatile, compact subterahertz antenna arrays for deployment across the nation. These arrays could support various space-based initiatives, such as a subterahertz space interferometer and a lunar telescope. Furthermore, ground-based compact arrays could serve as a foundation for the very long baseline interferometry capabilities of the Millimetron observatory.",acceptable,acceptable,acceptable,4.2,3.6,3.6
193,"Deep into the affinity spaces and authentic activities of astronomy camps: science teachers' interests, perceptions, and experiences","Camps are among the activities that teachers join in by taking full responsibility for their own ongoing development and eagerly following in accordance with their needs. This paper aims to demonstrate that the affinity space and authentic nature of astronomy camp activities provide teachers much more than expected. Therefore, the study will provide supporting evidence for developing a better understanding of the extent to which science teachers have an interest in astronomy, their perceptions about camp environments, and their learning experiences in such an atmosphere. The study employs both qualitative and quantitative methodologies. The design of the study presents a statistical analysis of teachers' interest in astronomy using a validated scale and their perceptions using a semantic differentiation form, as well as interprets their experiences that stimulate this interest in astronomy and perception about camp environments through a qualitative analysis of teacher reflections and views on activities. Findings show that the social context of the camp is constructed by a selected group of individuals who have an interest in the camp and attach high-level meanings to it. And their views on activities reveal meaningful experiences that varied depending on the camp's affinity space, as well as authentic activities to support their development. In summary, the current study contributes to the growing body of evidence that affinity spaces and the authentic nature of the outdoor camp activities provide valuable experiences for teacher development.","Educators participate in camps by taking full ownership of their own continuous development and actively engaging according to their specific needs. This paper aims to show that the unique environment and genuine nature of astronomy camp activities offer teachers more benefits than anticipated. Consequently, the study will supply evidence to foster a better understanding of the extent of science teachers' interest in astronomy, their views on camp settings, and their learning experiences in such environments. The study utilizes both qualitative and quantitative techniques. It includes a statistical analysis using a validated scale to measure teachers' interest in astronomy and their perceptions via a semantic differentiation form, along with a qualitative analysis of teachers’ reflections and opinions on activities that kindle this interest and perspectives on camp settings. Results indicate that the social context of the camp is built by a chosen group of interested individuals who assign significant meanings to it. Their opinions on activities uncover significant experiences that differ based on the camp's unique space and genuine activities that bolster their development. In conclusion, the study adds to the growing body of evidence that specialized spaces and the authentic nature of outdoor camp activities provide valuable experiences for teacher growth.","Educators proactively engage in their continuous professional growth by embracing opportunities like camps, where they take ownership of their development and enthusiastically respond to their individual needs. This research seeks to illustrate that astronomy camps offer a unique synergy of affinity space and authenticity, yielding a richer experience for teachers than anticipated. The study aims to provide insight into the degree of science teachers' fascination with astronomy, their perceptions of camp settings, and their learning outcomes in these environments. By combining qualitative and quantitative approaches, the research design incorporates a statistical examination of teachers' interest in astronomy using a validated instrument, as well as a semantic analysis of their perceptions, supplemented by an interpretive exploration of their reflections and views on activities. The findings suggest that the camp's social context is shaped by a dedicated group of individuals who attribute profound significance to the experience, and their activity-based feedback reveals diverse, meaningful experiences influenced by the camp's affinity space and authentic activities, which support their growth. Ultimately, this study adds to the accumulating evidence that affinity spaces and authentic outdoor camp activities provide a valuable catalyst for teacher development.","Teacher participation in camps, marked by their commitment to personal and professional growth, transcends mere duty. This research explores the unexpectedly rich learning environment astronomy camps offer, delving into teachers' astronomical interest, their perspectives on camp settings, and the educational value they derive from such experiences. Employing a mixed-methods approach, the study analyzes teacher interest in astronomy using a validated scale, gauges their perceptions via a semantic differential, and qualitatively examines their reflections and opinions on activities to understand the factors driving their interest and perceptions. The findings highlight that the camp's social fabric is woven by individuals united by their shared passion, imbuing it with profound significance. Moreover, teacher perspectives on activities reveal impactful experiences shaped by the camp's affinity space and authentic learning opportunities that foster their professional development. This research substantiates the growing recognition that affinity spaces and the genuine nature of outdoor camp activities provide invaluable avenues for teacher growth.",acceptable,acceptable,acceptable,3.6,3.2,3.2
194,Disentropy in astronomy,"Astronomers often have to deal with randomness. For example, stars and radio telescopes are sources of randomness. On the other hand, randomly distributed stars in some astronomical images can make harder the task of an algorithm that aims the automatic identification of important structures in the image. Therefore, a randomness measure, like the disentropy of the autocorrelation function, can be a useful mathematical tool for astronomers. In this direction, in the present work we firstly show three applications of the disentropy of the autocorrelation in astronomy. Initially, we calculate the randomness of the images of cosmic microwave background maps produced by Planck satellite, providing for the first time a numerical value for that randomness. Following, we use the disentropy to build an algorithm that erases parts of astronomical images with large randomness, what is particularly useful to remove background stars. In the third application, the disentropy of the autocorrelation is used to calculate the randomness of the signal of a radio pulsar used as random number generator. At last, we used the relative disentropy as distance measure between probability distributions in order to find the parameters of the probability density function of the flux density of a pulsar.","Astronomers frequently encounter randomness in their work. Stars and radio telescopes, for instance, are sources of this randomness. Conversely, randomly scattered stars in some astronomical images can complicate an algorithm's task of automatically identifying key structures within the image. Hence, a measure of randomness, such as the disentropy of the autocorrelation function, can serve as a valuable mathematical tool for astronomers. In this context, this study presents three specific applications of disentropy in astronomy. First, we quantify the randomness in images of cosmic microwave background maps from the Planck satellite, providing a numerical value for the first time. Next, we utilize disentropy to develop an algorithm that removes highly random sections of astronomical images, which is particularly useful for eliminating background stars. Lastly, we apply the disentropy of the autocorrelation to measure the randomness in the signal of a radio pulsar used as a random number generator. Finally, we employ relative disentropy as a metric for comparing probability distributions to determine the parameters of the probability density function for a pulsar's flux density.","Astronomers frequently encounter stochasticity in their work, with celestial bodies and radio telescopes being prominent sources of uncertainty. Conversely, the random scattering of stars in certain astronomical images can hinder the performance of algorithms designed to automatically detect crucial features within those images. As a result, a stochasticity metric, such as the disentropy of the autocorrelation function, can serve as a valuable mathematical instrument for astronomers. In this study, we explore three novel applications of disentropy in astronomy. We begin by quantifying the stochasticity of cosmic microwave background maps generated by the Planck satellite, thereby providing a numerical estimate of this randomness for the first time. Next, we develop an algorithm that utilizes disentropy to eliminate regions of astronomical images exhibiting high stochasticity, which is particularly effective in removing background stars. In our third application, we employ disentropy to calculate the stochasticity of a radio pulsar's signal, which is used as a random number generator. Finally, we utilize relative disentropy as a distance metric between probability distributions to determine the parameters of a pulsar's flux density probability density function.","Astronomical research frequently encounters inherent randomness, originating from sources like stars and radio telescopes. While this randomness is intrinsic, it can complicate algorithmic identification of significant features in astronomical images, particularly when stars are randomly dispersed. A quantitative measure of randomness, such as the disentropy of the autocorrelation function, proves valuable in these scenarios. This study showcases three astronomical applications of autocorrelation disentropy. First, we quantify the randomness of cosmic microwave background maps from the Planck satellite, establishing a numerical value for this characteristic. Second, we develop an algorithm leveraging disentropy to selectively remove highly random sections of astronomical images, effectively filtering out background stars. Lastly, we employ autocorrelation disentropy to determine the randomness of a radio pulsar signal used for random number generation and utilize relative disentropy as a distance metric between probability distributions to estimate the parameters of a pulsar's flux density probability density function.",acceptable,acceptable,acceptable,3.2,3.2,3.2
195,Cultural diversity and innovative entrepreneurship,"A growing empirical literature has established a positive relationship between cultural diversity and entrepreneurship, often attributing this effect to innovation benefits of diversity. However, not all entrepreneurship is inherently innovative, raising the question of whether cultural diversity may increase the likelihood of an entrepreneur pursuing an innovative instead of a more replicative business strategy. This study investigates the relationship between regional cultural diversity and the innovation orientation of early-stage entrepreneurs and considers moderating factors by decomposing shares of foreign-born population by origin (within and outside of the EU) and by education level. Combining survey data from the Global Entrepreneurship Monitor with population-based indicators of cultural diversity, we carry out a multilevel analysis for 140 European regions. The results suggest that entrepreneurs in culturally more diverse regions are significantly more likely to exhibit innovation orientation.","An expanding body of empirical research has shown a positive correlation between cultural diversity and entrepreneurship, often crediting this connection to the innovation advantages offered by diversity. Nonetheless, not all entrepreneurial ventures are innovative by nature, prompting the question of whether cultural diversity might influence an entrepreneur's inclination toward an innovative rather than a replicative business approach. This research examines the link between regional cultural diversity and the innovative tendencies of early-stage entrepreneurs, taking into account moderating factors by breaking down the foreign-born population based on origin (inside and outside the EU) and education level. Utilizing survey data from the Global Entrepreneurship Monitor alongside region-specific cultural diversity indicators, we conduct a multilevel analysis across 140 European regions. The findings indicate that entrepreneurs in regions with greater cultural diversity are significantly more inclined toward innovation.","A burgeoning body of research has unearthed a significant correlation between the richness of cultural heritage and entrepreneurial spirit, frequently crediting this phenomenon to the inventive advantages afforded by diverse perspectives. Nevertheless, not all entrepreneurial ventures are inherently groundbreaking, prompting inquiry into whether culturally diverse environments might incline entrepreneurs towards pioneering business models rather than replicative ones. This investigation delves into the nexus between regional cultural heterogeneity and the innovative proclivities of nascent entrepreneurs, while also examining the moderating influence of foreign-born population demographics, categorized by EU origin and educational attainment. By integrating Global Entrepreneurship Monitor survey data with population-based metrics of cultural diversity, a multilevel analysis of 140 European regions reveals that entrepreneurs operating in culturally rich environments are markedly more prone to exhibit an innovation-oriented mindset.","A burgeoning body of research has demonstrated a link between cultural heterogeneity and entrepreneurial activity, frequently citing the innovation-enhancing benefits of diversity as the underlying mechanism. Yet, not all entrepreneurial endeavors are intrinsically innovative, prompting the inquiry of whether cultural heterogeneity might influence an entrepreneur's propensity to adopt an innovation-focused business strategy over a more imitative one. This investigation examines the connection between regional cultural heterogeneity and the innovative disposition of nascent entrepreneurs, taking into account moderating variables by disaggregating foreign-born populations based on origin (EU and non-EU) and educational attainment. Merging survey data from the Global Entrepreneurship Monitor with population-based metrics of cultural heterogeneity, a multilevel analysis encompassing 140 European regions is conducted. The findings indicate a significantly higher likelihood of exhibiting an innovation-oriented approach among entrepreneurs situated in culturally richer regions.",acceptable,acceptable,acceptable,4.8,3.2,3.6
196,"Cultural diversity, social integration, and migrant entrepreneurship—evidence from the China migrants dynamic survey","Cultural diversity in host regions presents challenges for migrant entrepreneurs, such as resource competition and social conflicts. However, whether and how cultural diversity in the host regions affects migrants’ participation in entrepreneurship is not yet well understood. This study investigates the relationship by utilizing the China Migrants Dynamic Survey (CMDS) database and introducing food diversity as a novel proxy for cultural diversity. The logit regression analysis reveals that cultural diversity in host regions can reduce migrant engagement in entrepreneurial activities, especially in “self-employed” entrepreneurship. The results are consistent with several robustness tests. Additionally, a mechanism analysis based on a multi-path mediation model reveals that social integration, including factors such as social interaction, social exclusion, and social identification, plays a mediating role in this relationship. However, robust institutional environments can moderate the negative impact of cultural diversity on migrant entrepreneurship. This study provides a fresh non-market perspective for understanding and promoting cross-cultural entrepreneurial behavior.","Migrant entrepreneurs face obstacles in culturally diverse host regions, including competition for resources and social conflicts. Despite this, the effect of cultural diversity on migrant entrepreneurship remains unclear. This research explores the connection using the China Migrants Dynamic Survey (CMDS) database, employing food diversity as an innovative measure for cultural diversity. Findings from a logistic regression analysis suggest that cultural diversity can decrease migrant entrepreneurial activity, particularly in self-employment. These results are backed by several robustness checks. Furthermore, a mechanism analysis with a multi-path mediation model indicates that social integration—comprising social interaction, exclusion, and identification—mediates this relationship. However, strong institutional frameworks can mitigate the adverse effects of cultural diversity on migrant entrepreneurship. This study offers a novel non-market perspective on fostering cross-cultural entrepreneurial behavior.","The presence of diverse cultural backgrounds in host regions poses obstacles for entrepreneurs who are migrants, including rivalry for resources and social unrest. Despite this, the extent to which cultural diversity in these regions influences migrants' inclination to engage in entrepreneurial pursuits remains unclear. This research explores this connection by leveraging the China Migrants Dynamic Survey database and innovatively employing food diversity as a proxy for cultural diversity. The logit regression analysis uncovers that cultural diversity in host regions can deter migrants from participating in entrepreneurial ventures, particularly in self-employment. These findings are corroborated by multiple robustness tests. Furthermore, a mechanism analysis based on a multi-path mediation model reveals that social integration, encompassing factors such as social interaction, social exclusion, and social identification, serves as an intermediary in this relationship. However, a robust institutional framework can mitigate the adverse effects of cultural diversity on migrant entrepreneurship. This study offers a novel, non-market-oriented perspective on understanding and fostering entrepreneurial behavior across cultural boundaries.","The influence of culturally diverse host communities on migrant entrepreneurs remains underexplored, although difficulties like resource scarcity and social discord are recognized. This research examines this relationship using the China Migrants Dynamic Survey (CMDS) database, employing food diversity as a unique indicator of cultural variety. Logit regression analysis shows that cultural diversity in host communities can hinder migrant entrepreneurial activity, particularly in self-employment. These findings are confirmed through various robustness checks. Further, a multi-path mediation model reveals that social integration, encompassing elements like social interaction, exclusion, and identification, mediates this relationship. Notably, strong institutional frameworks can mitigate the adverse impact of cultural diversity on migrant entrepreneurship. This study offers a novel, non-market viewpoint for comprehending and fostering cross-cultural entrepreneurial endeavors.",acceptable,acceptable,acceptable,3.6,3.6,3.2
197,“People Gathered by Sorghum”: Cultural Practices and sorghum Diversity in Northern Ethiopia,"Sorghum is an important crop in the livelihoods of Kunama and Tigrayan farmers in Northern Ethiopia and we present here a study of what factors have shaped the genetic diversity of the varieties cultivated in neighboring communities of the two ethnolinguistic groups. Using a combination of methods from crop science and cultural anthropology, we investigate patterns of historical and contemporary relationships between crop genetic diversity and cultural and social factors. The spatial genetic structure reveals patterns of ethnolinguistic differentiation and admixture that reflect deep affinities between cultures and crops, but the seed systems of the two communities are also open to exchange and gene-flow. Our findings highlight the importance of understanding cultural factors for genetic resource conservation, as well as for plant breeding and seed system development efforts.","Sorghum holds significant value for the livelihoods of Kunama and Tigrayan farmers in Northern Ethiopia. This study explores the factors influencing the genetic diversity of sorghum varieties grown by these neighboring ethnolinguistic communities. By employing methods from both crop science and cultural anthropology, we examine the historical and current connections between crop genetic diversity and cultural and social elements. The spatial genetic structure reveals patterns of ethnolinguistic differentiation and admixture, indicating deep cultural and crop-related ties. However, the seed systems in both communities remain open to exchange and gene flow. Our results underscore the critical role of cultural factors in the conservation of genetic resources, as well as in plant breeding and seed system development initiatives.","In Northern Ethiopia, the cultivation of sorghum is vital to the well-being of Kunama and Tigrayan farmers, and this research examines the factors that have influenced the genetic variation of the crop varieties grown in adjacent communities of these two ethnolinguistic groups. By integrating approaches from agronomy and cultural anthropology, we explore the historical and contemporary correlations between crop genetic diversity and sociocultural factors. The geographic distribution of genetic traits reveals a complex pattern of ethnolinguistic segregation and hybridization, reflecting the profound connections between cultures and crops, yet the seed exchange systems of both communities remain receptive to external influences and genetic exchange. Our results underscore the significance of considering cultural dynamics in efforts to conserve genetic resources, as well as in plant breeding and seed system development initiatives.","This study explores the factors influencing the genetic diversity of sorghum, a vital crop for Kunama and Tigrayan farmers in Northern Ethiopia. Employing a multidisciplinary approach integrating agricultural science and cultural anthropology, we analyze the historical and current interplay between sorghum genetic variability and socio-cultural elements. The results indicate that while the spatial distribution of genetic variations mirrors distinct ethnolinguistic lineages and intermingling, reflecting deep-seated connections between cultural practices and crop evolution, the seed exchange networks of both communities remain receptive to gene flow and cross-pollination. Our research underscores the significance of incorporating cultural considerations in genetic resource preservation initiatives, plant breeding strategies, and seed system advancement endeavors.",acceptable,acceptable,acceptable,4.2,3.2,3.2
198,How business groups build globally relevant knowledge from local contexts? Exploring the double-edged sword effect of cultural diversity,"In this study, we theorize and empirically explore whether and how locally relevant learning contributes to the enhancement of globally relevant learning. We also examine the conditions under which specific types of such locally relevant learning contribute to globally relevant learning in group-affiliated firms in an emerging economy. Using firm-level survey data from India, we explicitly model and test the hypotheses based on our questions. Results suggest positive and significant contributions of home- and host-based locally relevant learning of group-affiliated firms in improving their global learning capabilities. Interestingly, evidence shows an inverse U-shaped moderating effect of dynamic cultural diversity, indicating that the effects of home- and host-based locally relevant learning on globally relevant learning are the highest when dynamic cultural diversity is moderate. The effects are lower when cultural diversity is low or high.","In this research, we hypothesize and experimentally investigate whether and how region-specific learning aids in the enhancement of globally applicable learning. We also analyze the circumstances under which distinct types of such region-specific learning support global learning in corporations affiliated with groups within a developing economy. Utilizing company-specific survey data from India, we precisely model and assess the hypotheses stemming from our queries. Findings reveal that home-based and host-based locally relevant learning significantly and positively contribute to enhancing the global learning capabilities of these group-affiliated firms. Notably, the data shows an inverse U-shaped moderating impact of dynamic cultural diversity, implying that the benefits of home-based and host-based locally relevant learning on global learning are most pronounced when dynamic cultural diversity is at a moderate level, whereas the benefits diminish when cultural diversity is either low or high.","This research investigates the interplay between locally grounded knowledge acquisition and its impact on fostering globally applicable learning outcomes, with a specific focus on the circumstances under which distinct forms of local learning within group-affiliated enterprises in emerging markets contribute to enhanced global learning capacities. Analyzing survey data from Indian firms, we develop and test hypotheses to address these questions. The findings reveal that both home-based and host-based local knowledge acquisition have a positive and significant impact on strengthening global learning capabilities in group-affiliated firms. Notably, the results also indicate that dynamic cultural diversity has a curvilinear moderating effect, with the greatest benefits of local learning on global learning occurring at moderate levels of cultural diversity, and diminishing returns at both low and high levels.","This research investigates the impact of locally acquired knowledge on the development of globally applicable knowledge, focusing on how this relationship manifests within group-affiliated companies operating in an emerging economy. Drawing upon survey data from Indian firms, we rigorously test the hypothesis that locally relevant learning, specifically knowledge gained from both the firm's home country and the host nation, positively influences global learning capacity. Our findings confirm this proposition, highlighting the significant role of locally-embedded learning in enhancing global knowledge acquisition. Notably, our analysis reveals a non-linear relationship with cultural diversity, suggesting that the benefits of locally relevant learning on global knowledge attainment are maximized within environments characterized by moderate cultural dynamism, while diminishing in settings with either very low or very high levels of cultural heterogeneity.",acceptable,acceptable,acceptable,3.2,3.2,3.2
199,Wearing the Same Jersey? The Impact of Players’ Cultural Diversity and Shared Team Tenure on National Soccer Team Performance,"In the present paper, we empirically analyze a dataset from national soccer teams between 2004 and 2019 to investigate the impact of team members’ cultural diversity on final team outcomes. Further, we examine the role of shared team tenure as a proxy of tacit knowledge and within team communications in relation to the cultural diversity–team performance relationship. After addressing a potential endogeneity issue, results from multiple instrumental variable estimation methods implied a higher level of cultural diversity enhanced on-field performance. Meanwhile, increased level of shared team tenure further strengthened the effect associated with cultural diversity on team performance.","In this study, we empirically examine data from national soccer teams spanning 2004 to 2019 to explore the influence of cultural diversity among team members on their ultimate performance outcomes. Additionally, we analyze the significance of shared team tenure as an indicator of implicit knowledge and internal communication within the team concerning the relationship between cultural diversity and team performance. Addressing potential endogeneity, results from various instrumental variable estimation techniques suggested that greater cultural diversity improved on-field outcomes. Furthermore, a higher level of shared team tenure amplified the positive impact of cultural diversity on team performance.","This study undertakes an empirical examination of a comprehensive dataset spanning 15 years, encompassing national soccer teams from 2004 to 2019, to elucidate the influence of cultural heterogeneity among team members on ultimate team achievements. Additionally, we probe the mediating role of collective team experience as a surrogate for implicit knowledge and intra-team collaboration in the context of the cultural diversity-team performance nexus. Following the mitigation of a potential endogeneity concern, our findings, derived from multiple instrumental variable estimation approaches, suggest that a more diverse cultural composition yields improved on-field outcomes, with an increased level of shared team experience serving to amplify this positive correlation.","This study leverages data from national soccer teams spanning 2004 to 2019 to explore the connection between a team's cultural mix and its overall success. The research also delves into the influence of shared team experience, viewed as a measure of implicit knowledge and internal communication, on the relationship between cultural diversity and team performance. Employing several instrumental variable estimation techniques to mitigate potential endogeneity concerns, the findings indicate that greater cultural diversity within a team bolsters its on-field performance. Furthermore, the analysis reveals that a longer shared team tenure amplifies the positive impact of cultural diversity on team performance.",acceptable,acceptable,acceptable,3.6,3.2,3.2
200,The Cost and Benefit of Regional Cultural Diversity on the Income of Rural Workers: Evidence from China,"This paper studies the impact of regional cultural diversity of working cities on the income of rural workers. Using a nationally representative micro-dataset in China, and adopting dialect diversity at the city level as the indicator of regional cultural diversity, we find that regional cultural diversity has a highly significant hump-shaped effect on rural workers' incomes from the wage employment and self-employment, reflecting a trade-off between the beneficial and the detrimental effects of regional cultural diversity on rural workers' incomes. The results remain robust to the inclusion of a set of covariates, alternative estimation technique, alternative measure of regional cultural diversity, and a placebo test. We also find that the detrimental effect of diversity is weaker for high-educated rural workers, and the impact of regional cultural diversity remains stable in the short term. To address potential endogeneity, we employ an instrumental variable approach by using the river length of cities to instrument the dialect diversity, and the instrumented results confirm the conclusions. In addition, we provide empirical evidence that the cost and benefit of regional cultural diversity on the income of rural workers can be attributed to reduced social capital and increased creativity.","This study examines how the cultural diversity of urban areas affects the earnings of rural laborers. Drawing on a comprehensive micro-dataset from China and using city-level dialect diversity as a measure of regional cultural diversity, we discover that this diversity has a statistically significant hump-shaped influence on the incomes of rural workers involved in both wage employment and self-employment. This indicates a balance between the positive and negative impacts of cultural diversity on their earnings. The findings are robust even when accounting for various covariates, alternative estimation methods, different measures of cultural diversity, and a placebo test. Additionally, we observe that the adverse effect of diversity is less pronounced for rural workers with higher education, and the impact of cultural diversity remains consistent in the short term. To mitigate potential endogeneity, we apply an instrumental variable approach using city river length as an instrument for dialect diversity, with instrumented results corroborating our conclusions. Our empirical evidence also suggests that the costs and benefits of regional cultural diversity on rural workers' incomes can be linked to decreased social capital and enhanced creativity.","This research examines how the cultural heterogeneity of urban centers in a region affects the earnings of rural laborers, utilizing a comprehensive micro-dataset from China and measuring cultural diversity through dialectal variation at the city level. The findings reveal a significant, nonlinear relationship between regional cultural diversity and rural workers' income from both wage and self-employment, suggesting a balance between the positive and negative consequences of cultural diversity on rural incomes. The results withstand the inclusion of control variables, alternative estimation methods, and alternative cultural diversity metrics, as well as a placebo test. Furthermore, the analysis shows that the adverse effects of diversity are mitigated for highly educated rural workers, and the impact of cultural diversity remains consistent in the short term. To address potential biases, an instrumental variable approach is employed, using city river lengths to proxy dialect diversity, and the results confirm the conclusions. The study also provides empirical evidence that the costs and benefits of regional cultural diversity on rural workers' income can be attributed to decreased social cohesion and enhanced innovation.","This study investigates how the cultural variety within cities where rural workers seek employment affects their earnings. Utilizing a comprehensive Chinese micro-dataset and employing dialect diversity as a proxy for cultural richness, the research reveals a notable non-linear relationship between cultural diversity and rural worker income, regardless of employment type. This suggests a balance between the advantages and disadvantages of such diversity. Rigorous testing with various statistical methods, alternative diversity measures, and placebo tests validate these findings. Further analysis indicates that well-educated rural workers are less susceptible to the negative impacts of diversity, and the observed effects persist over time. To mitigate potential biases, the study uses an instrumental variable approach, leveraging river length as a proxy for dialect diversity, with consistent results. Finally, empirical evidence is presented that links the economic implications of regional cultural diversity to its influence on social capital and creative output.",acceptable,acceptable,acceptable,3.6,3.2,3.2
201,Cultural diversity in unequal societies sustained through cross-cultural competence and identity valuation,"In much contemporary political discourse, valued cultural characteristics are threatened by interaction with culturally distinct others, such as immigrants or a hegemonic majority. Such interaction often fosters cross-cultural competence (CCC), the ability to interact successfully across cultural boundaries. However, most theories of cultural dynamics ignore CCC, making cultural diversity incompatible with mutually beneficial inter-group interaction, and contributing to fears of cultural loss. Here, interview-based field methods at an Amazonian ethnic boundary demonstrate the prevalence of CCC. These data motivate a new theoretical mathematical model, incorporating competing developmental paths to CCC and group identity valuation, that illuminates how a common strategy of disempowered minorities can counter-intuitively sustain cultural diversity within a single generation: Given strong group identity, minorities in a structurally unequal, integrative society can maintain their distinctive cultural norms by learning those of the majority. Furthermore, rather than a rejection of, or threat to, majority culture, the valuation of a distinctive minority identity can characterize CCC individuals committed to extensive, mutually beneficial engagement with the majority as members of an integrative, multi-cultural society.","In current political discussions, valuable cultural traits are perceived to be endangered by interactions with culturally different groups, such as immigrants or a dominant majority. These interactions often promote the development of cross-cultural competence (CCC), which is the skill to effectively communicate across cultural divides. However, many cultural dynamics theories overlook CCC, making cultural diversity seem at odds with mutually advantageous inter-group interaction and fueling fears of cultural erosion. Fieldwork utilizing interviews at an Amazonian ethnic boundary highlights the widespread presence of CCC. This evidence inspires a novel mathematical model that considers various developmental paths to achieving CCC and valuing group identity. This model shows that a strategy commonly adopted by disadvantaged minorities can unexpectedly help preserve cultural diversity within a single generation: Strong group identity enables minorities in an unequal, integrated society to uphold their unique cultural practices by learning those of the majority. Additionally, valuing a unique minority identity is not necessarily a rejection or threat to the majority culture; rather, CCC individuals dedicated to beneficial, extensive engagement with the majority can contribute to a cohesive, multi-cultural society.","In today's political landscape, cherished cultural traits are perceived to be under siege when encountering individuals from diverse cultural backgrounds, such as migrant populations or dominant social groups. Paradoxically, these interactions can cultivate cross-cultural proficiency, enabling effective communication across cultural divides. Despite this, prevailing theories of cultural evolution overlook this phenomenon, implying that cultural diversity is incompatible with harmonious inter-group relations and fueling anxieties about cultural erosion. A study employing in-depth interviews at an Amazonian cultural frontier reveals the widespread existence of cross-cultural proficiency. These findings inform a novel mathematical model that incorporates competing pathways to cross-cultural proficiency and group identity valuation, shedding light on how a common strategy employed by marginalized groups can, counterintuitively, preserve cultural diversity within a single generation: When group identity is strong, minorities in an unequal, yet inclusive, society can maintain their unique cultural norms by adopting those of the dominant group. Moreover, rather than rejecting or threatening the dominant culture, the appreciation of a distinct minority identity can define individuals who embody cross-cultural proficiency, committed to extensive, mutually beneficial engagement with the dominant group as members of a cohesive, multicultural society.","Modern political rhetoric frequently frames interactions with culturally distinct groups, like immigrants or dominant majorities, as threats to cherished cultural values. Such exchanges often cultivate intercultural competence (ICC), the capacity for successful cross-cultural engagement. Yet, prevalent theories on cultural dynamics often overlook ICC, presenting cultural diversity and positive intergroup relations as incompatible, thereby fueling anxieties around cultural erosion. Ethnographic research conducted at an Amazonian ethnic boundary reveals the widespread presence of ICC. Inspired by these findings, a novel theoretical model, incorporating competing pathways for ICC and group identity development, illuminates a seemingly paradoxical strategy employed by marginalized groups to preserve cultural diversity within a single generation: In structurally unequal, yet integrative societies, strong group identity allows minorities to retain unique cultural practices by acquiring the majority's cultural norms. Moreover, rather than signifying a rejection or threat to the dominant culture, valuing a distinct minority identity can be a hallmark of individuals possessing ICC who actively engage with the majority in a mutually beneficial manner, contributing to an integrated, multicultural society.",acceptable,acceptable,acceptable,3.2,3.2,3.2
